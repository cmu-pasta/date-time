{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "\n",
    "#pip install seaborn\n",
    "# %pip install seaborn\n",
    "\n",
    "# Read the data from the TSV file\n",
    "df = pd.read_csv('Bug_Analysis.tsv', sep='\\t')\n",
    "\n",
    "# Drop rows were the Skipped? column is true\n",
    "# df = df[df['Skipped?'] != True]\n",
    "# Drop rows where false positives is true\n",
    "df = df[df['False pos?'] != True]\n",
    "# Only keep rows where either Training? or Testing? is true\n",
    "df = df[(df['Training?'] == True) | (df['Testing?'] == True)]\n",
    "\n",
    "# Drop columns\n",
    "df = df.drop(columns=['Link', 'Fix Link', 'Make Benchmark?', 'Associated Benchmark', 'Rater', 'Training?', 'Testing?', 'Skipped?', 'False pos?'])\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Index(['Owner', 'Project', 'Title', 'Stars', 'TF-IDFs', 'Size', 'Datetime',\n",
    "       'Arrow', 'Pendulum', 'Description', 'Category 1', 'Category 2',\n",
    "       'Affected Computation 1', 'Affected Computation 2',\n",
    "       'Affected Computation 3', 'Obscurity', 'Impact/Severity', '# LOC',\n",
    "       'Logic Needed', 'Comments', 'BPST1', 'BPST2', 'BPST3'],\n",
    "      dtype='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the most common cause of bugs?\n",
    "##### Representation of Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    \"Date\",\n",
    "\"DST\",\n",
    "\"Duration\",\n",
    "\"String Representation\",\n",
    "\"Timestamps\",\n",
    "\"Timezone\",\n",
    "\"Deprecated\"\n",
    "#    \"Other\" #added\n",
    "]\n",
    "\"\"\"\n",
    "categories = [\n",
    "    \"Date\",\n",
    "\"DST\",\n",
    "\"Duration\",\n",
    "\"String Representation\",\n",
    "\"Timestamps\",\n",
    "\"Timezone\",\n",
    "\"Deprecated\",\n",
    "\"Other\",\n",
    "\"Fold\",\n",
    "\"Leap year\",\n",
    "\"NTP/Leap Seconds\"\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "affected_comp = [\n",
    "    \"Timestamp/Hash Construction\",\n",
    "\"Datetime Objects\",\n",
    "\"Delta Objects\",\n",
    "\"Components\",\n",
    "\"String Parsing/Formatting\",\n",
    "\"Timezone Conversions/Equality\",\n",
    "\"Library Conversions\",\n",
    "#    \"Other\" #added\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "affected_comp = [\"Timestamp/Hash Construction\",\n",
    "\"Datetime Arithmetic\",\n",
    "\"Datetime Comparison\",\n",
    "\"Datetime Construction\",\n",
    "\"Datetime Equality\",\n",
    "\"Delta Arithmetic\",\n",
    "\"Delta Comparison\",\n",
    "\"Delta Construction\",\n",
    "\"Delta Conversion\",\n",
    "\"Delta Equality\",\n",
    "\"Querying Datetime Components\",\n",
    "\"Replacing/Rounding Datetime Components\",\n",
    "\"String Parsing/Formatting (humanized)\",\n",
    "\"String Parsing/Formatting (data)\",\n",
    "\"Timezone Conversions\",\n",
    "\"Timezone Equality\",\n",
    "\"Library Conversions\"]\n",
    "\"\"\"\n",
    "#bpst = ac\n",
    "#bpsts = affected_comp\n",
    "#bpstmap = acmap\n",
    "#rowbpst = rowac\n",
    "\n",
    "acmap = {\"Category\": categories, \"total\": [0]*len(categories)}\n",
    "for ac in affected_comp:\n",
    "    acmap[ac] = [0]*len(categories)\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    cats = [row['Category 1'], row['Category 2']]\n",
    "    indecies = []\n",
    "    for c in cats:\n",
    "      if type(c) is str:\n",
    "        if c not in categories:\n",
    "          c = \"Other\"\n",
    "        indecies.append(categories.index(c))\n",
    "    rowac = [row['Affected Computation 1'], row['Affected Computation 2'], row['Affected Computation 3']]\n",
    "    for ac in rowac:\n",
    "        if type(ac) is str:\n",
    "            if ac==\"Datetime Arithmetic\" or ac==\"Datetime Comparison\" or ac==\"Datetime Construction\" or ac==\"Datetime Equality\":\n",
    "              ac = \"Datetime Objects\"\n",
    "            elif ac==\"Delta Arithmetic\" or ac==\"Delta Comparison\" or ac==\"Delta Construction\" or ac==\"Delta Equality\":\n",
    "              ac = \"Delta Objects\"\n",
    "            elif ac==\"Querying Datetime Components\" or ac==\"Replacing/Rounding Datetime Components\":\n",
    "              ac = \"Components\"\n",
    "            elif ac==\"String Parsing/Formatting (humanized)\" or ac==\"String Parsing/Formatting (data)\":\n",
    "              ac = \"String Parsing/Formatting\"\n",
    "            elif ac==\"Timezone Conversions\" or ac==\"Timezone Equality\":\n",
    "              ac = \"Timezone Conversions/Equality\"\n",
    "            #else:\n",
    "            #  ac = \"Other\"\n",
    "            #mapping stuff\n",
    "            \"\"\"\n",
    "            \"Timestamp/Hash Construction\"\n",
    "            \"Datetime\" = Datetime Arithmetic, Datetime Comparison, Datetime Construction, Datetime Equality\n",
    "            \"Delta\" = Delta Arithmetic, Delta Comparison, Delta Construction, Delta Equality\n",
    "            \"Components\" = Querying Datetime Components, Replacing/Rounding Datetime Components\n",
    "            \"String Parsing/Formatting\" = String Parsing/Formatting (humanized), String Parsing/Formatting (data)\n",
    "            \"Timezone Conversions/Equality\" = Timezone Conversions, Timezone Equality\n",
    "            \"Library Conversions\" = Library Conversions\n",
    "            \"Other\"\n",
    "            \"\"\"\n",
    "            for i in indecies:\n",
    "                acmap[ac][i] += 1\n",
    "                acmap[\"total\"][i] += 1\n",
    "\n",
    "sns.set(style='white')\n",
    "\n",
    "# colors = ['Pastel1', 'Pastel2', 'Paired', 'Accent', 'Dark2','Set1', 'Set2', 'Set3', 'tab10', 'tab20', 'tab20b','tab20c']\n",
    "# colors = \"Set2\"\n",
    "# colors = \"Dark2\"\n",
    "#colors = \"tab20b\"\n",
    "#colors = [\"#003f5c\", \"#58508d\", \"#8a508f\", \"#a9ff95\", \"#88f5ff\", \"#98bfff\", \"#a294ff\", \"#ffadff\"]\n",
    "#colors = [\"#003f5c\",  \"#58508d\",  \"#8a508f\",  \"#bc5090\",  \"#de5a79\",  \"#ff6361\",  \"#ff8531\", \"#ffa600\"]\n",
    "\n",
    "# colors = [\"#ffb610\", \"#a05195\", \"#ff7c43\", \"#9681c1\", \"#f95d6a\", \"#2f4b7c\", \"#d45087\"] #funk retro, adjusted for 7\n",
    "# colors = [\"#F94144\", \"#F3722C\", \"#F8961E\", \"#F9C74F\", \"#90BE6D\", \"#43AA8B\", \"#277DA1\"] #arcade vibes, adjusted for 7\n",
    "colors = [\"#642915\", \"#c7522a\", \"#d68a58\", \"#e5c185\", \"#74a892\", \"#094d4d\", \"#80c2c2\", \"#b1e0e0\"]\n",
    "\n",
    "print(\"Color map:\", colors)\n",
    "\n",
    "\n",
    "temp_df = pd.DataFrame(acmap).set_index('Category')\n",
    "temp_df = temp_df.sort_values(\"total\").sort_values(\"Timezone\", axis=1).drop(columns=\"total\")\n",
    "custom_cmap = mcolors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "ax = temp_df.plot( kind='barh', legend='reverse', colormap=custom_cmap, stacked=True, figsize=(12, 8))\n",
    "#ax.set_xticklabels(ax.get_xticklabels(), rotation=20, ha='right')\n",
    "ax.set_xlabel(\"# of Affected Computations\")\n",
    "\n",
    "plt.savefig('fig1.png', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the characteristics of each category?\n",
    "##### Measure of obscurity and impact/severity for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame and already loaded with data\n",
    "\n",
    "# Initialize an empty dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Combine unique categories from both columns\n",
    "categories = pd.concat([df['Affected Computation 1'], df['Affected Computation 2'], df['Affected Computation 3']], axis=0).unique()\n",
    "\n",
    "# Loop through each unique category\n",
    "for category in categories:\n",
    "    # Filter the DataFrame for the current category\n",
    "    df_category = df[(df['Affected Computation 1'] == category) | (df['Affected Computation 2'] == category) | (df['Affected Computation 3'] == category)]\n",
    "\n",
    "    # Count the occurrences of each obscurity level\n",
    "    counts_o = df_category['Obscurity'].value_counts().to_dict()\n",
    "    counts_s = df_category['Impact/Severity'].value_counts().to_dict()\n",
    "\n",
    "    # Ensure all levels are included in the result\n",
    "    results[category] = {\n",
    "        'Low Obscurity': counts_o.get('Low', 0),\n",
    "        'Medium Obscurity': counts_o.get('Medium', 0),\n",
    "        'High Obscurity': counts_o.get('High', 0),\n",
    "        'Low Impact/Severity': counts_s.get('Low', 0),\n",
    "        'Medium Impact/Severity': counts_s.get('Medium', 0),\n",
    "        'High Impact/Severity': counts_s.get('High', 0)\n",
    "    }\n",
    "\n",
    "print(results)\n",
    "\n",
    "# Convert the results dictionary to a DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results).T\n",
    "# Convert the results dictionary to a DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results).T\n",
    "\n",
    "# Calculate the size of each category\n",
    "results_df['Total'] = results_df.sum(axis=1)\n",
    "\n",
    "# Select the top 5 categories by size\n",
    "top_categories = results_df.nlargest(9, 'Total')\n",
    "\n",
    "# Select the remaining categories for \"Other\"\n",
    "other_categories = results_df.drop(top_categories.index)\n",
    "\n",
    "# Sum the counts for the \"Other\" category\n",
    "other_sums = other_categories.sum()\n",
    "other_sums.name = 'Other'\n",
    "\n",
    "# Append the \"Other\" category to the top categories\n",
    "top_categories = pd.concat([top_categories, other_sums.to_frame().T])\n",
    "\n",
    "\n",
    "# Create a grouped bar chart for the top 5 categories + \"Other\"\n",
    "categories = top_categories.index\n",
    "percentages = [f\"{float(int(342 * i / 5))/10}%\" for i in range(100)]\n",
    "obscurity_counts = top_categories[['Low Obscurity', 'Medium Obscurity', 'High Obscurity']]\n",
    "severity_counts = top_categories[['Low Impact/Severity', 'Medium Impact/Severity', 'High Impact/Severity']]\n",
    "\n",
    "x = pd.Index(range(len(categories)))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "# colors = ['#FBFBF2', '#E5E6E4', '#CFD2CD', '#A6A2A2', '#847577', '#615758']\n",
    "#colors = ['#10A0EC', '#7CC6FE', '#ACD5FF', '#E7BBE3', '#C884A6', '#B25282']\n",
    "colors = [\"#642915\", \"#c7522a\", \"#c69a68\", \"#094d4d\", \"#80c2c2\", \"#b1e0e0\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "rects1 = ax.bar(x - width/2, obscurity_counts['Low Obscurity'], width, label='Low Obscurity', color=colors[0])\n",
    "rects2 = ax.bar(x - width/2, obscurity_counts['Medium Obscurity'], width, bottom=obscurity_counts['Low Obscurity'], label='Medium Obscurity', color=colors[1])\n",
    "rects3 = ax.bar(x - width/2, obscurity_counts['High Obscurity'], width, bottom=obscurity_counts['Low Obscurity'] + obscurity_counts['Medium Obscurity'], label='High Obscurity', color=colors[2])\n",
    "\n",
    "rects4 = ax.bar(x + width/2, severity_counts['Low Impact/Severity'], width, label='Low Impact/Severity', color=colors[3])\n",
    "rects5 = ax.bar(x + width/2, severity_counts['Medium Impact/Severity'], width, bottom=severity_counts['Low Impact/Severity'], label='Medium Impact/Severity', color=colors[4])\n",
    "rects6 = ax.bar(x + width/2, severity_counts['High Impact/Severity'], width, bottom=severity_counts['Low Impact/Severity'] + severity_counts['Medium Impact/Severity'], label='High Impact/Severity', color=colors[5])\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_xlabel('Category')\n",
    "ax.set_ylabel('')\n",
    "#ax.set_title('Categories vs Impact/Severity and Obscurity')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories, rotation=20, ha='right')\n",
    "ax.set_yticklabels(percentages, ha='right')\n",
    "ax.legend(title='Level', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('fig3.png', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the BPSTs associated with each category?\n",
    "##### Proportion of BPSTs for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = \"\"\"Date\n",
    "DST\n",
    "Duration\n",
    "String Representation\n",
    "Timestamps\n",
    "Timezone\n",
    "Deprecated\"\"\".split(\"\\n\")\n",
    "\n",
    "bpsts_short = \"\"\"Outdated/Deprecated APIs\n",
    "Using Naïve Datetime Incorrectly\n",
    "Dropping Timezones\n",
    "Adding Support for New Features\n",
    "Unintuitive Arithmetic\n",
    "Adding Support for New Features\n",
    "Adding Support for New Libraries\n",
    "Crossing DST Boundaries\n",
    "Other\"\"\".split(\"\\n\")\n",
    "# only categories listed >=8 times\n",
    "\n",
    "bpsts = \"\"\"Incorrect API usage\n",
    "Outdated/Deprecated APIs\n",
    "Calling datetime.now() Multiple Times\n",
    "Using Naïve Datetime Incorrectly\n",
    "Dropping Timezones\n",
    "Typo\n",
    "Subtracting Dates\n",
    "Adding Support for New Libraries\n",
    "Adding Support for New Features\n",
    "Precision of Representation\n",
    "Library Bug\n",
    "OOB Timestamps\n",
    "OOB Datetimes\n",
    "Creating time in unspecified fold\n",
    "Crossing DST boundaries\n",
    "Comparing Timezones\n",
    "Unintuitive Arithmetic\n",
    "TODO\n",
    "Other\"\"\".split(\"\\n\")\n",
    "\n",
    "# Figure 2a - Chart bug patterns across each category\n",
    "\n",
    "bpstmap = {\"Category\": categories, \"total\": [0]*len(categories)}\n",
    "for bpst in bpsts_short:\n",
    "    bpstmap[bpst] = [0]*len(categories)\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    cats = [row['Category 1'], row['Category 2']]\n",
    "    indecies = []\n",
    "    for c in cats:\n",
    "        if type(c) is str:\n",
    "            indecies.append(categories.index(c))\n",
    "    rowbpsts = [row['BPST1'], row['BPST2'], row['BPST3']]\n",
    "    for bpst in rowbpsts:\n",
    "        if type(bpst) is str:\n",
    "            if bpst not in bpsts_short:\n",
    "                bpst = \"Other\"\n",
    "            for i in indecies:\n",
    "                bpstmap[bpst][i] += 1\n",
    "                bpstmap[\"total\"][i] += 1\n",
    "\n",
    "sns.set(style='white')\n",
    "\n",
    "# colors = ['Pastel1', 'Pastel2', 'Paired', 'Accent', 'Dark2','Set1', 'Set2', 'Set3', 'tab10', 'tab20', 'tab20b','tab20c']\n",
    "# colors = \"Set2\"\n",
    "# colors = \"Dark2\"\n",
    "#colors = \"tab20b\"\n",
    "colors = [\"#642915\", \"#c7522a\", \"#d68a58\", \"#e5c185\", \"#74a892\", \"#094d4d\", \"#80c2c2\", \"#b1e0e0\"]\n",
    "print(\"Color map:\", colors)\n",
    "\n",
    "temp_df = pd.DataFrame(bpstmap).set_index('Category')\n",
    "temp_df = temp_df.sort_values(\"total\").sort_values(\"Timezone\", ascending=False, axis=1).drop(columns=\"total\")\n",
    "custom_cmap = mcolors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "ax = temp_df.plot(kind='bar', legend='reverse', colormap=custom_cmap, stacked=True)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=20,ha='right')\n",
    "\n",
    "plt.savefig('fig2.png', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the average impact/severity for each BPST?\n",
    "##### Number of issues with each BPST, and the proportions of them that have low medium or high impact/severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2b - Chart severity across bpst for string rep\n",
    "\n",
    "df_sr = df[(df['Category 1'] == 'String Representation') | (df['Category 2'] == 'String Representation')]\n",
    "\n",
    "\n",
    "ratings = [\"Low\", \"Medium\", \"High\"]\n",
    "temp_data = {\"Bug Pattern\": bpsts, \"total\": [0]*len(bpsts)}\n",
    "for r in ratings:\n",
    "    temp_data[r] = [0]*len(bpsts)\n",
    "\n",
    "for index, row in df_sr.iterrows():\n",
    "    rowbpsts = [row['BPST1'], row['BPST2'], row['BPST3']]\n",
    "    for bpst in rowbpsts:\n",
    "        if type(bpst) is str:\n",
    "            bpst = bpst if bpst in bpsts else \"Other\"\n",
    "            val = row[\"Impact/Severity\"]\n",
    "            temp_data[val][bpsts.index(bpst)] += 1\n",
    "            temp_data[\"total\"][bpsts.index(bpst)] += 1\n",
    "\n",
    "\n",
    "temp_df = pd.DataFrame(temp_data).set_index('Bug Pattern')\n",
    "temp_df = temp_df.loc[temp_df['total'] !=0]\n",
    "temp_df = temp_df.sort_values(\"total\").drop(columns=\"total\")\n",
    "temp_df = temp_df.drop(\"TODO\")\n",
    "\n",
    "#colors = ['#0a00b3', '#346bcc', '#00a9ec']\n",
    "# colors = [\"#642915\", \"#c7522a\", \"#d68a58\", \"#e5c185\", \"#74a892\", \"#094d4d\", \"#80c2c2\", \"#b1e0e0\"]\n",
    "# custom_cmap = mcolors.LinearSegmentedColormap.from_list(\"\", colors[1:4])\n",
    "colors = [\"#3C7C7C\", \"#80c2c2\", \"#B6DCDC\"]\n",
    "custom_cmap = mcolors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "\n",
    "ax = temp_df.plot(kind='bar', legend='reverse', colormap=custom_cmap, stacked=True)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=20,ha='right')\n",
    "ax.set_ylabel(\"Issues\")\n",
    "\n",
    "# rects = ax.patches\n",
    "# print(rects)\n",
    "\n",
    "# Make some labels.\n",
    "# labels = [f\"label{i}\" for i in range(len(rects))]\n",
    "\n",
    "# for rect, label in zip(rects, labels):\n",
    "#     height = rect.get_height()\n",
    "#     ax.text(\n",
    "#         rect.get_x() + rect.get_width() / 2, height + 5, label, ha=\"center\", va=\"bottom\"\n",
    "#     )\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('fig2-1.png', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the distribution of logic and impact/severity levels for datetime construction (affected computation) issues?\n",
    "\n",
    "##### Logic levels and impact/severity levels for datetime construction issues in affected computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datetime Construction\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df_TZ = df[(df['Category 1'] == \"Timezone\") | (df['Category 2'] == \"Timezone\")]\n",
    "\n",
    "# print(df_TZ['Affected Computation 1'])\n",
    "\n",
    "df_TZ_cn = df_TZ[(df_TZ['Affected Computation 1'] == \"Datetime Construction\") | (df_TZ['Affected Computation 2'] == \"Datetime Construction\") | (df_TZ['Affected Computation 3'] == \"Datetime Construction\")]\n",
    "# df_TZ_cn\n",
    "\n",
    "logic_data = {}\n",
    "impact_data = {}\n",
    "\n",
    "logic_data['Low'] = df_TZ_cn['Logic Needed'].value_counts().get('Low', 0)\n",
    "logic_data['Medium'] = df_TZ_cn['Logic Needed'].value_counts().get('Medium', 0)\n",
    "logic_data['High'] = df_TZ_cn['Logic Needed'].value_counts().get('High', 0)\n",
    "\n",
    "\n",
    "impact_data['Low'] = df_TZ_cn['Impact/Severity'].value_counts().get('Low', 0)\n",
    "impact_data['Medium'] = df_TZ_cn['Impact/Severity'].value_counts().get('Medium', 0)\n",
    "impact_data['High'] = df_TZ_cn['Impact/Severity'].value_counts().get('High', 0)\n",
    "\n",
    "#colors = ['#10A0EC', '#7CC6FE', '#ACD5FF', '#E7BBE3', '#C884A6', '#B25282']\n",
    "colors = [\"#E7A590\", \"#D66640\", \"#B84B27\", \"#3C7C7C\", \"#80c2c2\", \"#B6DCDC\"]\n",
    "\n",
    "# Create pie chart for logic levels\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pie(logic_data.values(), labels=logic_data.keys(), autopct='%1.1f%%', startangle=140, colors=colors[0:3])\n",
    "plt.title('Logic Levels')\n",
    "\n",
    "# Create pie chart for impact/severity levels\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(impact_data.values(), labels=impact_data.keys(), autopct='%1.1f%%', startangle=140, colors=colors[3:6])\n",
    "plt.title('Impact/Severity Levels')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig1-1_datetime.png', transparent=True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the distribution of logic and impact/severity levels for issues in deprecated affected computations?\n",
    "\n",
    "##### Logic levels and impact/severity levels for deprecated issues in affected computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deprecated\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df_D = df[(df['Category 1'] == \"Deprecated\") | (df['Category 2'] == \"Deprecated\")]\n",
    "\n",
    "logic_data = {}\n",
    "impact_data = {}\n",
    "\n",
    "logic_data['Low'] = df_D['Logic Needed'].value_counts().get('Low', 0)\n",
    "logic_data['Medium'] = df_D['Logic Needed'].value_counts().get('Medium', 0)\n",
    "logic_data['High'] = df_D['Logic Needed'].value_counts().get('High', 0)\n",
    "\n",
    "\n",
    "impact_data['Low'] = df_D['Impact/Severity'].value_counts().get('Low', 0)\n",
    "impact_data['Medium'] = df_D['Impact/Severity'].value_counts().get('Medium', 0)\n",
    "# impact_data['High'] = df_D['Impact/Severity'].value_counts().get('High', 0)\n",
    "\n",
    "#colors = ['#10A0EC', '#7CC6FE', '#ACD5FF', '#E7BBE3', '#C884A6', '#B25282']\n",
    "colors = [\"#E7A590\", \"#D66640\", \"#B84B27\", \"#3C7C7C\", \"#80c2c2\", \"#B6DCDC\"]\n",
    "\n",
    "# Create pie chart for logic levels\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pie(logic_data.values(), labels=logic_data.keys(), autopct='%1.1f%%', startangle=140, colors=colors[0:3])\n",
    "plt.title('Logic Levels')\n",
    "\n",
    "# Create pie chart for impact/severity levels\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(impact_data.values(), labels=impact_data.keys(), autopct='%1.1f%%', startangle=140, colors=colors[3:6])\n",
    "plt.title('Impact/Severity Levels')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig1-2_deprecated.png', transparent=True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the distribution of logic and impact/severity levels for issues in the category String Representation?\n",
    "\n",
    "##### Logic levels and impact/severity levels for String Representation category issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#String Representation\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df_SR = df[(df['Category 1'] == \"String Representation\") | (df['Category 2'] == \"String Representation\")]\n",
    "\n",
    "logic_data = {}\n",
    "impact_data = {}\n",
    "\n",
    "logic_data['Low'] = df_SR['Logic Needed'].value_counts().get('Low', 0)\n",
    "logic_data['Medium'] = df_SR['Logic Needed'].value_counts().get('Medium', 0)\n",
    "logic_data['High'] = df_SR['Logic Needed'].value_counts().get('High', 0)\n",
    "\n",
    "\n",
    "impact_data['Low'] = df_SR['Impact/Severity'].value_counts().get('Low', 0)\n",
    "impact_data['Medium'] = df_SR['Impact/Severity'].value_counts().get('Medium', 0)\n",
    "impact_data['High'] = df_SR['Impact/Severity'].value_counts().get('High', 0)\n",
    "\n",
    "#colors = ['#10A0EC', '#7CC6FE', '#ACD5FF', '#E7BBE3', '#C884A6', '#B25282']\n",
    "colors = [\"#E7A590\", \"#D66640\", \"#B84B27\", \"#3C7C7C\", \"#80c2c2\", \"#B6DCDC\"]\n",
    "\n",
    "# Create pie chart for logic levels\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pie(logic_data.values(), labels=logic_data.keys(), autopct='%1.1f%%', startangle=140, colors=colors[0:3])\n",
    "plt.title('Logic Levels')\n",
    "\n",
    "# Create pie chart for impact/severity levels\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(impact_data.values(), labels=impact_data.keys(), autopct='%1.1f%%', startangle=140, colors=colors[3:6])\n",
    "plt.title('Impact/Severity Levels')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig1-3_stringrep.png', transparent=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is each characteristic correlated?\n",
    "##### Correlation graph for impact, obscurity, LOC, and logic needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert low, medium, high to 1, 2, 3 for 'Obscurity', 'Impact/Severity', '# LOC', and 'Logic Needed'\n",
    "df_temp = df.copy()\n",
    "df_temp['Impact/Severity'] = df['Impact/Severity'].map({'Low': 1, 'Medium': 2, 'High': 3})\n",
    "df_temp['Obscurity'] = df['Obscurity'].map({'Low': 1, 'Medium': 2, 'High': 3})\n",
    "df_temp['# LOC'] = df['# LOC'].map({'Low': 1, 'Medium': 2, 'High': 3, 'Very High': 4})\n",
    "df_temp['Logic Needed'] = df['Logic Needed'].map({'Low': 1, 'Medium': 2, 'High': 3})\n",
    "df_temp.describe()\n",
    "df_temp = df_temp[['Obscurity', 'Impact/Severity', '# LOC', 'Logic Needed']]\n",
    "df_temp = df_temp.fillna(0)  # You can choose another method to fill missing values\n",
    "df_temp = df_temp.reset_index(drop=True)\n",
    "print(df_temp)\n",
    "print(df_temp.corr())\n",
    "colors = [\"#642915\", \"#c7522a\", \"#d68a58\", \"#e5c185\", \"#74a892\", \"#094d4d\", \"#80c2c2\", \"#b1e0e0\"]\n",
    "custom_cmap = mcolors.LinearSegmentedColormap.from_list(\"\", colors[3::-1])\n",
    "sns.heatmap(df_temp.corr(), annot=True, annot_kws={\"size\": 12}, cmap=custom_cmap, fmt=\".2f\")\n",
    "\n",
    "\n",
    "plt.savefig('fig4.png', transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
