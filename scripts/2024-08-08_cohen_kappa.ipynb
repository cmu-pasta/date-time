{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "* Download the most recent version of the Bug Analysis Google Sheet\n",
    "* Delete Row 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "961\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rater</th>\n",
       "      <th>Training?</th>\n",
       "      <th>Testing?</th>\n",
       "      <th>Set 3?</th>\n",
       "      <th>False pos?</th>\n",
       "      <th>Owner</th>\n",
       "      <th>Project</th>\n",
       "      <th>Title</th>\n",
       "      <th>Stars</th>\n",
       "      <th>TF-IDFs</th>\n",
       "      <th>...</th>\n",
       "      <th>Affected Computation 2</th>\n",
       "      <th>Affected Computation 3</th>\n",
       "      <th>Obscurity</th>\n",
       "      <th>Impact/Severity</th>\n",
       "      <th># LOC</th>\n",
       "      <th>Logic Needed</th>\n",
       "      <th>BPST1</th>\n",
       "      <th>BPST2</th>\n",
       "      <th>BPST3</th>\n",
       "      <th>Make Benchmark?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>python-poetry</td>\n",
       "      <td>tomlkit</td>\n",
       "      <td>datetime.utcnow and datetime.utcfromtimestamp ...</td>\n",
       "      <td>643.0</td>\n",
       "      <td>1.312623</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>Outdated/Deprecated APIs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5: Peter Sasha</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>frictionlessdata</td>\n",
       "      <td>frictionless-py</td>\n",
       "      <td>SpssParser ignores timezones</td>\n",
       "      <td>683.0</td>\n",
       "      <td>1.270077</td>\n",
       "      <td>...</td>\n",
       "      <td>Replacing/Rounding Datetime Components</td>\n",
       "      <td>Library Conversions</td>\n",
       "      <td>Low</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Using Naïve Datetime Incorrectly</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>sdispater</td>\n",
       "      <td>pendulum</td>\n",
       "      <td>Deepcopy of Month-based Duration produces a di...</td>\n",
       "      <td>6109.0</td>\n",
       "      <td>1.191295</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2: Shrey Serena</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>googleapis</td>\n",
       "      <td>python-storage</td>\n",
       "      <td>`DeprecationWarning` warning in build log for ...</td>\n",
       "      <td>420.0</td>\n",
       "      <td>1.176351</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>Outdated/Deprecated APIs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>googleapis</td>\n",
       "      <td>python-logging</td>\n",
       "      <td>`DeprecationWarning` warning in build log for ...</td>\n",
       "      <td>119.0</td>\n",
       "      <td>1.167279</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>961 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Rater  Training?  Testing?  Set 3?  False pos?  \\\n",
       "0                NaN       True     False   False       False   \n",
       "1     5: Peter Sasha      False      True   False       False   \n",
       "2                NaN       True     False   False       False   \n",
       "3    2: Shrey Serena      False      True   False       False   \n",
       "4                NaN       True     False   False       False   \n",
       "..               ...        ...       ...     ...         ...   \n",
       "956              NaN      False     False   False       False   \n",
       "957              NaN      False     False   False       False   \n",
       "958              NaN      False     False   False       False   \n",
       "959              NaN      False     False   False       False   \n",
       "960              NaN      False     False   False       False   \n",
       "\n",
       "                Owner          Project  \\\n",
       "0       python-poetry          tomlkit   \n",
       "1    frictionlessdata  frictionless-py   \n",
       "2           sdispater         pendulum   \n",
       "3          googleapis   python-storage   \n",
       "4          googleapis   python-logging   \n",
       "..                ...              ...   \n",
       "956               NaN              NaN   \n",
       "957               NaN              NaN   \n",
       "958               NaN              NaN   \n",
       "959               NaN              NaN   \n",
       "960               NaN              NaN   \n",
       "\n",
       "                                                 Title   Stars   TF-IDFs  ...  \\\n",
       "0    datetime.utcnow and datetime.utcfromtimestamp ...   643.0  1.312623  ...   \n",
       "1                         SpssParser ignores timezones   683.0  1.270077  ...   \n",
       "2    Deepcopy of Month-based Duration produces a di...  6109.0  1.191295  ...   \n",
       "3    `DeprecationWarning` warning in build log for ...   420.0  1.176351  ...   \n",
       "4    `DeprecationWarning` warning in build log for ...   119.0  1.167279  ...   \n",
       "..                                                 ...     ...       ...  ...   \n",
       "956                                                NaN     NaN       NaN  ...   \n",
       "957                                                NaN     NaN       NaN  ...   \n",
       "958                                                NaN     NaN       NaN  ...   \n",
       "959                                                NaN     NaN       NaN  ...   \n",
       "960                                                NaN     NaN       NaN  ...   \n",
       "\n",
       "                     Affected Computation 2  Affected Computation 3  \\\n",
       "0                                       NaN                     NaN   \n",
       "1    Replacing/Rounding Datetime Components     Library Conversions   \n",
       "2                                       NaN                     NaN   \n",
       "3                                       NaN                     NaN   \n",
       "4                                       NaN                     NaN   \n",
       "..                                      ...                     ...   \n",
       "956                                     NaN                     NaN   \n",
       "957                                     NaN                     NaN   \n",
       "958                                     NaN                     NaN   \n",
       "959                                     NaN                     NaN   \n",
       "960                                     NaN                     NaN   \n",
       "\n",
       "     Obscurity  Impact/Severity   # LOC Logic Needed  \\\n",
       "0          Low              Low     Low          Low   \n",
       "1          Low           Medium  Medium       Medium   \n",
       "2          NaN              NaN     NaN          NaN   \n",
       "3          Low              Low     Low          Low   \n",
       "4          NaN              NaN     NaN          NaN   \n",
       "..         ...              ...     ...          ...   \n",
       "956        NaN              NaN     NaN          NaN   \n",
       "957        NaN              NaN     NaN          NaN   \n",
       "958        NaN              NaN     NaN          NaN   \n",
       "959        NaN              NaN     NaN          NaN   \n",
       "960        NaN              NaN     NaN          NaN   \n",
       "\n",
       "                                BPST1 BPST2 BPST3 Make Benchmark?  \n",
       "0            Outdated/Deprecated APIs   NaN   NaN             Yes  \n",
       "1    Using Naïve Datetime Incorrectly   NaN   NaN              No  \n",
       "2                                 NaN   NaN   NaN             NaN  \n",
       "3            Outdated/Deprecated APIs   NaN   NaN             Yes  \n",
       "4                                 NaN   NaN   NaN             NaN  \n",
       "..                                ...   ...   ...             ...  \n",
       "956                               NaN   NaN   NaN             NaN  \n",
       "957                               NaN   NaN   NaN             NaN  \n",
       "958                               NaN   NaN   NaN             NaN  \n",
       "959                               NaN   NaN   NaN             NaN  \n",
       "960                               NaN   NaN   NaN             NaN  \n",
       "\n",
       "[961 rows x 27 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#pip install seaborn\n",
    "# %pip install seaborn\n",
    "\n",
    "# Read the data from the TSV file\n",
    "df_base = pd.read_csv('../ck_data/2024-08-17_bug_analysis_base.tsv', sep='\\t')\n",
    "df_rater1 = pd.read_csv('../ck_data/2024-08-17_bug_analysis_rater1.tsv', sep='\\t')\n",
    "df_rater2 = pd.read_csv('../ck_data/2024-08-17_bug_analysis_rater2.tsv', sep='\\t')\n",
    "\n",
    "# Drop rows were the Skipped? column is true\n",
    "#df_base = df[df['Skipped?'] != True]\n",
    "# Drop rows where false positives is true\n",
    "#df = df[df['False pos?'] != True]\n",
    "\n",
    "# Only keep rows where either Testing? or Set 3? is true\n",
    "#can't actually delete rows bc it'll mess with the indexing\n",
    "\"\"\"\n",
    "df_base = df_base[(df_base['Testing?'] == True) | (df_base['Set 3?'] == True)]\n",
    "df_rater1 = df_rater1[(df_rater1['Testing?'] == True) | (df_rater1['Set 3?'] == True)]\n",
    "df_rater2 = df_rater2[(df_rater2['Testing?'] == True) | (df_rater2['Set 3?'] == True)]\n",
    "\"\"\"\n",
    "\n",
    "# Drop columns\n",
    "#df = df.drop(columns=['Link', 'Fix Link', 'Make Benchmark?', 'Associated Benchmark', 'Rater', 'Training?', 'Testing?', 'Skipped?', 'False pos?'])\n",
    "df_base = df_base.drop(columns=['Skipped?', 'Link', 'Fix Link', 'Description', 'Comments', 'Associated Benchmark'])\n",
    "df_rater1 = df_rater1.drop(columns=['Skipped?', 'Link', 'Fix Link', 'Description', 'Comments', 'Associated Benchmark'])\n",
    "df_rater2 = df_rater2.drop(columns=['Skipped?', 'Link', 'Fix Link', 'Description', 'Comments', 'Associated Benchmark'])\n",
    "\n",
    "print(len(df_rater2))\n",
    "df_rater2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Shrey Peter 24\n",
      "2: Shrey Serena 20\n",
      "3: Shrey Sasha 24\n",
      "4: Peter Serena 27\n",
      "5: Peter Sasha 25\n",
      "6: Serena Sasha 26\n"
     ]
    }
   ],
   "source": [
    "#calculate the number of agreed false positives (either both think it's a fp or both think not fp)\n",
    "# for each pair\n",
    "\n",
    "#rater pairs and fp counts\n",
    "fp_rater_pairs = [\n",
    "    (\"1: Shrey Peter\", 0),\n",
    "    (\"2: Shrey Serena\", 0),\n",
    "    (\"3: Shrey Sasha\", 0),\n",
    "    (\"4: Peter Serena\", 0),\n",
    "    (\"5: Peter Sasha\", 0),\n",
    "    (\"6: Serena Sasha\", 0)\n",
    "]\n",
    "\n",
    "#convert to boolean or it wont work\n",
    "df_base[\"Testing?\"] = df_base[\"Testing?\"].astype(bool)\n",
    "df_base[\"Set 3?\"] = df_base[\"Set 3?\"].astype(bool)\n",
    "\n",
    "for i in range(len(df_base)):\n",
    "    if (df_base[\"Testing?\"].iloc[i]) | (df_base[\"Set 3?\"].iloc[i]):\n",
    "        if df_rater1.iloc[i]['False pos?'] == df_rater2.iloc[i]['False pos?']:\n",
    "            for j in range(len(fp_rater_pairs)):\n",
    "                pair, count = fp_rater_pairs[j]\n",
    "                if pair == df_base.iloc[i]['Rater']:\n",
    "                    fp_rater_pairs[j] = (pair, count + 1)\n",
    "\n",
    "#printing\n",
    "for pair, count in fp_rater_pairs:\n",
    "    print(pair, count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Shrey Peter 24 --> 0.8\n",
      "2: Shrey Serena 20 --> 0.6666666666666666\n",
      "3: Shrey Sasha 24 --> 0.8\n",
      "4: Peter Serena 27 --> 0.9\n",
      "5: Peter Sasha 25 --> 0.8333333333333334\n",
      "6: Serena Sasha 26 --> 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "#entire process: get fp agreement rate by going through each row, \n",
    "# getting the false pos values for Rater 1 and Rater 2, \n",
    "# comparing them and setting as 1 if equal and 0 otherwise,\n",
    "# sum the results, and divide by number of bugs per pair\n",
    "\n",
    "#GLOBAL VAR\n",
    "NUMBER_BUGS_PER_PAIR = 30\n",
    "for pair, count in fp_rater_pairs:\n",
    "    print(pair, count, \"-->\", count/NUMBER_BUGS_PER_PAIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Shrey Peter 18\n",
      "2: Shrey Serena 19\n",
      "3: Shrey Sasha 15\n",
      "4: Peter Serena 19\n",
      "5: Peter Sasha 18\n",
      "6: Serena Sasha 19\n",
      "1: Shrey Peter 15 --> 0.8333333333333334\n",
      "2: Shrey Serena 4 --> 0.21052631578947367\n",
      "3: Shrey Sasha 8 --> 0.5333333333333333\n",
      "4: Peter Serena 16 --> 0.8421052631578947\n",
      "5: Peter Sasha 12 --> 0.6666666666666666\n",
      "6: Serena Sasha 17 --> 0.8947368421052632\n"
     ]
    }
   ],
   "source": [
    "#if both raters classified the item as not fp, \n",
    "# check if the categories assigned by the 2 raters are the same\n",
    "\n",
    "not_fp_rater_pairs = [\n",
    "    (\"1: Shrey Peter\", 0),\n",
    "    (\"2: Shrey Serena\", 0),\n",
    "    (\"3: Shrey Sasha\", 0),\n",
    "    (\"4: Peter Serena\", 0),\n",
    "    (\"5: Peter Sasha\", 0),\n",
    "    (\"6: Serena Sasha\", 0)\n",
    "]\n",
    "\n",
    "category_rater_pairs = [\n",
    "    (\"1: Shrey Peter\", 0),\n",
    "    (\"2: Shrey Serena\", 0),\n",
    "    (\"3: Shrey Sasha\", 0),\n",
    "    (\"4: Peter Serena\", 0),\n",
    "    (\"5: Peter Sasha\", 0),\n",
    "    (\"6: Serena Sasha\", 0)\n",
    "]\n",
    "\n",
    "for i in range(len(df_base)):\n",
    "    if (df_base[\"Testing?\"].iloc[i]) | (df_base[\"Set 3?\"].iloc[i]):\n",
    "        if (df_rater1.iloc[i]['False pos?']==False) & (df_rater2.iloc[i]['False pos?']==False):\n",
    "            for j in range(len(not_fp_rater_pairs)):\n",
    "                    pair, count = not_fp_rater_pairs[j]\n",
    "                    if pair == df_base.iloc[i]['Rater']:\n",
    "                        not_fp_rater_pairs[j] = (pair, count + 1)\n",
    "            if(df_rater1.iloc[i]['Category 1']==df_rater2.iloc[i]['Category 1']):\n",
    "                for j in range(len(category_rater_pairs)):\n",
    "                    pair, count = category_rater_pairs[j]\n",
    "                    if pair == df_base.iloc[i]['Rater']:\n",
    "                        category_rater_pairs[j] = (pair, count + 1)\n",
    "\n",
    "for pair, count in not_fp_rater_pairs:\n",
    "    print(pair, count)\n",
    "\n",
    "counter = 0\n",
    "for pair, count in category_rater_pairs:\n",
    "    print(pair, count, \"-->\", count/not_fp_rater_pairs[counter][1])\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Shrey Peter 0.5925925925925926\n",
      "2: Shrey Serena 0.037037037037037035\n",
      "3: Shrey Sasha 0.1111111111111111\n",
      "4: Peter Serena 0.6172839506172839\n",
      "5: Peter Sasha 0.037037037037037035\n",
      "6: Serena Sasha 0.345679012345679\n"
     ]
    }
   ],
   "source": [
    "# calculate the P_e score for categories\n",
    "# 1) take a rater pair (A), and only the values that are !FP\n",
    "# 2) for each value (category rn), count how many times it appears for rater 1 (A1) and rater 2 (A2)\n",
    "# 3) values (C) are the total number of values (categories)\n",
    "# 4) calculate (A1*A2 / (C*C)) for each value, and \\sum them together\n",
    "\n",
    "category_pe = [\n",
    "    (\"1: Shrey Peter\", 0),\n",
    "    (\"2: Shrey Serena\", 0),\n",
    "    (\"3: Shrey Sasha\", 0),\n",
    "    (\"4: Peter Serena\", 0),\n",
    "    (\"5: Peter Sasha\", 0),\n",
    "    (\"6: Serena Sasha\", 0)\n",
    "]\n",
    "\n",
    "#GLOBAL VAR\n",
    "CATEGORIES = [\n",
    "    \"Date\",\n",
    "    \"DST\",\n",
    "    \"Duration\",\n",
    "    \"String Representation\",\n",
    "    \"Timestamps\",\n",
    "    \"Timezone\",\n",
    "    \"Deprecated\",\n",
    "    \"Fold\",\n",
    "    \"TODO\"\n",
    "]\n",
    "\n",
    "categories_rater1 = [\n",
    "    0, 0, 0, 0, 0, 0, 0, 0, 0 #9 values\n",
    "] # for incrementing as we find values of diff categories\n",
    "categories_rater2 = [\n",
    "    0, 0, 0, 0, 0, 0, 0, 0, 0 #9 values\n",
    "] # for incrementing as we find values of diff categories\n",
    "\n",
    "for r in range(len(category_pe)): #for each rater pair\n",
    "    for i in range(len(df_base)): #for each row in the sheet\n",
    "        if(df_base[\"Rater\"].iloc[i]==category_pe[r][0]): #if the row's Rater == the current rater pair\n",
    "            if (df_rater1.iloc[i]['False pos?']==False) & (df_rater2.iloc[i]['False pos?']==False): #if it's not a fp\n",
    "                for j in range(len(CATEGORIES)): #for each category\n",
    "                    if(df_rater1.iloc[i][\"Category 1\"]==CATEGORIES[j]): #if rater 1 marked it as this category\n",
    "                        categories_rater1[j] +=1 #increment count\n",
    "                    if(df_rater2.iloc[i][\"Category 2\"]==CATEGORIES[j]): #if rater 2 marked it as this category\n",
    "                        categories_rater2[j] +=1 #increment count\n",
    "    tmp = 0\n",
    "    for v in range(len(CATEGORIES)): #increment proportions\n",
    "        tmp += ((categories_rater1[v]*categories_rater2[v]) / (len(CATEGORIES)*len(CATEGORIES))) #CHECK THIS FORMULA\n",
    "    category_pe[r]= (category_pe[r][0], tmp)\n",
    "\n",
    "    #reset values\n",
    "    categories_rater1 = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    categories_rater2 = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "for pair, count in category_pe:\n",
    "    print(pair, count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Shrey Peter 35.36363636363636\n",
      "2: Shrey Serena 4.115384615384615\n",
      "3: Shrey Sasha 8.875000000000002\n",
      "4: Peter Serena 40.193548387096776\n",
      "5: Peter Sasha 12.423076923076923\n",
      "6: Serena Sasha 25.452830188679243\n"
     ]
    }
   ],
   "source": [
    "# calculate the cohen kappa score for categories\n",
    "category_ck = [\n",
    "    (\"1: Shrey Peter\", 0),\n",
    "    (\"2: Shrey Serena\", 0),\n",
    "    (\"3: Shrey Sasha\", 0),\n",
    "    (\"4: Peter Serena\", 0),\n",
    "    (\"5: Peter Sasha\", 0),\n",
    "    (\"6: Serena Sasha\", 0)\n",
    "]\n",
    "\n",
    "for i in range(len(category_ck)):\n",
    "    category_ck[i] = (\n",
    "        category_ck[i][0],\n",
    "        (category_rater_pairs[i][1] - category_pe[i][1]) / (1 - category_pe[i][1])\n",
    "    )\n",
    "\n",
    "for pair, count in category_ck:\n",
    "    print(pair, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affected Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Shrey Peter 12 --> 0.6666666666666666\n",
      "2: Shrey Serena 4 --> 0.21052631578947367\n",
      "3: Shrey Sasha 4 --> 0.26666666666666666\n",
      "4: Peter Serena 13 --> 0.6842105263157895\n",
      "5: Peter Sasha 11 --> 0.6111111111111112\n",
      "6: Serena Sasha 13 --> 0.6842105263157895\n"
     ]
    }
   ],
   "source": [
    "#if both raters classified the item as not fp, \n",
    "# check if the affected computation assigned by the 2 raters are the same\n",
    "\n",
    "affcomp_rater_pairs = [\n",
    "    (\"1: Shrey Peter\", 0),\n",
    "    (\"2: Shrey Serena\", 0),\n",
    "    (\"3: Shrey Sasha\", 0),\n",
    "    (\"4: Peter Serena\", 0),\n",
    "    (\"5: Peter Sasha\", 0),\n",
    "    (\"6: Serena Sasha\", 0)\n",
    "]\n",
    "\n",
    "for i in range(len(df_base)):\n",
    "    if (df_base[\"Testing?\"].iloc[i]) | (df_base[\"Set 3?\"].iloc[i]):\n",
    "        if (df_rater1.iloc[i]['False pos?']==False) & (df_rater2.iloc[i]['False pos?']==False):\n",
    "            if(df_rater1.iloc[i]['Affected Computation 1']==df_rater2.iloc[i]['Affected Computation 1']):\n",
    "                for j in range(len(affcomp_rater_pairs)):\n",
    "                    pair, count = affcomp_rater_pairs[j]\n",
    "                    if pair == df_base.iloc[i]['Rater']:\n",
    "                        affcomp_rater_pairs[j] = (pair, count + 1)\n",
    "\n",
    "\n",
    "counter = 0\n",
    "for pair, count in affcomp_rater_pairs:\n",
    "    print(pair, count, \"-->\", count/not_fp_rater_pairs[counter][1])\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Shrey Peter 0.1953125\n",
      "2: Shrey Serena 0.015625\n",
      "3: Shrey Sasha 0.0\n",
      "4: Peter Serena 0.0703125\n",
      "5: Peter Sasha 0.00390625\n",
      "6: Serena Sasha 0.046875\n"
     ]
    }
   ],
   "source": [
    "# calculate the P_e score for affected computations\n",
    "# 1) take a rater pair (A), and only the values that are !FP\n",
    "# 2) for each value (affected computations rn), count how many times it appears for rater 1 (A1) and rater 2 (A2)\n",
    "# 3) values (C) are the total number of values (affcomp)\n",
    "# 4) calculate (A1*A2 / (C*C)) for each value, and \\sum them together\n",
    "\n",
    "affcomp_pe = [\n",
    "    (\"1: Shrey Peter\", 0),\n",
    "    (\"2: Shrey Serena\", 0),\n",
    "    (\"3: Shrey Sasha\", 0),\n",
    "    (\"4: Peter Serena\", 0),\n",
    "    (\"5: Peter Sasha\", 0),\n",
    "    (\"6: Serena Sasha\", 0)\n",
    "]\n",
    "\n",
    "#GLOBAL VAR\n",
    "AFFECTED_COMPUTATIONS = [\n",
    "    \"Timestamp/Hash Construction\",\n",
    "    \"Datetime Arithmetic\",\n",
    "    \"Datetime Comparison\",\n",
    "    \"Datetime Construction\",\n",
    "    \"Datetime Equality\",\n",
    "    \"Delta Arithmetic\",\n",
    "    \"Delta Comparison\",\n",
    "    \"Delta Construction\",\n",
    "    \"Querying Datetime Components\",\n",
    "    \"Replacing/Rounding Datetime Components\",\n",
    "    \"String Parsing/Formatting (humanized)\",\n",
    "    \"String Parsing/Formatting (data)\",\n",
    "    \"Timezone Conversions\",\n",
    "    \"Timezone Equality\",\n",
    "    \"Library Conversions\",\n",
    "    \"TODO\"\n",
    "]\n",
    "\n",
    "affcomp_rater1 = [0]*16 # for incrementing as we find values of diff affcomps\n",
    "affcomp_rater2 = [0]*16 # for incrementing as we find values of diff affcomps\n",
    "\n",
    "for r in range(len(affcomp_pe)): #for each rater pair\n",
    "    for i in range(len(df_base)): #for each row in the sheet\n",
    "        if(df_base[\"Rater\"].iloc[i]==affcomp_pe[r][0]): #if the row's Rater == the current rater pair\n",
    "            if (df_rater1.iloc[i]['False pos?']==False) & (df_rater2.iloc[i]['False pos?']==False): #if it's not a fp\n",
    "                for j in range(len(CATEGORIES)): #for each affcomp\n",
    "                    if(df_rater1.iloc[i][\"Affected Computation 1\"]==AFFECTED_COMPUTATIONS[j]): #if rater 1 marked it as this affcomp\n",
    "                        affcomp_rater1[j] +=1 #increment count\n",
    "                    if(df_rater2.iloc[i][\"Affected Computation 2\"]==AFFECTED_COMPUTATIONS[j]): #if rater 2 marked it as this affcomp\n",
    "                        affcomp_rater2[j] +=1 #increment count\n",
    "    tmp = 0\n",
    "    for v in range(len(AFFECTED_COMPUTATIONS)): #increment proportions\n",
    "        tmp += ((affcomp_rater1[v]*affcomp_rater2[v]) / (len(AFFECTED_COMPUTATIONS)*len(AFFECTED_COMPUTATIONS))) #CHECK THIS FORMULA\n",
    "    affcomp_pe[r]= (affcomp_pe[r][0], tmp)\n",
    "\n",
    "    #reset values\n",
    "    affcomp_rater1 = [0]*16\n",
    "    affcomp_rater2 = [0]*16\n",
    "\n",
    "for pair, count in affcomp_pe:\n",
    "    print(pair, count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Shrey Peter 14.669902912621358\n",
      "2: Shrey Serena 4.0476190476190474\n",
      "3: Shrey Sasha 4.0\n",
      "4: Peter Serena 13.907563025210084\n",
      "5: Peter Sasha 11.03921568627451\n",
      "6: Serena Sasha 13.59016393442623\n"
     ]
    }
   ],
   "source": [
    "# calculate the cohen kappa score for affected computations\n",
    "affcomp_ck = [\n",
    "    (\"1: Shrey Peter\", 0),\n",
    "    (\"2: Shrey Serena\", 0),\n",
    "    (\"3: Shrey Sasha\", 0),\n",
    "    (\"4: Peter Serena\", 0),\n",
    "    (\"5: Peter Sasha\", 0),\n",
    "    (\"6: Serena Sasha\", 0)\n",
    "]\n",
    "\n",
    "for i in range(len(affcomp_ck)):\n",
    "    affcomp_ck[i] = (\n",
    "        affcomp_ck[i][0],\n",
    "        (affcomp_rater_pairs[i][1] - affcomp_pe[i][1]) / (1 - affcomp_pe[i][1])\n",
    "    )\n",
    "\n",
    "for pair, count in affcomp_ck:\n",
    "    print(pair, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPSTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Shrey Peter 9 --> 0.5\n",
      "2: Shrey Serena 2 --> 0.10526315789473684\n",
      "3: Shrey Sasha 5 --> 0.3333333333333333\n",
      "4: Peter Serena 13 --> 0.6842105263157895\n",
      "5: Peter Sasha 10 --> 0.5555555555555556\n",
      "6: Serena Sasha 11 --> 0.5789473684210527\n"
     ]
    }
   ],
   "source": [
    "#if both raters classified the item as not fp, \n",
    "# check if the affected computation assigned by the 2 raters are the same\n",
    "\n",
    "bpst_rater_pairs = [\n",
    "    (\"1: Shrey Peter\", 0),\n",
    "    (\"2: Shrey Serena\", 0),\n",
    "    (\"3: Shrey Sasha\", 0),\n",
    "    (\"4: Peter Serena\", 0),\n",
    "    (\"5: Peter Sasha\", 0),\n",
    "    (\"6: Serena Sasha\", 0)\n",
    "]\n",
    "\n",
    "for i in range(len(df_base)):\n",
    "    if (df_base[\"Testing?\"].iloc[i]) | (df_base[\"Set 3?\"].iloc[i]):\n",
    "        if (df_rater1.iloc[i]['False pos?']==False) & (df_rater2.iloc[i]['False pos?']==False):\n",
    "            if(df_rater1.iloc[i]['BPST1']==df_rater2.iloc[i]['BPST1']):\n",
    "                for j in range(len(bpst_rater_pairs)):\n",
    "                    pair, count = bpst_rater_pairs[j]\n",
    "                    if pair == df_base.iloc[i]['Rater']:\n",
    "                        bpst_rater_pairs[j] = (pair, count + 1)\n",
    "\n",
    "\n",
    "counter = 0\n",
    "for pair, count in bpst_rater_pairs:\n",
    "    print(pair, count, \"-->\", count/not_fp_rater_pairs[counter][1])\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Shrey Peter 0.024221453287197235\n",
      "2: Shrey Serena 0.01384083044982699\n",
      "3: Shrey Sasha 0.0034602076124567475\n",
      "4: Peter Serena 0.04498269896193772\n",
      "5: Peter Sasha 0.01384083044982699\n",
      "6: Serena Sasha 0.020761245674740487\n"
     ]
    }
   ],
   "source": [
    "# calculate the P_e score for bpsts\n",
    "# 1) take a rater pair (A), and only the values that are !FP\n",
    "# 2) for each value (bpsts rn), count how many times it appears for rater 1 (A1) and rater 2 (A2)\n",
    "# 3) values (C) are the total number of values (bpst)\n",
    "# 4) calculate (A1*A2 / (C*C)) for each value, and \\sum them together\n",
    "\n",
    "bpst_pe = [\n",
    "    (\"1: Shrey Peter\", 0),\n",
    "    (\"2: Shrey Serena\", 0),\n",
    "    (\"3: Shrey Sasha\", 0),\n",
    "    (\"4: Peter Serena\", 0),\n",
    "    (\"5: Peter Sasha\", 0),\n",
    "    (\"6: Serena Sasha\", 0)\n",
    "]\n",
    "\n",
    "#GLOBAL VAR\n",
    "BPSTs = [\n",
    "    \"Incorrect API usage\",\n",
    "    \"Outdated/Deprecated APIs\",\n",
    "    \"Typo\",\n",
    "    \"Using Naïve Datetime Incorrectly\",\n",
    "    \"Dropping Timezones\",\n",
    "    \"Adding Support for New Libraries\",\n",
    "    \"Adding Support for New Features\",\n",
    "    \"Precision of Representation\",\n",
    "    \"Library Bug\",\n",
    "    \"OOB Timestamps\",\n",
    "    \"OOB Datetimes\",\n",
    "    \"Creating time in unspecified fold\",\n",
    "    \"Comparing Timezones\",\n",
    "    \"Unintuitive Arithmetic\",\n",
    "    \"Compatibility Issues\",\n",
    "    \"Incorrect Format Assumptions\",\n",
    "    \"TODO\"\n",
    "]\n",
    "\n",
    "bpst_rater1 = [0]*17 # for incrementing as we find values of diff bpst\n",
    "bpst_rater2 = [0]*17 # for incrementing as we find values of diff bpst\n",
    "\n",
    "for r in range(len(bpst_pe)): #for each rater pair\n",
    "    for i in range(len(df_base)): #for each row in the sheet\n",
    "        if(df_base[\"Rater\"].iloc[i]==bpst_pe[r][0]): #if the row's Rater == the current rater pair\n",
    "            if (df_rater1.iloc[i]['False pos?']==False) & (df_rater2.iloc[i]['False pos?']==False): #if it's not a fp\n",
    "                for j in range(len(BPSTs)): #for each affcomp\n",
    "                    if(df_rater1.iloc[i][\"BPST1\"]==BPSTs[j]): #if rater 1 marked it as this bpst\n",
    "                        bpst_rater1[j] +=1 #increment count\n",
    "                    if(df_rater2.iloc[i][\"BPST2\"]==BPSTs[j]): #if rater 2 marked it as this bpst\n",
    "                        bpst_rater2[j] +=1 #increment count\n",
    "    tmp = 0\n",
    "    for v in range(len(BPSTs)): #increment proportions\n",
    "        tmp += ((bpst_rater1[v]*bpst_rater2[v]) / (len(BPSTs)*len(BPSTs))) #CHECK THIS FORMULA\n",
    "    bpst_pe[r]= (bpst_pe[r][0], tmp)\n",
    "\n",
    "    #reset values\n",
    "    bpst_rater1 = [0]*17\n",
    "    bpst_rater2 = [0]*17\n",
    "\n",
    "for pair, count in bpst_pe:\n",
    "    print(pair, count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Shrey Peter 9.198581560283689\n",
      "2: Shrey Serena 2.0140350877192983\n",
      "3: Shrey Sasha 5.013888888888889\n",
      "4: Peter Serena 13.565217391304348\n",
      "5: Peter Sasha 10.126315789473685\n",
      "6: Serena Sasha 11.212014134275618\n"
     ]
    }
   ],
   "source": [
    "# calculate the cohen kappa score for bpsts\n",
    "bpst_ck = [\n",
    "    (\"1: Shrey Peter\", 0),\n",
    "    (\"2: Shrey Serena\", 0),\n",
    "    (\"3: Shrey Sasha\", 0),\n",
    "    (\"4: Peter Serena\", 0),\n",
    "    (\"5: Peter Sasha\", 0),\n",
    "    (\"6: Serena Sasha\", 0)\n",
    "]\n",
    "\n",
    "for i in range(len(bpst_ck)):\n",
    "    bpst_ck[i] = (\n",
    "        bpst_ck[i][0],\n",
    "        (bpst_rater_pairs[i][1] - bpst_pe[i][1]) / (1 - bpst_pe[i][1])\n",
    "    )\n",
    "\n",
    "for pair, count in bpst_ck:\n",
    "    print(pair, count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
