u'857'b'csibm857'u'csibm857'b'ibm857'u'ibm857'b'cp858'u'cp858'b'858'u'858'b'csibm858'u'csibm858'b'ibm858'u'ibm858'b'cp860'u'cp860'b'860'u'860'b'csibm860'u'csibm860'b'ibm860'u'ibm860'b'cp861'u'cp861'b'861'u'861'b'cp_is'u'cp_is'b'csibm861'u'csibm861'b'ibm861'u'ibm861'b'cp862'u'cp862'b'862'u'862'b'cspc862latinhebrew'u'cspc862latinhebrew'b'ibm862'u'ibm862'b'cp863'u'cp863'b'863'u'863'b'csibm863'u'csibm863'b'ibm863'u'ibm863'b'cp864'u'cp864'b'864'u'864'b'csibm864'u'csibm864'b'ibm864'u'ibm864'b'cp865'u'cp865'b'865'u'865'b'csibm865'u'csibm865'b'ibm865'u'ibm865'b'cp866'u'cp866'b'866'u'866'b'csibm866'u'csibm866'b'ibm866'u'ibm866'b'cp869'u'cp869'b'869'u'869'b'cp_gr'u'cp_gr'b'csibm869'u'csibm869'b'ibm869'u'ibm869'b'cp932'u'cp932'b'932'u'932'b'ms932'u'ms932'b'mskanji'u'mskanji'b'ms_kanji'u'ms_kanji'b'cp949'u'cp949'b'949'u'949'b'ms949'u'ms949'b'uhc'u'uhc'b'cp950'u'cp950'b'950'u'950'b'ms950'u'ms950'b'euc_jis_2004'u'euc_jis_2004'b'jisx0213'u'jisx0213'b'eucjis2004'u'eucjis2004'b'euc_jis2004'u'euc_jis2004'b'euc_jisx0213'u'euc_jisx0213'b'eucjisx0213'u'eucjisx0213'b'euc_jp'u'euc_jp'b'eucjp'u'eucjp'b'ujis'u'ujis'b'u_jis'u'u_jis'b'euc_kr'u'euc_kr'b'euckr'u'euckr'b'korean'u'korean'b'ksc5601'u'ksc5601'b'ks_c_5601'u'ks_c_5601'b'ks_c_5601_1987'u'ks_c_5601_1987'b'ksx1001'u'ksx1001'b'ks_x_1001'u'ks_x_1001'b'gb18030'u'gb18030'b'gb18030_2000'u'gb18030_2000'b'gb2312'u'gb2312'b'chinese'u'chinese'b'csiso58gb231280'u'csiso58gb231280'b'euc_cn'u'euc_cn'b'euccn'u'euccn'b'eucgb2312_cn'u'eucgb2312_cn'b'gb2312_1980'u'gb2312_1980'b'gb2312_80'u'gb2312_80'b'iso_ir_58'u'iso_ir_58'b'gbk'u'gbk'b'936'u'936'b'cp936'u'cp936'b'ms936'u'ms936'b'hex_codec'u'hex_codec'b'hex'u'hex'b'hp_roman8'u'hp_roman8'b'roman8'u'roman8'b'r8'u'r8'b'csHPRoman8'u'csHPRoman8'b'cp1051'u'cp1051'b'ibm1051'u'ibm1051'b'hz'u'hz'b'hzgb'u'hzgb'b'hz_gb'u'hz_gb'b'hz_gb_2312'u'hz_gb_2312'b'iso2022_jp'u'iso2022_jp'b'csiso2022jp'u'csiso2022jp'b'iso2022jp'u'iso2022jp'b'iso_2022_jp'u'iso_2022_jp'b'iso2022_jp_1'u'iso2022_jp_1'b'iso2022jp_1'u'iso2022jp_1'b'iso_2022_jp_1'u'iso_2022_jp_1'b'iso2022_jp_2'u'iso2022_jp_2'b'iso2022jp_2'u'iso2022jp_2'b'iso_2022_jp_2'u'iso_2022_jp_2'b'iso2022_jp_2004'u'iso2022_jp_2004'b'iso_2022_jp_2004'u'iso_2022_jp_2004'b'iso2022jp_2004'u'iso2022jp_2004'b'iso2022_jp_3'u'iso2022_jp_3'b'iso2022jp_3'u'iso2022jp_3'b'iso_2022_jp_3'u'iso_2022_jp_3'b'iso2022_jp_ext'u'iso2022_jp_ext'b'iso2022jp_ext'u'iso2022jp_ext'b'iso_2022_jp_ext'u'iso_2022_jp_ext'b'iso2022_kr'u'iso2022_kr'b'csiso2022kr'u'csiso2022kr'b'iso2022kr'u'iso2022kr'b'iso_2022_kr'u'iso_2022_kr'b'iso8859_10'u'iso8859_10'b'csisolatin6'u'csisolatin6'b'iso_8859_10'u'iso_8859_10'b'iso_8859_10_1992'u'iso_8859_10_1992'b'iso_ir_157'u'iso_ir_157'b'l6'u'l6'b'latin6'u'latin6'b'iso8859_11'u'iso8859_11'b'thai'u'thai'b'iso_8859_11'u'iso_8859_11'b'iso_8859_11_2001'u'iso_8859_11_2001'b'iso8859_13'u'iso8859_13'b'iso_8859_13'u'iso_8859_13'b'l7'u'l7'b'latin7'u'latin7'b'iso8859_14'u'iso8859_14'b'iso_8859_14'u'iso_8859_14'b'iso_8859_14_1998'u'iso_8859_14_1998'b'iso_celtic'u'iso_celtic'b'iso_ir_199'u'iso_ir_199'b'l8'u'l8'b'latin8'u'latin8'b'iso8859_15'u'iso8859_15'b'iso_8859_15'u'iso_8859_15'b'l9'u'l9'b'latin9'u'latin9'b'iso8859_16'u'iso8859_16'b'iso_8859_16'u'iso_8859_16'b'iso_8859_16_2001'u'iso_8859_16_2001'b'iso_ir_226'u'iso_ir_226'b'l10'u'l10'b'latin10'u'latin10'b'iso8859_2'u'iso8859_2'b'csisolatin2'u'csisolatin2'b'iso_8859_2'u'iso_8859_2'b'iso_8859_2_1987'u'iso_8859_2_1987'b'iso_ir_101'u'iso_ir_101'b'l2'u'l2'b'latin2'u'latin2'b'iso8859_3'u'iso8859_3'b'csisolatin3'u'csisolatin3'b'iso_8859_3'u'iso_8859_3'b'iso_8859_3_1988'u'iso_8859_3_1988'b'iso_ir_109'u'iso_ir_109'b'l3'u'l3'b'latin3'u'latin3'b'iso8859_4'u'iso8859_4'b'csisolatin4'u'csisolatin4'b'iso_8859_4'u'iso_8859_4'b'iso_8859_4_1988'u'iso_8859_4_1988'b'iso_ir_110'u'iso_ir_110'b'l4'u'l4'b'latin4'u'latin4'b'iso8859_5'u'iso8859_5'b'csisolatincyrillic'u'csisolatincyrillic'b'cyrillic'u'cyrillic'b'iso_8859_5'u'iso_8859_5'b'iso_8859_5_1988'u'iso_8859_5_1988'b'iso_ir_144'u'iso_ir_144'b'iso8859_6'u'iso8859_6'b'arabic'u'arabic'b'asmo_708'u'asmo_708'b'csisolatinarabic'u'csisolatinarabic'b'ecma_114'u'ecma_114'b'iso_8859_6'u'iso_8859_6'b'iso_8859_6_1987'u'iso_8859_6_1987'b'iso_ir_127'u'iso_ir_127'b'iso8859_7'u'iso8859_7'b'csisolatingreek'u'csisolatingreek'b'ecma_118'u'ecma_118'b'elot_928'u'elot_928'b'greek'u'greek'b'greek8'u'greek8'b'iso_8859_7'u'iso_8859_7'b'iso_8859_7_1987'u'iso_8859_7_1987'b'iso_ir_126'u'iso_ir_126'b'iso8859_8'u'iso8859_8'b'csisolatinhebrew'u'csisolatinhebrew'b'hebrew'u'hebrew'b'iso_8859_8'u'iso_8859_8'b'iso_8859_8_1988'u'iso_8859_8_1988'b'iso_ir_138'u'iso_ir_138'b'iso8859_9'u'iso8859_9'b'csisolatin5'u'csisolatin5'b'iso_8859_9'u'iso_8859_9'b'iso_8859_9_1989'u'iso_8859_9_1989'b'iso_ir_148'u'iso_ir_148'b'l5'u'l5'b'latin5'u'latin5'b'johab'u'johab'b'cp1361'u'cp1361'b'ms1361'u'ms1361'b'koi8_r'u'koi8_r'b'cskoi8r'u'cskoi8r'b'kz1048'u'kz1048'b'kz_1048'u'kz_1048'b'rk1048'u'rk1048'b'strk1048_2002'u'strk1048_2002'b'latin_1'u'latin_1'b'8859'u'8859'b'cp819'u'cp819'b'csisolatin1'u'csisolatin1'b'ibm819'u'ibm819'b'iso8859'u'iso8859'b'iso8859_1'u'iso8859_1'b'iso_8859_1'u'iso_8859_1'b'iso_8859_1_1987'u'iso_8859_1_1987'b'iso_ir_100'u'iso_ir_100'b'l1'u'l1'b'latin'u'latin'b'mac_cyrillic'u'mac_cyrillic'b'maccyrillic'u'maccyrillic'b'mac_greek'u'mac_greek'b'macgreek'u'macgreek'b'mac_iceland'u'mac_iceland'b'maciceland'u'maciceland'b'mac_latin2'u'mac_latin2'b'maccentraleurope'u'maccentraleurope'b'mac_centeuro'u'mac_centeuro'b'maclatin2'u'maclatin2'b'mac_roman'u'mac_roman'b'macintosh'u'macintosh'b'macroman'u'macroman'b'mac_turkish'u'mac_turkish'b'macturkish'u'macturkish'b'mbcs'u'mbcs'b'ansi'u'ansi'b'dbcs'u'dbcs'b'ptcp154'u'ptcp154'b'csptcp154'u'csptcp154'b'pt154'u'pt154'b'cp154'u'cp154'b'cyrillic_asian'u'cyrillic_asian'b'quopri_codec'u'quopri_codec'b'quopri'u'quopri'b'quoted_printable'u'quoted_printable'b'quotedprintable'u'quotedprintable'b'rot_13'u'rot_13'b'rot13'u'rot13'b'shift_jis'u'shift_jis'b'csshiftjis'u'csshiftjis'b'shiftjis'u'shiftjis'b'sjis'u'sjis'b's_jis'u's_jis'b'shift_jis_2004'u'shift_jis_2004'b'shiftjis2004'u'shiftjis2004'b'sjis_2004'u'sjis_2004'b's_jis_2004'u's_jis_2004'b'shift_jisx0213'u'shift_jisx0213'b'shiftjisx0213'u'shiftjisx0213'b'sjisx0213'u'sjisx0213'b's_jisx0213'u's_jisx0213'b'tis_620'u'tis_620'b'tis620'u'tis620'b'tis_620_0'u'tis_620_0'b'tis_620_2529_0'u'tis_620_2529_0'b'tis_620_2529_1'u'tis_620_2529_1'b'iso_ir_166'u'iso_ir_166'b'utf_16'u'utf_16'b'u16'u'u16'b'utf16'u'utf16'b'utf_16_be'u'utf_16_be'b'unicodebigunmarked'u'unicodebigunmarked'b'utf_16be'u'utf_16be'b'utf_16_le'u'utf_16_le'b'unicodelittleunmarked'u'unicodelittleunmarked'b'utf_16le'u'utf_16le'b'utf_32'u'utf_32'b'u32'u'u32'b'utf32'u'utf32'b'utf_32_be'u'utf_32_be'b'utf_32be'u'utf_32be'b'utf_32_le'u'utf_32_le'b'utf_32le'u'utf_32le'b'utf_7'u'utf_7'b'u7'u'u7'b'utf7'u'utf7'b'unicode_1_1_utf_7'u'unicode_1_1_utf_7'b'utf_8'u'utf_8'b'u8'u'u8'b'utf'u'utf'b'utf8'u'utf8'b'utf8_ucs2'u'utf8_ucs2'b'utf8_ucs4'u'utf8_ucs4'b'cp65001'u'cp65001'b'uu_codec'u'uu_codec'b'uu'u'uu'b'zlib_codec'u'zlib_codec'b'zlib'b'x_mac_japanese'u'x_mac_japanese'b'x_mac_korean'u'x_mac_korean'b'x_mac_simp_chinese'u'x_mac_simp_chinese'b'x_mac_trad_chinese'u'x_mac_trad_chinese'u'Lib.encodings.aliases'u'encodings.aliases'u'aliases'Command-line parsing library

This module is an optparse-inspired command-line parsing library that:

    - handles both optional and positional arguments
    - produces highly informative usage messages
    - supports parsers that dispatch to sub-parsers

The following is a simple usage example that sums integers from the
command-line and writes the result to a file::

    parser = argparse.ArgumentParser(
        description='sum the integers at the command line')
    parser.add_argument(
        'integers', metavar='int', nargs='+', type=int,
        help='an integer to be summed')
    parser.add_argument(
        '--log', default=sys.stdout, type=argparse.FileType('w'),
        help='the file where the sum should be written')
    args = parser.parse_args()
    args.log.write('%s' % sum(args.integers))
    args.log.close()

The module contains the following public classes:

    - ArgumentParser -- The main entry point for command-line parsing. As the
        example above shows, the add_argument() method is used to populate
        the parser with actions for optional and positional arguments. Then
        the parse_args() method is invoked to convert the args at the
        command-line into an object with attributes.

    - ArgumentError -- The exception raised by ArgumentParser objects when
        there are errors with the parser's actions. Errors raised while
        parsing the command-line are caught by ArgumentParser and emitted
        as command-line messages.

    - FileType -- A factory for defining types of files to be created. As the
        example above shows, instances of FileType are typically passed as
        the type= argument of add_argument() calls.

    - Action -- The base class for parser actions. Typically actions are
        selected by passing strings like 'store_true' or 'append_const' to
        the action= argument of add_argument(). However, for greater
        customization of ArgumentParser actions, subclasses of Action may
        be defined and passed as the action= argument.

    - HelpFormatter, RawDescriptionHelpFormatter, RawTextHelpFormatter,
        ArgumentDefaultsHelpFormatter -- Formatter classes which
        may be passed as the formatter_class= argument to the
        ArgumentParser constructor. HelpFormatter is the default,
        RawDescriptionHelpFormatter and RawTextHelpFormatter tell the parser
        not to change the formatting for help text, and
        ArgumentDefaultsHelpFormatter adds information about argument defaults
        to the help.

All other classes in this module are considered implementation details.
(Also note that HelpFormatter and RawDescriptionHelpFormatter are only
considered public as object names -- the API of the formatter objects is
still considered an implementation detail.)
1.1ArgumentErrorArgumentTypeErrorBooleanOptionalActionFileTypeHelpFormatterArgumentDefaultsHelpFormatterRawDescriptionHelpFormatterRawTextHelpFormatterMetavarTypeHelpFormatterNamespaceActionONE_OR_MOREOPTIONALPARSERREMAINDERSUPPRESSZERO_OR_MOREgettextngettext==SUPPRESS==A..._unrecognized_args_UNRECOGNIZED_ARGS_ATTR_AttributeHolderAbstract base class that provides __repr__.

    The __repr__ method returns a string in the format::
        ClassName(attr=name, attr=name, ...)
    The attributes are determined either by a class-level attribute,
    '_kwarg_names', or by inspecting the instance __dict__.
    type_namearg_stringsstar_args_get_args_get_kwargs%s=%r**%s%s(%s)_copy_itemsFormatter for generating usage messages and argument help strings.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    progindent_incrementmax_help_positionget_terminal_sizecolumns_prog_indent_increment_max_help_position_width_current_indent_level_action_max_length_Section_root_section_current_section\s+_whitespace_matcher\n\n\n+_long_break_matcher_indent_dedentIndent decreased below 0.headingformat_help_join_partsitem_helpcurrent_indent%(heading)s:heading_text%*s%s
_add_itemstart_sectionsectionend_sectionadd_text_format_textadd_usageusageactions_format_usage_format_action_invocationget_invocationinvocationssubaction_iter_indented_subactionsinvocation_lengthaction_length_format_actionadd_arguments

part_stringsusage: %(prog)soptionalspositionalsoption_strings_format_actions_usageaction_usagetext_width\(.*?\)+(?=\s|$)|\[.*?\]+(?=\s|$)|\S+r'\(.*?\)+(?=\s|$)|'r'\[.*?\]+(?=\s|$)|'r'\S+'part_regexpopt_usagepos_usageopt_partspos_partsget_linesindentlinesindent_lengthline_len0.75%s%s

group_actionsinserts_group_actionsempty group group_action_countsuppressed_actions_countexposed_actions_count [_get_default_metavar_for_positional_format_argsoption_stringformat_usage_get_default_metavar_for_optionalargs_string%s %s[\[(][\])](%s) \1 (%s)%s *%s%(prog)_fill_texthelp_positionhelp_widthaction_widthaction_headertup%*s%-*s  indent_first_expand_helphelp_text_split_lineshelp_lines_metavar_formatterdefault_metavarchoiceschoicechoice_strs{%s}tuple_sizeget_metavar%s[%s [%s ...]][%s ...]%s [%s ...]%s ...formatsinvalid nargs valueparamschoices_str_get_help_string_get_subactionsget_subactionstextwrapwrapinitial_indentsubsequent_indentHelp message formatter which retains any formatting in descriptions.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    Help message formatter which retains formatting of all help text.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    Help message formatter which adds default values to argument help.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    
        Add the default value to the option help message.

        ArgumentDefaultsHelpFormatter and BooleanOptionalAction when it isn't
        already present. This code will do that, detecting cornercases to
        prevent duplicates or cases where it wouldn't make sense to the end
        user.
        %(default)defaulting_nargs (default: %(default)s)Help message formatter which uses the argument 'type' as the default
    metavar value (instead of the argument 'dest')

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    _get_action_nameargumentAn error from creating or using an argument (optional or positional).

    The string value of this exception is the message, augmented with
    information about the argument that caused it.
    argument_nameargument %(argument_name)s: %(message)sAn error from trying to convert a command line string to a type.Information about how to convert command line strings to Python objects.

    Action objects are used by an ArgumentParser to represent the information
    needed to parse a single argument from one or more strings from the
    command line. The keyword arguments to the Action constructor are also
    all attributes of Action instances.

    Keyword Arguments:

        - option_strings -- A list of command-line option strings which
            should be associated with this action.

        - dest -- The name of the attribute to hold the created object(s)

        - nargs -- The number of command-line arguments that should be
            consumed. By default, one argument will be consumed and a single
            value will be produced.  Other values include:
                - N (an integer) consumes N arguments (and produces a list)
                - '?' consumes zero or one arguments
                - '*' consumes zero or more arguments (and produces a list)
                - '+' consumes one or more arguments (and produces a list)
            Note that the difference between the default and nargs=1 is that
            with the default, a single value will be produced, while with
            nargs=1, a list containing a single value will be produced.

        - const -- The value to be produced if the option is specified and the
            option uses an action that takes no values.

        - default -- The value to be produced if the option is not specified.

        - type -- A callable that accepts a single string argument, and
            returns the converted value.  The standard Python types str, int,
            float, and complex are useful examples of such callables.  If None,
            str is used.

        - choices -- A container of values that should be allowed. If not None,
            after a command-line argument has been converted to the appropriate
            type, an exception will be raised if it is not a member of this
            collection.

        - required -- True if the action must always be specified at the
            command line. This is only meaningful for optional command-line
            arguments.

        - help -- The help string describing the argument.

        - metavar -- The name to be used for the option's argument with the
            help string. If None, the 'dest' value will be used as the name.
    const.__call__() not defined_deprecated_default_option_strings----no-field_name{name!r} is deprecated as of Python 3.12 and will be removed in Python {remove}."{name!r} is deprecated as of Python 3.12 and will be ""removed in Python {remove}." | _StoreActionnargs for store actions must be != 0; if you have nothing to store, actions such as store true or store const may be more appropriate'nargs for store actions must be != 0; if you ''have nothing to store, actions such as store ''true or store const may be more appropriate'nargs must be %r to supply const_StoreConstAction_StoreTrueAction_StoreFalseAction_AppendActionnargs for append actions must be != 0; if arg strings are not supplying the value to append, the append const action may be more appropriate'nargs for append actions must be != 0; if arg ''strings are not supplying the value to append, ''the append const action may be more appropriate'_AppendConstAction_CountAction_HelpActionprint_help_VersionActionshow program's version number and exit_get_formatter_print_message_SubParsersAction_ChoicesPseudoActionsupparser_class_prog_prefix_parser_class_name_parser_map_choices_actionsadd_parserconflicting subparser: %sconflicting subparser alias: %schoice_actionparser_nameunknown parser %(parser_name)r (choices: %(choices)s)parse_known_argssubnamespace_ExtendActionFactory for creating file object types

    Instances of FileType are typically passed as type= arguments to the
    ArgumentParser add_argument() method.

    Keyword Arguments:
        - mode -- A string indicating how the file is to be opened. Accepts the
            same values as the builtin open() function.
        - bufsize -- The file's desired buffer size. Accepts the same values as
            the builtin open() function.
        - encoding -- The file's encoding. Accepts the same values as the
            builtin open() function.
        - errors -- A string indicating how encoding and decoding errors are to
            be handled. Accepts the same value as the builtin open() function.
    bufsize_bufsize_encoding_errorswaxargument "-" with mode %rcan't open '%(filename)s': %(error)sargs_strSimple object for storing attributes.

    Implements equality by attribute names and values, and provides a simple
    string representation.
    _ActionsContainerprefix_charsargument_defaultconflict_handler_registriesstore_conststore_truestore_falseappend_const_get_handler_actions_option_string_actions_action_groups_mutually_exclusive_groups^-\d+$|^-\d*\.\d+$_negative_number_matcher_has_negative_number_optionalsregistry_nameregistry_registry_getset_defaultsget_default
        add_argument(dest, ..., name=value, ...)
        add_argument(option_string, option_string, ..., name=value, ...)
        dest supplied twice for positional argument_get_positional_kwargs_get_optional_kwargs_pop_action_classaction_classunknown action "%s"type_func%r is not callable%r is a FileType class object, instance of it must be passed'%r is a FileType class object, instance of it'' must be passed'length of metavar tuple does not match nargs_add_actionadd_argument_group_ArgumentGroup_MutuallyExclusiveGroup_check_conflictcontainer_remove_action_add_container_actionstitle_group_mapcannot merge actions - two groups are named %rgroup_mapmutex_group'required' is an invalid argument for positionalslong_option_stringsoptioninvalid option string %(option)r: must start with a character %(prefix_chars)r'invalid option string %(option)r: ''must start with a character %(prefix_chars)r'dest_option_stringdest= is required for options like %r_handle_conflict_%shandler_func_nameinvalid conflict_resolution value: %rconfl_optionalsconfl_optional_handle_conflict_errorconflicting_actionsconflicting option string: %sconflicting option strings: %sconflict_string_handle_conflict_resolvesuper_initNesting argument groups is deprecated._containermutually exclusive arguments must be optionalNesting mutually exclusive groups is deprecated.Object for parsing command line strings into Python objects.

    Keyword Arguments:
        - prog -- The name of the program (default:
            ``os.path.basename(sys.argv[0])``)
        - usage -- A usage message (default: auto-generated from arguments)
        - description -- A description of what the program does
        - epilog -- Text following the argument descriptions
        - parents -- Parsers whose arguments should be copied into this one
        - formatter_class -- HelpFormatter class for printing help messages
        - prefix_chars -- Characters that prefix optional arguments
        - fromfile_prefix_chars -- Characters that prefix files containing
            additional arguments
        - argument_default -- The default value for all arguments
        - conflict_handler -- String indicating how to handle conflicts
        - add_help -- Add a -h/-help option
        - allow_abbrev -- Allow long options to be abbreviated unambiguously
        - exit_on_error -- Determines whether or not ArgumentParser exits with
            error info when an error occurs
    epilogformatter_classfromfile_prefix_charsadd_helpallow_abbrevexit_on_errorsuperinitadd_grouppositional arguments_positionalsoptions_optionals_subparsersidentitydefault_prefixshow this help message and exitadd_subparserscannot have multiple subparser argumentssubcommands_get_positional_actionsparsers_class_get_optional_actionsunrecognized arguments: %s_parse_known_args_read_args_from_filesaction_conflictsmutex_actionconflictsoption_string_indicesarg_string_pattern_partsarg_strings_iterarg_string_parse_optionaloption_tupleOarg_strings_patternseen_actionsseen_non_default_actionstake_actionargument_strings_get_valuesargument_valuesconflict_actionnot allowed with argument %saction_nameconsume_optionalstart_indexexplicit_arg_match_argumentmatch_argumentaction_tuplesextrasarg_countignored explicit argument %roptionals_mapselected_patternsconsume_positionals_match_arguments_partialmatch_partialselected_patternarg_countsmax_option_string_indexnext_option_string_indexpositionals_end_indexstringsstop_indexrequired_actions_get_valuethe following arguments are required: %sone of the arguments %s is requirednew_arg_stringsargs_filearg_lineconvert_arg_line_to_args_get_nargs_patternnargs_patternexpected one argumentexpected at most one argumentexpected at least one argumentnargs_errorsexpected %s argumentexpected %s argumentsactions_slice_get_option_tuplesoption_tuplesambiguous option: %(option)s could match %(matches)soption_prefixshort_option_prefixshort_explicit_argunexpected option string: %s(-*A-*)(-*A?-*)(-*[A-]*)(-*A[A-]*)([-AO]*)(-*A[-AO]*)(-*-*)(-*%s-*)-*parse_intermixed_argsparse_known_intermixed_argsparse_intermixed_args: positional arg with nargs=%s'parse_intermixed_args: positional arg'' with nargs=%s'parse_intermixed_args: positional in mutuallyExclusiveGroup'parse_intermixed_args: positional in'' mutuallyExclusiveGroup'save_usagesave_nargssave_defaultremaining_argsDo not expect %s in %ssave_required_check_valueinvalid %(type)s value: %(value)rinvalid choice: %(value)r (choose from %(choices)s)action_groupprint_usageerror(message: string)

        Prints a usage message incorporating the message to stderr and
        exits.

        If you override this in a subclass, it should not return -- it
        should either exit or raise an exception.
        %(prog)s: error: %(message)s
# Author: Steven J. Bethard <steven.bethard@gmail.com>.# New maintainer as of 29 August 2019:  Raymond Hettinger <raymond.hettinger@gmail.com># =============================# Utility functions and classes# The copy module is used only in the 'append' and 'append_const'# actions, and it is needed only when the default value isn't a list.# Delay its import for speeding up the common case.# ===============# Formatting Help# default setting for width# ===============================# Section and indentation methods# format the indented section# return nothing if the section was empty# add the heading if the section was non-empty# join the section-initial newline, the heading and the help# ========================# Message building methods# find all invocations# update the maximum item length# add the item to the list# =======================# Help-formatting methods# if usage is specified, use that# if no optionals or positionals are available, usage is just prog# if optionals and positionals are available, calculate usage# split optionals from positionals# build full usage string# wrap the usage parts if it's too long# break usage into wrappable parts# helper for wrapping lines# if prog is short, follow it with optionals or positionals# if prog is long, put it on its own line# join lines into usage# prefix with 'usage:'# find group indices and identify actions in groups# collect all actions format strings# suppressed arguments are marked with None# remove | separators for suppressed arguments# produce all arg strings# if it's in a group, strip the outer []# add the action string to the list# produce the first way to invoke the option in brackets# if the Optional doesn't take a value, format is:#    -s or --long# if the Optional takes a value, format is:#    -s ARGS or --long ARGS# make it look optional if it's not required or in a group# insert things at the necessary indices# join all the action items with spaces# clean up separators for mutually exclusive groups# return the text# determine the required width and the entry label# no help; start on same line and add a final newline# short action name; start on the same line and pad two spaces# long action name; start on the next line# collect the pieces of the action help# if there was help for the action, add lines of help text# or add a newline if the description doesn't end with one# if there are any sub-actions, add their help as well# return a single string#    -s, --long#    -s ARGS, --long ARGS# The textwrap module is used only for formatting help.# Delay its import for speeding up the common usage of argparse.# =====================# Options and Arguments# ==============# Action classes# FIXME: remove together with `BooleanOptionalAction` deprecated arguments.# We need `_deprecated` special value to ban explicit arguments that# match default value. Like:#   parser.add_argument('-f', action=BooleanOptionalAction, type=int)# set prog from the existing prefix# create a pseudo-action to hold the choice help# create the parser and add it to the map# make parser available under aliases also# set the parser name if requested# select the parser# parse all the remaining options into the namespace# store any unrecognized options on the object, so that the top# level parser can decide what to do with them# In case this subparser defines new defaults, we parse them# in a new namespace object and then update the original# namespace for the relevant parts.# Type classes# the special argument "-" means sys.std{in,out}# all other arguments are used as file names# ===========================# Optional and Positional Parsing# set up registries# register actions# raise an exception if the conflict handler is invalid# action storage# groups# defaults storage# determines whether an "option" looks like a negative number# whether or not there are any optionals that look like negative# numbers -- uses a list so it can be shared and edited# ====================# Registration methods# ==================================# Namespace default accessor methods# if these defaults match any existing arguments, replace# the previous default on the object with the new one# Adding argument actions# if no positional args are supplied or only one is supplied and# it doesn't look like an option string, parse a positional# argument# otherwise, we're adding an optional argument# if no default was supplied, use the parser-level default# create the action object, and add it to the parser# raise an error if the action type is not callable# raise an error if the metavar does not match the type# resolve any conflicts# add to actions list# index the action by any option strings it has# set the flag if any option strings look like negative numbers# return the created action# collect groups by titles# map each action to its group# if a group with the title exists, use that, otherwise# create a new group matching the container's group# map the actions to their new group# add container's mutually exclusive groups# NOTE: if add_mutually_exclusive_group ever gains title= and# description= then this code will need to be expanded as above# map the actions to their new mutex group# add all actions to this container or their group# make sure required is not specified# mark positional arguments as required if at least one is# always required# return the keyword arguments with no option strings# determine short and long option strings# error on strings that don't start with an appropriate prefix# strings starting with two prefix characters are long options# infer destination, '--foo-bar' -> 'foo_bar' and '-x' -> 'x'# return the updated keyword arguments# determine function from conflict handler string# find all options that conflict with this option# remove all conflicting options# remove the conflicting option# if the option now has no option string, remove it from the# container holding it# add any missing keyword arguments by checking the container# group attributes# share most attributes with the container# default setting for prog# register types# add help argument if necessary# (using explicit default to override global argument_default)# add parent arguments and defaults# Pretty __repr__ methods# Optional/Positional adding methods# add the parser class to the arguments if it's not present# prog defaults to the usage message of this parser, skipping# optional arguments and with no "usage:" prefix# create the parsers action and add it to the positionals list# return the created parsers action# =====================================# Command line argument parsing methods# args default to the system args# make sure that args are mutable# default Namespace built from parser defaults# add any action defaults that aren't present# add any parser defaults that aren't present# parse the arguments and exit if there are any errors# replace arg strings that are file references# map all mutually exclusive arguments to the other arguments# they can't occur with# find all option indices, and determine the arg_string_pattern# which has an 'O' if there is an option at an index,# an 'A' if there is an argument, or a '-' if there is a '--'# all args after -- are non-options# otherwise, add the arg to the arg strings# and note the index if it was an option# join the pieces together to form the pattern# converts arg strings to the appropriate and then takes the action# error if this argument is not allowed with other previously# seen arguments, assuming that actions that use the default# value don't really count as "present"# take the action if we didn't receive a SUPPRESS value# (e.g. from a default)# function to convert arg_strings into an optional action# get the optional identified at this index# identify additional optionals in the same arg string# (e.g. -xyz is the same as -x -y -z if no args are required)# if we found no optional action, skip it# if there is an explicit argument, try to match the# optional's string arguments to only this# if the action is a single-dash option and takes no# arguments, try to parse more single-dash options out# of the tail of the option string# if the action expect exactly one argument, we've# successfully matched the option; exit the loop# error if a double-dash option did not use the# explicit argument# if there is no explicit argument, try to match the# optional's string arguments with the following strings# if successful, exit the loop# add the Optional to the list and return the index at which# the Optional's string args stopped# the list of Positionals left to be parsed; this is modified# by consume_positionals()# function to convert arg_strings into positional actions# match as many Positionals as possible# slice off the appropriate arg strings for each Positional# and add the Positional and its args to the list# slice off the Positionals that we just parsed and return the# index at which the Positionals' string args stopped# consume Positionals and Optionals alternately, until we have# passed the last option string# consume any Positionals preceding the next option# only try to parse the next optional if we didn't consume# the option string during the positionals parsing# if we consumed all the positionals we could and we're not# at the index of an option string, there were extra arguments# consume the next optional and any arguments for it# consume any positionals following the last Optional# if we didn't consume all the argument strings, there were extras# make sure all required actions were present and also convert# action defaults which were not given as arguments# Convert action default now instead of doing it before# parsing arguments to avoid calling convert functions# twice (which may fail) if the argument was given, but# only if it was defined already in the namespace# make sure all required groups had one option present# if no actions were used, report the error# return the updated namespace and the extra arguments# expand arguments referencing files# for regular arguments, just add them back into the list# replace arguments referencing files with the file content# return the modified argument list# match the pattern for this action to the arg strings# raise an exception if we weren't able to find a match# return the number of arguments matched# progressively shorten the actions list by slicing off the# final actions until we find a match# return the list of arg string counts# if it's an empty string, it was meant to be a positional# if it doesn't start with a prefix, it was meant to be positional# if the option string is present in the parser, return the action# if it's just a single character, it was meant to be positional# if the option string before the "=" is present, return the action# search through all possible prefixes of the option string# and all actions in the parser for possible interpretations# if multiple actions match, the option string was ambiguous# if exactly one action matched, this segmentation is good,# so return the parsed action# if it was not found as an option, but it looks like a negative# number, it was meant to be positional# unless there are negative-number-like options# if it contains a space, it was meant to be a positional# it was meant to be an optional but there is no such option# in this parser (though it might be a valid option in a subparser)# option strings starting with two prefix characters are only# split at the '='# single character options can be concatenated with their arguments# but multiple character options always have to have their argument# separate# shouldn't ever get here# return the collected option tuples# in all examples below, we have to allow for '--' args# which are represented as '-' in the pattern# the default (None) is assumed to be a single argument# allow zero or one arguments# allow zero or more arguments# allow one or more arguments# allow any number of options or arguments# allow one argument followed by any number of options or arguments# suppress action, like nargs=0# all others should be integers# if this is an optional action, -- is not allowed# return the pattern# Alt command line argument parsing, allowing free intermix# returns a namespace and list of extras# positional can be freely intermixed with optionals.  optionals are# first parsed with all positional arguments deactivated.  The 'extras'# are then parsed.  If the parser definition is incompatible with the# intermixed assumptions (e.g. use of REMAINDER, subparsers) a# TypeError is raised.# positionals are 'deactivated' by setting nargs and default to# SUPPRESS.  This blocks the addition of that positional to the# namespace# capture the full usage for use in error messages# deactivate positionals# action.nargs = 0# remove the empty positional values from namespace# restore nargs and usage before exiting# parse positionals.  optionals aren't normally required, but# they could be, so make sure they aren't.# restore parser values before exiting# Value conversion methods# for everything but PARSER, REMAINDER args, strip out first '--'# optional argument produces a default when not present# when nargs='*' on a positional, if there were no command-line# args, use the default if it is anything other than None# since arg_strings is always [] at this point# there is no need to use self._check_value(action, value)# single argument or optional argument produces a single value# REMAINDER arguments convert all values, checking none# PARSER arguments convert all values, but check only the first# SUPPRESS argument does not put anything in the namespace# all other types of nargs produce a list# return the converted value# convert the value to the appropriate type# ArgumentTypeErrors indicate errors# TypeErrors or ValueErrors also indicate errors# converted value must be one of the choices (if specified)# usage# description# positionals, optionals and user-defined groups# epilog# determine help from format above# Help-printing methods# Exiting methodsb'Command-line parsing library

This module is an optparse-inspired command-line parsing library that:

    - handles both optional and positional arguments
    - produces highly informative usage messages
    - supports parsers that dispatch to sub-parsers

The following is a simple usage example that sums integers from the
command-line and writes the result to a file::

    parser = argparse.ArgumentParser(
        description='sum the integers at the command line')
    parser.add_argument(
        'integers', metavar='int', nargs='+', type=int,
        help='an integer to be summed')
    parser.add_argument(
        '--log', default=sys.stdout, type=argparse.FileType('w'),
        help='the file where the sum should be written')
    args = parser.parse_args()
    args.log.write('%s' % sum(args.integers))
    args.log.close()

The module contains the following public classes:

    - ArgumentParser -- The main entry point for command-line parsing. As the
        example above shows, the add_argument() method is used to populate
        the parser with actions for optional and positional arguments. Then
        the parse_args() method is invoked to convert the args at the
        command-line into an object with attributes.

    - ArgumentError -- The exception raised by ArgumentParser objects when
        there are errors with the parser's actions. Errors raised while
        parsing the command-line are caught by ArgumentParser and emitted
        as command-line messages.

    - FileType -- A factory for defining types of files to be created. As the
        example above shows, instances of FileType are typically passed as
        the type= argument of add_argument() calls.

    - Action -- The base class for parser actions. Typically actions are
        selected by passing strings like 'store_true' or 'append_const' to
        the action= argument of add_argument(). However, for greater
        customization of ArgumentParser actions, subclasses of Action may
        be defined and passed as the action= argument.

    - HelpFormatter, RawDescriptionHelpFormatter, RawTextHelpFormatter,
        ArgumentDefaultsHelpFormatter -- Formatter classes which
        may be passed as the formatter_class= argument to the
        ArgumentParser constructor. HelpFormatter is the default,
        RawDescriptionHelpFormatter and RawTextHelpFormatter tell the parser
        not to change the formatting for help text, and
        ArgumentDefaultsHelpFormatter adds information about argument defaults
        to the help.

All other classes in this module are considered implementation details.
(Also note that HelpFormatter and RawDescriptionHelpFormatter are only
considered public as object names -- the API of the formatter objects is
still considered an implementation detail.)
'u'Command-line parsing library

This module is an optparse-inspired command-line parsing library that:

    - handles both optional and positional arguments
    - produces highly informative usage messages
    - supports parsers that dispatch to sub-parsers

The following is a simple usage example that sums integers from the
command-line and writes the result to a file::

    parser = argparse.ArgumentParser(
        description='sum the integers at the command line')
    parser.add_argument(
        'integers', metavar='int', nargs='+', type=int,
        help='an integer to be summed')
    parser.add_argument(
        '--log', default=sys.stdout, type=argparse.FileType('w'),
        help='the file where the sum should be written')
    args = parser.parse_args()
    args.log.write('%s' % sum(args.integers))
    args.log.close()

The module contains the following public classes:

    - ArgumentParser -- The main entry point for command-line parsing. As the
        example above shows, the add_argument() method is used to populate
        the parser with actions for optional and positional arguments. Then
        the parse_args() method is invoked to convert the args at the
        command-line into an object with attributes.

    - ArgumentError -- The exception raised by ArgumentParser objects when
        there are errors with the parser's actions. Errors raised while
        parsing the command-line are caught by ArgumentParser and emitted
        as command-line messages.

    - FileType -- A factory for defining types of files to be created. As the
        example above shows, instances of FileType are typically passed as
        the type= argument of add_argument() calls.

    - Action -- The base class for parser actions. Typically actions are
        selected by passing strings like 'store_true' or 'append_const' to
        the action= argument of add_argument(). However, for greater
        customization of ArgumentParser actions, subclasses of Action may
        be defined and passed as the action= argument.

    - HelpFormatter, RawDescriptionHelpFormatter, RawTextHelpFormatter,
        ArgumentDefaultsHelpFormatter -- Formatter classes which
        may be passed as the formatter_class= argument to the
        ArgumentParser constructor. HelpFormatter is the default,
        RawDescriptionHelpFormatter and RawTextHelpFormatter tell the parser
        not to change the formatting for help text, and
        ArgumentDefaultsHelpFormatter adds information about argument defaults
        to the help.

All other classes in this module are considered implementation details.
(Also note that HelpFormatter and RawDescriptionHelpFormatter are only
considered public as object names -- the API of the formatter objects is
still considered an implementation detail.)
'b'1.1'u'1.1'b'ArgumentParser'u'ArgumentParser'b'ArgumentError'u'ArgumentError'b'ArgumentTypeError'u'ArgumentTypeError'b'BooleanOptionalAction'u'BooleanOptionalAction'b'FileType'u'FileType'b'HelpFormatter'u'HelpFormatter'b'ArgumentDefaultsHelpFormatter'u'ArgumentDefaultsHelpFormatter'b'RawDescriptionHelpFormatter'u'RawDescriptionHelpFormatter'b'RawTextHelpFormatter'u'RawTextHelpFormatter'b'MetavarTypeHelpFormatter'u'MetavarTypeHelpFormatter'b'Namespace'u'Namespace'b'Action'u'Action'b'ONE_OR_MORE'u'ONE_OR_MORE'b'OPTIONAL'u'OPTIONAL'b'PARSER'u'PARSER'b'REMAINDER'u'REMAINDER'b'SUPPRESS'u'SUPPRESS'b'ZERO_OR_MORE'u'ZERO_OR_MORE'b'==SUPPRESS=='u'==SUPPRESS=='b'A...'u'A...'b'_unrecognized_args'u'_unrecognized_args'b'Abstract base class that provides __repr__.

    The __repr__ method returns a string in the format::
        ClassName(attr=name, attr=name, ...)
    The attributes are determined either by a class-level attribute,
    '_kwarg_names', or by inspecting the instance __dict__.
    'u'Abstract base class that provides __repr__.

    The __repr__ method returns a string in the format::
        ClassName(attr=name, attr=name, ...)
    The attributes are determined either by a class-level attribute,
    '_kwarg_names', or by inspecting the instance __dict__.
    'b'%s=%r'u'%s=%r'b'**%s'u'**%s'b'%s(%s)'u'%s(%s)'b'Formatter for generating usage messages and argument help strings.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    'u'Formatter for generating usage messages and argument help strings.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    'b'\s+'u'\s+'b'\n\n\n+'u'\n\n\n+'b'Indent decreased below 0.'u'Indent decreased below 0.'b'%(heading)s:'u'%(heading)s:'b'%*s%s
'u'%*s%s
'b'

'u'

'b'usage: 'u'usage: 'b'%(prog)s'u'%(prog)s'b'\(.*?\)+(?=\s|$)|\[.*?\]+(?=\s|$)|\S+'u'\(.*?\)+(?=\s|$)|\[.*?\]+(?=\s|$)|\S+'b'%s%s

'u'%s%s

'b'empty group 'u'empty group 'b' ['u' ['b'%s %s'u'%s %s'b'[\[(]'u'[\[(]'b'[\])]'u'[\])]'b'(%s) 'u'(%s) 'b'\1'u'\1'b' (%s)'u' (%s)'b'%s *%s'u'%s *%s'b'%(prog)'u'%(prog)'b'%*s%-*s  'u'%*s%-*s  'b'{%s}'u'{%s}'b'%s'u'%s'b'[%s [%s ...]]'u'[%s [%s ...]]'b'[%s ...]'u'[%s ...]'b'%s [%s ...]'u'%s [%s ...]'b'%s ...'u'%s ...'b'invalid nargs value'u'invalid nargs value'b'choices'u'choices'b'Help message formatter which retains any formatting in descriptions.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    'u'Help message formatter which retains any formatting in descriptions.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    'b'Help message formatter which retains formatting of all help text.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    'u'Help message formatter which retains formatting of all help text.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    'b'Help message formatter which adds default values to argument help.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    'u'Help message formatter which adds default values to argument help.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    'b'
        Add the default value to the option help message.

        ArgumentDefaultsHelpFormatter and BooleanOptionalAction when it isn't
        already present. This code will do that, detecting cornercases to
        prevent duplicates or cases where it wouldn't make sense to the end
        user.
        'u'
        Add the default value to the option help message.

        ArgumentDefaultsHelpFormatter and BooleanOptionalAction when it isn't
        already present. This code will do that, detecting cornercases to
        prevent duplicates or cases where it wouldn't make sense to the end
        user.
        'b'%(default)'u'%(default)'b' (default: %(default)s)'u' (default: %(default)s)'b'Help message formatter which uses the argument 'type' as the default
    metavar value (instead of the argument 'dest')

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    'u'Help message formatter which uses the argument 'type' as the default
    metavar value (instead of the argument 'dest')

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    'b'An error from creating or using an argument (optional or positional).

    The string value of this exception is the message, augmented with
    information about the argument that caused it.
    'u'An error from creating or using an argument (optional or positional).

    The string value of this exception is the message, augmented with
    information about the argument that caused it.
    'b'argument %(argument_name)s: %(message)s'u'argument %(argument_name)s: %(message)s'b'An error from trying to convert a command line string to a type.'u'An error from trying to convert a command line string to a type.'b'Information about how to convert command line strings to Python objects.

    Action objects are used by an ArgumentParser to represent the information
    needed to parse a single argument from one or more strings from the
    command line. The keyword arguments to the Action constructor are also
    all attributes of Action instances.

    Keyword Arguments:

        - option_strings -- A list of command-line option strings which
            should be associated with this action.

        - dest -- The name of the attribute to hold the created object(s)

        - nargs -- The number of command-line arguments that should be
            consumed. By default, one argument will be consumed and a single
            value will be produced.  Other values include:
                - N (an integer) consumes N arguments (and produces a list)
                - '?' consumes zero or one arguments
                - '*' consumes zero or more arguments (and produces a list)
                - '+' consumes one or more arguments (and produces a list)
            Note that the difference between the default and nargs=1 is that
            with the default, a single value will be produced, while with
            nargs=1, a list containing a single value will be produced.

        - const -- The value to be produced if the option is specified and the
            option uses an action that takes no values.

        - default -- The value to be produced if the option is not specified.

        - type -- A callable that accepts a single string argument, and
            returns the converted value.  The standard Python types str, int,
            float, and complex are useful examples of such callables.  If None,
            str is used.

        - choices -- A container of values that should be allowed. If not None,
            after a command-line argument has been converted to the appropriate
            type, an exception will be raised if it is not a member of this
            collection.

        - required -- True if the action must always be specified at the
            command line. This is only meaningful for optional command-line
            arguments.

        - help -- The help string describing the argument.

        - metavar -- The name to be used for the option's argument with the
            help string. If None, the 'dest' value will be used as the name.
    'u'Information about how to convert command line strings to Python objects.

    Action objects are used by an ArgumentParser to represent the information
    needed to parse a single argument from one or more strings from the
    command line. The keyword arguments to the Action constructor are also
    all attributes of Action instances.

    Keyword Arguments:

        - option_strings -- A list of command-line option strings which
            should be associated with this action.

        - dest -- The name of the attribute to hold the created object(s)

        - nargs -- The number of command-line arguments that should be
            consumed. By default, one argument will be consumed and a single
            value will be produced.  Other values include:
                - N (an integer) consumes N arguments (and produces a list)
                - '?' consumes zero or one arguments
                - '*' consumes zero or more arguments (and produces a list)
                - '+' consumes one or more arguments (and produces a list)
            Note that the difference between the default and nargs=1 is that
            with the default, a single value will be produced, while with
            nargs=1, a list containing a single value will be produced.

        - const -- The value to be produced if the option is specified and the
            option uses an action that takes no values.

        - default -- The value to be produced if the option is not specified.

        - type -- A callable that accepts a single string argument, and
            returns the converted value.  The standard Python types str, int,
            float, and complex are useful examples of such callables.  If None,
            str is used.

        - choices -- A container of values that should be allowed. If not None,
            after a command-line argument has been converted to the appropriate
            type, an exception will be raised if it is not a member of this
            collection.

        - required -- True if the action must always be specified at the
            command line. This is only meaningful for optional command-line
            arguments.

        - help -- The help string describing the argument.

        - metavar -- The name to be used for the option's argument with the
            help string. If None, the 'dest' value will be used as the name.
    'b'option_strings'u'option_strings'b'dest'u'dest'b'nargs'u'nargs'b'const'u'const'b'default'b'required'u'required'b'help'u'help'b'metavar'u'metavar'b'.__call__() not defined'u'.__call__() not defined'b'--'u'--'b'--no-'u'--no-'b'{name!r} is deprecated as of Python 3.12 and will be removed in Python {remove}.'u'{name!r} is deprecated as of Python 3.12 and will be removed in Python {remove}.'b' | 'u' | 'b'nargs for store actions must be != 0; if you have nothing to store, actions such as store true or store const may be more appropriate'u'nargs for store actions must be != 0; if you have nothing to store, actions such as store true or store const may be more appropriate'b'nargs must be %r to supply const'u'nargs must be %r to supply const'b'nargs for append actions must be != 0; if arg strings are not supplying the value to append, the append const action may be more appropriate'u'nargs for append actions must be != 0; if arg strings are not supplying the value to append, the append const action may be more appropriate'b'show program's version number and exit'u'show program's version number and exit'b'prog'u'prog'b'aliases'b'conflicting subparser: %s'u'conflicting subparser: %s'b'conflicting subparser alias: %s'u'conflicting subparser alias: %s'b'parser_name'u'parser_name'b'unknown parser %(parser_name)r (choices: %(choices)s)'u'unknown parser %(parser_name)r (choices: %(choices)s)'b'Factory for creating file object types

    Instances of FileType are typically passed as type= arguments to the
    ArgumentParser add_argument() method.

    Keyword Arguments:
        - mode -- A string indicating how the file is to be opened. Accepts the
            same values as the builtin open() function.
        - bufsize -- The file's desired buffer size. Accepts the same values as
            the builtin open() function.
        - encoding -- The file's encoding. Accepts the same values as the
            builtin open() function.
        - errors -- A string indicating how encoding and decoding errors are to
            be handled. Accepts the same value as the builtin open() function.
    'u'Factory for creating file object types

    Instances of FileType are typically passed as type= arguments to the
    ArgumentParser add_argument() method.

    Keyword Arguments:
        - mode -- A string indicating how the file is to be opened. Accepts the
            same values as the builtin open() function.
        - bufsize -- The file's desired buffer size. Accepts the same values as
            the builtin open() function.
        - encoding -- The file's encoding. Accepts the same values as the
            builtin open() function.
        - errors -- A string indicating how encoding and decoding errors are to
            be handled. Accepts the same value as the builtin open() function.
    'b'wax'u'wax'b'argument "-" with mode %r'u'argument "-" with mode %r'b'can't open '%(filename)s': %(error)s'u'can't open '%(filename)s': %(error)s'b'Simple object for storing attributes.

    Implements equality by attribute names and values, and provides a simple
    string representation.
    'u'Simple object for storing attributes.

    Implements equality by attribute names and values, and provides a simple
    string representation.
    'b'action'u'action'b'store_const'u'store_const'b'store_true'u'store_true'b'store_false'u'store_false'b'append'u'append'b'append_const'u'append_const'b'count'u'count'b'version'b'extend'u'extend'b'^-\d+$|^-\d*\.\d+$'u'^-\d+$|^-\d*\.\d+$'b'
        add_argument(dest, ..., name=value, ...)
        add_argument(option_string, option_string, ..., name=value, ...)
        'u'
        add_argument(dest, ..., name=value, ...)
        add_argument(option_string, option_string, ..., name=value, ...)
        'b'dest supplied twice for positional argument'u'dest supplied twice for positional argument'b'unknown action "%s"'u'unknown action "%s"'b'%r is not callable'u'%r is not callable'b'%r is a FileType class object, instance of it must be passed'u'%r is a FileType class object, instance of it must be passed'b'_get_formatter'u'_get_formatter'b'length of metavar tuple does not match nargs'u'length of metavar tuple does not match nargs'b'cannot merge actions - two groups are named %r'u'cannot merge actions - two groups are named %r'b''required' is an invalid argument for positionals'u''required' is an invalid argument for positionals'b'option'u'option'b'prefix_chars'u'prefix_chars'b'invalid option string %(option)r: must start with a character %(prefix_chars)r'u'invalid option string %(option)r: must start with a character %(prefix_chars)r'b'dest= is required for options like %r'u'dest= is required for options like %r'b'_handle_conflict_%s'u'_handle_conflict_%s'b'invalid conflict_resolution value: %r'u'invalid conflict_resolution value: %r'b'conflicting option string: %s'u'conflicting option string: %s'b'conflicting option strings: %s'u'conflicting option strings: %s'b'conflict_handler'u'conflict_handler'b'argument_default'u'argument_default'b'Nesting argument groups is deprecated.'u'Nesting argument groups is deprecated.'b'mutually exclusive arguments must be optional'u'mutually exclusive arguments must be optional'b'Nesting mutually exclusive groups is deprecated.'u'Nesting mutually exclusive groups is deprecated.'b'Object for parsing command line strings into Python objects.

    Keyword Arguments:
        - prog -- The name of the program (default:
            ``os.path.basename(sys.argv[0])``)
        - usage -- A usage message (default: auto-generated from arguments)
        - description -- A description of what the program does
        - epilog -- Text following the argument descriptions
        - parents -- Parsers whose arguments should be copied into this one
        - formatter_class -- HelpFormatter class for printing help messages
        - prefix_chars -- Characters that prefix optional arguments
        - fromfile_prefix_chars -- Characters that prefix files containing
            additional arguments
        - argument_default -- The default value for all arguments
        - conflict_handler -- String indicating how to handle conflicts
        - add_help -- Add a -h/-help option
        - allow_abbrev -- Allow long options to be abbreviated unambiguously
        - exit_on_error -- Determines whether or not ArgumentParser exits with
            error info when an error occurs
    'u'Object for parsing command line strings into Python objects.

    Keyword Arguments:
        - prog -- The name of the program (default:
            ``os.path.basename(sys.argv[0])``)
        - usage -- A usage message (default: auto-generated from arguments)
        - description -- A description of what the program does
        - epilog -- Text following the argument descriptions
        - parents -- Parsers whose arguments should be copied into this one
        - formatter_class -- HelpFormatter class for printing help messages
        - prefix_chars -- Characters that prefix optional arguments
        - fromfile_prefix_chars -- Characters that prefix files containing
            additional arguments
        - argument_default -- The default value for all arguments
        - conflict_handler -- String indicating how to handle conflicts
        - add_help -- Add a -h/-help option
        - allow_abbrev -- Allow long options to be abbreviated unambiguously
        - exit_on_error -- Determines whether or not ArgumentParser exits with
            error info when an error occurs
    'b'positional arguments'u'positional arguments'b'options'u'options'b'h'u'h'b'show this help message and exit'u'show this help message and exit'b'usage'u'usage'b'description'u'description'b'formatter_class'u'formatter_class'b'add_help'u'add_help'b'cannot have multiple subparser arguments'u'cannot have multiple subparser arguments'b'parser_class'u'parser_class'b'title'u'title'b'subcommands'u'subcommands'b'unrecognized arguments: %s'u'unrecognized arguments: %s'b'O'u'O'b'not allowed with argument %s'u'not allowed with argument %s'b'ignored explicit argument %r'u'ignored explicit argument %r'b'the following arguments are required: %s'u'the following arguments are required: %s'b'one of the arguments %s is required'u'one of the arguments %s is required'b'expected one argument'u'expected one argument'b'expected at most one argument'u'expected at most one argument'b'expected at least one argument'u'expected at least one argument'b'expected %s argument'u'expected %s argument'b'expected %s arguments'u'expected %s arguments'b'matches'u'matches'b'ambiguous option: %(option)s could match %(matches)s'u'ambiguous option: %(option)s could match %(matches)s'b'unexpected option string: %s'u'unexpected option string: %s'b'(-*A-*)'u'(-*A-*)'b'(-*A?-*)'u'(-*A?-*)'b'(-*[A-]*)'u'(-*[A-]*)'b'(-*A[A-]*)'u'(-*A[A-]*)'b'([-AO]*)'u'([-AO]*)'b'(-*A[-AO]*)'u'(-*A[-AO]*)'b'(-*-*)'u'(-*-*)'b'(-*%s-*)'u'(-*%s-*)'b'-*'u'-*'b'parse_intermixed_args: positional arg with nargs=%s'u'parse_intermixed_args: positional arg with nargs=%s'b'parse_intermixed_args: positional in mutuallyExclusiveGroup'u'parse_intermixed_args: positional in mutuallyExclusiveGroup'b'Do not expect %s in %s'u'Do not expect %s in %s'b'value'b'invalid %(type)s value: %(value)r'u'invalid %(type)s value: %(value)r'b'invalid choice: %(value)r (choose from %(choices)s)'u'invalid choice: %(value)r (choose from %(choices)s)'b'error(message: string)

        Prints a usage message incorporating the message to stderr and
        exits.

        If you override this in a subclass, it should not return -- it
        should either exit or raise an exception.
        'u'error(message: string)

        Prints a usage message incorporating the message to stderr and
        exits.

        If you override this in a subclass, it should not return -- it
        should either exit or raise an exception.
        'b'%(prog)s: error: %(message)s
'u'%(prog)s: error: %(message)s
'u'Lib.argparse'u'argparse'dateutilgettzAmerica/New_YorktzNYCtzUTCbenchmark_arithmetic_0tomorrowbenchmark_arithmetic_1benchmark_arithmetic_21.5a_bit_laterbenchmark_arithmetic_3benchmark_arithmetic_4now_copy_onenow_copy_tworun_benchmarks_naive_utc_localbenchmarksbenchmark# assuming integer number of hours diff# precision differenceb'America/New_York'u'America/New_York'u'Temp.date_time.benchmarks.arithmetic'u'Temp.date_time.benchmarks'u'Temp.date_time'u'Temp'u'date_time.benchmarks.arithmetic'u'date_time.benchmarks'u'benchmarks.arithmetic'u'benchmarks'u'arithmetic'u'array(typecode [, initializer]) -> array

Return a new array whose items are restricted by typecode, and
initialized from the optional initializer value, which must be a list,
string or iterable over elements of the appropriate type.

Arrays represent basic values and behave very much like lists, except
the type of objects stored in them is constrained. The type is specified
at object creation time by using a type code, which is a single character.
The following type codes are defined:

    Type code   C Type             Minimum size in bytes
    'b'         signed integer     1
    'B'         unsigned integer   1
    'u'         Unicode character  2 (see note)
    'h'         signed integer     2
    'H'         unsigned integer   2
    'i'         signed integer     2
    'I'         unsigned integer   2
    'l'         signed integer     4
    'L'         unsigned integer   4
    'q'         signed integer     8 (see note)
    'Q'         unsigned integer   8 (see note)
    'f'         floating point     4
    'd'         floating point     8

NOTE: The 'u' typecode corresponds to Python's unicode character. On
narrow builds this is 2-bytes on wide builds this is 4-bytes.

NOTE: The 'q' and 'Q' type codes are only available if the platform
C compiler used to build Python supports 'long long', or, on Windows,
'__int64'.

Methods:

append() -- append a new item to the end of the array
buffer_info() -- return information giving the current memory info
byteswap() -- byteswap all the items of the array
count() -- return number of occurrences of an object
extend() -- extend array by appending multiple elements from an iterable
fromfile() -- read items from a file object
fromlist() -- append items from the list
frombytes() -- append items from the string
index() -- return index of first occurrence of an object
insert() -- insert a new item into the array at a provided position
pop() -- remove and return item (default last)
remove() -- remove first occurrence of an object
reverse() -- reverse the order of the items in the array
tofile() -- write all items to a file object
tolist() -- return the array converted to an ordinary list
tobytes() -- return the array converted to a string

Attributes:

typecode -- the typecode character used to create the array
itemsize -- the length in bytes of one array item
'buffer_infobyteswapfrombytesfromfilefromunicodeu'the size, in bytes, of one array item'u'array.itemsize'tofiletounicodeu'the typecode character used to create the array'u'array.typecode'typecodearray.arrayArrayTypeu'This module defines an object type which can efficiently represent
an array of basic values: characters, integers, floating point
numbers.  Arrays are sequence types and behave very much like lists,
except that the type of objects stored in them is constrained.
'_array_reconstructorarrayu'bBuhHiIlLqQfd'typecodes
    ast
    ~~~

    The `ast` module helps Python applications to process trees of the Python
    abstract syntax grammar.  The abstract syntax itself might change with
    each Python release; this module helps to find out programmatically what
    the current grammar looks like and allows modifications of it.

    An abstract syntax tree can be generated by passing `ast.PyCF_ONLY_AST` as
    a flag to the `compile()` builtin function or by using the `parse()`
    function from this module.  The result will be a tree of objects whose
    classes all inherit from `ast.AST`.

    A modified abstract syntax tree can be compiled into a Python code object
    using the built-in `compile()` function.

    Additionally various helper functions are provided that make working with
    the trees simpler.  The main intention of the helper functions and this
    module in general is to provide an easy to use interface for libraries
    that work tightly with the python syntax (template engines for example).


    :copyright: Copyright 2008 by Armin Ronacher.
    :license: Python License.
nullcontexttype_commentsfeature_version
    Parse the source into an AST node.
    Equivalent to compile(source, filename, mode, PyCF_ONLY_AST).
    Pass type_comments=True to get back type comments where the syntax allows.
    Unsupported major version: _feature_versionliteral_evalnode_or_string
    Evaluate an expression node or a string containing only a Python
    expression.  The string or node provided may only consist of the following
    Python literal structures: strings, bytes, numbers, tuples, lists, dicts,
    sets, booleans, and None.

    Caution: A complex expression can overflow the C stack and cause a crash.
    _raise_malformed_nodenodemalformed node or string on line _convert_num_convert_signed_numoperand_converteltsleftrightannotate_fieldsinclude_attributes
    Return a formatted dump of the tree in node.  This is mainly useful for
    debugging purposes.  If annotate_fields is true (by default),
    the returned string will show the names and the values for fields.
    If annotate_fields is false, the result string will be more compact by
    omitting unambiguous field names.  Attributes such as line
    numbers and column offsets are not dumped by default.  If this is wanted,
    include_attributes can be set to true.  If indent is a non-negative
    integer or string, then the tree will be pretty-printed with that indent
    level. None (the default) selects the single line representation.
    ,
allsimplesimple%s=%s%s(%s%s)[][%s%s]expected AST, got %rcopy_locationnew_nodeold_node
    Copy source location (`lineno`, `col_offset`, `end_lineno`, and `end_col_offset`
    attributes) from *old_node* to *new_node* if possible, and return *new_node*.
    col_offsetend_fix_missing_locations
    When you compile a node tree with compile(), the compiler expects lineno and
    col_offset attributes for every node that supports them.  This is rather
    tedious to fill in for generated nodes, so this helper adds these attributes
    recursively where not already set, by setting them to the values of the
    parent node.  It works recursively starting at *node*.
    iter_child_nodesincrement_lineno
    Increment the line number and end line number of each node in the tree
    starting at *node* by *n*. This is useful to "move code" to a different
    location in a file.
    walkiter_fields
    Yield a tuple of ``(fieldname, value)`` for each field in ``node._fields``
    that is present on *node*.
    
    Yield all direct child nodes of *node*, that is, all fields that are nodes
    and all items of fields that are lists of nodes.
    get_docstringclean
    Return the docstring for the given node or None if no docstring can
    be found.  If the node provided does not have docstrings a TypeError
    will be raised.

    If *clean* is `True`, all tabs are expanded to spaces and any whitespace
    that can be uniformly removed from the second line onwards is removed.
    %r can't have docstringscleandoc(.*?(?:\r\n|\n|\r|$))_line_pattern_splitlines_no_ffmaxlinesSplit a string into lines ignoring form feed and other chars.

    This mimics how the Python parser splits source code.
    _pad_whitespaceReplace all chars except '\f\t' in a line with spaces.	get_source_segmentpaddedGet source code segment of the *source* that generated *node*.

    If some location information (`lineno`, `end_lineno`, `col_offset`,
    or `end_col_offset`) is missing, return None.

    If *padded* is `True`, the first line of a multi-line statement will
    be padded with spaces to match its original position.
    
    Recursively yield all descendant nodes in the tree starting at *node*
    (including *node* itself), in no specified order.  This is useful if you
    only want to modify nodes in place and don't care about the context.
    todoNodeVisitor
    A node visitor base class that walks the abstract syntax tree and calls a
    visitor function for every node found.  This function may return a value
    which is forwarded by the `visit` method.

    This class is meant to be subclassed, with the subclass adding visitor
    methods.

    Per default the visitor functions for the nodes are ``'visit_'`` +
    class name of the node.  So a `TryFinally` node visit function would
    be `visit_TryFinally`.  This behavior can be changed by overriding
    the `visit` method.  If no visitor function exists for a node
    (return value `None`) the `generic_visit` visitor is used instead.

    Don't use the `NodeVisitor` if you want to apply changes to nodes during
    traversing.  For this a special visitor exists (`NodeTransformer`) that
    allows modifications.
    visitVisit a node.visit_generic_visitvisitorCalled if no explicit visitor function exists for a node.visit_Constant_const_node_type_names is deprecated; add visit_ConstantNodeTransformer
    A :class:`NodeVisitor` subclass that walks the abstract syntax tree and
    allows modification of nodes.

    The `NodeTransformer` will walk the AST and use the return value of the
    visitor methods to replace or remove the old node.  If the return value of
    the visitor method is ``None``, the node will be removed from its location,
    otherwise it is replaced with the return value.  The return value may be the
    original node in which case no replacement takes place.

    Here is an example transformer that rewrites all occurrences of name lookups
    (``foo``) to ``data['foo']``::

       class RewriteName(NodeTransformer):

           def visit_Name(self, node):
               return Subscript(
                   value=Name(id='data', ctx=Load()),
                   slice=Constant(value=node.id),
                   ctx=node.ctx
               )

    Keep in mind that if the node you're operating on has child nodes you must
    either transform the child nodes yourself or call the :meth:`generic_visit`
    method for the node first.

    For nodes that were part of a collection of statements (that applies to all
    statement nodes), the visitor may also return a list of nodes rather than
    just a single node.

    Usually you use the transformer like this::

       node = YourTransformer().visit(node)
    new_values{name} is deprecated and will be removed in Python {remove}; use value instead_DEPRECATED_VALUE_ALIAS_MESSAGE{name} is deprecated and will be removed in Python {remove}; use ast.Constant instead"{name} is deprecated and will be removed in Python {remove}; ""use ast.Constant instead"_DEPRECATED_CLASS_MESSAGE_n_getterDeprecated. Use value instead.Attribute n_n_setter_s_getterAttribute s_s_setter_ABCDeprecated AST node class. Use ast.Constant instead_const_typesast._const_types_not_new got multiple values for argument NumStrBytesNameConstant_ast_Ellipsisast.EllipsisDeprecated AST node class.IndexDeprecated AST node class. Use the index value directly instead.ExtSliceDeprecated AST node class. Use ast.Tuple instead._dims_getterDeprecated. Use elts instead._dims_setterSuiteDeprecated AST node class.  Unused in Python 3.AugLoadAugStoreParam1e_INFSTR_PrecedencePrecedence table that originated from python grammar.NAMED_EXPRTUPLEYIELDTESTANDNOTCMPEXPRBORBXORBANDSHIFTARITHTERMFACTORPOWERAWAITATOM_SINGLE_QUOTES_MULTI_QUOTES_ALL_QUOTES_UnparserMethods in this class recursively traverse an AST and
    output source code for the abstract syntax; original formatting
    is disregarded._avoid_backslashes_source_precedences_type_ignores_in_try_starinterleaveinterCall f on each item in seq, calling inter() in between.items_viewtraverserTraverse and separate the given *items* with a comma and append it to
        the buffer. If *items* is a single item sequence, a trailing comma
        will be added.maybe_newlineAdds a newline if it isn't the start of generated sourceIndent a piece of text and append it, according to the current
        indentation level    Add new source partsbufferedoriginal_sourceA context manager for preparing the source for blocks. It adds
        the character':', increases the indentation on enter and decreases
        the indentation on exit. If *extra* is given, it will be directly
        appended after the colon character.
        delimitA context manager for preparing the source for expressions. It adds
        *start* to the buffer and enters, after exit it adds *end*.delimit_ifrequire_parensprecedenceShortcut to adding precedence related parensget_precedenceset_precedencenodesget_raw_docstringIf a docstring node is found in the body of the *node* parameter,
        return that docstring node, None otherwise.

        Logic mirrored from ``_PyAST_GetDocString``.get_type_comment # type: traverseOutputs a source code string that, if converted back to an ast
        (using ast.parse) will generate an AST equivalent to *node*_write_docstring_and_traverse_bodydocstring_write_docstringvisit_Moduletype_ignoresvisit_FunctionTypeargtypes -> visit_Exprvisit_NamedExpr := visit_Importvisit_ImportFromfrom  import visit_Assigntargets = visit_AugAssignbinop= visit_AnnAssignvisit_Returnreturnvisit_Passpassvisit_Breakbreakvisit_Continuecontinuevisit_Deletedel visit_Assertassert visit_Globalglobal visit_Nonlocalnonlocal visit_Awaitawaitvisit_Yieldyieldvisit_YieldFromyield from Node can't be used without a value attribute.visit_RaiseraiseNode can't use cause without an exception.do_visit_trytryexorelseelsefinalbodyfinallyvisit_Tryprev_in_try_starvisit_TryStarvisit_ExceptHandlerexcept*except as visit_ClassDefdecodecorator_listclass type_params_type_params_helpercommavisit_FunctionDef_function_helperdefvisit_AsyncFunctionDefasync deffill_suffixdef_strvisit_TypeVarvisit_TypeVarTuplevisit_ParamSpec**visit_TypeAliastype visit_For_for_helperfor visit_AsyncForasync for visit_Ifif elif visit_Whilewhile visit_Withwith visit_AsyncWithasync with _str_literal_helperquote_typesescape_special_whitespaceHelper for writing string literals, minimizing escapes.
        Returns the tuple (string literal to write, possible quote types).
        escape_char
	unicode_escapeescaped_stringpossible_quotes_write_str_avoiding_backslashesWrite string literal value with a best effort attempt to avoid backslashes.quote_typevisit_JoinedStrfstring_parts_write_fstring_innernew_fstring_partsfallback_to_repris_constantnew_quote_types'"expected_prefixis_format_spec{{}}\'visit_FormattedValueUnexpected node inside JoinedStr, unparse_innerinnerunparser!visit_Name_write_constantvisit_Listvisit_ListCompeltgenvisit_GeneratorExpvisit_SetCompvisit_DictCompvisit_comprehensionis_async async for  for ifsif_clause if visit_IfExp else visit_Set{*()}visit_Dictwrite_key_value_pairwrite_itemvisit_Tuplenotunopunop_precedencevisit_UnaryOpoperator_precedence<<>>//binop_precedencebinop_rassocvisit_BinOpleft_precedenceright_precedence!=<=>=isis notnot incmpopsvisit_Comparecomparatorsopsandorboolopsboolop_precedencevisit_BoolOpincreasing_level_traversevisit_Attributevisit_Callvisit_Subscriptis_non_empty_tupleslice_valuevisit_Starredvisit_Ellipsisvisit_Slicevisit_Matchmatch subjectcasesvisit_argvisit_argumentsposonlyargsall_args, /kwonlyargskw_defaultsvisit_keywordvisit_Lambdavisit_aliasvisit_withitemcontext_exprvisit_match_casecase visit_MatchValuevisit_MatchSingletonvisit_MatchSequencepatternsvisit_MatchStarvisit_MatchMappingwrite_key_pattern_pairpairvisit_MatchClasskwd_attrsattrswrite_attr_patternkwd_patternsvisit_MatchAsvisit_MatchOrunparseast_obj_deprecated_globalsmodule 'ast' has no attribute 'python -m astinfilethe file to parse; defaults to stdin-m--modesinglefunc_typespecify what kind of code must be parsed--no-type-commentsdon't add information about type comments-a--include-attributesinclude attributes such as line numbers and column offsets'include attributes such as line numbers and ''column offsets'-i--indentindentation of nodes (number of spaces)no_type_commentstree# Should be a 2-tuple.# Else it should be an int giving the minor version for 3.x.# end_lineno and end_col_offset are optional attributes, and they# should be copied whether the value is None or not.# TypeIgnore is a special case where lineno is not an attribute# but rather a field of the node itself.# If the ast module is loaded more than once, only add deprecated methods once# The following code is for backward compatibility.# It will be removed in future.# arbitrary keyword arguments are accepted# Keep another reference to Ellipsis in the global namespace# so it can be referenced in Ellipsis.__new__# (The original "Ellipsis" name is removed from the global namespace later on)# should be before int# Large float and imaginary literals get turned into infinities in the AST.# We unparse those infinities to INFSTR.# <target> := <expr1># <expr1>, <expr2># 'yield', 'yield from'# 'if'-'else', 'lambda'# 'or'# 'and'# 'not'# '<', '>', '==', '>=', '<=', '!=',# 'in', 'not in', 'is', 'is not'# '|'# '^'# '&'# '<<', '>>'# '+', '-'# '*', '@', '/', '%', '//'# unary '+', '-', '~'# '**'# 'await'# Note: as visit() resets the output text, do NOT rely on# NodeVisitor.generic_visit to handle any nodes (as it calls back in to# the subclass visit() method, which resets self._source to an empty list)# collapse nested ifs into equivalent elifs.# final else# \n and \t are non-printable, but we only escape them if# escape_special_whitespace is True# Always escape backslashes and other non-printable characters# If there aren't any possible_quotes, fallback to using repr# on the original string. Try to use a quote from quote_types,# e.g., so that we use triple quotes for docstrings.# Sort so that we prefer '''"''' over """\""""# If we're using triple quotes and we'd need to escape a final# quote, escape it# If we weren't able to find a quote type that works for all parts# of the JoinedStr, fallback to using repr and triple single quotes.# force repr to use single quotes# for both the f-string itself, and format_spec# Separate pair of opening brackets as "{ {"# Substitute overflowing decimal literal for AST infinities,# and inf - inf for NaNs.# `{}` would be interpreted as a dictionary literal, and# `set` might be shadowed. Thus:# for dictionary unpacking operator in dicts {**{'y': 2}}# see PEP 448 for details# factor prefixes (+, -, ~) shouldn't be separated# from the value they belong, (e.g: +1 instead of + 1)# Special case: 3.__abs__() is a syntax error, so if node.value# is an integer literal then we need to either parenthesize# it or add an extra space to get 3 .__abs__().# parentheses can be omitted if the tuple isn't empty# normal arguments# varargs, or bare '*' if no varargs but keyword-only arguments present# keyword-only arguments# kwargsb'
    ast
    ~~~

    The `ast` module helps Python applications to process trees of the Python
    abstract syntax grammar.  The abstract syntax itself might change with
    each Python release; this module helps to find out programmatically what
    the current grammar looks like and allows modifications of it.

    An abstract syntax tree can be generated by passing `ast.PyCF_ONLY_AST` as
    a flag to the `compile()` builtin function or by using the `parse()`
    function from this module.  The result will be a tree of objects whose
    classes all inherit from `ast.AST`.

    A modified abstract syntax tree can be compiled into a Python code object
    using the built-in `compile()` function.

    Additionally various helper functions are provided that make working with
    the trees simpler.  The main intention of the helper functions and this
    module in general is to provide an easy to use interface for libraries
    that work tightly with the python syntax (template engines for example).


    :copyright: Copyright 2008 by Armin Ronacher.
    :license: Python License.
'u'
    ast
    ~~~

    The `ast` module helps Python applications to process trees of the Python
    abstract syntax grammar.  The abstract syntax itself might change with
    each Python release; this module helps to find out programmatically what
    the current grammar looks like and allows modifications of it.

    An abstract syntax tree can be generated by passing `ast.PyCF_ONLY_AST` as
    a flag to the `compile()` builtin function or by using the `parse()`
    function from this module.  The result will be a tree of objects whose
    classes all inherit from `ast.AST`.

    A modified abstract syntax tree can be compiled into a Python code object
    using the built-in `compile()` function.

    Additionally various helper functions are provided that make working with
    the trees simpler.  The main intention of the helper functions and this
    module in general is to provide an easy to use interface for libraries
    that work tightly with the python syntax (template engines for example).


    :copyright: Copyright 2008 by Armin Ronacher.
    :license: Python License.
'b'
    Parse the source into an AST node.
    Equivalent to compile(source, filename, mode, PyCF_ONLY_AST).
    Pass type_comments=True to get back type comments where the syntax allows.
    'u'
    Parse the source into an AST node.
    Equivalent to compile(source, filename, mode, PyCF_ONLY_AST).
    Pass type_comments=True to get back type comments where the syntax allows.
    'b'Unsupported major version: 'u'Unsupported major version: 'b'
    Evaluate an expression node or a string containing only a Python
    expression.  The string or node provided may only consist of the following
    Python literal structures: strings, bytes, numbers, tuples, lists, dicts,
    sets, booleans, and None.

    Caution: A complex expression can overflow the C stack and cause a crash.
    'u'
    Evaluate an expression node or a string containing only a Python
    expression.  The string or node provided may only consist of the following
    Python literal structures: strings, bytes, numbers, tuples, lists, dicts,
    sets, booleans, and None.

    Caution: A complex expression can overflow the C stack and cause a crash.
    'b'eval'u'eval'b'malformed node or string'u'malformed node or string'b'lineno'b' on line 'u' on line 'b'set'u'set'b'
    Return a formatted dump of the tree in node.  This is mainly useful for
    debugging purposes.  If annotate_fields is true (by default),
    the returned string will show the names and the values for fields.
    If annotate_fields is false, the result string will be more compact by
    omitting unambiguous field names.  Attributes such as line
    numbers and column offsets are not dumped by default.  If this is wanted,
    include_attributes can be set to true.  If indent is a non-negative
    integer or string, then the tree will be pretty-printed with that indent
    level. None (the default) selects the single line representation.
    'u'
    Return a formatted dump of the tree in node.  This is mainly useful for
    debugging purposes.  If annotate_fields is true (by default),
    the returned string will show the names and the values for fields.
    If annotate_fields is false, the result string will be more compact by
    omitting unambiguous field names.  Attributes such as line
    numbers and column offsets are not dumped by default.  If this is wanted,
    include_attributes can be set to true.  If indent is a non-negative
    integer or string, then the tree will be pretty-printed with that indent
    level. None (the default) selects the single line representation.
    'b',
'u',
'b'%s=%s'u'%s=%s'b'%s(%s%s)'u'%s(%s%s)'b'[]'u'[]'b'[%s%s]'u'[%s%s]'b'expected AST, got %r'u'expected AST, got %r'b'
    Copy source location (`lineno`, `col_offset`, `end_lineno`, and `end_col_offset`
    attributes) from *old_node* to *new_node* if possible, and return *new_node*.
    'u'
    Copy source location (`lineno`, `col_offset`, `end_lineno`, and `end_col_offset`
    attributes) from *old_node* to *new_node* if possible, and return *new_node*.
    'b'col_offset'b'end_lineno'b'end_col_offset'b'end_'u'end_'b'
    When you compile a node tree with compile(), the compiler expects lineno and
    col_offset attributes for every node that supports them.  This is rather
    tedious to fill in for generated nodes, so this helper adds these attributes
    recursively where not already set, by setting them to the values of the
    parent node.  It works recursively starting at *node*.
    'u'
    When you compile a node tree with compile(), the compiler expects lineno and
    col_offset attributes for every node that supports them.  This is rather
    tedious to fill in for generated nodes, so this helper adds these attributes
    recursively where not already set, by setting them to the values of the
    parent node.  It works recursively starting at *node*.
    'b'
    Increment the line number and end line number of each node in the tree
    starting at *node* by *n*. This is useful to "move code" to a different
    location in a file.
    'u'
    Increment the line number and end line number of each node in the tree
    starting at *node* by *n*. This is useful to "move code" to a different
    location in a file.
    'b'
    Yield a tuple of ``(fieldname, value)`` for each field in ``node._fields``
    that is present on *node*.
    'u'
    Yield a tuple of ``(fieldname, value)`` for each field in ``node._fields``
    that is present on *node*.
    'b'
    Yield all direct child nodes of *node*, that is, all fields that are nodes
    and all items of fields that are lists of nodes.
    'u'
    Yield all direct child nodes of *node*, that is, all fields that are nodes
    and all items of fields that are lists of nodes.
    'b'
    Return the docstring for the given node or None if no docstring can
    be found.  If the node provided does not have docstrings a TypeError
    will be raised.

    If *clean* is `True`, all tabs are expanded to spaces and any whitespace
    that can be uniformly removed from the second line onwards is removed.
    'u'
    Return the docstring for the given node or None if no docstring can
    be found.  If the node provided does not have docstrings a TypeError
    will be raised.

    If *clean* is `True`, all tabs are expanded to spaces and any whitespace
    that can be uniformly removed from the second line onwards is removed.
    'b'%r can't have docstrings'u'%r can't have docstrings'b'(.*?(?:\r\n|\n|\r|$))'u'(.*?(?:\r\n|\n|\r|$))'b'Split a string into lines ignoring form feed and other chars.

    This mimics how the Python parser splits source code.
    'u'Split a string into lines ignoring form feed and other chars.

    This mimics how the Python parser splits source code.
    'b'Replace all chars except '\f\t' in a line with spaces.'u'Replace all chars except '\f\t' in a line with spaces.'b'	'u'	'b'Get source code segment of the *source* that generated *node*.

    If some location information (`lineno`, `end_lineno`, `col_offset`,
    or `end_col_offset`) is missing, return None.

    If *padded* is `True`, the first line of a multi-line statement will
    be padded with spaces to match its original position.
    'u'Get source code segment of the *source* that generated *node*.

    If some location information (`lineno`, `end_lineno`, `col_offset`,
    or `end_col_offset`) is missing, return None.

    If *padded* is `True`, the first line of a multi-line statement will
    be padded with spaces to match its original position.
    'b'
    Recursively yield all descendant nodes in the tree starting at *node*
    (including *node* itself), in no specified order.  This is useful if you
    only want to modify nodes in place and don't care about the context.
    'u'
    Recursively yield all descendant nodes in the tree starting at *node*
    (including *node* itself), in no specified order.  This is useful if you
    only want to modify nodes in place and don't care about the context.
    'b'
    A node visitor base class that walks the abstract syntax tree and calls a
    visitor function for every node found.  This function may return a value
    which is forwarded by the `visit` method.

    This class is meant to be subclassed, with the subclass adding visitor
    methods.

    Per default the visitor functions for the nodes are ``'visit_'`` +
    class name of the node.  So a `TryFinally` node visit function would
    be `visit_TryFinally`.  This behavior can be changed by overriding
    the `visit` method.  If no visitor function exists for a node
    (return value `None`) the `generic_visit` visitor is used instead.

    Don't use the `NodeVisitor` if you want to apply changes to nodes during
    traversing.  For this a special visitor exists (`NodeTransformer`) that
    allows modifications.
    'u'
    A node visitor base class that walks the abstract syntax tree and calls a
    visitor function for every node found.  This function may return a value
    which is forwarded by the `visit` method.

    This class is meant to be subclassed, with the subclass adding visitor
    methods.

    Per default the visitor functions for the nodes are ``'visit_'`` +
    class name of the node.  So a `TryFinally` node visit function would
    be `visit_TryFinally`.  This behavior can be changed by overriding
    the `visit` method.  If no visitor function exists for a node
    (return value `None`) the `generic_visit` visitor is used instead.

    Don't use the `NodeVisitor` if you want to apply changes to nodes during
    traversing.  For this a special visitor exists (`NodeTransformer`) that
    allows modifications.
    'b'Visit a node.'u'Visit a node.'b'visit_'u'visit_'b'Called if no explicit visitor function exists for a node.'u'Called if no explicit visitor function exists for a node.'b' is deprecated; add visit_Constant'u' is deprecated; add visit_Constant'b'
    A :class:`NodeVisitor` subclass that walks the abstract syntax tree and
    allows modification of nodes.

    The `NodeTransformer` will walk the AST and use the return value of the
    visitor methods to replace or remove the old node.  If the return value of
    the visitor method is ``None``, the node will be removed from its location,
    otherwise it is replaced with the return value.  The return value may be the
    original node in which case no replacement takes place.

    Here is an example transformer that rewrites all occurrences of name lookups
    (``foo``) to ``data['foo']``::

       class RewriteName(NodeTransformer):

           def visit_Name(self, node):
               return Subscript(
                   value=Name(id='data', ctx=Load()),
                   slice=Constant(value=node.id),
                   ctx=node.ctx
               )

    Keep in mind that if the node you're operating on has child nodes you must
    either transform the child nodes yourself or call the :meth:`generic_visit`
    method for the node first.

    For nodes that were part of a collection of statements (that applies to all
    statement nodes), the visitor may also return a list of nodes rather than
    just a single node.

    Usually you use the transformer like this::

       node = YourTransformer().visit(node)
    'u'
    A :class:`NodeVisitor` subclass that walks the abstract syntax tree and
    allows modification of nodes.

    The `NodeTransformer` will walk the AST and use the return value of the
    visitor methods to replace or remove the old node.  If the return value of
    the visitor method is ``None``, the node will be removed from its location,
    otherwise it is replaced with the return value.  The return value may be the
    original node in which case no replacement takes place.

    Here is an example transformer that rewrites all occurrences of name lookups
    (``foo``) to ``data['foo']``::

       class RewriteName(NodeTransformer):

           def visit_Name(self, node):
               return Subscript(
                   value=Name(id='data', ctx=Load()),
                   slice=Constant(value=node.id),
                   ctx=node.ctx
               )

    Keep in mind that if the node you're operating on has child nodes you must
    either transform the child nodes yourself or call the :meth:`generic_visit`
    method for the node first.

    For nodes that were part of a collection of statements (that applies to all
    statement nodes), the visitor may also return a list of nodes rather than
    just a single node.

    Usually you use the transformer like this::

       node = YourTransformer().visit(node)
    'b'{name} is deprecated and will be removed in Python {remove}; use value instead'u'{name} is deprecated and will be removed in Python {remove}; use value instead'b'{name} is deprecated and will be removed in Python {remove}; use ast.Constant instead'u'{name} is deprecated and will be removed in Python {remove}; use ast.Constant instead'b'Deprecated. Use value instead.'u'Deprecated. Use value instead.'b'Attribute n'u'Attribute n'b'Attribute s'u'Attribute s'b'Deprecated AST node class. Use ast.Constant instead'u'Deprecated AST node class. Use ast.Constant instead'b'ast.'u'ast.'b' got multiple values for argument 'u' got multiple values for argument 'b'ast.Ellipsis'u'ast.Ellipsis'b'NameConstant'u'NameConstant'b'Num'u'Num'b'Str'u'Str'b'Bytes'u'Bytes'b'Ellipsis'u'Ellipsis'b'Deprecated AST node class.'u'Deprecated AST node class.'b'Deprecated AST node class. Use the index value directly instead.'u'Deprecated AST node class. Use the index value directly instead.'b'Deprecated AST node class. Use ast.Tuple instead.'u'Deprecated AST node class. Use ast.Tuple instead.'b'dims'u'dims'b'Deprecated. Use elts instead.'u'Deprecated. Use elts instead.'b'Deprecated AST node class.  Unused in Python 3.'u'Deprecated AST node class.  Unused in Python 3.'b'1e'u'1e'b'Precedence table that originated from python grammar.'u'Precedence table that originated from python grammar.'b'"""'u'"""'b'''''u'''''b'Methods in this class recursively traverse an AST and
    output source code for the abstract syntax; original formatting
    is disregarded.'u'Methods in this class recursively traverse an AST and
    output source code for the abstract syntax; original formatting
    is disregarded.'b'Call f on each item in seq, calling inter() in between.'u'Call f on each item in seq, calling inter() in between.'b'Traverse and separate the given *items* with a comma and append it to
        the buffer. If *items* is a single item sequence, a trailing comma
        will be added.'u'Traverse and separate the given *items* with a comma and append it to
        the buffer. If *items* is a single item sequence, a trailing comma
        will be added.'b'Adds a newline if it isn't the start of generated source'u'Adds a newline if it isn't the start of generated source'b'Indent a piece of text and append it, according to the current
        indentation level'u'Indent a piece of text and append it, according to the current
        indentation level'b'    'u'    'b'Add new source parts'u'Add new source parts'b'A context manager for preparing the source for blocks. It adds
        the character':', increases the indentation on enter and decreases
        the indentation on exit. If *extra* is given, it will be directly
        appended after the colon character.
        'u'A context manager for preparing the source for blocks. It adds
        the character':', increases the indentation on enter and decreases
        the indentation on exit. If *extra* is given, it will be directly
        appended after the colon character.
        'b'A context manager for preparing the source for expressions. It adds
        *start* to the buffer and enters, after exit it adds *end*.'u'A context manager for preparing the source for expressions. It adds
        *start* to the buffer and enters, after exit it adds *end*.'b'Shortcut to adding precedence related parens'u'Shortcut to adding precedence related parens'b'If a docstring node is found in the body of the *node* parameter,
        return that docstring node, None otherwise.

        Logic mirrored from ``_PyAST_GetDocString``.'u'If a docstring node is found in the body of the *node* parameter,
        return that docstring node, None otherwise.

        Logic mirrored from ``_PyAST_GetDocString``.'b' # type: 'u' # type: 'b'Outputs a source code string that, if converted back to an ast
        (using ast.parse) will generate an AST equivalent to *node*'u'Outputs a source code string that, if converted back to an ast
        (using ast.parse) will generate an AST equivalent to *node*'b' -> 'u' -> 'b' := 'u' := 'b'from 'u'from 'b' import 'u' import 'b' = 'u' = 'b'= 'u'= 'b'return'u'return'b'pass'u'pass'b'break'u'break'b'continue'u'continue'b'del 'u'del 'b'assert 'u'assert 'b'global 'u'global 'b'nonlocal 'u'nonlocal 'b'await'u'await'b'yield'u'yield'b'yield from 'u'yield from 'b'Node can't be used without a value attribute.'u'Node can't be used without a value attribute.'b'raise'u'raise'b'Node can't use cause without an exception.'u'Node can't use cause without an exception.'b'try'u'try'b'else'u'else'b'finally'u'finally'b'except*'u'except*'b'except'u'except'b' as 'u' as 'b'class 'u'class 'b'type_params'b'def'u'def'b'async def'u'async def'b'**'u'**'b'type 'u'type 'b'for 'u'for 'b'async for 'u'async for 'b'if 'u'if 'b'elif 'u'elif 'b'while 'u'while 'b'with 'u'with 'b'async with 'u'async with 'b'Helper for writing string literals, minimizing escapes.
        Returns the tuple (string literal to write, possible quote types).
        'u'Helper for writing string literals, minimizing escapes.
        Returns the tuple (string literal to write, possible quote types).
        'b'
	'u'
	'b'unicode_escape'u'unicode_escape'b'Write string literal value with a best effort attempt to avoid backslashes.'u'Write string literal value with a best effort attempt to avoid backslashes.'b''"'u''"'b'{{'u'{{'b'}}'u'}}'b'\''u'\''b'Unexpected node inside JoinedStr, 'u'Unexpected node inside JoinedStr, 'b'!'u'!'b' async for 'u' async for 'b' for 'u' for 'b' if 'u' if 'b' else 'u' else 'b'{*()}'u'{*()}'b'Invert'b'not'u'not'b'Not'b'UAdd'b'USub'b'Add'b'Sub'b'Mult'b'MatMult'b'Div'b'Mod'b'<<'u'<<'b'LShift'b'>>'u'>>'b'RShift'b'BitOr'b'BitXor'b'BitAnd'b'//'u'//'b'FloorDiv'b'Pow'u'=='b'Eq'b'!='u'!='b'NotEq'b'Lt'b'<='u'<='b'LtE'b'Gt'b'>='u'>='b'GtE'b'is'u'is'b'Is'b'is not'u'is not'b'IsNot'b'In'b'not in'u'not in'b'NotIn'b'and'u'and'b'And'b'or'u'or'b'Or'b'match 'u'match 'b', /'u', /'b'lambda'u'lambda'b'case 'u'case 'b'module 'ast' has no attribute ''u'module 'ast' has no attribute ''b'python -m ast'u'python -m ast'b'infile'u'infile'b'the file to parse; defaults to stdin'u'the file to parse; defaults to stdin'b'-m'u'-m'b'--mode'u'--mode'b'single'u'single'b'func_type'u'func_type'b'specify what kind of code must be parsed'u'specify what kind of code must be parsed'b'--no-type-comments'u'--no-type-comments'b'don't add information about type comments'u'don't add information about type comments'b'-a'u'-a'b'--include-attributes'u'--include-attributes'b'include attributes such as line numbers and column offsets'u'include attributes such as line numbers and column offsets'b'-i'u'-i'b'--indent'u'--indent'b'indentation of nodes (number of spaces)'u'indentation of nodes (number of spaces)'u'Lib.ast'runTestmethodName_asyncioRunner_asyncioTestContextasyncSetUpasyncTearDownaddAsyncCleanupaddCleanupenterAsyncContextcmEnters the supplied asynchronous context manager.

        If successful, also adds its __aexit__ method as a cleanup
        function and returns the result of the __aenter__ method.
        __aenter__enter__aexit__' object does not support the asynchronous context manager protocol"' object does ""not support the asynchronous context manager protocol"_callSetUpget_loopsetUp_callAsync_callTestMethod_callMaybeAsyncIt is deprecated to return a value that is not None from a test case ('It is deprecated to return a value that is not None from a ''test case ('_callTearDowntearDown_callCleanupasyncio runner is not initializediscoroutinefunction is not an async function_setupAsyncioRunnerasyncio runner is already initializedRunner_tearDownAsyncioRunner# Names intentionally have a long prefix# to reduce a chance of clashing with user-defined attributes# from inherited test case# The class doesn't call loop.run_until_complete(self.setUp()) and family# but uses a different approach:# 1. create a long-running task that reads self.setUp()#    awaitable from queue along with a future# 2. await the awaitable object passing in and set the result#    into the future object# 3. Outer code puts the awaitable and the future object into a queue#    with waiting for the future# The trick is necessary because every run_until_complete() call# creates a new task with embedded ContextVar context.# To share contextvars between setUp(), test and tearDown() we need to execute# them inside the same task.# Note: the test case modifies event loop policy if the policy was not instantiated# yet.# asyncio.get_event_loop_policy() creates a default policy on demand but never# returns None# I believe this is not an issue in user level tests but python itself for testing# should reset a policy in every test module# by calling asyncio.set_event_loop_policy(None) in tearDownModule()# A trivial trampoline to addCleanup()# the function exists because it has a different semantics# and signature:# addCleanup() accepts regular functions# but addAsyncCleanup() accepts coroutines# We intentionally don't add inspect.iscoroutinefunction() check# for func argument because there is no way# to check for async function reliably:# 1. It can be "async def func()" itself# 2. Class can implement "async def __call__()" method# 3. Regular "def func()" that returns awaitable object# We look up the special methods on the type to match the with# statement.# Force loop to be initialized and set as the current loop# so that setUp functions can use get_event_loop() and get the# correct loop instance.b'runTest'u'runTest'b'Enters the supplied asynchronous context manager.

        If successful, also adds its __aexit__ method as a cleanup
        function and returns the result of the __aenter__ method.
        'u'Enters the supplied asynchronous context manager.

        If successful, also adds its __aexit__ method as a cleanup
        function and returns the result of the __aenter__ method.
        'b'' object does not support the asynchronous context manager protocol'u'' object does not support the asynchronous context manager protocol'b'It is deprecated to return a value that is not None from a test case ('u'It is deprecated to return a value that is not None from a test case ('b'asyncio runner is not initialized'u'asyncio runner is not initialized'b' is not an async function'u' is not an async function'b'asyncio runner is already initialized'u'asyncio runner is already initialized'u'Lib.unittest.async_case'u'unittest.async_case'u'async_case'u'allow programmer to define multiple exit functions to be executed
upon normal program termination.

Two public functions, register and unregister, are defined.
'_clear_ncallbacks_run_exitfuncstzESTtzEST_offsetbenchmark_bad_timezones_01000000000nowESTnowNYCbenchmark_bad_timezones_1nowEST_offsetbenchmark_bad_timezones_2tzOFFnowOFFrun_benchmarks_bad_timezones# create timezone from current timezone differencesu'Temp.date_time.benchmarks.bad_timezones'u'date_time.benchmarks.bad_timezones'u'benchmarks.bad_timezones'u'bad_timezones'Base16, Base32, Base64 (RFC 3548), Base85 and Ascii85 data encodingsencodebytesdecodebytesb32encodeb32decodeb32hexencodeb32hexdecodeb16encodeb16decodeb85encodeb85decodea85encodea85decodestandard_b64encodestandard_b64decodeurlsafe_b64encodeurlsafe_b64decodebytes_types_bytes_from_decode_datastring argument should contain only ASCII charactersargument should be a bytes-like object or ASCII string, not %r"argument should be a bytes-like object or ASCII ""string, not %r"altcharsEncode the bytes-like object s using Base64 and return a bytes object.

    Optional altchars should be a byte string of length 2 which specifies an
    alternative alphabet for the '+' and '/' characters.  This allows an
    application to e.g. generate url or filesystem safe Base64 strings.
    b2a_base64+/Decode the Base64 encoded bytes-like object or ASCII string s.

    Optional altchars must be a bytes-like object or ASCII string of length 2
    which specifies the alternative alphabet used instead of the '+' and '/'
    characters.

    The result is returned as a bytes object.  A binascii.Error is raised if
    s is incorrectly padded.

    If validate is False (the default), characters that are neither in the
    normal base-64 alphabet nor the alternative alphabet are discarded prior
    to the padding check.  If validate is True, these non-alphabet characters
    in the input result in a binascii.Error.
    For more information about the strict base64 check, see:

    https://docs.python.org/3.11/library/binascii.html#binascii.a2b_base64
    a2b_base64strict_modeEncode bytes-like object s using the standard Base64 alphabet.

    The result is returned as a bytes object.
    Decode bytes encoded with the standard Base64 alphabet.

    Argument s is a bytes-like object or ASCII string to decode.  The result
    is returned as a bytes object.  A binascii.Error is raised if the input
    is incorrectly padded.  Characters that are not in the standard alphabet
    are discarded prior to the padding check.
    -__urlsafe_encode_translation_urlsafe_decode_translationEncode bytes using the URL- and filesystem-safe Base64 alphabet.

    Argument s is a bytes-like object to encode.  The result is returned as a
    bytes object.  The alphabet uses '-' instead of '+' and '_' instead of
    '/'.
    Decode bytes using the URL- and filesystem-safe Base64 alphabet.

    Argument s is a bytes-like object or ASCII string to decode.  The result
    is returned as a bytes object.  A binascii.Error is raised if the input
    is incorrectly padded.  Characters that are not in the URL-safe base-64
    alphabet, and are not a plus '+' or slash '/', are discarded prior to the
    padding check.

    The alphabet uses '-' instead of '+' and '_' instead of '/'.
    
Encode the bytes-like objects using {encoding} and return a bytes object.
_B32_ENCODE_DOCSTRING
Decode the {encoding} encoded bytes-like object or ASCII string s.

Optional casefold is a flag specifying whether a lowercase alphabet is
acceptable as input.  For security purposes, the default is False.
{extra_args}
The result is returned as a bytes object.  A binascii.Error is raised if
the input is incorrectly padded or if there are non-alphabet
characters present in the input.
_B32_DECODE_DOCSTRING
RFC 3548 allows for optional mapping of the digit 0 (zero) to the
letter O (oh), and for optional mapping of the digit 1 (one) to
either the letter I (eye) or letter L (el).  The optional argument
map01 when not None, specifies which letter the digit 1 should be
mapped to (when map01 is not None, the digit 0 is always mapped to
the letter O).  For security purposes the default is None, so that
0 and 1 are not allowed in the input.
_B32_DECODE_MAP01_DOCSTRINGABCDEFGHIJKLMNOPQRSTUVWXYZ234567_b32alphabet0123456789ABCDEFGHIJKLMNOPQRSTUV_b32hexalphabet_b32tab2_b32rev_b32encodealphabetb32tabb32tab210230x3ff==========_b32decodemap01Incorrect paddingpadcharsdecodedb32revquantaaccNon-base32 digit found43base32extra_argsbase32hexEncode the bytes-like object s using Base16 and return a bytes object.
    hexlifyDecode the Base16 encoded bytes-like object or ASCII string s.

    Optional casefold is a flag specifying whether a lowercase alphabet is
    acceptable as input.  For security purposes, the default is False.

    The result is returned as a bytes object.  A binascii.Error is raised if
    s is incorrectly padded or if there are non-alphabet characters present
    in the input.
    [^0-9A-F]Non-base16 digit foundunhexlify_a85chars_a85chars2<~_A85START~>_A85END_85encodechars2padfoldnulsfoldspaces!%dIwordsword5389762880x202020206141257225wrapcoladobeEncode bytes-like object b using Ascii85 and return a bytes object.

    foldspaces is an optional flag that uses the special short sequence 'y'
    instead of 4 consecutive spaces (ASCII 0x20) as supported by 'btoa'. This
    feature is not supported by the "standard" Adobe encoding.

    wrapcol controls whether the output should have newline (b'\n') characters
    added to it. If this is non-zero, each output line will be at most this
    many characters long, excluding the trailing newline.

    pad controls whether the input is padded to a multiple of 4 before
    encoding. Note that the btoa implementation always pads.

    adobe controls whether the encoded byte sequence is framed with <~ and ~>,
    which is used by the Adobe implementation.
    33118 	
ignorecharsDecode the Ascii85 encoded bytes-like object or ASCII string b.

    foldspaces is a flag that specifies whether the 'y' short sequence should be
    accepted as shorthand for 4 consecutive spaces (ASCII 0x20). This feature is
    not supported by the "standard" Adobe encoding.

    adobe controls whether the input sequence is in Adobe Ascii85 format (i.e.
    is framed with <~ and ~>).

    ignorechars should be a byte string containing characters to ignore from the
    input. This should only contain whitespace characters, and by default
    contains all whitespace characters in ASCII.

    The result is returned as a bytes object.
    Ascii85 encoded byte sequences must end with {!r}"Ascii85 encoded byte sequences must end ""with {!r}"!IpackIdecoded_appendcurr_appendcurr_clearAscii85 overflowz inside Ascii85 5-tuple    y inside Ascii85 5-tupleNon-Ascii85 digit found: %c0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz!#$%&()*+-;<=>?@^_`{|}~b"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ"b"abcdefghijklmnopqrstuvwxyz!#$%&()*+-;<=>?@^_`{|}~"_b85alphabet_b85chars_b85chars2_b85decEncode bytes-like object b in base85 format and return a bytes object.

    If pad is true, the input is padded with b'\0' so its length is a multiple of
    4 bytes before encoding.
    Decode the base85-encoded bytes-like object or ASCII string b

    The result is returned as a bytes object.
    bad base85 character at position %dbase85 overflow in hunk starting at byte %d76MAXLINESIZEMAXBINSIZEoutputEncode a file; input and output are binary files.Decode a file; input and output are binary files._input_type_checkexpected bytes-like object, not %sexpected single byte elements, not %r from %sexpected 1-D data, not %d-D data from %sEncode a bytestring into a bytes object containing multiple lines
    of base-64 data.piecesDecode a bytestring of base-64 data into a bytes object.Small main programgetoptf""" [-h|-d|-e|-u] [file|-]
        -h: print this help message and exit
        -d, -u: decode
        -e: encode (default)hdeuopts-d-u-hScript#! /usr/bin/env python3# Modified 04-Oct-1995 by Jack Jansen to use binascii module# Modified 30-Dec-2003 by Barry Warsaw to add full RFC 3548 support# Modified 22-May-2007 by Guido van Rossum to use bytes everywhere# Legacy interface exports traditional RFC 2045 Base64 encodings# Generalized interface for other encodings# Base85 and Ascii85 encodings# Standard Base64 encoding# Some common Base64 alternatives.  As referenced by RFC 3458, see thread# starting at:# http://zgp.org/pipermail/p2p-hackers/2001-September/000316.html# Types acceptable as binary data# Base64 encoding/decoding uses binascii# Base32 encoding/decoding must be done in Python# Delay the initialization of the table to not waste memory# if the function is never called# Pad the last quantum with zero bits if necessary# Don't use += !# big endian# bits 1 - 10# bits 11 - 20# bits 21 - 30# bits 31 - 40# Adjust for any leftover partial quanta# Handle section 2.4 zero and one mapping.  The flag map01 will be either# False, or the character to map the digit 1 (one) to.  It should be# either L (el) or I (eye).# Strip off pad characters from the right.  We need to count the pad# characters because this will tell us how many null bytes to remove from# the end of the decoded string.# Now decode the full quanta# Process the last, partial quanta# 1: 4, 3: 3, 4: 2, 6: 1# base32hex does not have the 01 mapping# RFC 3548, Base 16 Alphabet specifies uppercase, but hexlify() returns# lowercase.  The RFC also recommends against accepting input case# insensitively.# Ascii85 encoding/decoding# Helper function for a85encode and b85encode# Delay the initialization of tables to not waste memory# Strip off start/end markers# We have to go through this stepwise, so as to ignore spaces and handle# special short sequences# Skip whitespace# Throw away the extra padding# The following code is originally taken (with permission) from Mercurial# Legacy interface.  This code could be cleaned up since I don't believe# binascii has any line length limitations.  It just doesn't seem worth it# though.  The files should be opened in binary mode.# Excluding the CRLF# Usable as a script...b'Base16, Base32, Base64 (RFC 3548), Base85 and Ascii85 data encodings'u'Base16, Base32, Base64 (RFC 3548), Base85 and Ascii85 data encodings'b'encodebytes'u'encodebytes'b'decodebytes'u'decodebytes'b'b64encode'u'b64encode'b'b64decode'u'b64decode'b'b32encode'u'b32encode'b'b32decode'u'b32decode'b'b32hexencode'u'b32hexencode'b'b32hexdecode'u'b32hexdecode'b'b16encode'u'b16encode'b'b16decode'u'b16decode'b'b85encode'u'b85encode'b'b85decode'u'b85decode'b'a85encode'u'a85encode'b'a85decode'u'a85decode'b'standard_b64encode'u'standard_b64encode'b'standard_b64decode'u'standard_b64decode'b'urlsafe_b64encode'u'urlsafe_b64encode'b'urlsafe_b64decode'u'urlsafe_b64decode'b'string argument should contain only ASCII characters'u'string argument should contain only ASCII characters'b'argument should be a bytes-like object or ASCII string, not %r'u'argument should be a bytes-like object or ASCII string, not %r'b'Encode the bytes-like object s using Base64 and return a bytes object.

    Optional altchars should be a byte string of length 2 which specifies an
    alternative alphabet for the '+' and '/' characters.  This allows an
    application to e.g. generate url or filesystem safe Base64 strings.
    'u'Encode the bytes-like object s using Base64 and return a bytes object.

    Optional altchars should be a byte string of length 2 which specifies an
    alternative alphabet for the '+' and '/' characters.  This allows an
    application to e.g. generate url or filesystem safe Base64 strings.
    'b'+/'b'Decode the Base64 encoded bytes-like object or ASCII string s.

    Optional altchars must be a bytes-like object or ASCII string of length 2
    which specifies the alternative alphabet used instead of the '+' and '/'
    characters.

    The result is returned as a bytes object.  A binascii.Error is raised if
    s is incorrectly padded.

    If validate is False (the default), characters that are neither in the
    normal base-64 alphabet nor the alternative alphabet are discarded prior
    to the padding check.  If validate is True, these non-alphabet characters
    in the input result in a binascii.Error.
    For more information about the strict base64 check, see:

    https://docs.python.org/3.11/library/binascii.html#binascii.a2b_base64
    'u'Decode the Base64 encoded bytes-like object or ASCII string s.

    Optional altchars must be a bytes-like object or ASCII string of length 2
    which specifies the alternative alphabet used instead of the '+' and '/'
    characters.

    The result is returned as a bytes object.  A binascii.Error is raised if
    s is incorrectly padded.

    If validate is False (the default), characters that are neither in the
    normal base-64 alphabet nor the alternative alphabet are discarded prior
    to the padding check.  If validate is True, these non-alphabet characters
    in the input result in a binascii.Error.
    For more information about the strict base64 check, see:

    https://docs.python.org/3.11/library/binascii.html#binascii.a2b_base64
    'b'Encode bytes-like object s using the standard Base64 alphabet.

    The result is returned as a bytes object.
    'u'Encode bytes-like object s using the standard Base64 alphabet.

    The result is returned as a bytes object.
    'b'Decode bytes encoded with the standard Base64 alphabet.

    Argument s is a bytes-like object or ASCII string to decode.  The result
    is returned as a bytes object.  A binascii.Error is raised if the input
    is incorrectly padded.  Characters that are not in the standard alphabet
    are discarded prior to the padding check.
    'u'Decode bytes encoded with the standard Base64 alphabet.

    Argument s is a bytes-like object or ASCII string to decode.  The result
    is returned as a bytes object.  A binascii.Error is raised if the input
    is incorrectly padded.  Characters that are not in the standard alphabet
    are discarded prior to the padding check.
    'b'-_'b'Encode bytes using the URL- and filesystem-safe Base64 alphabet.

    Argument s is a bytes-like object to encode.  The result is returned as a
    bytes object.  The alphabet uses '-' instead of '+' and '_' instead of
    '/'.
    'u'Encode bytes using the URL- and filesystem-safe Base64 alphabet.

    Argument s is a bytes-like object to encode.  The result is returned as a
    bytes object.  The alphabet uses '-' instead of '+' and '_' instead of
    '/'.
    'b'Decode bytes using the URL- and filesystem-safe Base64 alphabet.

    Argument s is a bytes-like object or ASCII string to decode.  The result
    is returned as a bytes object.  A binascii.Error is raised if the input
    is incorrectly padded.  Characters that are not in the URL-safe base-64
    alphabet, and are not a plus '+' or slash '/', are discarded prior to the
    padding check.

    The alphabet uses '-' instead of '+' and '_' instead of '/'.
    'u'Decode bytes using the URL- and filesystem-safe Base64 alphabet.

    Argument s is a bytes-like object or ASCII string to decode.  The result
    is returned as a bytes object.  A binascii.Error is raised if the input
    is incorrectly padded.  Characters that are not in the URL-safe base-64
    alphabet, and are not a plus '+' or slash '/', are discarded prior to the
    padding check.

    The alphabet uses '-' instead of '+' and '_' instead of '/'.
    'b'
Encode the bytes-like objects using {encoding} and return a bytes object.
'u'
Encode the bytes-like objects using {encoding} and return a bytes object.
'b'
Decode the {encoding} encoded bytes-like object or ASCII string s.

Optional casefold is a flag specifying whether a lowercase alphabet is
acceptable as input.  For security purposes, the default is False.
{extra_args}
The result is returned as a bytes object.  A binascii.Error is raised if
the input is incorrectly padded or if there are non-alphabet
characters present in the input.
'u'
Decode the {encoding} encoded bytes-like object or ASCII string s.

Optional casefold is a flag specifying whether a lowercase alphabet is
acceptable as input.  For security purposes, the default is False.
{extra_args}
The result is returned as a bytes object.  A binascii.Error is raised if
the input is incorrectly padded or if there are non-alphabet
characters present in the input.
'b'
RFC 3548 allows for optional mapping of the digit 0 (zero) to the
letter O (oh), and for optional mapping of the digit 1 (one) to
either the letter I (eye) or letter L (el).  The optional argument
map01 when not None, specifies which letter the digit 1 should be
mapped to (when map01 is not None, the digit 0 is always mapped to
the letter O).  For security purposes the default is None, so that
0 and 1 are not allowed in the input.
'u'
RFC 3548 allows for optional mapping of the digit 0 (zero) to the
letter O (oh), and for optional mapping of the digit 1 (one) to
either the letter I (eye) or letter L (el).  The optional argument
map01 when not None, specifies which letter the digit 1 should be
mapped to (when map01 is not None, the digit 0 is always mapped to
the letter O).  For security purposes the default is None, so that
0 and 1 are not allowed in the input.
'b'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567'b'0123456789ABCDEFGHIJKLMNOPQRSTUV'b'======'b'===='b'Incorrect padding'u'Incorrect padding'b'Non-base32 digit found'u'Non-base32 digit found'b'base32'u'base32'b'base32hex'u'base32hex'b'Encode the bytes-like object s using Base16 and return a bytes object.
    'u'Encode the bytes-like object s using Base16 and return a bytes object.
    'b'Decode the Base16 encoded bytes-like object or ASCII string s.

    Optional casefold is a flag specifying whether a lowercase alphabet is
    acceptable as input.  For security purposes, the default is False.

    The result is returned as a bytes object.  A binascii.Error is raised if
    s is incorrectly padded or if there are non-alphabet characters present
    in the input.
    'u'Decode the Base16 encoded bytes-like object or ASCII string s.

    Optional casefold is a flag specifying whether a lowercase alphabet is
    acceptable as input.  For security purposes, the default is False.

    The result is returned as a bytes object.  A binascii.Error is raised if
    s is incorrectly padded or if there are non-alphabet characters present
    in the input.
    'b'[^0-9A-F]'b'Non-base16 digit found'u'Non-base16 digit found'b'<~'b'~>'b'!%dI'u'!%dI'b'y'b'Encode bytes-like object b using Ascii85 and return a bytes object.

    foldspaces is an optional flag that uses the special short sequence 'y'
    instead of 4 consecutive spaces (ASCII 0x20) as supported by 'btoa'. This
    feature is not supported by the "standard" Adobe encoding.

    wrapcol controls whether the output should have newline (b'\n') characters
    added to it. If this is non-zero, each output line will be at most this
    many characters long, excluding the trailing newline.

    pad controls whether the input is padded to a multiple of 4 before
    encoding. Note that the btoa implementation always pads.

    adobe controls whether the encoded byte sequence is framed with <~ and ~>,
    which is used by the Adobe implementation.
    'u'Encode bytes-like object b using Ascii85 and return a bytes object.

    foldspaces is an optional flag that uses the special short sequence 'y'
    instead of 4 consecutive spaces (ASCII 0x20) as supported by 'btoa'. This
    feature is not supported by the "standard" Adobe encoding.

    wrapcol controls whether the output should have newline (b'\n') characters
    added to it. If this is non-zero, each output line will be at most this
    many characters long, excluding the trailing newline.

    pad controls whether the input is padded to a multiple of 4 before
    encoding. Note that the btoa implementation always pads.

    adobe controls whether the encoded byte sequence is framed with <~ and ~>,
    which is used by the Adobe implementation.
    'b' 	
'b'Decode the Ascii85 encoded bytes-like object or ASCII string b.

    foldspaces is a flag that specifies whether the 'y' short sequence should be
    accepted as shorthand for 4 consecutive spaces (ASCII 0x20). This feature is
    not supported by the "standard" Adobe encoding.

    adobe controls whether the input sequence is in Adobe Ascii85 format (i.e.
    is framed with <~ and ~>).

    ignorechars should be a byte string containing characters to ignore from the
    input. This should only contain whitespace characters, and by default
    contains all whitespace characters in ASCII.

    The result is returned as a bytes object.
    'u'Decode the Ascii85 encoded bytes-like object or ASCII string b.

    foldspaces is a flag that specifies whether the 'y' short sequence should be
    accepted as shorthand for 4 consecutive spaces (ASCII 0x20). This feature is
    not supported by the "standard" Adobe encoding.

    adobe controls whether the input sequence is in Adobe Ascii85 format (i.e.
    is framed with <~ and ~>).

    ignorechars should be a byte string containing characters to ignore from the
    input. This should only contain whitespace characters, and by default
    contains all whitespace characters in ASCII.

    The result is returned as a bytes object.
    'b'Ascii85 encoded byte sequences must end with {!r}'u'Ascii85 encoded byte sequences must end with {!r}'b'!I'u'!I'b'Ascii85 overflow'u'Ascii85 overflow'b'z inside Ascii85 5-tuple'u'z inside Ascii85 5-tuple'b'    'b'y inside Ascii85 5-tuple'u'y inside Ascii85 5-tuple'b'Non-Ascii85 digit found: %c'u'Non-Ascii85 digit found: %c'b'0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz!#$%&()*+-;<=>?@^_`{|}~'b'Encode bytes-like object b in base85 format and return a bytes object.

    If pad is true, the input is padded with b'\0' so its length is a multiple of
    4 bytes before encoding.
    'u'Encode bytes-like object b in base85 format and return a bytes object.

    If pad is true, the input is padded with b'\0' so its length is a multiple of
    4 bytes before encoding.
    'b'Decode the base85-encoded bytes-like object or ASCII string b

    The result is returned as a bytes object.
    'u'Decode the base85-encoded bytes-like object or ASCII string b

    The result is returned as a bytes object.
    'b'bad base85 character at position %d'u'bad base85 character at position %d'b'base85 overflow in hunk starting at byte %d'u'base85 overflow in hunk starting at byte %d'b'Encode a file; input and output are binary files.'u'Encode a file; input and output are binary files.'b'Decode a file; input and output are binary files.'u'Decode a file; input and output are binary files.'b'expected bytes-like object, not %s'u'expected bytes-like object, not %s'b'c'u'c'b'expected single byte elements, not %r from %s'u'expected single byte elements, not %r from %s'b'expected 1-D data, not %d-D data from %s'u'expected 1-D data, not %d-D data from %s'b'Encode a bytestring into a bytes object containing multiple lines
    of base-64 data.'u'Encode a bytestring into a bytes object containing multiple lines
    of base-64 data.'b'Decode a bytestring of base-64 data into a bytes object.'u'Decode a bytestring of base-64 data into a bytes object.'b'Small main program'u'Small main program'b' [-h|-d|-e|-u] [file|-]
        -h: print this help message and exit
        -d, -u: decode
        -e: encode (default)'u' [-h|-d|-e|-u] [file|-]
        -h: print this help message and exit
        -d, -u: decode
        -e: encode (default)'b'hdeu'u'hdeu'b'-d'u'-d'b'-u'u'-u'b'-h'u'-h'u'Lib.base64'Base64 content transfer encoding per RFCs 2045-2047.

This module handles the content transfer encoding method defined in RFC 2045
to encode arbitrary 8-bit data using the three 8-bit bytes in four 7-bit
characters encoding known as Base64.

It is used in the MIME standards for email to attach images, audio, and text
using some 8-bit character sets to messages.

This module provides an interface to encode and decode both headers and bodies
with Base64 encoding.

RFC 2045 defines a method for including character set information in an
`encoded-word' in a header.  This method is commonly used for 8-bit real names
in To:, From:, Cc:, etc. fields, as well as Subject: lines.

This module does not do the line wrapping or end-of-line character conversion
necessary for proper internationalized headers; it only does dumb encoding and
decoding.  To deal with the various line wrapping issues, use the email.header
module.
body_decodebody_encodedecodestringheader_encodeheader_lengthCRLFNLMISC_LENReturn the length of s when it is encoded with base64.iso-8859-1header_bytesEncode a single header line with Base64 encoding in a given charset.

    charset names the character set to use to encode the header.  It defaults
    to iso-8859-1.  Base64 encoding is defined in RFC 2045.
    =?%s?b?%s?=eolEncode a string with base64.

    Each line will be wrapped at, at most, maxlinelen characters (defaults to
    76 characters).

    Each line of encoded text will end with eol, which defaults to "\n".  Set
    this to "\r\n" if you will be using the result of this function directly
    in an email.
    encvecmax_unencodedencDecode a raw base64 string, returning a bytes object.

    This function does not parse a full MIME header value encoded with
    base64 (like =?iso-8859-1?b?bmloISBuaWgh?=) -- please use the high
    level email.header class for that functionality.
    raw-unicode-escape# Author: Ben Gertzfield# See also Charset.py# Helpers# BAW: should encode() inherit b2a_base64()'s dubious behavior in# adding a newline to the encoded string?# For convenience and backwards compatibility w/ standard base64 moduleb'Base64 content transfer encoding per RFCs 2045-2047.

This module handles the content transfer encoding method defined in RFC 2045
to encode arbitrary 8-bit data using the three 8-bit bytes in four 7-bit
characters encoding known as Base64.

It is used in the MIME standards for email to attach images, audio, and text
using some 8-bit character sets to messages.

This module provides an interface to encode and decode both headers and bodies
with Base64 encoding.

RFC 2045 defines a method for including character set information in an
`encoded-word' in a header.  This method is commonly used for 8-bit real names
in To:, From:, Cc:, etc. fields, as well as Subject: lines.

This module does not do the line wrapping or end-of-line character conversion
necessary for proper internationalized headers; it only does dumb encoding and
decoding.  To deal with the various line wrapping issues, use the email.header
module.
'u'Base64 content transfer encoding per RFCs 2045-2047.

This module handles the content transfer encoding method defined in RFC 2045
to encode arbitrary 8-bit data using the three 8-bit bytes in four 7-bit
characters encoding known as Base64.

It is used in the MIME standards for email to attach images, audio, and text
using some 8-bit character sets to messages.

This module provides an interface to encode and decode both headers and bodies
with Base64 encoding.

RFC 2045 defines a method for including character set information in an
`encoded-word' in a header.  This method is commonly used for 8-bit real names
in To:, From:, Cc:, etc. fields, as well as Subject: lines.

This module does not do the line wrapping or end-of-line character conversion
necessary for proper internationalized headers; it only does dumb encoding and
decoding.  To deal with the various line wrapping issues, use the email.header
module.
'b'body_decode'u'body_decode'b'body_encode'u'body_encode'b'decodestring'u'decodestring'b'header_encode'u'header_encode'b'header_length'u'header_length'b'Return the length of s when it is encoded with base64.'u'Return the length of s when it is encoded with base64.'b'iso-8859-1'u'iso-8859-1'b'Encode a single header line with Base64 encoding in a given charset.

    charset names the character set to use to encode the header.  It defaults
    to iso-8859-1.  Base64 encoding is defined in RFC 2045.
    'u'Encode a single header line with Base64 encoding in a given charset.

    charset names the character set to use to encode the header.  It defaults
    to iso-8859-1.  Base64 encoding is defined in RFC 2045.
    'b'=?%s?b?%s?='u'=?%s?b?%s?='b'Encode a string with base64.

    Each line will be wrapped at, at most, maxlinelen characters (defaults to
    76 characters).

    Each line of encoded text will end with eol, which defaults to "\n".  Set
    this to "\r\n" if you will be using the result of this function directly
    in an email.
    'u'Encode a string with base64.

    Each line will be wrapped at, at most, maxlinelen characters (defaults to
    76 characters).

    Each line of encoded text will end with eol, which defaults to "\n".  Set
    this to "\r\n" if you will be using the result of this function directly
    in an email.
    'b'Decode a raw base64 string, returning a bytes object.

    This function does not parse a full MIME header value encoded with
    base64 (like =?iso-8859-1?b?bmloISBuaWgh?=) -- please use the high
    level email.header class for that functionality.
    'u'Decode a raw base64 string, returning a bytes object.

    This function does not parse a full MIME header value encoded with
    base64 (like =?iso-8859-1?b?bmloISBuaWgh?=) -- please use the high
    level email.header class for that functionality.
    'b'raw-unicode-escape'u'raw-unicode-escape'u'Lib.email.base64mime'u'email.base64mime'Base implementation of event loop.

The event loop can be broken up into a multiplexer (the part
responsible for notifying us of I/O events) and the event loop proper,
which wraps a multiplexer with functionality for scheduling callbacks,
immediately or at a given time in the future.

Whenever a public API takes a callback, subsequent positional
arguments will be passed to the callback if/when it is called.  This
avoids the proliferation of trivial lambdas implementing closures.
Keyword arguments for the callback are not supported; this is a
conscious design decision, leaving the door open for keyword arguments
to modify the meaning of the API call itself.
concurrentsslconstantssslprotostaggeredtrsockBaseEventLoopServer_MIN_SCHEDULED_TIMER_HANDLES0.5_MIN_CANCELLED_TIMER_HANDLES_FRACTIONAF_INET6_HAS_IPv6MAXIMUM_SELECT_TIMEOUT_format_handle_callbackTask_format_pipePIPE<pipe>STDOUT<stdout>_set_reuseportsockSO_REUSEPORTreuse_port not supported by socket modulesetsockoptSOL_SOCKETreuse_port not supported by socket module, SO_REUSEPORT defined but not implemented.'reuse_port not supported by socket module, ''SO_REUSEPORT defined but not implemented.'_ipaddr_infohostportfamilyprotoflowinfoscopeidinet_ptonIPPROTO_TCPIPPROTO_UDPSOCK_STREAMSOCK_DGRAMAF_UNSPECAF_INETafsidnaaf_interleave_addrinfosaddrinfosfirst_address_family_countInterleave list of addrinfo tuples by family.addrinfos_by_familyaddraddrinfos_listsreordered_run_until_complete_cb_get_loopTCP_NODELAY_set_nodelay_check_ssl_socketSSLSocketSocket cannot be of type SSLSocket_SendfileFallbackProtocolProtocoltransp_FlowControlMixintransport should be _FlowControlMixin instance_transportget_protocol_protois_reading_should_resume_reading_protocol_paused_should_resume_writingpause_readingset_protocol_loopcreate_future_write_ready_futdrainis_closingConnection closed by peerconnection_madetransportInvalid state: connection should have been established already."Invalid state: ""connection should have been established already."connection_lostConnection is closed by peerpause_writingresume_writingdata_receivedInvalid state: reading should be pausedeof_receivedrestoreresume_readingAbstractServerloopsocketsprotocol_factoryssl_contextbacklogssl_handshake_timeoutssl_shutdown_timeout_sockets_active_count_protocol_factory_backlog_ssl_context_ssl_handshake_timeout_ssl_shutdown_timeout_serving_serving_forever_fut sockets=_attach_detach_wakeup_start_servinglistenis_servingTransportSocket_stop_servingstart_servingsleepserve_foreverserver  is already being awaited on serve_forever() is closedwait_closedWait until server is closed and all connections are dropped.

        - If the server is not closed, wait.
        - If it is closed, but there are still active connections, wait.

        Anyone waiting here will be unblocked once both conditions
        (server is closed and all connections have been dropped)
        have become true, in either order.

        Historical note: In 3.11 and before, this was broken, returning
        immediately if the server was already closed, even if there
        were still active connections. An attempted fix in 3.12.0 was
        still broken, returning immediately if the server was still
        open and there were no active connections. Hopefully in 3.12.1
        we have it right.
        AbstractEventLoop_timer_cancelled_count_stopping_ready_scheduled_default_executor_internal_fds_thread_idget_clock_info_clock_resolution_exception_handlerset_debug_is_debug_mode0.1slow_callback_duration_current_handle_task_factory_coroutine_origin_tracking_enabled_coroutine_origin_tracking_saved_depth_asyncgens_asyncgens_shutdown_called_executor_shutdown_called running=is_running closed=' ''closed='is_closed debug=get_debugCreate a Future object attached to the loop.create_taskcoroSchedule a coroutine object.

        Return a task object.
        _check_closedtask_source_traceback_set_task_nameset_task_factorySet a task factory that will be used by loop.create_task().

        If factory is None the default task factory will be set.

        If factory is a callable, it should have a signature matching
        '(loop, coro)', where 'loop' will be a reference to the active
        event loop, 'coro' will be a coroutine object.  The callable
        must return a Future.
        task factory must be a callable or Noneget_task_factoryReturn a task factory, or None if the default one is in use._make_socket_transportserverCreate socket transport._make_ssl_transportrawsocksslcontextserver_sideserver_hostnamecall_connection_madeCreate SSL transport._make_datagram_transportaddressCreate datagram transport._make_read_pipe_transportpipeCreate read pipe transport._make_write_pipe_transportCreate write pipe transport._make_subprocess_transportshellCreate subprocess transport._write_to_selfWrite a byte to self-pipe, to wake up the event loop.

        This may be called from a different thread.

        The subclass is responsible for implementing the self-pipe.
        _process_eventsevent_listProcess selector events.Event loop is closed_check_default_executorExecutor shutdown has been called_asyncgen_finalizer_hookagencall_soon_threadsafe_asyncgen_firstiter_hookasynchronous generator  was scheduled after loop.shutdown_asyncgens() call" was scheduled after ""loop.shutdown_asyncgens() call"shutdown_asyncgensShutdown all active asynchronous generators.closing_agensgatheragreturn_exceptionsresultscall_exception_handleran error occurred during closing of asynchronous generator 'an error occurred during closing of ''asynchronous generator 'asyncgenshutdown_default_executorSchedule the shutdown of the default executor.

        The timeout parameter specifies the amount of time the executor will
        be given to finish joining. The default value is None, which means
        that the executor will be given an unlimited amount of time.
        Thread_do_shutdownThe executor did not finishing joining its threads within "The executor did not finishing joining ""its threads within " seconds._set_result_unless_cancelled_check_runningThis event loop is already running_get_running_loopCannot run the event loop while another loop is runningrun_foreverRun until stop() is called._set_coroutine_origin_tracking_debugold_agen_hooksfirstiterfinalizer_set_running_loop_run_oncerun_until_completeRun until the Future is done.

        If the argument is a coroutine, it is wrapped in a Task.

        WARNING: It would be disastrous to call run_until_complete()
        with the same coroutine twice -- it would wrap it in two
        different Tasks and that can't be good.

        Return the Future's result, or raise its exception.
        isfuturenew_taskensure_future_log_destroy_pendingremove_done_callbackEvent loop stopped before Future completed.Stop running the event loop.

        Every callback already scheduled will still run.  This simply informs
        run_forever to stop looping after a complete iteration.
        Close the event loop.

        This clears the queues and shuts down the executor,
        but does not wait for the executor to finish.

        The event loop must not be running.
        Cannot close a running event loopClose %rexecutorReturns True if the event loop was closed._warnunclosed event loop Returns True if the event loop is running.Return the time according to the event loop's clock.

        This is a float expressed in seconds since an epoch, but the
        epoch, precision, accuracy and drift are unspecified and may
        differ per event loop.
        call_laterArrange for a callback to be called at a given time.

        Return a Handle: an opaque object with a cancel() method that
        can be used to cancel the call.

        The delay can be an int or float, expressed in seconds.  It is
        always relative to the current time.

        Each callback will be called exactly once.  If two callbacks
        are scheduled for exactly the same time, it is undefined which
        will be called first.

        Any positional arguments after the callback will be passed to
        the callback when it is called.
        delay must not be Nonecall_attimerwhenLike call_later(), but uses an absolute time.

        Absolute time corresponds to the event loop's time() method.
        when cannot be None_check_thread_check_callbackTimerHandlecall_soonArrange for a callback to be called as soon as possible.

        This operates as a FIFO queue: callbacks are called in the
        order in which they are registered.  Each callback will be
        called exactly once.

        Any positional arguments after the callback will be passed to
        the callback when it is called.
        _call_sooniscoroutinecoroutines cannot be used with a callable object was expected by (), got '(), ''got 'HandleCheck that the current thread is the thread running the event loop.

        Non-thread-safe methods of this class make this assumption and will
        likely behave incorrectly when the assumption is violated.

        Should only be called when (self._debug == True).  The caller is
        responsible for checking this condition for performance reasons.
        Non-thread-safe operation invoked on an event loop other than the current one"Non-thread-safe operation invoked on an event loop other ""than the current one"Like call_soon(), but thread-safe.run_in_executorthread_name_prefixwrap_futureset_default_executorexecutor must be ThreadPoolExecutor instance_getaddrinfo_debugfamily=type=proto=flags=Get address info %st0getaddrinfoaddrinfoGetting address info  took 1000.01e3ms: getaddr_funcgetnameinfosockaddrsock_sendfilefallbackgettimeoutthe socket must be non-blocking_check_sendfile_params_sock_sendfile_nativeSendfileNotAvailableError_sock_sendfile_fallbacksyscall sendfile is not available for socket  and file "and file " combinationSENDFILE_FALLBACK_READBUFFER_SIZEblocksizetotal_sentsock_sendallfile should be opened in binary modeonly SOCK_STREAM type sockets are supportedcount must be a positive integer (got {!r})offset must be a non-negative integer (got {!r})_connect_sockaddr_infolocal_addr_infosCreate, bind and connect one socket.my_exceptionstype_setblockinglfamilyladdrbinderror while attempting to bind on address 'error while attempting to bind on ''address '': 'no matching local address with  foundsock_connectcreate_connectionlocal_addrhappy_eyeballs_delayall_errorsConnect to a TCP server.

        Create a streaming transport connection to a given internet host and
        port: socket family AF_INET or socket.AF_INET6 depending on host (or
        family if specified), socket type SOCK_STREAM. protocol_factory must be
        a callable returning a protocol instance.

        This method is a coroutine which will try to establish the connection
        in the background.  When successful, the coroutine returns a
        (transport, protocol) pair.
        server_hostname is only meaningful with sslYou must set server_hostname when using ssl without a host'You must set server_hostname ''when using ssl without a host'ssl_handshake_timeout is only meaningful with sslssl_shutdown_timeout is only meaningful with sslhost/port and sock can not be specified at the same time_ensure_resolvedinfosgetaddrinfo() returned empty listladdr_infosstaggered_racecreate_connection failedmodelMultiple exceptions: {}host and port was not specified and no sock specifiedA Stream Socket was expected, got _create_connection_transportget_extra_info%r connected to %s:%r: (%r, %r)sendfileSend a file to transport.

        Return the total number of bytes which were sent.

        The method uses high-performance os.sendfile if available.

        file must be a regular file object opened in binary mode.

        offset tells from where to start reading the file. If specified,
        count is the total number of bytes to transmit as opposed to
        sending the file until EOF is reached. File position is updated on
        return or also in case of error in which case file.tell()
        can be used to figure out the number of bytes
        which were sent.

        fallback set to True makes asyncio to manually read and send
        the file when the platform does not support the sendfile syscall
        (e.g. Windows or SSL socket on Unix).

        Raise SendfileNotAvailableError if the system does not support
        sendfile syscall and fallback is False.
        Transport is closing_sendfile_compatible_SendfileModeUNSUPPORTEDsendfile is not supported for transport TRY_NATIVE_sendfile_nativefallback is disabled and native sendfile is not supported for transport "fallback is disabled and native sendfile is not ""supported for transport "_sendfile_fallbacksendfile syscall is not supportedstart_tlsUpgrade transport to TLS.

        Return a new transport that *protocol* should start using
        immediately.
        Python ssl module is not availableSSLContextsslcontext is expected to be an instance of ssl.SSLContext, got 'sslcontext is expected to be an instance of ssl.SSLContext, '_start_tls_compatibletransport  is not supported by start_tls()SSLProtocolssl_protocolconmade_cbresume_cb_app_transportcreate_datagram_endpointremote_addrreuse_portallow_broadcastCreate datagram connection.A datagram socket was expected, got problemssocket modifier keyword arguments can not be used when sock is specified. ('socket modifier keyword arguments can not be used ''when sock is specified. ('r_addrunexpected address familyaddr_pairs_infoAF_UNIXstring is expectedUnable to check or remove stale UNIX socket %r: %r'Unable to check or remove stale UNIX ''socket %r: %r'addr_infos2-tuple is expectedfamproaddr_paircan not get address informationlocal_addressremote_addressSO_BROADCASTDatagram endpoint local_addr=%r remote_addr=%r created: (%r, %r)"Datagram endpoint local_addr=%r remote_addr=%r ""created: (%r, %r)"Datagram endpoint remote_addr=%r created: (%r, %r)"Datagram endpoint remote_addr=%r created: ""(%r, %r)"_create_server_getaddrinfogetaddrinfo() returned empty listcreate_serverAI_PASSIVEreuse_addressCreate a TCP server.

        The host parameter can be a string, in that case the TCP server is
        bound to host and port.

        The host parameter can also be a sequence of strings and in that case
        the TCP server is bound to all hosts of the sequence. If a host
        appears multiple times (possibly indirectly e.g. when hostnames
        resolve to the same IP address), the server is only bound once to that
        host.

        Return a Server object which can be used to stop the service.

        This method is a coroutine.
        ssl argument must be an SSLContext or Nonehostscompletedsocktypecanonnamesacreate_server() failed to create socket.socket(%r, %r, %r)'create_server() failed to create ''socket.socket(%r, %r, %r)'SO_REUSEADDRIPPROTO_IPV6IPV6_V6ONLYerror while attempting to bind on address %r: %s'error while attempting ''to bind on address %r: %s'EADDRNOTAVAILcould not bind on any address out of %rNeither host/port nor sock were specified%r is servingconnect_accepted_socket%r handled: (%r, %r)connect_read_pipeRead pipe %r connected: (%r, %r)connect_write_pipeWrite pipe %r connected: (%r, %r)_log_subprocessstdin=stdout=stderr=stdout=stderr=subprocess_shelluniversal_newlinescmd must be a stringuniversal_newlines must be Falseshell must be Truebufsize must be 0text must be Falseencoding must be Noneerrors must be Nonedebug_logrun shell command %r%s: %rsubprocess_execprogramshell must be Falsepopen_argsexecute program get_exception_handlerReturn an exception handler, or None if the default one is in use.
        set_exception_handlerSet handler as the new event loop exception handler.

        If handler is None, the default exception handler will
        be set.

        If handler is a callable object, it should have a
        signature matching '(loop, context)', where 'loop'
        will be a reference to the active event loop, 'context'
        will be a dict object (see `call_exception_handler()`
        documentation for details about context).
        A callable object or None is expected, got 'A callable object or None is expected, 'default_exception_handlerDefault exception handler.

        This is called when an exception occurs and no exception
        handler is set, and can be called by a custom exception
        handler that wants to defer to the default behavior.

        This default handler logs the error message and other
        context-dependent information.  In debug mode, a truncated
        stack trace is also appended showing where the given object
        (e.g. a handle or future or task) was created, if any.

        The context parameter has the same meaning as in
        `call_exception_handler()`.
        Unhandled exception in event loopsource_tracebackhandle_tracebacklog_linesformat_listObject created at (most recent call last):
Handle created at (most recent call last):
Call the current event loop's exception handler.

        The context argument is a dict containing the following keys:

        - 'message': Error message;
        - 'exception' (optional): Exception object;
        - 'future' (optional): Future instance;
        - 'task' (optional): Task instance;
        - 'handle' (optional): Handle instance;
        - 'protocol' (optional): Protocol instance;
        - 'transport' (optional): Transport instance;
        - 'socket' (optional): Socket instance;
        - 'asyncgen' (optional): Asynchronous generator that caused
                                 the exception.

        New keys maybe introduced in the future.

        Note: do not overload this method in an event loop subclass.
        For custom exception handling, use the
        `set_exception_handler()` method.
        Exception in default exception handlerthingget_contextUnhandled error in exception handlerException in default exception handler while handling an unexpected error in custom exception handler'Exception in default exception handler ''while handling an unexpected error ''in custom exception handler'_add_callbackAdd a Handle to _ready._cancelled_add_callback_signalsafeLike _add_callback() but called from a signal handler._timer_handle_cancelledNotification that a TimerHandle has been cancelled.Run one full iteration of the event loop.

        This calls all currently ready callbacks, polls for I/O,
        schedules the resulting callbacks, and finally schedules
        'call_later' callbacks.
        sched_countnew_scheduled_when_selectorselectntodo_runExecuting %s took %.3f secondsenabledDEBUG_STACK_DEPTH# Minimum number of _scheduled timer handles before cleanup of# cancelled handles is performed.# Minimum fraction of _scheduled timer handles that are cancelled# before cleanup of cancelled handles is performed.# Maximum timeout passed to select to avoid OS limitations# format the task# Try to skip getaddrinfo if "host" is already an IP. Users might have# handled name resolution in their own code and pass in resolved IPs.# If port's a service name like "http", don't skip getaddrinfo.# Linux's inet_pton doesn't accept an IPv6 zone index after host,# like '::1%lo0'.# The host has already been resolved.# "host" is not an IP address.# Group addresses by family# Issue #22429: run_forever() already finished, no need to# stop it.# Never happens if peer disconnects after sending the whole content# Thus disconnection is always an exception from user perspective# Cancel the future.# Basically it has no effect because protocol is switched back,# no code should wait for it anymore.# Skip one loop iteration so that all 'loop.add_reader'# go through.# Waiters are unblocked by self._wakeup(), which is called# from two places: self.close() and self._detach(), but only# when both conditions have become true. To signal that this# has happened, self._wakeup() sets self._waiters to None.# Identifier of the thread running the event loop, or None if the# event loop is not running# In debug mode, if the execution of a callback or a step of a task# exceed this duration in seconds, the slow callback/task is logged.# A weak set of all asynchronous generators that are# being iterated by the loop.# Set to True when `loop.shutdown_asyncgens` is called.# Set to True when `loop.shutdown_default_executor` is called.# Use legacy API if context is not needed# If Python version is <3.6 or we don't have any asynchronous# generators alive.# An exception is raised if the future didn't complete, so there# is no need to log the "destroy pending task" message# The coroutine raised a BaseException. Consume the exception# to not log a warning, the caller doesn't have access to the# local task.# Only check when the default executor is being used# NB: sendfile syscall is not supported for SSL sockets and# non-mmap files even if sendfile is supported by OS# EOF# skip local addresses of different family# all bind attempts failed# Use host as default for server_hostname.  It is an error# if host is empty or not set, e.g. when an# already-connected socket was passed or when only a port# is given.  To avoid this error, you can pass# server_hostname='' -- this will bypass the hostname# check.  (This also means that if host is a numeric# IP/IPv6 address, we will attempt to verify that exact# address; this will probably fail, but it is possible to# create a certificate for a specific IP address, so we# don't judge it here.)# If using happy eyeballs, default to interleave addresses by family# not using happy eyeballs# using happy eyeballs# If they all have the same str(), raise one.# Raise a combined exception so the user can see all# the various error messages.# We allow AF_INET, AF_INET6, AF_UNIX as long as they# are SOCK_STREAM.# We support passing AF_UNIX sockets even though we have# a dedicated API for that: create_unix_connection.# Disallowing AF_UNIX in this method, breaks backwards# compatibility.# Get the socket from the transport because SSL transport closes# the old socket and creates a new SSL socket# Pause early so that "ssl_protocol.data_received()" doesn't# have a chance to get called before "ssl_protocol.connection_made()".# show the problematic kwargs in exception msg# Directory may have permissions only to create socket.# join address by (family, protocol)# Using order preserving dict# each addr has to have info for each (family, proto) pair# "host" is already a resolved IP.# Assume it's a bad family/type/protocol combination.# Disable IPv4/IPv6 dual stack support (enabled by# default on Linux) which makes a single socket# listen on both address families.# Assume the family is not enabled (bpo-30945)# don't log parameters: they may contain sensitive information# (password) and may be too long# Second protection layer for unexpected errors# in the default implementation, as well as for subclassed# event loops with overloaded "default_exception_handler".# Even though Futures don't have a context,# Task is a subclass of Future,# and sometimes the 'future' key holds a Task.# Handles also have a context.# Exception in the user set custom exception handler.# Let's try default handler.# Guard 'default_exception_handler' in case it is# overloaded.# Remove delayed calls that were cancelled if their number# is too high# Remove delayed calls that were cancelled from head of queue.# Compute the desired timeout.# Needed to break cycles when an exception occurs.# Handle 'later' callbacks that are ready.# This is the only place where callbacks are actually *called*.# All other places just add them to ready.# Note: We run all currently scheduled callbacks, but not any# callbacks scheduled by callbacks run this time around --# they will be run the next time (after another I/O poll).# Use an idiom that is thread-safe without using locks.b'Base implementation of event loop.

The event loop can be broken up into a multiplexer (the part
responsible for notifying us of I/O events) and the event loop proper,
which wraps a multiplexer with functionality for scheduling callbacks,
immediately or at a given time in the future.

Whenever a public API takes a callback, subsequent positional
arguments will be passed to the callback if/when it is called.  This
avoids the proliferation of trivial lambdas implementing closures.
Keyword arguments for the callback are not supported; this is a
conscious design decision, leaving the door open for keyword arguments
to modify the meaning of the API call itself.
'u'Base implementation of event loop.

The event loop can be broken up into a multiplexer (the part
responsible for notifying us of I/O events) and the event loop proper,
which wraps a multiplexer with functionality for scheduling callbacks,
immediately or at a given time in the future.

Whenever a public API takes a callback, subsequent positional
arguments will be passed to the callback if/when it is called.  This
avoids the proliferation of trivial lambdas implementing closures.
Keyword arguments for the callback are not supported; this is a
conscious design decision, leaving the door open for keyword arguments
to modify the meaning of the API call itself.
'b'BaseEventLoop'u'BaseEventLoop'b'Server'u'Server'b'AF_INET6'u'AF_INET6'b'__self__'u'__self__'b'<pipe>'u'<pipe>'b'<stdout>'u'<stdout>'b'SO_REUSEPORT'u'SO_REUSEPORT'b'reuse_port not supported by socket module'u'reuse_port not supported by socket module'b'reuse_port not supported by socket module, SO_REUSEPORT defined but not implemented.'u'reuse_port not supported by socket module, SO_REUSEPORT defined but not implemented.'b'inet_pton'u'inet_pton'b'idna'u'idna'b'Interleave list of addrinfo tuples by family.'u'Interleave list of addrinfo tuples by family.'b'TCP_NODELAY'u'TCP_NODELAY'b'Socket cannot be of type SSLSocket'u'Socket cannot be of type SSLSocket'b'transport should be _FlowControlMixin instance'u'transport should be _FlowControlMixin instance'b'Connection closed by peer'u'Connection closed by peer'b'Invalid state: connection should have been established already.'u'Invalid state: connection should have been established already.'b'Connection is closed by peer'u'Connection is closed by peer'b'Invalid state: reading should be paused'u'Invalid state: reading should be paused'b' sockets='u' sockets='b'server 'u'server 'b' is already being awaited on serve_forever()'u' is already being awaited on serve_forever()'b' is closed'u' is closed'b'Wait until server is closed and all connections are dropped.

        - If the server is not closed, wait.
        - If it is closed, but there are still active connections, wait.

        Anyone waiting here will be unblocked once both conditions
        (server is closed and all connections have been dropped)
        have become true, in either order.

        Historical note: In 3.11 and before, this was broken, returning
        immediately if the server was already closed, even if there
        were still active connections. An attempted fix in 3.12.0 was
        still broken, returning immediately if the server was still
        open and there were no active connections. Hopefully in 3.12.1
        we have it right.
        'u'Wait until server is closed and all connections are dropped.

        - If the server is not closed, wait.
        - If it is closed, but there are still active connections, wait.

        Anyone waiting here will be unblocked once both conditions
        (server is closed and all connections have been dropped)
        have become true, in either order.

        Historical note: In 3.11 and before, this was broken, returning
        immediately if the server was already closed, even if there
        were still active connections. An attempted fix in 3.12.0 was
        still broken, returning immediately if the server was still
        open and there were no active connections. Hopefully in 3.12.1
        we have it right.
        'b'monotonic'u'monotonic'b' running='u' running='b' closed='u' closed='b' debug='u' debug='b'Create a Future object attached to the loop.'u'Create a Future object attached to the loop.'b'Schedule a coroutine object.

        Return a task object.
        'u'Schedule a coroutine object.

        Return a task object.
        'b'Set a task factory that will be used by loop.create_task().

        If factory is None the default task factory will be set.

        If factory is a callable, it should have a signature matching
        '(loop, coro)', where 'loop' will be a reference to the active
        event loop, 'coro' will be a coroutine object.  The callable
        must return a Future.
        'u'Set a task factory that will be used by loop.create_task().

        If factory is None the default task factory will be set.

        If factory is a callable, it should have a signature matching
        '(loop, coro)', where 'loop' will be a reference to the active
        event loop, 'coro' will be a coroutine object.  The callable
        must return a Future.
        'b'task factory must be a callable or None'u'task factory must be a callable or None'b'Return a task factory, or None if the default one is in use.'u'Return a task factory, or None if the default one is in use.'b'Create socket transport.'u'Create socket transport.'b'Create SSL transport.'u'Create SSL transport.'b'Create datagram transport.'u'Create datagram transport.'b'Create read pipe transport.'u'Create read pipe transport.'b'Create write pipe transport.'u'Create write pipe transport.'b'Create subprocess transport.'u'Create subprocess transport.'b'Write a byte to self-pipe, to wake up the event loop.

        This may be called from a different thread.

        The subclass is responsible for implementing the self-pipe.
        'u'Write a byte to self-pipe, to wake up the event loop.

        This may be called from a different thread.

        The subclass is responsible for implementing the self-pipe.
        'b'Process selector events.'u'Process selector events.'b'Event loop is closed'u'Event loop is closed'b'Executor shutdown has been called'u'Executor shutdown has been called'b'asynchronous generator 'u'asynchronous generator 'b' was scheduled after loop.shutdown_asyncgens() call'u' was scheduled after loop.shutdown_asyncgens() call'b'Shutdown all active asynchronous generators.'u'Shutdown all active asynchronous generators.'b'an error occurred during closing of asynchronous generator 'u'an error occurred during closing of asynchronous generator 'b'asyncgen'u'asyncgen'b'Schedule the shutdown of the default executor.

        The timeout parameter specifies the amount of time the executor will
        be given to finish joining. The default value is None, which means
        that the executor will be given an unlimited amount of time.
        'u'Schedule the shutdown of the default executor.

        The timeout parameter specifies the amount of time the executor will
        be given to finish joining. The default value is None, which means
        that the executor will be given an unlimited amount of time.
        'b'The executor did not finishing joining its threads within 'u'The executor did not finishing joining its threads within 'b' seconds.'u' seconds.'b'This event loop is already running'u'This event loop is already running'b'Cannot run the event loop while another loop is running'u'Cannot run the event loop while another loop is running'b'Run until stop() is called.'u'Run until stop() is called.'b'Run until the Future is done.

        If the argument is a coroutine, it is wrapped in a Task.

        WARNING: It would be disastrous to call run_until_complete()
        with the same coroutine twice -- it would wrap it in two
        different Tasks and that can't be good.

        Return the Future's result, or raise its exception.
        'u'Run until the Future is done.

        If the argument is a coroutine, it is wrapped in a Task.

        WARNING: It would be disastrous to call run_until_complete()
        with the same coroutine twice -- it would wrap it in two
        different Tasks and that can't be good.

        Return the Future's result, or raise its exception.
        'b'Event loop stopped before Future completed.'u'Event loop stopped before Future completed.'b'Stop running the event loop.

        Every callback already scheduled will still run.  This simply informs
        run_forever to stop looping after a complete iteration.
        'u'Stop running the event loop.

        Every callback already scheduled will still run.  This simply informs
        run_forever to stop looping after a complete iteration.
        'b'Close the event loop.

        This clears the queues and shuts down the executor,
        but does not wait for the executor to finish.

        The event loop must not be running.
        'u'Close the event loop.

        This clears the queues and shuts down the executor,
        but does not wait for the executor to finish.

        The event loop must not be running.
        'b'Cannot close a running event loop'u'Cannot close a running event loop'b'Close %r'u'Close %r'b'Returns True if the event loop was closed.'u'Returns True if the event loop was closed.'b'unclosed event loop 'u'unclosed event loop 'b'Returns True if the event loop is running.'u'Returns True if the event loop is running.'b'Return the time according to the event loop's clock.

        This is a float expressed in seconds since an epoch, but the
        epoch, precision, accuracy and drift are unspecified and may
        differ per event loop.
        'u'Return the time according to the event loop's clock.

        This is a float expressed in seconds since an epoch, but the
        epoch, precision, accuracy and drift are unspecified and may
        differ per event loop.
        'b'Arrange for a callback to be called at a given time.

        Return a Handle: an opaque object with a cancel() method that
        can be used to cancel the call.

        The delay can be an int or float, expressed in seconds.  It is
        always relative to the current time.

        Each callback will be called exactly once.  If two callbacks
        are scheduled for exactly the same time, it is undefined which
        will be called first.

        Any positional arguments after the callback will be passed to
        the callback when it is called.
        'u'Arrange for a callback to be called at a given time.

        Return a Handle: an opaque object with a cancel() method that
        can be used to cancel the call.

        The delay can be an int or float, expressed in seconds.  It is
        always relative to the current time.

        Each callback will be called exactly once.  If two callbacks
        are scheduled for exactly the same time, it is undefined which
        will be called first.

        Any positional arguments after the callback will be passed to
        the callback when it is called.
        'b'delay must not be None'u'delay must not be None'b'Like call_later(), but uses an absolute time.

        Absolute time corresponds to the event loop's time() method.
        'u'Like call_later(), but uses an absolute time.

        Absolute time corresponds to the event loop's time() method.
        'b'when cannot be None'u'when cannot be None'b'call_at'u'call_at'b'Arrange for a callback to be called as soon as possible.

        This operates as a FIFO queue: callbacks are called in the
        order in which they are registered.  Each callback will be
        called exactly once.

        Any positional arguments after the callback will be passed to
        the callback when it is called.
        'u'Arrange for a callback to be called as soon as possible.

        This operates as a FIFO queue: callbacks are called in the
        order in which they are registered.  Each callback will be
        called exactly once.

        Any positional arguments after the callback will be passed to
        the callback when it is called.
        'b'call_soon'u'call_soon'b'coroutines cannot be used with 'u'coroutines cannot be used with 'b'a callable object was expected by 'u'a callable object was expected by 'b'(), got 'u'(), got 'b'Check that the current thread is the thread running the event loop.

        Non-thread-safe methods of this class make this assumption and will
        likely behave incorrectly when the assumption is violated.

        Should only be called when (self._debug == True).  The caller is
        responsible for checking this condition for performance reasons.
        'u'Check that the current thread is the thread running the event loop.

        Non-thread-safe methods of this class make this assumption and will
        likely behave incorrectly when the assumption is violated.

        Should only be called when (self._debug == True).  The caller is
        responsible for checking this condition for performance reasons.
        'b'Non-thread-safe operation invoked on an event loop other than the current one'u'Non-thread-safe operation invoked on an event loop other than the current one'b'Like call_soon(), but thread-safe.'u'Like call_soon(), but thread-safe.'b'call_soon_threadsafe'u'call_soon_threadsafe'b'run_in_executor'u'run_in_executor'b'executor must be ThreadPoolExecutor instance'u'executor must be ThreadPoolExecutor instance'b'family='u'family='b'type='u'type='b'proto='u'proto='b'flags='u'flags='b'Get address info %s'u'Get address info %s'b'Getting address info 'u'Getting address info 'b' took 'u' took 'b'ms: 'u'ms: 'b'the socket must be non-blocking'u'the socket must be non-blocking'b'syscall sendfile is not available for socket 'u'syscall sendfile is not available for socket 'b' and file 'u' and file 'b' combination'u' combination'b'seek'u'seek'b'mode'u'mode'b'file should be opened in binary mode'u'file should be opened in binary mode'b'only SOCK_STREAM type sockets are supported'u'only SOCK_STREAM type sockets are supported'b'count must be a positive integer (got {!r})'u'count must be a positive integer (got {!r})'b'offset must be a non-negative integer (got {!r})'u'offset must be a non-negative integer (got {!r})'b'Create, bind and connect one socket.'u'Create, bind and connect one socket.'b'error while attempting to bind on address 'u'error while attempting to bind on address 'b'no matching local address with 'u'no matching local address with 'b' found'u' found'b'Connect to a TCP server.

        Create a streaming transport connection to a given internet host and
        port: socket family AF_INET or socket.AF_INET6 depending on host (or
        family if specified), socket type SOCK_STREAM. protocol_factory must be
        a callable returning a protocol instance.

        This method is a coroutine which will try to establish the connection
        in the background.  When successful, the coroutine returns a
        (transport, protocol) pair.
        'u'Connect to a TCP server.

        Create a streaming transport connection to a given internet host and
        port: socket family AF_INET or socket.AF_INET6 depending on host (or
        family if specified), socket type SOCK_STREAM. protocol_factory must be
        a callable returning a protocol instance.

        This method is a coroutine which will try to establish the connection
        in the background.  When successful, the coroutine returns a
        (transport, protocol) pair.
        'b'server_hostname is only meaningful with ssl'u'server_hostname is only meaningful with ssl'b'You must set server_hostname when using ssl without a host'u'You must set server_hostname when using ssl without a host'b'ssl_handshake_timeout is only meaningful with ssl'u'ssl_handshake_timeout is only meaningful with ssl'b'ssl_shutdown_timeout is only meaningful with ssl'u'ssl_shutdown_timeout is only meaningful with ssl'b'host/port and sock can not be specified at the same time'u'host/port and sock can not be specified at the same time'b'getaddrinfo() returned empty list'u'getaddrinfo() returned empty list'b'create_connection failed'u'create_connection failed'b'Multiple exceptions: {}'u'Multiple exceptions: {}'b'host and port was not specified and no sock specified'u'host and port was not specified and no sock specified'b'A Stream Socket was expected, got 'u'A Stream Socket was expected, got 'b'%r connected to %s:%r: (%r, %r)'u'%r connected to %s:%r: (%r, %r)'b'Send a file to transport.

        Return the total number of bytes which were sent.

        The method uses high-performance os.sendfile if available.

        file must be a regular file object opened in binary mode.

        offset tells from where to start reading the file. If specified,
        count is the total number of bytes to transmit as opposed to
        sending the file until EOF is reached. File position is updated on
        return or also in case of error in which case file.tell()
        can be used to figure out the number of bytes
        which were sent.

        fallback set to True makes asyncio to manually read and send
        the file when the platform does not support the sendfile syscall
        (e.g. Windows or SSL socket on Unix).

        Raise SendfileNotAvailableError if the system does not support
        sendfile syscall and fallback is False.
        'u'Send a file to transport.

        Return the total number of bytes which were sent.

        The method uses high-performance os.sendfile if available.

        file must be a regular file object opened in binary mode.

        offset tells from where to start reading the file. If specified,
        count is the total number of bytes to transmit as opposed to
        sending the file until EOF is reached. File position is updated on
        return or also in case of error in which case file.tell()
        can be used to figure out the number of bytes
        which were sent.

        fallback set to True makes asyncio to manually read and send
        the file when the platform does not support the sendfile syscall
        (e.g. Windows or SSL socket on Unix).

        Raise SendfileNotAvailableError if the system does not support
        sendfile syscall and fallback is False.
        'b'Transport is closing'u'Transport is closing'b'_sendfile_compatible'u'_sendfile_compatible'b'sendfile is not supported for transport 'u'sendfile is not supported for transport 'b'fallback is disabled and native sendfile is not supported for transport 'u'fallback is disabled and native sendfile is not supported for transport 'b'sendfile syscall is not supported'u'sendfile syscall is not supported'b'Upgrade transport to TLS.

        Return a new transport that *protocol* should start using
        immediately.
        'u'Upgrade transport to TLS.

        Return a new transport that *protocol* should start using
        immediately.
        'b'Python ssl module is not available'u'Python ssl module is not available'b'sslcontext is expected to be an instance of ssl.SSLContext, got 'u'sslcontext is expected to be an instance of ssl.SSLContext, got 'b'_start_tls_compatible'u'_start_tls_compatible'b'transport 'u'transport 'b' is not supported by start_tls()'u' is not supported by start_tls()'b'Create datagram connection.'u'Create datagram connection.'b'A datagram socket was expected, got 'u'A datagram socket was expected, got 'b'socket modifier keyword arguments can not be used when sock is specified. ('u'socket modifier keyword arguments can not be used when sock is specified. ('b'unexpected address family'u'unexpected address family'b'AF_UNIX'u'AF_UNIX'b'string is expected'u'string is expected'u' 'b'Unable to check or remove stale UNIX socket %r: %r'u'Unable to check or remove stale UNIX socket %r: %r'b'2-tuple is expected'u'2-tuple is expected'b'can not get address information'u'can not get address information'b'Datagram endpoint local_addr=%r remote_addr=%r created: (%r, %r)'u'Datagram endpoint local_addr=%r remote_addr=%r created: (%r, %r)'b'Datagram endpoint remote_addr=%r created: (%r, %r)'u'Datagram endpoint remote_addr=%r created: (%r, %r)'b'getaddrinfo('u'getaddrinfo('b') returned empty list'u') returned empty list'b'Create a TCP server.

        The host parameter can be a string, in that case the TCP server is
        bound to host and port.

        The host parameter can also be a sequence of strings and in that case
        the TCP server is bound to all hosts of the sequence. If a host
        appears multiple times (possibly indirectly e.g. when hostnames
        resolve to the same IP address), the server is only bound once to that
        host.

        Return a Server object which can be used to stop the service.

        This method is a coroutine.
        'u'Create a TCP server.

        The host parameter can be a string, in that case the TCP server is
        bound to host and port.

        The host parameter can also be a sequence of strings and in that case
        the TCP server is bound to all hosts of the sequence. If a host
        appears multiple times (possibly indirectly e.g. when hostnames
        resolve to the same IP address), the server is only bound once to that
        host.

        Return a Server object which can be used to stop the service.

        This method is a coroutine.
        'b'ssl argument must be an SSLContext or None'u'ssl argument must be an SSLContext or None'b'posix'u'posix'b'create_server() failed to create socket.socket(%r, %r, %r)'u'create_server() failed to create socket.socket(%r, %r, %r)'b'IPPROTO_IPV6'u'IPPROTO_IPV6'b'error while attempting to bind on address %r: %s'u'error while attempting to bind on address %r: %s'b'could not bind on any address out of %r'u'could not bind on any address out of %r'b'Neither host/port nor sock were specified'u'Neither host/port nor sock were specified'b'%r is serving'u'%r is serving'b'%r handled: (%r, %r)'u'%r handled: (%r, %r)'b'Read pipe %r connected: (%r, %r)'u'Read pipe %r connected: (%r, %r)'b'Write pipe %r connected: (%r, %r)'u'Write pipe %r connected: (%r, %r)'b'stdin='u'stdin='b'stdout=stderr='u'stdout=stderr='b'stdout='u'stdout='b'stderr='u'stderr='b'cmd must be a string'u'cmd must be a string'b'universal_newlines must be False'u'universal_newlines must be False'b'shell must be True'u'shell must be True'b'bufsize must be 0'u'bufsize must be 0'b'text must be False'u'text must be False'b'encoding must be None'u'encoding must be None'b'errors must be None'u'errors must be None'b'run shell command %r'u'run shell command %r'b'%s: %r'u'%s: %r'b'shell must be False'u'shell must be False'b'execute program 'u'execute program 'b'Return an exception handler, or None if the default one is in use.
        'u'Return an exception handler, or None if the default one is in use.
        'b'Set handler as the new event loop exception handler.

        If handler is None, the default exception handler will
        be set.

        If handler is a callable object, it should have a
        signature matching '(loop, context)', where 'loop'
        will be a reference to the active event loop, 'context'
        will be a dict object (see `call_exception_handler()`
        documentation for details about context).
        'u'Set handler as the new event loop exception handler.

        If handler is None, the default exception handler will
        be set.

        If handler is a callable object, it should have a
        signature matching '(loop, context)', where 'loop'
        will be a reference to the active event loop, 'context'
        will be a dict object (see `call_exception_handler()`
        documentation for details about context).
        'b'A callable object or None is expected, got 'u'A callable object or None is expected, got 'b'Default exception handler.

        This is called when an exception occurs and no exception
        handler is set, and can be called by a custom exception
        handler that wants to defer to the default behavior.

        This default handler logs the error message and other
        context-dependent information.  In debug mode, a truncated
        stack trace is also appended showing where the given object
        (e.g. a handle or future or task) was created, if any.

        The context parameter has the same meaning as in
        `call_exception_handler()`.
        'u'Default exception handler.

        This is called when an exception occurs and no exception
        handler is set, and can be called by a custom exception
        handler that wants to defer to the default behavior.

        This default handler logs the error message and other
        context-dependent information.  In debug mode, a truncated
        stack trace is also appended showing where the given object
        (e.g. a handle or future or task) was created, if any.

        The context parameter has the same meaning as in
        `call_exception_handler()`.
        'b'Unhandled exception in event loop'u'Unhandled exception in event loop'b'source_traceback'u'source_traceback'b'handle_traceback'u'handle_traceback'b'Object created at (most recent call last):
'u'Object created at (most recent call last):
'b'Handle created at (most recent call last):
'u'Handle created at (most recent call last):
'b'Call the current event loop's exception handler.

        The context argument is a dict containing the following keys:

        - 'message': Error message;
        - 'exception' (optional): Exception object;
        - 'future' (optional): Future instance;
        - 'task' (optional): Task instance;
        - 'handle' (optional): Handle instance;
        - 'protocol' (optional): Protocol instance;
        - 'transport' (optional): Transport instance;
        - 'socket' (optional): Socket instance;
        - 'asyncgen' (optional): Asynchronous generator that caused
                                 the exception.

        New keys maybe introduced in the future.

        Note: do not overload this method in an event loop subclass.
        For custom exception handling, use the
        `set_exception_handler()` method.
        'u'Call the current event loop's exception handler.

        The context argument is a dict containing the following keys:

        - 'message': Error message;
        - 'exception' (optional): Exception object;
        - 'future' (optional): Future instance;
        - 'task' (optional): Task instance;
        - 'handle' (optional): Handle instance;
        - 'protocol' (optional): Protocol instance;
        - 'transport' (optional): Transport instance;
        - 'socket' (optional): Socket instance;
        - 'asyncgen' (optional): Asynchronous generator that caused
                                 the exception.

        New keys maybe introduced in the future.

        Note: do not overload this method in an event loop subclass.
        For custom exception handling, use the
        `set_exception_handler()` method.
        'b'Exception in default exception handler'u'Exception in default exception handler'b'task'u'task'b'future'u'future'b'handle'u'handle'b'get_context'u'get_context'b'run'u'run'b'Unhandled error in exception handler'u'Unhandled error in exception handler'b'context'u'context'b'Exception in default exception handler while handling an unexpected error in custom exception handler'u'Exception in default exception handler while handling an unexpected error in custom exception handler'b'Add a Handle to _ready.'u'Add a Handle to _ready.'b'Like _add_callback() but called from a signal handler.'u'Like _add_callback() but called from a signal handler.'b'Notification that a TimerHandle has been cancelled.'u'Notification that a TimerHandle has been cancelled.'b'Run one full iteration of the event loop.

        This calls all currently ready callbacks, polls for I/O,
        schedules the resulting callbacks, and finally schedules
        'call_later' callbacks.
        'u'Run one full iteration of the event loop.

        This calls all currently ready callbacks, polls for I/O,
        schedules the resulting callbacks, and finally schedules
        'call_later' callbacks.
        'b'Executing %s took %.3f seconds'u'Executing %s took %.3f seconds'u'Lib.asyncio.base_events'u'asyncio.base_events'u'base_events'format_helpers_PENDING_CANCELLED_FINISHEDCheck for a Future.

    This returns True when obj is a Future instance or is advertising
    itself as duck-type compatible by setting _asyncio_future_blocking.
    See comment in Future for more details.
    _asyncio_future_blocking_format_callbackshelper function for Future.__repr__format_cb_format_callback_source{}, {}{}, <{} more>, {}cb=[_future_repr_infoexception=result=_callbackscreated at _future_repr# States for Future.# (Future) -> str# use reprlib to limit the length of the output, especially# for very long stringsb'Check for a Future.

    This returns True when obj is a Future instance or is advertising
    itself as duck-type compatible by setting _asyncio_future_blocking.
    See comment in Future for more details.
    'u'Check for a Future.

    This returns True when obj is a Future instance or is advertising
    itself as duck-type compatible by setting _asyncio_future_blocking.
    See comment in Future for more details.
    'b'_asyncio_future_blocking'u'_asyncio_future_blocking'b'helper function for Future.__repr__'u'helper function for Future.__repr__'b'{}, {}'u'{}, {}'b'{}, <{} more>, {}'u'{}, <{} more>, {}'b'cb=['u'cb=['b'exception='u'exception='b'result='u'result='b'created at 'u'created at 'u'Lib.asyncio.base_futures'u'asyncio.base_futures'u'base_futures'BaseSubprocessTransportSubprocessTransport_protocol_proc_pid_returncode_exit_waiters_pending_calls_pipes_finished_startpid_extraprocess %r created: pid %s_connect_pipespid=returncode=not started<{}>pollClose running child process: kill %rkillunclosed transport get_pidget_returncodeget_pipe_transport_check_procsend_signalterminateprocWriteSubprocessPipeProtoReadSubprocessPipeProto_call_pipe_connection_lostpipe_connection_lost_try_finish_pipe_data_receivedpipe_data_received_process_exitedreturncode%r exited with return code %rprocess_exited_waitWait until the process exit and return the process return code.

        This method is a coroutine.disconnected_call_connection_lostBaseProtocol fd= pipe=# Create the child process: set the _proc attribute# has the child process finished?# the child process has finished, but the# transport hasn't been notified yet?# Don't clear the _proc reference yet: _post_init() may still run# asyncio uses a child watcher: copy the status into the Popen# object. On Python 3.6, it is required to avoid a ResourceWarning.# wake up futures waiting for wait()b'process %r created: pid %s'u'process %r created: pid %s'b'closed'u'closed'b'pid='u'pid='b'returncode='u'returncode='b'not started'u'not started'b'<{}>'u'<{}>'b'Close running child process: kill %r'u'Close running child process: kill %r'b'unclosed transport 'u'unclosed transport 'b'%r exited with return code %r'u'%r exited with return code %r'b'Wait until the process exit and return the process return code.

        This method is a coroutine.'u'Wait until the process exit and return the process return code.

        This method is a coroutine.'b' fd='u' fd='b' pipe='u' pipe='u'Lib.asyncio.base_subprocess'u'asyncio.base_subprocess'u'base_subprocess'linecachebase_futures_task_repr_infocancellingname=%r_fut_waiterwait_for=_format_coroutinecoro=<_task_repr_task_get_stackframescr_frameag_frametb_next_task_print_stackextracted_listget_stackcheckcachegetlineNo stack for Traceback for  (most recent call last):Stack for print_listformat_exception_only# replace status# case 1: 'async def' coroutines# case 2: legacy coroutines# case 3: async generators# case 4: unknown objectsb'cancelling'u'cancelling'b'name=%r'u'name=%r'b'wait_for='u'wait_for='b'coro=<'u'coro=<'b'cr_frame'u'cr_frame'b'gi_frame'u'gi_frame'b'ag_frame'u'ag_frame'b'No stack for 'u'No stack for 'b'Traceback for 'u'Traceback for 'b' (most recent call last):'u' (most recent call last):'b'Stack for 'u'Stack for 'u'Lib.asyncio.base_tasks'u'asyncio.base_tasks'u'base_tasks'Debugger basicsfnmatchCO_GENERATORCO_COROUTINECO_ASYNC_GENERATORBdbQuitBdbBreakpointGENERATOR_AND_COROUTINE_FLAGSException to give up completely.Generic Python debugger base class.

    This class takes care of details of the trace facility;
    a derived class should implement user interaction.
    The standard debugger class (pdb.Pdb) is an example.

    The optional skip argument must be an iterable of glob-style
    module name patterns.  The debugger will not step into frames
    that originate in a module that matches one of these patterns.
    Whether a frame is considered to originate in a certain module
    is determined by the __name__ in the frame globals.
    breaksfncacheframe_returning_load_breakscanonicReturn canonical form of filename.

        For real filenames, the canonical form is a case-normalized (on
        case insensitive filesystems) absolute path.  'Filenames' with
        angle brackets, such as "<stdin>", generated in interactive
        mode, are returned unchanged.
        Set values of attributes as ready to start debugging.botframe_set_stopinfotrace_dispatchDispatch a trace function for debugged frames based on the event.

        This function is installed as the trace function for debugged
        frames. Its return value is the new trace function, which is
        usually itself. The default implementation decides how to
        dispatch a frame, depending on the type of event (passed in as a
        string) that is about to be executed.

        The event can be one of the following:
            line: A new line of code is going to be executed.
            call: A function is about to be called or another code block
                  is entered.
            return: A function or other code block is about to return.
            exception: An exception has occurred.
            c_call: A C function is about to be called.
            c_return: A C function has returned.
            c_exception: A C function has raised an exception.

        For the Python events, specialized functions (see the dispatch_*()
        methods) are called.  For the C events, no action is taken.

        The arg parameter depends on the previous event.
        quittingdispatch_linedispatch_calldispatch_returndispatch_exceptionc_callc_exceptionc_returnbdb.Bdb.dispatch: unknown debugging event:Invoke user function and return trace function for line event.

        If the debugger stops on the current line, invoke
        self.user_line(). Raise BdbQuit if self.quitting is set.
        Return self.trace_dispatch to continue tracing in this scope.
        stop_herebreak_hereuser_lineInvoke user function and return trace function for call event.

        If the debugger stops on this function call, invoke
        self.user_call(). Raise BdbQuit if self.quitting is set.
        Return self.trace_dispatch to continue tracing in this scope.
        break_anywherestopframeco_flagsuser_callInvoke user function and return trace function for return event.

        If the debugger stops on this function return, invoke
        self.user_return(). Raise BdbQuit if self.quitting is set.
        Return self.trace_dispatch to continue tracing in this scope.
        returnframeuser_returnstoplineno_set_caller_tracefuncInvoke user function and return trace function for exception event.

        If the debugger stops on this exception, invoke
        self.user_exception(). Raise BdbQuit if self.quitting is set.
        Return self.trace_dispatch to continue tracing in this scope.
        user_exceptionis_skipped_moduleReturn True if module_name matches any skip pattern.Return True if frame is below the starting frame in the stack.Return True if there is an effective breakpoint for this line.

        Check for line or function breakpoint and if in effect.
        Delete temporary breakpoints if effective() says to.
        co_firstlinenoeffectivebpnumbercurrentbptemporarydo_clearRemove temporary breakpoint.

        Must implement in derived classes or get NotImplementedError.
        subclass of bdb must implement do_clear()Return True if there is any breakpoint for frame's filename.
        argument_listCalled if we might stop in a function.Called when we stop or break at a line.return_valueCalled when a return trap is set here.Called when we stop on an exception.Set the attributes for stopping.

        If stoplineno is greater than or equal to 0, then stop at line
        greater than or equal to the stopline.  If stoplineno is -1, then
        don't stop at all.
        current_framecaller_framef_traceset_untilStop when the line with the lineno greater than the current one is
        reached or when returning from current frame.set_stepStop after one line of code.set_nextStop on the next line in or below the given frame.set_returnStop when returning from the given frame.set_traceStart debugging from frame.

        If frame is not specified, debugging starts from caller's frame.
        set_continueStop only at breakpoints or when finished.

        If there are no breakpoints, set the system trace function to None.
        set_quitSet quitting attribute to True.

        Raises BdbQuit exception in the next call to a dispatch_*() method.
        _add_to_breaksAdd breakpoint to breaks, if not already there.bp_linenosset_breakcondfuncnameSet a new breakpoint for filename:lineno.

        If lineno doesn't exist for the filename, return an error message.
        The filename should be in canonical form.
        Line %s:%d does not existApply all breakpoints (set in other instances) to this one.

        Populates this instance's breaks list from the Breakpoint class's
        list, which can have breakpoints set by another Bdb instance. This
        is necessary for interactive sessions to keep the breakpoints
        active across multiple calls to run().
        bplist_prune_breaksPrune breakpoints for filename:lineno.

        A list of breakpoints is maintained in the Bdb instance and in
        the Breakpoint class.  If a breakpoint in the Bdb instance no
        longer exists in the Breakpoint class, then it's removed from the
        Bdb instance.
        clear_breakDelete breakpoints for filename:lineno.

        If no breakpoints were set, return an error message.
        There are no breakpoints in %sThere is no breakpoint at %s:%ddeleteMeclear_bpbynumberDelete a breakpoint by its index in Breakpoint.bpbynumber.

        If arg is invalid, return an error message.
        get_bpbynumberclear_all_file_breaksDelete all breakpoints in filename.

        If none were set, return an error message.
        blistclear_all_breaksDelete all existing breakpoints.

        If none were set, return an error message.
        There are no breakpointsbpbynumberReturn a breakpoint by its index in Breakpoint.bybpnumber.

        For invalid arg values or if the breakpoint doesn't exist,
        raise a ValueError.
        Breakpoint number expectedNon-numeric breakpoint number %sBreakpoint number %d out of rangeBreakpoint %d already deletedget_breakReturn True if there is a breakpoint for filename:lineno.get_breaksReturn all breakpoints for filename:lineno.

        If no breakpoints are set, return an empty list.
        get_file_breaksReturn all lines with breakpoints for filename.

        If no breakpoints are set, return an empty list.
        get_all_breaksReturn all breakpoints that are set.Return a list of (frame, lineno) in a stack trace and a size.

        List starts with original calling frame, if there is one.
        Size may be number of frames above or below f.
        stacktb_linenoformat_stack_entryframe_linenolprefixReturn a string with information about a stack entry.

        The stack entry frame_lineno is a (frame, lineno) tuple.  The
        return string contains the canonical filename, the function name
        or '<lambda>', the input arguments, the return value, and the
        line of code (if it exists).

        <lambda>__return__f_locals->Warning: lineno is NoneDebug a statement executed via the exec() function.

        globals defaults to __main__.dict; locals defaults to globals.
        runevalDebug an expression executed via the eval() function.

        globals defaults to __main__.dict; locals defaults to globals.
        runctxFor backwards-compatibility.  Defers to run().runcallDebug a single function call.

        Return the result of the function call.
        Start debugging with a Bdb instance from the caller's frame.Breakpoint class.

    Implements temporary breakpoints, ignore counts, disabling and
    (re)-enabling, and conditionals.

    Breakpoints are indexed by number through bpbynumber and by
    the (file, line) tuple using bplist.  The former points to a
    single instance of class Breakpoint.  The latter points to a
    list of such instances since there may be more than one
    breakpoint per line.

    When creating a breakpoint, its associated filename should be
    in canonical form.  If funcname is defined, a breakpoint hit will be
    counted when the first line of that function is executed.  A
    conditional breakpoint always counts a hit.
    func_first_executable_linehitsclearBreakpointsDelete the breakpoint from the list associated to a file:line.

        If it is the last breakpoint in that position, it also deletes
        the entry for the file:line.
        enableMark the breakpoint as enabled.Mark the breakpoint as disabled.bpprintPrint the output of bpformat().

        The optional out argument directs where the output is sent
        and defaults to standard output.
        bpformatReturn a string with information about the breakpoint.

        The information includes the breakpoint number, temporary
        status, file:line position, break condition, number of times to
        ignore, and number of times hit.

        del  dispkeep yes  no   %-4dbreakpoint   %s at %s:%dret
	stop only if %s
	ignore next %d hits
	breakpoint already hit %d time%sReturn a condensed description of the breakpoint.breakpoint %s at %s:%scheckfuncnameReturn True if break should happen here.

    Whether a break should happen depends on the way that b (the breakpoint)
    was set.  If it was set via line number, check if b.line is the same as
    the one in the frame.  If it was set via function name, check if this is
    the right function and if it is on the first executable line.
    Return (active breakpoint, delete temporary flag) or (None, None) as
       breakpoint to act upon.

       The "active breakpoint" is the first entry in bplist[line, file] (which
       must exist) that is enabled, for which checkfuncname is True, and that
       has neither a False condition nor a positive ignore count.  The flag,
       meaning that a temporary breakpoint should be deleted, is False only
       when the condiion cannot be evaluated (in which case, ignore count is
       ignored).

       If no such entry exists, then (None, None) is returned.
    possiblesTdb???+++ call+++retval+++ returnexc_stuff+++ exceptionfoofoo(barbar returnedbar(import bdb; bdb.foo(10)# None# XXX 'arg' is no longer used# First call of dispatch since reset()# (CT) Note that this may also be None!# No need to trace this function# Ignore call events in generator except when stepping.# Ignore return events in generator except when stepping.# The user issued a 'next' or 'until' command.# The previous frame might not have f_trace set, unless we are# issuing a command that does not expect to stop, we should set# f_trace# When stepping with next/until/return in a generator frame, skip# the internal StopIteration exception (with no traceback)# triggered by a subiterator run with the 'yield from' statement.# Stop at the StopIteration or GeneratorExit exception when the user# has set stopframe in a generator by issuing a return command, or a# next/until command at the last statement in the generator before the# exception.# Normally derived classes don't override the following# methods, but they may if they want to redefine the# definition of stopping and breakpoints.# some modules do not have names# (CT) stopframe may now also be None, see dispatch_call.# (CT) the former test for None is therefore removed from here.# The line itself has no breakpoint, but maybe the line is the# first line of a function with breakpoint set by function name.# flag says ok to delete temp. bp# Derived classes should override the user_* methods# to gain control.# stoplineno >= 0 means: stop at line >= the stoplineno# stoplineno -1 means: don't stop at all# Issue #13183: pdb skips frames after hitting a breakpoint and running# step commands.# Restore the trace function in the caller (that may not have been set# for performance reasons) when returning from the current frame.# Derived classes and clients can call the following methods# to affect the stepping state.# the name "until" is borrowed from gdb# Don't stop except at breakpoints or when finished# no breakpoints; run without debugger overhead# to manipulate breakpoints.  These methods return an# error message if something went wrong, None if all is well.# Set_break prints out the breakpoint line and file:lineno.# Call self.get_*break*() to see the breakpoints or better# for bp in Breakpoint.bpbynumber: if bp: bp.bpprint().# Import as late as possible# If there's only one bp in the list for that file,line# pair, then remove the breaks entry# Derived classes and clients can call the following method# to get a data structure representing a stack trace.# The following methods can be called by clients to use# a debugger to debug a statement or an expression.# Both can be given as a string, or a code object.# B/W compatibility# This method is more useful to debug a single function call.# XXX Keeping state in the class is a mistake -- this means# you cannot have more than one active Bdb instance.# Next bp to be assigned# indexed by (file, lineno) tuple# Each entry is None or an instance of Bpt# index 0 is unused, except for marking an# effective break .... see effective()# Needed if funcname is not None.# This better be in canonical form!# Build the two lists# No longer in list# No more bp for this f:l combo# -----------end of Breakpoint class----------# Breakpoint was set via line number.# Breakpoint was set at a line with a def statement and the function# defined is called: don't break.# Breakpoint set via function name.# It's not a function call, but rather execution of def statement.# We are in the right frame.# The function is entered for the 1st time.# But we are not at the first line number: don't break.# Count every hit when bp is enabled# If unconditional, and ignoring go on to next, else break# breakpoint and marker that it's ok to delete if temporary# Conditional bp.# Ignore count applies only to those bpt hits where the# condition evaluates to true.# continue# else:#   continue# if eval fails, most conservative thing is to stop on# breakpoint regardless of ignore count.  Don't delete# temporary, as another hint to user.# -------------------- testing --------------------b'Debugger basics'u'Debugger basics'b'BdbQuit'u'BdbQuit'b'Bdb'u'Bdb'b'Breakpoint'u'Breakpoint'b'Exception to give up completely.'u'Exception to give up completely.'b'Generic Python debugger base class.

    This class takes care of details of the trace facility;
    a derived class should implement user interaction.
    The standard debugger class (pdb.Pdb) is an example.

    The optional skip argument must be an iterable of glob-style
    module name patterns.  The debugger will not step into frames
    that originate in a module that matches one of these patterns.
    Whether a frame is considered to originate in a certain module
    is determined by the __name__ in the frame globals.
    'u'Generic Python debugger base class.

    This class takes care of details of the trace facility;
    a derived class should implement user interaction.
    The standard debugger class (pdb.Pdb) is an example.

    The optional skip argument must be an iterable of glob-style
    module name patterns.  The debugger will not step into frames
    that originate in a module that matches one of these patterns.
    Whether a frame is considered to originate in a certain module
    is determined by the __name__ in the frame globals.
    'b'Return canonical form of filename.

        For real filenames, the canonical form is a case-normalized (on
        case insensitive filesystems) absolute path.  'Filenames' with
        angle brackets, such as "<stdin>", generated in interactive
        mode, are returned unchanged.
        'u'Return canonical form of filename.

        For real filenames, the canonical form is a case-normalized (on
        case insensitive filesystems) absolute path.  'Filenames' with
        angle brackets, such as "<stdin>", generated in interactive
        mode, are returned unchanged.
        'b'Set values of attributes as ready to start debugging.'u'Set values of attributes as ready to start debugging.'b'Dispatch a trace function for debugged frames based on the event.

        This function is installed as the trace function for debugged
        frames. Its return value is the new trace function, which is
        usually itself. The default implementation decides how to
        dispatch a frame, depending on the type of event (passed in as a
        string) that is about to be executed.

        The event can be one of the following:
            line: A new line of code is going to be executed.
            call: A function is about to be called or another code block
                  is entered.
            return: A function or other code block is about to return.
            exception: An exception has occurred.
            c_call: A C function is about to be called.
            c_return: A C function has returned.
            c_exception: A C function has raised an exception.

        For the Python events, specialized functions (see the dispatch_*()
        methods) are called.  For the C events, no action is taken.

        The arg parameter depends on the previous event.
        'u'Dispatch a trace function for debugged frames based on the event.

        This function is installed as the trace function for debugged
        frames. Its return value is the new trace function, which is
        usually itself. The default implementation decides how to
        dispatch a frame, depending on the type of event (passed in as a
        string) that is about to be executed.

        The event can be one of the following:
            line: A new line of code is going to be executed.
            call: A function is about to be called or another code block
                  is entered.
            return: A function or other code block is about to return.
            exception: An exception has occurred.
            c_call: A C function is about to be called.
            c_return: A C function has returned.
            c_exception: A C function has raised an exception.

        For the Python events, specialized functions (see the dispatch_*()
        methods) are called.  For the C events, no action is taken.

        The arg parameter depends on the previous event.
        'b'line'u'line'b'call'u'call'b'c_call'u'c_call'b'c_exception'u'c_exception'b'c_return'u'c_return'b'bdb.Bdb.dispatch: unknown debugging event:'u'bdb.Bdb.dispatch: unknown debugging event:'b'Invoke user function and return trace function for line event.

        If the debugger stops on the current line, invoke
        self.user_line(). Raise BdbQuit if self.quitting is set.
        Return self.trace_dispatch to continue tracing in this scope.
        'u'Invoke user function and return trace function for line event.

        If the debugger stops on the current line, invoke
        self.user_line(). Raise BdbQuit if self.quitting is set.
        Return self.trace_dispatch to continue tracing in this scope.
        'b'Invoke user function and return trace function for call event.

        If the debugger stops on this function call, invoke
        self.user_call(). Raise BdbQuit if self.quitting is set.
        Return self.trace_dispatch to continue tracing in this scope.
        'u'Invoke user function and return trace function for call event.

        If the debugger stops on this function call, invoke
        self.user_call(). Raise BdbQuit if self.quitting is set.
        Return self.trace_dispatch to continue tracing in this scope.
        'b'Invoke user function and return trace function for return event.

        If the debugger stops on this function return, invoke
        self.user_return(). Raise BdbQuit if self.quitting is set.
        Return self.trace_dispatch to continue tracing in this scope.
        'u'Invoke user function and return trace function for return event.

        If the debugger stops on this function return, invoke
        self.user_return(). Raise BdbQuit if self.quitting is set.
        Return self.trace_dispatch to continue tracing in this scope.
        'b'Invoke user function and return trace function for exception event.

        If the debugger stops on this exception, invoke
        self.user_exception(). Raise BdbQuit if self.quitting is set.
        Return self.trace_dispatch to continue tracing in this scope.
        'u'Invoke user function and return trace function for exception event.

        If the debugger stops on this exception, invoke
        self.user_exception(). Raise BdbQuit if self.quitting is set.
        Return self.trace_dispatch to continue tracing in this scope.
        'b'Return True if module_name matches any skip pattern.'u'Return True if module_name matches any skip pattern.'b'Return True if frame is below the starting frame in the stack.'u'Return True if frame is below the starting frame in the stack.'b'Return True if there is an effective breakpoint for this line.

        Check for line or function breakpoint and if in effect.
        Delete temporary breakpoints if effective() says to.
        'u'Return True if there is an effective breakpoint for this line.

        Check for line or function breakpoint and if in effect.
        Delete temporary breakpoints if effective() says to.
        'b'Remove temporary breakpoint.

        Must implement in derived classes or get NotImplementedError.
        'u'Remove temporary breakpoint.

        Must implement in derived classes or get NotImplementedError.
        'b'subclass of bdb must implement do_clear()'u'subclass of bdb must implement do_clear()'b'Return True if there is any breakpoint for frame's filename.
        'u'Return True if there is any breakpoint for frame's filename.
        'b'Called if we might stop in a function.'u'Called if we might stop in a function.'b'Called when we stop or break at a line.'u'Called when we stop or break at a line.'b'Called when a return trap is set here.'u'Called when a return trap is set here.'b'Called when we stop on an exception.'u'Called when we stop on an exception.'b'Set the attributes for stopping.

        If stoplineno is greater than or equal to 0, then stop at line
        greater than or equal to the stopline.  If stoplineno is -1, then
        don't stop at all.
        'u'Set the attributes for stopping.

        If stoplineno is greater than or equal to 0, then stop at line
        greater than or equal to the stopline.  If stoplineno is -1, then
        don't stop at all.
        'b'Stop when the line with the lineno greater than the current one is
        reached or when returning from current frame.'u'Stop when the line with the lineno greater than the current one is
        reached or when returning from current frame.'b'Stop after one line of code.'u'Stop after one line of code.'b'Stop on the next line in or below the given frame.'u'Stop on the next line in or below the given frame.'b'Stop when returning from the given frame.'u'Stop when returning from the given frame.'b'Start debugging from frame.

        If frame is not specified, debugging starts from caller's frame.
        'u'Start debugging from frame.

        If frame is not specified, debugging starts from caller's frame.
        'b'Stop only at breakpoints or when finished.

        If there are no breakpoints, set the system trace function to None.
        'u'Stop only at breakpoints or when finished.

        If there are no breakpoints, set the system trace function to None.
        'b'Set quitting attribute to True.

        Raises BdbQuit exception in the next call to a dispatch_*() method.
        'u'Set quitting attribute to True.

        Raises BdbQuit exception in the next call to a dispatch_*() method.
        'b'Add breakpoint to breaks, if not already there.'u'Add breakpoint to breaks, if not already there.'b'Set a new breakpoint for filename:lineno.

        If lineno doesn't exist for the filename, return an error message.
        The filename should be in canonical form.
        'u'Set a new breakpoint for filename:lineno.

        If lineno doesn't exist for the filename, return an error message.
        The filename should be in canonical form.
        'b'Line %s:%d does not exist'u'Line %s:%d does not exist'b'Apply all breakpoints (set in other instances) to this one.

        Populates this instance's breaks list from the Breakpoint class's
        list, which can have breakpoints set by another Bdb instance. This
        is necessary for interactive sessions to keep the breakpoints
        active across multiple calls to run().
        'u'Apply all breakpoints (set in other instances) to this one.

        Populates this instance's breaks list from the Breakpoint class's
        list, which can have breakpoints set by another Bdb instance. This
        is necessary for interactive sessions to keep the breakpoints
        active across multiple calls to run().
        'b'Prune breakpoints for filename:lineno.

        A list of breakpoints is maintained in the Bdb instance and in
        the Breakpoint class.  If a breakpoint in the Bdb instance no
        longer exists in the Breakpoint class, then it's removed from the
        Bdb instance.
        'u'Prune breakpoints for filename:lineno.

        A list of breakpoints is maintained in the Bdb instance and in
        the Breakpoint class.  If a breakpoint in the Bdb instance no
        longer exists in the Breakpoint class, then it's removed from the
        Bdb instance.
        'b'Delete breakpoints for filename:lineno.

        If no breakpoints were set, return an error message.
        'u'Delete breakpoints for filename:lineno.

        If no breakpoints were set, return an error message.
        'b'There are no breakpoints in %s'u'There are no breakpoints in %s'b'There is no breakpoint at %s:%d'u'There is no breakpoint at %s:%d'b'Delete a breakpoint by its index in Breakpoint.bpbynumber.

        If arg is invalid, return an error message.
        'u'Delete a breakpoint by its index in Breakpoint.bpbynumber.

        If arg is invalid, return an error message.
        'b'Delete all breakpoints in filename.

        If none were set, return an error message.
        'u'Delete all breakpoints in filename.

        If none were set, return an error message.
        'b'Delete all existing breakpoints.

        If none were set, return an error message.
        'u'Delete all existing breakpoints.

        If none were set, return an error message.
        'b'There are no breakpoints'u'There are no breakpoints'b'Return a breakpoint by its index in Breakpoint.bybpnumber.

        For invalid arg values or if the breakpoint doesn't exist,
        raise a ValueError.
        'u'Return a breakpoint by its index in Breakpoint.bybpnumber.

        For invalid arg values or if the breakpoint doesn't exist,
        raise a ValueError.
        'b'Breakpoint number expected'u'Breakpoint number expected'b'Non-numeric breakpoint number %s'u'Non-numeric breakpoint number %s'b'Breakpoint number %d out of range'u'Breakpoint number %d out of range'b'Breakpoint %d already deleted'u'Breakpoint %d already deleted'b'Return True if there is a breakpoint for filename:lineno.'u'Return True if there is a breakpoint for filename:lineno.'b'Return all breakpoints for filename:lineno.

        If no breakpoints are set, return an empty list.
        'u'Return all breakpoints for filename:lineno.

        If no breakpoints are set, return an empty list.
        'b'Return all lines with breakpoints for filename.

        If no breakpoints are set, return an empty list.
        'u'Return all lines with breakpoints for filename.

        If no breakpoints are set, return an empty list.
        'b'Return all breakpoints that are set.'u'Return all breakpoints that are set.'b'Return a list of (frame, lineno) in a stack trace and a size.

        List starts with original calling frame, if there is one.
        Size may be number of frames above or below f.
        'u'Return a list of (frame, lineno) in a stack trace and a size.

        List starts with original calling frame, if there is one.
        Size may be number of frames above or below f.
        'b'Return a string with information about a stack entry.

        The stack entry frame_lineno is a (frame, lineno) tuple.  The
        return string contains the canonical filename, the function name
        or '<lambda>', the input arguments, the return value, and the
        line of code (if it exists).

        'u'Return a string with information about a stack entry.

        The stack entry frame_lineno is a (frame, lineno) tuple.  The
        return string contains the canonical filename, the function name
        or '<lambda>', the input arguments, the return value, and the
        line of code (if it exists).

        'b'<lambda>'u'<lambda>'b'__return__'u'__return__'b'->'u'->'b'Warning: lineno is None'u'Warning: lineno is None'b'Debug a statement executed via the exec() function.

        globals defaults to __main__.dict; locals defaults to globals.
        'u'Debug a statement executed via the exec() function.

        globals defaults to __main__.dict; locals defaults to globals.
        'b'Debug an expression executed via the eval() function.

        globals defaults to __main__.dict; locals defaults to globals.
        'u'Debug an expression executed via the eval() function.

        globals defaults to __main__.dict; locals defaults to globals.
        'b'For backwards-compatibility.  Defers to run().'u'For backwards-compatibility.  Defers to run().'b'Debug a single function call.

        Return the result of the function call.
        'u'Debug a single function call.

        Return the result of the function call.
        'b'Start debugging with a Bdb instance from the caller's frame.'u'Start debugging with a Bdb instance from the caller's frame.'b'Breakpoint class.

    Implements temporary breakpoints, ignore counts, disabling and
    (re)-enabling, and conditionals.

    Breakpoints are indexed by number through bpbynumber and by
    the (file, line) tuple using bplist.  The former points to a
    single instance of class Breakpoint.  The latter points to a
    list of such instances since there may be more than one
    breakpoint per line.

    When creating a breakpoint, its associated filename should be
    in canonical form.  If funcname is defined, a breakpoint hit will be
    counted when the first line of that function is executed.  A
    conditional breakpoint always counts a hit.
    'u'Breakpoint class.

    Implements temporary breakpoints, ignore counts, disabling and
    (re)-enabling, and conditionals.

    Breakpoints are indexed by number through bpbynumber and by
    the (file, line) tuple using bplist.  The former points to a
    single instance of class Breakpoint.  The latter points to a
    list of such instances since there may be more than one
    breakpoint per line.

    When creating a breakpoint, its associated filename should be
    in canonical form.  If funcname is defined, a breakpoint hit will be
    counted when the first line of that function is executed.  A
    conditional breakpoint always counts a hit.
    'b'Delete the breakpoint from the list associated to a file:line.

        If it is the last breakpoint in that position, it also deletes
        the entry for the file:line.
        'u'Delete the breakpoint from the list associated to a file:line.

        If it is the last breakpoint in that position, it also deletes
        the entry for the file:line.
        'b'Mark the breakpoint as enabled.'u'Mark the breakpoint as enabled.'b'Mark the breakpoint as disabled.'u'Mark the breakpoint as disabled.'b'Print the output of bpformat().

        The optional out argument directs where the output is sent
        and defaults to standard output.
        'u'Print the output of bpformat().

        The optional out argument directs where the output is sent
        and defaults to standard output.
        'b'Return a string with information about the breakpoint.

        The information includes the breakpoint number, temporary
        status, file:line position, break condition, number of times to
        ignore, and number of times hit.

        'u'Return a string with information about the breakpoint.

        The information includes the breakpoint number, temporary
        status, file:line position, break condition, number of times to
        ignore, and number of times hit.

        'b'del  'u'del  'b'keep 'u'keep 'b'yes  'u'yes  'b'no   'u'no   'b'%-4dbreakpoint   %s at %s:%d'u'%-4dbreakpoint   %s at %s:%d'b'
	stop only if %s'u'
	stop only if %s'b'
	ignore next %d hits'u'
	ignore next %d hits'b'
	breakpoint already hit %d time%s'u'
	breakpoint already hit %d time%s'b'Return a condensed description of the breakpoint.'u'Return a condensed description of the breakpoint.'b'breakpoint %s at %s:%s'u'breakpoint %s at %s:%s'b'Return True if break should happen here.

    Whether a break should happen depends on the way that b (the breakpoint)
    was set.  If it was set via line number, check if b.line is the same as
    the one in the frame.  If it was set via function name, check if this is
    the right function and if it is on the first executable line.
    'u'Return True if break should happen here.

    Whether a break should happen depends on the way that b (the breakpoint)
    was set.  If it was set via line number, check if b.line is the same as
    the one in the frame.  If it was set via function name, check if this is
    the right function and if it is on the first executable line.
    'b'Return (active breakpoint, delete temporary flag) or (None, None) as
       breakpoint to act upon.

       The "active breakpoint" is the first entry in bplist[line, file] (which
       must exist) that is enabled, for which checkfuncname is True, and that
       has neither a False condition nor a positive ignore count.  The flag,
       meaning that a temporary breakpoint should be deleted, is False only
       when the condiion cannot be evaluated (in which case, ignore count is
       ignored).

       If no such entry exists, then (None, None) is returned.
    'u'Return (active breakpoint, delete temporary flag) or (None, None) as
       breakpoint to act upon.

       The "active breakpoint" is the first entry in bplist[line, file] (which
       must exist) that is enabled, for which checkfuncname is True, and that
       has neither a False condition nor a positive ignore count.  The flag,
       meaning that a temporary breakpoint should be deleted, is False only
       when the condiion cannot be evaluated (in which case, ignore count is
       ignored).

       If no such entry exists, then (None, None) is returned.
    'b'???'u'???'b'+++ call'u'+++ call'b'+++'u'+++'b'+++ return'u'+++ return'b'+++ exception'u'+++ exception'b'foo('u'foo('b'bar returned'u'bar returned'b'bar('u'bar('b'import bdb; bdb.foo(10)'u'import bdb; bdb.foo(10)'u'Lib.bdb'u'bdb'binascii.Erroru'Incomplete.__weakref__'binascii.IncompleteIncompleteu'Conversion between binary data and ASCII'a2b_hexa2b_qpa2b_uub2a_hexb2a_qpb2a_uucrc_hqxBisection algorithms.Insert item x in list a, and keep it sorted assuming a is sorted.

    If x is already in a, insert it to the right of the rightmost x.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.

    A custom key function can be supplied to customize the sort order.
    Return the index where to insert item x in list a, assuming a is sorted.

    The return value i is such that all e in a[:i] have e <= x, and all e in
    a[i:] have e > x.  So if x already appears in the list, a.insert(i, x) will
    insert just after the rightmost x already there.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.

    A custom key function can be supplied to customize the sort order.
    lo must be non-negativemidInsert item x in list a, and keep it sorted assuming a is sorted.

    If x is already in a, insert it to the left of the leftmost x.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.

    A custom key function can be supplied to customize the sort order.
    Return the index where to insert item x in list a, assuming a is sorted.

    The return value i is such that all e in a[:i] have e < x, and all e in
    a[i:] have e >= x.  So if x already appears in the list, a.insert(i, x) will
    insert just before the leftmost x already there.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.

    A custom key function can be supplied to customize the sort order.
    bisectinsort# Note, the comparison uses "<" to match the# __lt__() logic in list.sort() and in heapq.# Overwrite above definitions with a fast C implementation# Create aliasesb'Bisection algorithms.'u'Bisection algorithms.'b'Insert item x in list a, and keep it sorted assuming a is sorted.

    If x is already in a, insert it to the right of the rightmost x.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.

    A custom key function can be supplied to customize the sort order.
    'u'Insert item x in list a, and keep it sorted assuming a is sorted.

    If x is already in a, insert it to the right of the rightmost x.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.

    A custom key function can be supplied to customize the sort order.
    'b'Return the index where to insert item x in list a, assuming a is sorted.

    The return value i is such that all e in a[:i] have e <= x, and all e in
    a[i:] have e > x.  So if x already appears in the list, a.insert(i, x) will
    insert just after the rightmost x already there.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.

    A custom key function can be supplied to customize the sort order.
    'u'Return the index where to insert item x in list a, assuming a is sorted.

    The return value i is such that all e in a[:i] have e <= x, and all e in
    a[i:] have e > x.  So if x already appears in the list, a.insert(i, x) will
    insert just after the rightmost x already there.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.

    A custom key function can be supplied to customize the sort order.
    'b'lo must be non-negative'u'lo must be non-negative'b'Insert item x in list a, and keep it sorted assuming a is sorted.

    If x is already in a, insert it to the left of the leftmost x.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.

    A custom key function can be supplied to customize the sort order.
    'u'Insert item x in list a, and keep it sorted assuming a is sorted.

    If x is already in a, insert it to the left of the leftmost x.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.

    A custom key function can be supplied to customize the sort order.
    'b'Return the index where to insert item x in list a, assuming a is sorted.

    The return value i is such that all e in a[:i] have e < x, and all e in
    a[i:] have e >= x.  So if x already appears in the list, a.insert(i, x) will
    insert just before the leftmost x already there.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.

    A custom key function can be supplied to customize the sort order.
    'u'Return the index where to insert item x in list a, assuming a is sorted.

    The return value i is such that all e in a[:i] have e < x, and all e in
    a[i:] have e >= x.  So if x already appears in the list, a.insert(i, x) will
    insert just before the leftmost x already there.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.

    A custom key function can be supplied to customize the sort order.
    'u'Lib.bisect'u'bisect'Interface to the libbzip2 compression library.

This module provides a file interface, classes for incremental
(de)compression, and functions for one-shot (de)compression.
BZ2FileNadeem Vawda <nadeem.vawda@gmail.com>_compression_MODE_CLOSED_MODE_READ_MODE_WRITEA file object providing transparent bzip2 (de)compression.

    A BZ2File can act as a wrapper for an existing file object, or refer
    directly to a named file on disk.

    Note that BZ2File provides a *binary* file interface - data read is
    returned as bytes, and data to be written should be given as bytes.
    Open a bzip2-compressed file.

        If filename is a str, bytes, or PathLike object, it gives the
        name of the file to be opened. Otherwise, it should be a file
        object, which will be used to read or write the compressed data.

        mode can be 'r' for reading (default), 'w' for (over)writing,
        'x' for creating exclusively, or 'a' for appending. These can
        equivalently be given as 'rb', 'wb', 'xb', and 'ab'.

        If mode is 'w', 'x' or 'a', compresslevel can be a number between 1
        and 9 specifying the level of compression: 1 produces the least
        compression, and 9 (default) produces the most compression.

        If mode is 'r', the input file may be the concatenation of
        multiple compressed streams.
        _closefpcompresslevel must be between 1 and 9mode_codeabInvalid mode: %rfilename must be a str, bytes, file or PathLike object_bufferFlush and close the file.

        May be called more than once without error. Once the file is
        closed, any other operation on it will raise a ValueError.
        True if this file is closed.Return the file descriptor for the underlying file.Return whether the file supports seeking.Return whether the file was opened for reading.Return whether the file was opened for writing.Return buffered data without advancing the file position.

        Always returns at least one byte of data, unless at EOF.
        The exact number of bytes returned is unspecified.
        Read up to size uncompressed bytes from the file.

        If size is negative or omitted, read until EOF is reached.
        Returns b'' if the file is already at EOF.
        Read up to size uncompressed bytes, while trying to avoid
        making multiple reads from the underlying stream. Reads up to a
        buffer's worth of data if size is negative.

        Returns b'' if the file is at EOF.
        Read bytes into b.

        Returns the number of bytes read (0 for EOF).
        Read a line of uncompressed bytes from the file.

        The terminating newline (if present) is retained. If size is
        non-negative, no more than size bytes will be read (in which
        case the line may be incomplete). Returns b'' if already at EOF.
        Integer argument expectedRead a list of lines of uncompressed bytes from the file.

        size can be specified to control the number of lines read: no
        further lines will be read once the total size of the lines read
        so far equals or exceeds size.
        Write a byte string to the file.

        Returns the number of uncompressed bytes written, which is
        always the length of data in bytes. Note that due to buffering,
        the file on disk may not reflect the data written until close()
        is called.
        lengthcompressedWrite a sequence of byte strings to the file.

        Returns the number of uncompressed bytes written.
        seq can be any iterable yielding byte strings.

        Line separators are not added between the written byte strings.
        Change the file position.

        The new position is specified by offset, relative to the
        position indicated by whence. Values for whence are:

            0: start of stream (default); offset must not be negative
            1: current stream position
            2: end of stream; offset must not be positive

        Returns the new file position.

        Note that seeking is emulated, so depending on the parameters,
        this operation may be extremely slow.
        Open a bzip2-compressed file in binary or text mode.

    The filename argument can be an actual filename (a str, bytes, or
    PathLike object), or an existing file object to read from or write
    to.

    The mode argument can be "r", "rb", "w", "wb", "x", "xb", "a" or
    "ab" for binary mode, or "rt", "wt", "xt" or "at" for text mode.
    The default mode is "rb", and the default compresslevel is 9.

    For binary mode, this function is equivalent to the BZ2File
    constructor: BZ2File(filename, mode, compresslevel). In this case,
    the encoding, errors and newline arguments must not be provided.

    For text mode, a BZ2File object is created, and wrapped in an
    io.TextIOWrapper instance with the specified encoding, error
    handling behavior, and line ending(s).

    Argument 'encoding' not supported in binary modeArgument 'errors' not supported in binary modeArgument 'newline' not supported in binary modebz_modebinary_fileCompress a block of data.

    compresslevel, if given, must be a number between 1 and 9.

    For incremental compression, use a BZ2Compressor object instead.
    Decompress a block of data.

    For incremental decompression, use a BZ2Decompressor object instead.
    decompCompressed data ended before the end-of-stream marker was reached"Compressed data ended before the "# Value 2 no longer used# Relies on the undocumented fact that BufferedReader.peek()# always returns at least one byte (except at EOF), independent# of the value of n# accept any data that supports the buffer protocol# Leftover data is not a valid bzip2 stream; ignore it.# Error on the first iteration; bail out.b'Interface to the libbzip2 compression library.

This module provides a file interface, classes for incremental
(de)compression, and functions for one-shot (de)compression.
'u'Interface to the libbzip2 compression library.

This module provides a file interface, classes for incremental
(de)compression, and functions for one-shot (de)compression.
'b'BZ2File'u'BZ2File'b'BZ2Compressor'u'BZ2Compressor'b'BZ2Decompressor'u'BZ2Decompressor'b'open'u'open'b'compress'u'compress'b'decompress'u'decompress'b'Nadeem Vawda <nadeem.vawda@gmail.com>'u'Nadeem Vawda <nadeem.vawda@gmail.com>'b'A file object providing transparent bzip2 (de)compression.

    A BZ2File can act as a wrapper for an existing file object, or refer
    directly to a named file on disk.

    Note that BZ2File provides a *binary* file interface - data read is
    returned as bytes, and data to be written should be given as bytes.
    'u'A file object providing transparent bzip2 (de)compression.

    A BZ2File can act as a wrapper for an existing file object, or refer
    directly to a named file on disk.

    Note that BZ2File provides a *binary* file interface - data read is
    returned as bytes, and data to be written should be given as bytes.
    'b'Open a bzip2-compressed file.

        If filename is a str, bytes, or PathLike object, it gives the
        name of the file to be opened. Otherwise, it should be a file
        object, which will be used to read or write the compressed data.

        mode can be 'r' for reading (default), 'w' for (over)writing,
        'x' for creating exclusively, or 'a' for appending. These can
        equivalently be given as 'rb', 'wb', 'xb', and 'ab'.

        If mode is 'w', 'x' or 'a', compresslevel can be a number between 1
        and 9 specifying the level of compression: 1 produces the least
        compression, and 9 (default) produces the most compression.

        If mode is 'r', the input file may be the concatenation of
        multiple compressed streams.
        'u'Open a bzip2-compressed file.

        If filename is a str, bytes, or PathLike object, it gives the
        name of the file to be opened. Otherwise, it should be a file
        object, which will be used to read or write the compressed data.

        mode can be 'r' for reading (default), 'w' for (over)writing,
        'x' for creating exclusively, or 'a' for appending. These can
        equivalently be given as 'rb', 'wb', 'xb', and 'ab'.

        If mode is 'w', 'x' or 'a', compresslevel can be a number between 1
        and 9 specifying the level of compression: 1 produces the least
        compression, and 9 (default) produces the most compression.

        If mode is 'r', the input file may be the concatenation of
        multiple compressed streams.
        'b'compresslevel must be between 1 and 9'u'compresslevel must be between 1 and 9'b'ab'u'ab'b'Invalid mode: %r'u'Invalid mode: %r'b'write'u'write'b'filename must be a str, bytes, file or PathLike object'u'filename must be a str, bytes, file or PathLike object'b'Flush and close the file.

        May be called more than once without error. Once the file is
        closed, any other operation on it will raise a ValueError.
        'u'Flush and close the file.

        May be called more than once without error. Once the file is
        closed, any other operation on it will raise a ValueError.
        'b'True if this file is closed.'u'True if this file is closed.'b'Return the file descriptor for the underlying file.'u'Return the file descriptor for the underlying file.'b'Return whether the file supports seeking.'u'Return whether the file supports seeking.'b'Return whether the file was opened for reading.'u'Return whether the file was opened for reading.'b'Return whether the file was opened for writing.'u'Return whether the file was opened for writing.'b'Return buffered data without advancing the file position.

        Always returns at least one byte of data, unless at EOF.
        The exact number of bytes returned is unspecified.
        'u'Return buffered data without advancing the file position.

        Always returns at least one byte of data, unless at EOF.
        The exact number of bytes returned is unspecified.
        'b'Read up to size uncompressed bytes from the file.

        If size is negative or omitted, read until EOF is reached.
        Returns b'' if the file is already at EOF.
        'u'Read up to size uncompressed bytes from the file.

        If size is negative or omitted, read until EOF is reached.
        Returns b'' if the file is already at EOF.
        'b'Read up to size uncompressed bytes, while trying to avoid
        making multiple reads from the underlying stream. Reads up to a
        buffer's worth of data if size is negative.

        Returns b'' if the file is at EOF.
        'u'Read up to size uncompressed bytes, while trying to avoid
        making multiple reads from the underlying stream. Reads up to a
        buffer's worth of data if size is negative.

        Returns b'' if the file is at EOF.
        'b'Read bytes into b.

        Returns the number of bytes read (0 for EOF).
        'u'Read bytes into b.

        Returns the number of bytes read (0 for EOF).
        'b'Read a line of uncompressed bytes from the file.

        The terminating newline (if present) is retained. If size is
        non-negative, no more than size bytes will be read (in which
        case the line may be incomplete). Returns b'' if already at EOF.
        'u'Read a line of uncompressed bytes from the file.

        The terminating newline (if present) is retained. If size is
        non-negative, no more than size bytes will be read (in which
        case the line may be incomplete). Returns b'' if already at EOF.
        'b'__index__'u'__index__'b'Integer argument expected'u'Integer argument expected'b'Read a list of lines of uncompressed bytes from the file.

        size can be specified to control the number of lines read: no
        further lines will be read once the total size of the lines read
        so far equals or exceeds size.
        'u'Read a list of lines of uncompressed bytes from the file.

        size can be specified to control the number of lines read: no
        further lines will be read once the total size of the lines read
        so far equals or exceeds size.
        'b'Write a byte string to the file.

        Returns the number of uncompressed bytes written, which is
        always the length of data in bytes. Note that due to buffering,
        the file on disk may not reflect the data written until close()
        is called.
        'u'Write a byte string to the file.

        Returns the number of uncompressed bytes written, which is
        always the length of data in bytes. Note that due to buffering,
        the file on disk may not reflect the data written until close()
        is called.
        'b'Write a sequence of byte strings to the file.

        Returns the number of uncompressed bytes written.
        seq can be any iterable yielding byte strings.

        Line separators are not added between the written byte strings.
        'u'Write a sequence of byte strings to the file.

        Returns the number of uncompressed bytes written.
        seq can be any iterable yielding byte strings.

        Line separators are not added between the written byte strings.
        'b'Change the file position.

        The new position is specified by offset, relative to the
        position indicated by whence. Values for whence are:

            0: start of stream (default); offset must not be negative
            1: current stream position
            2: end of stream; offset must not be positive

        Returns the new file position.

        Note that seeking is emulated, so depending on the parameters,
        this operation may be extremely slow.
        'u'Change the file position.

        The new position is specified by offset, relative to the
        position indicated by whence. Values for whence are:

            0: start of stream (default); offset must not be negative
            1: current stream position
            2: end of stream; offset must not be positive

        Returns the new file position.

        Note that seeking is emulated, so depending on the parameters,
        this operation may be extremely slow.
        'b'Open a bzip2-compressed file in binary or text mode.

    The filename argument can be an actual filename (a str, bytes, or
    PathLike object), or an existing file object to read from or write
    to.

    The mode argument can be "r", "rb", "w", "wb", "x", "xb", "a" or
    "ab" for binary mode, or "rt", "wt", "xt" or "at" for text mode.
    The default mode is "rb", and the default compresslevel is 9.

    For binary mode, this function is equivalent to the BZ2File
    constructor: BZ2File(filename, mode, compresslevel). In this case,
    the encoding, errors and newline arguments must not be provided.

    For text mode, a BZ2File object is created, and wrapped in an
    io.TextIOWrapper instance with the specified encoding, error
    handling behavior, and line ending(s).

    'u'Open a bzip2-compressed file in binary or text mode.

    The filename argument can be an actual filename (a str, bytes, or
    PathLike object), or an existing file object to read from or write
    to.

    The mode argument can be "r", "rb", "w", "wb", "x", "xb", "a" or
    "ab" for binary mode, or "rt", "wt", "xt" or "at" for text mode.
    The default mode is "rb", and the default compresslevel is 9.

    For binary mode, this function is equivalent to the BZ2File
    constructor: BZ2File(filename, mode, compresslevel). In this case,
    the encoding, errors and newline arguments must not be provided.

    For text mode, a BZ2File object is created, and wrapped in an
    io.TextIOWrapper instance with the specified encoding, error
    handling behavior, and line ending(s).

    'b'Argument 'encoding' not supported in binary mode'u'Argument 'encoding' not supported in binary mode'b'Argument 'errors' not supported in binary mode'u'Argument 'errors' not supported in binary mode'b'Argument 'newline' not supported in binary mode'u'Argument 'newline' not supported in binary mode'b'Compress a block of data.

    compresslevel, if given, must be a number between 1 and 9.

    For incremental compression, use a BZ2Compressor object instead.
    'u'Compress a block of data.

    compresslevel, if given, must be a number between 1 and 9.

    For incremental compression, use a BZ2Compressor object instead.
    'b'Decompress a block of data.

    For incremental decompression, use a BZ2Decompressor object instead.
    'u'Decompress a block of data.

    For incremental decompression, use a BZ2Decompressor object instead.
    'b'Compressed data ended before the end-of-stream marker was reached'u'Compressed data ended before the end-of-stream marker was reached'u'Lib.bz2'Calendar printing functions

Note when comparing these calendars to the ones printed by cal(1): By
default, these calendars have Monday as the first day of the week, and
Sunday as the last (the European convention). Use setfirstweekday() to
set the first day of the week (0=Monday, 6=Sunday).IllegalMonthErrorIllegalWeekdayErrorsetfirstweekdayisleapleapdaysmonthrangemonthcalendarprmonthprcalmonth_namemonth_abbrday_nameday_abbrCalendarTextCalendarHTMLCalendarLocaleTextCalendarLocaleHTMLCalendarweekheaderDayMonthJANUARYFEBRUARYMARCHAPRILMAYJUNEJULYAUGUSTSEPTEMBEROCTOBERNOVEMBERDECEMBERMONDAYTUESDAYWEDNESDAYFRIDAYSATURDAYSUNDAYbad month number %r; must be 1-12bad weekday number %r; must be 0 (Monday) to 6 (Sunday)JanuaryFebruaryThe '' attribute is deprecated, use '' insteadmodule '' has no attribute 'mdays_localized_month2001_monthsfuncs_localized_day%A%a%B%bReturn True for leap years, False for non-leap years.y1Return number of leap years in range [y1, y2).
       Assume y1 <= y2.Return weekday (0-6 ~ Mon-Sun) for year, month (1-12), day (1-31).Return weekday (0-6 ~ Mon-Sun) and number of days (28-31) for
       year, month.day1ndays_monthlen_prevmonth_nextmonth
    Base calendar class. This class doesn't do any formatting. It simply
    provides data to subclasses.
    getfirstweekday_firstweekdayiterweekdays
        Return an iterator for one week of weekday numbers starting with the
        configured first one.
        itermonthdates
        Return an iterator for one month. The iterator will yield datetime.date
        values and will always iterate through complete weeks, so it will yield
        dates outside the specified month.
        itermonthdays3itermonthdays
        Like itermonthdates(), but will yield day numbers. For days outside
        the specified month the day number is 0.
        days_beforedays_afteritermonthdays2
        Like itermonthdates(), but will yield (day number, weekday number)
        tuples. For days outside the specified month the day number is 0.
        
        Like itermonthdates(), but will yield (year, month, day) tuples.  Can be
        used for dates outside of datetime.date range.
        itermonthdays4
        Like itermonthdates(), but will yield (year, month, day, day_of_week) tuples.
        Can be used for dates outside of datetime.date range.
        monthdatescalendar
        Return a matrix (list of lists) representing a month's calendar.
        Each row represents a week; week entries are datetime.date values.
        datesmonthdays2calendar
        Return a matrix representing a month's calendar.
        Each row represents a week; week entries are
        (day number, weekday number) tuples. Day numbers outside this month
        are zero.
        monthdayscalendar
        Return a matrix representing a month's calendar.
        Each row represents a week; days outside this month are zero.
        yeardatescalendar
        Return the data for the specified year ready for formatting. The return
        value is a list of month rows. Each month row contains up to width months.
        Each month contains between 4 and 6 weeks and each week contains 1-7
        days. Days are datetime.date objects.
        monthsyeardays2calendar
        Return the data for the specified year ready for formatting (similar to
        yeardatescalendar()). Entries in the week lists are
        (day number, weekday number) tuples. Day numbers outside this month are
        zero.
        yeardayscalendar
        Return the data for the specified year ready for formatting (similar to
        yeardatescalendar()). Entries in the week lists are day numbers.
        Day numbers outside this month are zero.
        
    Subclass of Calendar that outputs a calendar as a simple plain text
    similar to the UNIX program cal.
    prweektheweek
        Print a single week (no newline).
        formatweekformatday
        Returns a formatted day.
        %2i
        Returns a single week in a string (no newline).
        wdformatweekday
        Returns a formatted week day name.
        formatweekheader
        Return a header for a week.
        formatmonthnametheyearthemonthwithyear
        Return a formatted month name.
        %s %r
        Print a month's calendar.
        formatmonth
        Return a month's calendar string (multi-line).
        formatyear
        Returns a year's calendar as a multi-line string.
        colwidthrowformatstringheaderscalheightpryearPrint a year's calendar.
    This calendar returns complete HTML pages.
    cssclassescssclasses_weekday_headnodaycssclass_nodaycssclass_month_headcssclass_monthcssclass_year_headcssclass_year
        Return a day as a table cell.
        <td class="%s">&nbsp;</td><td class="%s">%d</td>
        Return a complete week as a table row.
        <tr>%s</tr>
        Return a weekday name as a table header.
        <th class="%s">%s</th>
        Return a header for a week as a table row.
        
        Return a month name as a table row.
        <tr><th colspan="7" class="%s">%s</th></tr>
        Return a formatted month as a table.
        <table border="0" cellpadding="0" cellspacing="0" class="%s"></table>
        Return a formatted year as a table of tables.
        <tr><th colspan="%d" class="%s">%s</th></tr><tr><td></td></tr>formatyearpagecalendar.csscss
        Return a formatted year as a complete HTML page.
        <?xml version="1.0" encoding="%s"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=%s" />
<link rel="stylesheet" type="text/css" href="%s" />
<title>Calendar for %d</title>
</head>
<body>
</body>
</html>
xmlcharrefreplacedifferent_localeoldlocale_get_default_locale
    This class can be passed a locale name in the constructor and will return
    month and weekday names in the specified locale.
    _colwidth_spacingcolsspacingPrints multi-column formatting for year calendarsReturns a string formatted from n strings, centered within n columns.EPOCH_EPOCH_ORDUnrelated but handy function to calculate Unix timestamp from GMT.text only argumentstextgrouphtml only argumentshtmlgroup-w--widthwidth of date column (default 2)--linesnumber of lines for each week (default 1)-s--spacingspacing between months (default 6)--monthsmonths per row (default 3)--cssCSS to use for page-L--localelocale to use for month and weekday names--encodingencoding to use for output--typehtmloutput type (text or html)year numbermonth number (1-12, text only)if --locale is specified --encoding is requiredoptdictincorrect number of arguments# Exception raised for bad input (with string parameter for details)# Exceptions raised for bad input# Constants for months# Constants for days# Number of days per month (except for February in leap years)# This module used to have hard-coded lists of day and month names, as# English strings.  The classes following emulate a read-only version of# that, but supply localized names.  Note that the values are computed# fresh on each call, in case the user changes locale between calls.# January 1, 2001, was a Monday.# Full and abbreviated names of weekdays# Full and abbreviated names of months (1-based arrays!!!)# 0 = Monday, 6 = Sunday# right-align single-digit days# months in this row# max number of weeks for this row# CSS classes for the day <td>s# CSS classes for the day <th>s# CSS class for the days before and after current month# CSS class for the month's head# CSS class for the month# CSS class for the year's table head# CSS class for the whole year table# day outside month# The LC_TIME locale does not seem to be configured:# get the user preferred locale.# Support for old module level interface# Spacing of month columns for multi-column year calendar# Amount printed by prweek()# Number of spaces between columnsb'Calendar printing functions

Note when comparing these calendars to the ones printed by cal(1): By
default, these calendars have Monday as the first day of the week, and
Sunday as the last (the European convention). Use setfirstweekday() to
set the first day of the week (0=Monday, 6=Sunday).'u'Calendar printing functions

Note when comparing these calendars to the ones printed by cal(1): By
default, these calendars have Monday as the first day of the week, and
Sunday as the last (the European convention). Use setfirstweekday() to
set the first day of the week (0=Monday, 6=Sunday).'b'IllegalMonthError'u'IllegalMonthError'b'IllegalWeekdayError'u'IllegalWeekdayError'b'setfirstweekday'u'setfirstweekday'b'firstweekday'u'firstweekday'b'isleap'u'isleap'b'leapdays'u'leapdays'b'weekday'u'weekday'b'monthrange'u'monthrange'b'monthcalendar'u'monthcalendar'b'prmonth'u'prmonth'b'month'u'month'b'prcal'u'prcal'b'calendar'u'calendar'b'timegm'u'timegm'b'month_name'u'month_name'b'month_abbr'u'month_abbr'b'day_name'u'day_name'b'day_abbr'u'day_abbr'b'Calendar'u'Calendar'b'TextCalendar'u'TextCalendar'b'HTMLCalendar'u'HTMLCalendar'b'LocaleTextCalendar'u'LocaleTextCalendar'b'LocaleHTMLCalendar'u'LocaleHTMLCalendar'b'weekheader'u'weekheader'b'Day'u'Day'b'Month'u'Month'b'JANUARY'u'JANUARY'b'FEBRUARY'u'FEBRUARY'b'MARCH'u'MARCH'b'APRIL'u'APRIL'b'MAY'u'MAY'b'JUNE'u'JUNE'b'JULY'u'JULY'b'AUGUST'u'AUGUST'b'SEPTEMBER'u'SEPTEMBER'b'OCTOBER'u'OCTOBER'b'NOVEMBER'u'NOVEMBER'b'DECEMBER'u'DECEMBER'b'MONDAY'u'MONDAY'b'TUESDAY'u'TUESDAY'b'WEDNESDAY'u'WEDNESDAY'b'THURSDAY'u'THURSDAY'b'FRIDAY'u'FRIDAY'b'SATURDAY'u'SATURDAY'b'SUNDAY'u'SUNDAY'b'bad month number %r; must be 1-12'u'bad month number %r; must be 1-12'b'bad weekday number %r; must be 0 (Monday) to 6 (Sunday)'u'bad weekday number %r; must be 0 (Monday) to 6 (Sunday)'b'January'u'January'b'February'u'February'b'The ''u'The ''b'' attribute is deprecated, use ''u'' attribute is deprecated, use ''b'' instead'u'' instead'b'module ''u'module ''b'' has no attribute ''u'' has no attribute ''b'%A'u'%A'b'%a'u'%a'b'%B'u'%B'b'%b'u'%b'b'Return True for leap years, False for non-leap years.'u'Return True for leap years, False for non-leap years.'b'Return number of leap years in range [y1, y2).
       Assume y1 <= y2.'u'Return number of leap years in range [y1, y2).
       Assume y1 <= y2.'b'Return weekday (0-6 ~ Mon-Sun) for year, month (1-12), day (1-31).'u'Return weekday (0-6 ~ Mon-Sun) for year, month (1-12), day (1-31).'b'Return weekday (0-6 ~ Mon-Sun) and number of days (28-31) for
       year, month.'u'Return weekday (0-6 ~ Mon-Sun) and number of days (28-31) for
       year, month.'b'
    Base calendar class. This class doesn't do any formatting. It simply
    provides data to subclasses.
    'u'
    Base calendar class. This class doesn't do any formatting. It simply
    provides data to subclasses.
    'b'
        Return an iterator for one week of weekday numbers starting with the
        configured first one.
        'u'
        Return an iterator for one week of weekday numbers starting with the
        configured first one.
        'b'
        Return an iterator for one month. The iterator will yield datetime.date
        values and will always iterate through complete weeks, so it will yield
        dates outside the specified month.
        'u'
        Return an iterator for one month. The iterator will yield datetime.date
        values and will always iterate through complete weeks, so it will yield
        dates outside the specified month.
        'b'
        Like itermonthdates(), but will yield day numbers. For days outside
        the specified month the day number is 0.
        'u'
        Like itermonthdates(), but will yield day numbers. For days outside
        the specified month the day number is 0.
        'b'
        Like itermonthdates(), but will yield (day number, weekday number)
        tuples. For days outside the specified month the day number is 0.
        'u'
        Like itermonthdates(), but will yield (day number, weekday number)
        tuples. For days outside the specified month the day number is 0.
        'b'
        Like itermonthdates(), but will yield (year, month, day) tuples.  Can be
        used for dates outside of datetime.date range.
        'u'
        Like itermonthdates(), but will yield (year, month, day) tuples.  Can be
        used for dates outside of datetime.date range.
        'b'
        Like itermonthdates(), but will yield (year, month, day, day_of_week) tuples.
        Can be used for dates outside of datetime.date range.
        'u'
        Like itermonthdates(), but will yield (year, month, day, day_of_week) tuples.
        Can be used for dates outside of datetime.date range.
        'b'
        Return a matrix (list of lists) representing a month's calendar.
        Each row represents a week; week entries are datetime.date values.
        'u'
        Return a matrix (list of lists) representing a month's calendar.
        Each row represents a week; week entries are datetime.date values.
        'b'
        Return a matrix representing a month's calendar.
        Each row represents a week; week entries are
        (day number, weekday number) tuples. Day numbers outside this month
        are zero.
        'u'
        Return a matrix representing a month's calendar.
        Each row represents a week; week entries are
        (day number, weekday number) tuples. Day numbers outside this month
        are zero.
        'b'
        Return a matrix representing a month's calendar.
        Each row represents a week; days outside this month are zero.
        'u'
        Return a matrix representing a month's calendar.
        Each row represents a week; days outside this month are zero.
        'b'
        Return the data for the specified year ready for formatting. The return
        value is a list of month rows. Each month row contains up to width months.
        Each month contains between 4 and 6 weeks and each week contains 1-7
        days. Days are datetime.date objects.
        'u'
        Return the data for the specified year ready for formatting. The return
        value is a list of month rows. Each month row contains up to width months.
        Each month contains between 4 and 6 weeks and each week contains 1-7
        days. Days are datetime.date objects.
        'b'
        Return the data for the specified year ready for formatting (similar to
        yeardatescalendar()). Entries in the week lists are
        (day number, weekday number) tuples. Day numbers outside this month are
        zero.
        'u'
        Return the data for the specified year ready for formatting (similar to
        yeardatescalendar()). Entries in the week lists are
        (day number, weekday number) tuples. Day numbers outside this month are
        zero.
        'b'
        Return the data for the specified year ready for formatting (similar to
        yeardatescalendar()). Entries in the week lists are day numbers.
        Day numbers outside this month are zero.
        'u'
        Return the data for the specified year ready for formatting (similar to
        yeardatescalendar()). Entries in the week lists are day numbers.
        Day numbers outside this month are zero.
        'b'
    Subclass of Calendar that outputs a calendar as a simple plain text
    similar to the UNIX program cal.
    'u'
    Subclass of Calendar that outputs a calendar as a simple plain text
    similar to the UNIX program cal.
    'b'
        Print a single week (no newline).
        'u'
        Print a single week (no newline).
        'b'
        Returns a formatted day.
        'u'
        Returns a formatted day.
        'b'%2i'u'%2i'b'
        Returns a single week in a string (no newline).
        'u'
        Returns a single week in a string (no newline).
        'b'
        Returns a formatted week day name.
        'u'
        Returns a formatted week day name.
        'b'
        Return a header for a week.
        'u'
        Return a header for a week.
        'b'
        Return a formatted month name.
        'u'
        Return a formatted month name.
        'b'%s %r'u'%s %r'b'
        Print a month's calendar.
        'u'
        Print a month's calendar.
        'b'
        Return a month's calendar string (multi-line).
        'u'
        Return a month's calendar string (multi-line).
        'b'
        Returns a year's calendar as a multi-line string.
        'u'
        Returns a year's calendar as a multi-line string.
        'b'Print a year's calendar.'u'Print a year's calendar.'b'
    This calendar returns complete HTML pages.
    'u'
    This calendar returns complete HTML pages.
    'b'noday'u'noday'b'year'u'year'b'
        Return a day as a table cell.
        'u'
        Return a day as a table cell.
        'b'<td class="%s">&nbsp;</td>'u'<td class="%s">&nbsp;</td>'b'<td class="%s">%d</td>'u'<td class="%s">%d</td>'b'
        Return a complete week as a table row.
        'u'
        Return a complete week as a table row.
        'b'<tr>%s</tr>'u'<tr>%s</tr>'b'
        Return a weekday name as a table header.
        'u'
        Return a weekday name as a table header.
        'b'<th class="%s">%s</th>'u'<th class="%s">%s</th>'b'
        Return a header for a week as a table row.
        'u'
        Return a header for a week as a table row.
        'b'
        Return a month name as a table row.
        'u'
        Return a month name as a table row.
        'b'<tr><th colspan="7" class="%s">%s</th></tr>'u'<tr><th colspan="7" class="%s">%s</th></tr>'b'
        Return a formatted month as a table.
        'u'
        Return a formatted month as a table.
        'b'<table border="0" cellpadding="0" cellspacing="0" class="%s">'u'<table border="0" cellpadding="0" cellspacing="0" class="%s">'b'</table>'u'</table>'b'
        Return a formatted year as a table of tables.
        'u'
        Return a formatted year as a table of tables.
        'b'<tr><th colspan="%d" class="%s">%s</th></tr>'u'<tr><th colspan="%d" class="%s">%s</th></tr>'b'<tr>'u'<tr>'b'<td>'u'<td>'b'</td>'u'</td>'b'</tr>'u'</tr>'b'calendar.css'u'calendar.css'b'
        Return a formatted year as a complete HTML page.
        'u'
        Return a formatted year as a complete HTML page.
        'b'<?xml version="1.0" encoding="%s"?>
'u'<?xml version="1.0" encoding="%s"?>
'b'<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
'u'<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
'b'<html>
'u'<html>
'b'<head>
'u'<head>
'b'<meta http-equiv="Content-Type" content="text/html; charset=%s" />
'u'<meta http-equiv="Content-Type" content="text/html; charset=%s" />
'b'<link rel="stylesheet" type="text/css" href="%s" />
'u'<link rel="stylesheet" type="text/css" href="%s" />
'b'<title>Calendar for %d</title>
'u'<title>Calendar for %d</title>
'b'</head>
'u'</head>
'b'<body>
'u'<body>
'b'</body>
'u'</body>
'b'</html>
'u'</html>
'b'xmlcharrefreplace'u'xmlcharrefreplace'b'C'u'C'b'
    This class can be passed a locale name in the constructor and will return
    month and weekday names in the specified locale.
    'u'
    This class can be passed a locale name in the constructor and will return
    month and weekday names in the specified locale.
    'b'Prints multi-column formatting for year calendars'u'Prints multi-column formatting for year calendars'b'Returns a string formatted from n strings, centered within n columns.'u'Returns a string formatted from n strings, centered within n columns.'b'Unrelated but handy function to calculate Unix timestamp from GMT.'u'Unrelated but handy function to calculate Unix timestamp from GMT.'b'text only arguments'u'text only arguments'b'html only arguments'u'html only arguments'b'-w'u'-w'b'--width'u'--width'b'width of date column (default 2)'u'width of date column (default 2)'b'--lines'u'--lines'b'number of lines for each week (default 1)'u'number of lines for each week (default 1)'b'-s'u'-s'b'--spacing'u'--spacing'b'spacing between months (default 6)'u'spacing between months (default 6)'b'--months'u'--months'b'months per row (default 3)'u'months per row (default 3)'b'--css'u'--css'b'CSS to use for page'u'CSS to use for page'b'-L'u'-L'b'--locale'u'--locale'b'locale to use for month and weekday names'u'locale to use for month and weekday names'b'--encoding'u'--encoding'b'encoding to use for output'u'encoding to use for output'b'--type'u'--type'b'text'u'text'b'html'b'output type (text or html)'u'output type (text or html)'b'year number'u'year number'b'month number (1-12, text only)'u'month number (1-12, text only)'b'if --locale is specified --encoding is required'u'if --locale is specified --encoding is required'b'incorrect number of arguments'u'incorrect number of arguments'u'Lib.calendar'Test case implementationdifflibpprintstrclasssafe_repr_count_diff_all_purpose_count_diff_hashable_common_shorten_repr_subtest_msg_sentinel
Diff is %s characters long. Set self.maxDiff to None to see it.'\nDiff is %s characters long. ''Set self.maxDiff to None to see it.'DIFF_OMITTED
    Raise this exception in a test to skip it.

    Usually you can use TestCase.skipTest() or one of the skipping decorators
    instead of raising this directly.
    _ShouldStop
    The test should stop.
    _UnexpectedSuccess
    The test was supposed to fail, but it didn't!
    _Outcomeexpecting_failureaddSubTestresult_supports_subtestssuccesstestPartExecutortest_casesubTestold_success_addSkip_addErroraddSkipTestResult has no addSkip method, skips not reportedaddSuccessfailureExceptionaddFailureaddError_id_enter_contextaddcleanup' object does not support the context manager protocol"not support the context manager protocol"_module_cleanupsSame as addCleanup, except the cleanup items are called even if
    setUpModule fails (unlike tearDownModule).Same as enterContext, but module-wide.Execute all module cleanup functions. Normally called for you after
    tearDownModule.
    Unconditionally skip a test.
    decoratortest_itemwrapsskip_wrapper__unittest_skip____unittest_skip_why__
    Skip a test if the condition is true.
    
    Skip a test unless the condition is true.
    __unittest_expecting_failure___is_subtypeexpectedbasetype_BaseTestCaseContext_raiseFailurestandardMsg_formatMessage_AssertRaisesBaseContextexpected_regexobj_name
        If args is empty, assertRaises/Warns is being used as a
        context manager, so check for a 'msg' kwarg and return self.
        If args is not empty, call a callable passing positional and keyword
        arguments.
        _base_type%s() arg 1 must be %s_base_type_str%r is an invalid keyword argument for this function'%r is an invalid keyword argument for ''this function'callable_obj_AssertRaisesContextA context manager used to implement TestCase.assertRaises* methods.an exception type or tuple of exception typesexc_name{} not raised by {}{} not raisedclear_frames"{}" does not match "{}"_AssertWarnsContextA context manager used to implement TestCase.assertWarns* methods.a warning type or tuple of warning types__warningregistry__warnings_managerfirst_matching{} not triggered by {}{} not triggered_OrderedChainMapA class whose instances are single test cases.

    By default, the test code itself should be placed in a method named
    'runTest'.

    If the fixture may be used for many test cases, create as
    many test methods as are needed. When instantiating such a TestCase
    subclass, specify in the constructor arguments the name of the test method
    that the instance is to execute.

    Test authors should subclass TestCase for their own tests. Construction
    and deconstruction of the test's environment ('fixture') can be
    implemented by overriding the 'setUp' and 'tearDown' methods respectively.

    If it is necessary to override the __init__ method, the base class
    __init__ method must always be called. It is important that subclasses
    should not change the signature of their __init__ method, since instances
    of the classes are instantiated automatically by parts of the framework
    in order to be run.

    When subclassing TestCase, you can set these attributes:
    * failureException: determines which exception will be raised when
        the instance's assertion methods fail; test methods raising this
        exception will be deemed to have 'failed' rather than 'errored'.
    * longMessage: determines whether long messages (including repr of
        objects used in assert methods) will be printed on failure in *addition*
        to any explicit message passed.
    * maxDiff: sets the maximum length of a diff in failure messages
        by assert methods using difflib. It is looked up as an instance
        attribute so can be configured by individual tests if required.
    longMessage80maxDiff_diffThreshold_classSetupFailed_class_cleanupsCreate an instance of the class that will use the named test
           method when executed. Raises a ValueError if the instance does
           not have a method with the specified name.
        _testMethodName_outcomeNo test_testMethodDoctestMethodno such test method in %s: %s_cleanups_subtest_type_equality_funcsaddTypeEqualityFuncassertDictEqualassertListEqualassertTupleEqualassertSetEqualassertMultiLineEqualtypeobjAdd a type specific assertEqual style function to compare a type.

        This method is for use by TestCase subclasses that need to register
        their own type equality functions to provide nicer error messages.

        Args:
            typeobj: The data type to call this function on when both values
                    are of the same type in assertEqual().
            function: The callable taking two arguments and an optional
                    msg= argument that raises self.failureException with a
                    useful error message when the two arguments are not equal.
        Add a function, with arguments, to be called when the test is
        completed. Functions added are called on a LIFO basis and are
        called after tearDown on test failure or success.

        Cleanup items are called even if setUp fails (unlike tearDown).enterContextEnters the supplied context manager.

        If successful, also adds its __exit__ method as a cleanup
        function and returns the result of the __enter__ method.
        addClassCleanupSame as addCleanup, except the cleanup items are called even if
        setUpClass fails (unlike tearDownClass).enterClassContextSame as enterContext, but class-wide.Hook method for setting up the test fixture before exercising it.Hook method for deconstructing the test fixture after testing it.setUpClassHook method for setting up class fixture before running tests in the class.tearDownClassHook method for deconstructing the class fixture after running all tests in the class.countTestCasesdefaultTestResultshortDescriptionReturns a one-line description of the test, or None if no
        description has been provided.

        The default implementation of this method returns the first line of
        the specified test method's docstring.
        %s.%s%s (%s.%s)<%s testMethod=%s>Return a context manager that will return the enclosed block
        of code in a subtest identified by the optional message and
        keyword parameters.  A failure in the subtest marks the test
        case as failed but resumes execution at the end of the enclosed
        block, allowing further test code to be executed.
        params_map_SubTestfailfast_addExpectedFailureaddExpectedFailureTestResult has no addExpectedFailure method, reporting as passes_addUnexpectedSuccessaddUnexpectedSuccessTestResult has no addUnexpectedSuccess method, reporting as failure_addDurationelapsedaddDurationTestResult has no addDuration methodstartTestRunstopTestRunstartTestskip_whyoutcomeperf_counterstart_timedoCleanupsstopTestExecute all cleanup functions. Normally called for you after
        tearDown.doClassCleanupsExecute all class cleanup functions. Normally called for you after
        tearDownClass.tearDown_exceptionsRun the test without collecting errors in a TestResultskipTestSkip this test.failFail immediately, with the given message.assertFalseCheck that the expression is false.%s is not falseassertTrueCheck that the expression is true.%s is not trueHonour the longMessage attribute when generating failure messages.
        If longMessage is False this means:
        * Use only an explicit message if it is provided
        * Otherwise use the standard message for the assert

        If longMessage is True:
        * Use the standard message
        * If an explicit message is provided, plus ' : ' and the explicit message
        %s : %sassertRaisesexpected_exceptionFail unless an exception of class expected_exception is raised
           by the callable when invoked with specified positional and
           keyword arguments. If a different type of exception is
           raised, it will not be caught, and the test case will be
           deemed to have suffered an error, exactly as for an
           unexpected exception.

           If called with the callable and arguments omitted, will return a
           context object used like this::

                with self.assertRaises(SomeException):
                    do_something()

           An optional keyword argument 'msg' can be provided when assertRaises
           is used as a context object.

           The context manager keeps a reference to the exception as
           the 'exception' attribute. This allows you to inspect the
           exception after the assertion::

               with self.assertRaises(SomeException) as cm:
                   do_something()
               the_exception = cm.exception
               self.assertEqual(the_exception.error_code, 3)
        assertWarnsexpected_warningFail unless a warning of class warnClass is triggered
           by the callable when invoked with specified positional and
           keyword arguments.  If a different type of warning is
           triggered, it will not be handled: depending on the other
           warning filtering rules in effect, it might be silenced, printed
           out, or raised as an exception.

           If called with the callable and arguments omitted, will return a
           context object used like this::

                with self.assertWarns(SomeWarning):
                    do_something()

           An optional keyword argument 'msg' can be provided when assertWarns
           is used as a context object.

           The context manager keeps a reference to the first matching
           warning as the 'warning' attribute; similarly, the 'filename'
           and 'lineno' attributes give you information about the line
           of Python code from which the warning was triggered.
           This allows you to inspect the warning after the assertion::

               with self.assertWarns(SomeWarning) as cm:
                   do_something()
               the_warning = cm.warning
               self.assertEqual(the_warning.some_attribute, 147)
        assertLogsFail unless a log message of level *level* or higher is emitted
        on *logger_name* or its children.  If omitted, *level* defaults to
        INFO and *logger* defaults to the root logger.

        This method must be used as a context manager, and will yield
        a recording object with two attributes: `output` and `records`.
        At the end of the context manager, the `output` attribute will
        be a list of the matching formatted log messages and the
        `records` attribute will be a list of the corresponding LogRecord
        objects.

        Example::

            with self.assertLogs('foo', level='INFO') as cm:
                logging.getLogger('foo').info('first message')
                logging.getLogger('foo.bar').error('second message')
            self.assertEqual(cm.output, ['INFO:foo:first message',
                                         'ERROR:foo.bar:second message'])
        _AssertLogsContextno_logsassertNoLogs Fail unless no log messages of level *level* or higher are emitted
        on *logger_name* or its children.

        This method must be used as a context manager.
        _getAssertEqualityFuncGet a detailed comparison function for the types of the two args.

        Returns: A callable accepting (first, second, msg=None) that will
        raise a failure exception if first != second with a useful human
        readable error message for those types.
        asserter_baseAssertEqualThe default assertEqual implementation, not type specific.%s != %sassertEqualFail if the two objects are unequal as determined by the '=='
           operator.
        assertion_funcassertNotEqualFail if the two objects are equal as determined by the '!='
           operator.
        %s == %sassertAlmostEqualFail if the two objects are unequal as determined by their
           difference rounded to the given number of decimal places
           (default 7) and comparing to zero, or by comparing that the
           difference between the two objects is more than the given
           delta.

           Note that decimal places (from zero) are usually not the same
           as significant digits (measured from the most significant digit).

           If the two objects compare equal then they will automatically
           compare almost equal.
        specify delta or places not both%s != %s within %s delta (%s difference)%s != %s within %r places (%s difference)assertNotAlmostEqualFail if the two objects are equal as determined by their
           difference rounded to the given number of decimal places
           (default 7) and comparing to zero, or by comparing that the
           difference between the two objects is less than the given delta.

           Note that decimal places (from zero) are usually not the same
           as significant digits (measured from the most significant digit).

           Objects that are equal automatically fail.
        %s == %s within %s delta (%s difference)%s == %s within %r placesassertSequenceEqualseq1seq2seq_typeAn equality assertion for ordered sequences (like lists and tuples).

        For the purposes of this function, a valid ordered sequence type is one
        which can be indexed, has a length, and has an equality operator.

        Args:
            seq1: The first sequence to compare.
            seq2: The second sequence to compare.
            seq_type: The expected datatype of the sequences, or None if no
                    datatype should be enforced.
            msg: Optional message to use on failure instead of a list of
                    differences.
        seq_type_nameFirst sequence is not a %s: %sSecond sequence is not a %s: %ssequencedifferinglen1First %s has no length.    Non-sequence?len2Second %s has no length.    Non-sequence?%ss differ: %s != %s
item1
Unable to index element %d of first %s
item2
Unable to index element %d of second %s

First differing element %d:
%s
%s

First %s contains %d additional elements.
'\nFirst %s contains %d additional ''elements.\n'First extra element %d:
%s
Unable to index element %d of first %s
'Unable to index element %d ''of first %s\n'
Second %s contains %d additional elements.
'\nSecond %s contains %d additional 'Unable to index element %d of second %s
'of second %s\n'ndiffpformatdiffMsg_truncateMessagemax_difflist1list2A list-specific equality assertion.

        Args:
            list1: The first list to compare.
            list2: The second list to compare.
            msg: Optional message to use on failure instead of a list of
                    differences.

        tuple1tuple2A tuple-specific equality assertion.

        Args:
            tuple1: The first tuple to compare.
            tuple2: The second tuple to compare.
            msg: Optional message to use on failure instead of a list of
                    differences.
        set1set2A set-specific equality assertion.

        Args:
            set1: The first set to compare.
            set2: The second set to compare.
            msg: Optional message to use on failure instead of a list of
                    differences.

        assertSetEqual uses ducktyping to support different types of sets, and
        is optimized for sets specifically (parameters must support a
        difference method).
        difference1invalid type when attempting set difference: %sfirst argument does not support set difference: %sdifference2second argument does not support set difference: %sItems in the first set but not the second:Items in the second set but not the first:assertInJust like self.assertTrue(a in b), but with a nicer default message.%s not found in %sassertNotInJust like self.assertTrue(a not in b), but with a nicer default message.%s unexpectedly found in %sassertIsexpr1expr2Just like self.assertTrue(a is b), but with a nicer default message.%s is not %sassertIsNotJust like self.assertTrue(a is not b), but with a nicer default message.unexpectedly identical: %sd1assertIsInstanceFirst argument is not a dictionarySecond argument is not a dictionaryassertCountEqualAsserts that two iterables have the same elements, the same number of
        times, without regard to order.

            self.assertEqual(Counter(list(first)),
                             Counter(list(second)))

         Example:
            - [0, 1, 1] and [1, 0, 1] compare equal.
            - [0, 0, 1] and [0, 1] compare unequal.

        first_seqsecond_seqdifferencesElement counts were not equal:
First has %d, Second has %d:  %rAssert that two multi-line strings are equal.First argument is not a stringSecond argument is not a stringfirst_presplitsecond_presplitfirstlinessecondlinesassertLessJust like self.assertTrue(a < b), but with a nicer default message.%s not less than %sassertLessEqualJust like self.assertTrue(a <= b), but with a nicer default message.%s not less than or equal to %sassertGreaterJust like self.assertTrue(a > b), but with a nicer default message.%s not greater than %sassertGreaterEqualJust like self.assertTrue(a >= b), but with a nicer default message.%s not greater than or equal to %sassertIsNoneSame as self.assertTrue(obj is None), with a nicer default message.%s is not NoneassertIsNotNoneIncluded for symmetry with assertIsNone.unexpectedly NoneSame as self.assertTrue(isinstance(obj, cls)), with a nicer
        default message.%s is not an instance of %rassertNotIsInstanceIncluded for symmetry with assertIsInstance.%s is an instance of %rassertRaisesRegexAsserts that the message in a raised exception matches a regex.

        Args:
            expected_exception: Exception class expected to be raised.
            expected_regex: Regex (re.Pattern object or string) expected
                    to be found in error message.
            args: Function to be called and extra positional args.
            kwargs: Extra kwargs.
            msg: Optional message used in case of failure. Can only be used
                    when assertRaisesRegex is used as a context manager.
        assertWarnsRegexAsserts that the message in a triggered warning matches a regexp.
        Basic functioning is similar to assertWarns() with the addition
        that only warnings whose messages also match the regular expression
        are considered successful matches.

        Args:
            expected_warning: Warning class expected to be triggered.
            expected_regex: Regex (re.Pattern object or string) expected
                    to be found in error message.
            args: Function to be called and extra positional args.
            kwargs: Extra kwargs.
            msg: Optional message used in case of failure. Can only be used
                    when assertWarnsRegex is used as a context manager.
        assertRegexFail the test unless the text matches the regular expression.expected_regex must not be empty.Regex didn't match: %r not found in %rassertNotRegexunexpected_regexFail the test if the text matches the regular expression.Regex matched: %r matches %r in %rA test case that wraps a test function.

    This is useful for slipping pre-existing test functions into the
    unittest framework. Optionally, set-up and tidy-up functions can be
    supplied. As with TestCase, the tidy-up ('tearDown') function will
    always be called if the set-up ('setUp') function ran successfully.
    testFunc_setUpFunc_tearDownFunc_testFunc_description%s (%s)<%s tec=%s>_messagesubtests cannot be run directly_subDescription[{}]params_desc({})(<subtest>){} {}Returns a one-line description of the subtest, or None if no
        description has been provided.
        # explicitly break a reference cycle:# exc_info -> frame -> exc_info# Swallows all but first exception. If a multi-exception handler# gets written we should use that here instead.# bpo-23890: manually break a reference cycle# let unexpected exceptions pass through# store exception, without traceback, for later retrieval# The __warningregistry__'s need to be in a pristine state for tests# to work properly.# store warning for later retrieval# Now we simply try to choose a helpful failure message# If a string is longer than _diffThreshold, use normal comparison instead# of difflib.  See #11763.# Attribute used by TestSuite for classSetUp# we allow instantiation with no explicit method name# but not an *incorrect* or missing method name# Map types to custom assertEqual functions that will compare# instances of said type in more detail to generate a more useful# error message.# If the test is expecting a failure, we really want to# stop now and register the expected failure.# We need to pass an actual exception and traceback to addFailure,# otherwise the legacy result can choke.# If the class or method was skipped.# explicitly break reference cycle:# outcome.expectedFailure -> frame -> outcome -> outcome.expectedFailure# clear the outcome, no more needed# return this for backwards compatibility# even though we no longer use it internally# don't switch to '{}' formatting in Python 2.X# it changes the way unicode input is handled# Lazy import to avoid importing logging if it is not needed.# NOTE(gregory.p.smith): I considered isinstance(first, type(second))# and vice versa.  I opted for the conservative approach in case# subclasses are not intended to be compared in detail to their super# class instances using a type equality func.  This means testing# subtypes won't automagically use the detailed comparison.  Callers# should use their type specific assertSpamEqual method to compare# subclasses if the detailed comparison is desired and appropriate.# See the discussion in http://bugs.python.org/issue2578.# shortcut# The sequences are the same, but have differing types.# Handle case with unhashable elements# Don't use difflib if the strings are too long# Append \n to both strings if either is missing the \n.# This allows the final ndiff to show the \n difference. The# exception here is if the string is empty, in which case no# \n should be added# Generate the message and diff, then raise the exception# _formatMessage ensures the longMessage option is respectedb'Test case implementation'u'Test case implementation'b'
Diff is %s characters long. Set self.maxDiff to None to see it.'u'
Diff is %s characters long. Set self.maxDiff to None to see it.'b'
    Raise this exception in a test to skip it.

    Usually you can use TestCase.skipTest() or one of the skipping decorators
    instead of raising this directly.
    'u'
    Raise this exception in a test to skip it.

    Usually you can use TestCase.skipTest() or one of the skipping decorators
    instead of raising this directly.
    'b'
    The test should stop.
    'u'
    The test should stop.
    'b'
    The test was supposed to fail, but it didn't!
    'u'
    The test was supposed to fail, but it didn't!
    'b'addSubTest'u'addSubTest'b'addSkip'u'addSkip'b'TestResult has no addSkip method, skips not reported'u'TestResult has no addSkip method, skips not reported'b'' object does not support the context manager protocol'u'' object does not support the context manager protocol'b'Same as addCleanup, except the cleanup items are called even if
    setUpModule fails (unlike tearDownModule).'u'Same as addCleanup, except the cleanup items are called even if
    setUpModule fails (unlike tearDownModule).'b'Same as enterContext, but module-wide.'u'Same as enterContext, but module-wide.'b'Execute all module cleanup functions. Normally called for you after
    tearDownModule.'u'Execute all module cleanup functions. Normally called for you after
    tearDownModule.'b'
    Unconditionally skip a test.
    'u'
    Unconditionally skip a test.
    'b'
    Skip a test if the condition is true.
    'u'
    Skip a test if the condition is true.
    'b'
    Skip a test unless the condition is true.
    'u'
    Skip a test unless the condition is true.
    'b'
        If args is empty, assertRaises/Warns is being used as a
        context manager, so check for a 'msg' kwarg and return self.
        If args is not empty, call a callable passing positional and keyword
        arguments.
        'u'
        If args is empty, assertRaises/Warns is being used as a
        context manager, so check for a 'msg' kwarg and return self.
        If args is not empty, call a callable passing positional and keyword
        arguments.
        'b'%s() arg 1 must be %s'u'%s() arg 1 must be %s'b'msg'b'%r is an invalid keyword argument for this function'u'%r is an invalid keyword argument for this function'b'A context manager used to implement TestCase.assertRaises* methods.'u'A context manager used to implement TestCase.assertRaises* methods.'b'an exception type or tuple of exception types'u'an exception type or tuple of exception types'b'{} not raised by {}'u'{} not raised by {}'b'{} not raised'u'{} not raised'b'"{}" does not match "{}"'u'"{}" does not match "{}"'b'A context manager used to implement TestCase.assertWarns* methods.'u'A context manager used to implement TestCase.assertWarns* methods.'b'a warning type or tuple of warning types'u'a warning type or tuple of warning types'b'__warningregistry__'u'__warningregistry__'b'{} not triggered by {}'u'{} not triggered by {}'b'{} not triggered'u'{} not triggered'b'A class whose instances are single test cases.

    By default, the test code itself should be placed in a method named
    'runTest'.

    If the fixture may be used for many test cases, create as
    many test methods as are needed. When instantiating such a TestCase
    subclass, specify in the constructor arguments the name of the test method
    that the instance is to execute.

    Test authors should subclass TestCase for their own tests. Construction
    and deconstruction of the test's environment ('fixture') can be
    implemented by overriding the 'setUp' and 'tearDown' methods respectively.

    If it is necessary to override the __init__ method, the base class
    __init__ method must always be called. It is important that subclasses
    should not change the signature of their __init__ method, since instances
    of the classes are instantiated automatically by parts of the framework
    in order to be run.

    When subclassing TestCase, you can set these attributes:
    * failureException: determines which exception will be raised when
        the instance's assertion methods fail; test methods raising this
        exception will be deemed to have 'failed' rather than 'errored'.
    * longMessage: determines whether long messages (including repr of
        objects used in assert methods) will be printed on failure in *addition*
        to any explicit message passed.
    * maxDiff: sets the maximum length of a diff in failure messages
        by assert methods using difflib. It is looked up as an instance
        attribute so can be configured by individual tests if required.
    'u'A class whose instances are single test cases.

    By default, the test code itself should be placed in a method named
    'runTest'.

    If the fixture may be used for many test cases, create as
    many test methods as are needed. When instantiating such a TestCase
    subclass, specify in the constructor arguments the name of the test method
    that the instance is to execute.

    Test authors should subclass TestCase for their own tests. Construction
    and deconstruction of the test's environment ('fixture') can be
    implemented by overriding the 'setUp' and 'tearDown' methods respectively.

    If it is necessary to override the __init__ method, the base class
    __init__ method must always be called. It is important that subclasses
    should not change the signature of their __init__ method, since instances
    of the classes are instantiated automatically by parts of the framework
    in order to be run.

    When subclassing TestCase, you can set these attributes:
    * failureException: determines which exception will be raised when
        the instance's assertion methods fail; test methods raising this
        exception will be deemed to have 'failed' rather than 'errored'.
    * longMessage: determines whether long messages (including repr of
        objects used in assert methods) will be printed on failure in *addition*
        to any explicit message passed.
    * maxDiff: sets the maximum length of a diff in failure messages
        by assert methods using difflib. It is looked up as an instance
        attribute so can be configured by individual tests if required.
    'b'Create an instance of the class that will use the named test
           method when executed. Raises a ValueError if the instance does
           not have a method with the specified name.
        'u'Create an instance of the class that will use the named test
           method when executed. Raises a ValueError if the instance does
           not have a method with the specified name.
        'b'No test'u'No test'b'no such test method in %s: %s'u'no such test method in %s: %s'b'assertDictEqual'u'assertDictEqual'b'assertListEqual'u'assertListEqual'b'assertTupleEqual'u'assertTupleEqual'b'assertSetEqual'u'assertSetEqual'b'assertMultiLineEqual'u'assertMultiLineEqual'b'Add a type specific assertEqual style function to compare a type.

        This method is for use by TestCase subclasses that need to register
        their own type equality functions to provide nicer error messages.

        Args:
            typeobj: The data type to call this function on when both values
                    are of the same type in assertEqual().
            function: The callable taking two arguments and an optional
                    msg= argument that raises self.failureException with a
                    useful error message when the two arguments are not equal.
        'u'Add a type specific assertEqual style function to compare a type.

        This method is for use by TestCase subclasses that need to register
        their own type equality functions to provide nicer error messages.

        Args:
            typeobj: The data type to call this function on when both values
                    are of the same type in assertEqual().
            function: The callable taking two arguments and an optional
                    msg= argument that raises self.failureException with a
                    useful error message when the two arguments are not equal.
        'b'Add a function, with arguments, to be called when the test is
        completed. Functions added are called on a LIFO basis and are
        called after tearDown on test failure or success.

        Cleanup items are called even if setUp fails (unlike tearDown).'u'Add a function, with arguments, to be called when the test is
        completed. Functions added are called on a LIFO basis and are
        called after tearDown on test failure or success.

        Cleanup items are called even if setUp fails (unlike tearDown).'b'Enters the supplied context manager.

        If successful, also adds its __exit__ method as a cleanup
        function and returns the result of the __enter__ method.
        'u'Enters the supplied context manager.

        If successful, also adds its __exit__ method as a cleanup
        function and returns the result of the __enter__ method.
        'b'Same as addCleanup, except the cleanup items are called even if
        setUpClass fails (unlike tearDownClass).'u'Same as addCleanup, except the cleanup items are called even if
        setUpClass fails (unlike tearDownClass).'b'Same as enterContext, but class-wide.'u'Same as enterContext, but class-wide.'b'Hook method for setting up the test fixture before exercising it.'u'Hook method for setting up the test fixture before exercising it.'b'Hook method for deconstructing the test fixture after testing it.'u'Hook method for deconstructing the test fixture after testing it.'b'Hook method for setting up class fixture before running tests in the class.'u'Hook method for setting up class fixture before running tests in the class.'b'Hook method for deconstructing the class fixture after running all tests in the class.'u'Hook method for deconstructing the class fixture after running all tests in the class.'b'Returns a one-line description of the test, or None if no
        description has been provided.

        The default implementation of this method returns the first line of
        the specified test method's docstring.
        'u'Returns a one-line description of the test, or None if no
        description has been provided.

        The default implementation of this method returns the first line of
        the specified test method's docstring.
        'b'%s.%s'u'%s.%s'b'%s (%s.%s)'u'%s (%s.%s)'b'<%s testMethod=%s>'u'<%s testMethod=%s>'b'Return a context manager that will return the enclosed block
        of code in a subtest identified by the optional message and
        keyword parameters.  A failure in the subtest marks the test
        case as failed but resumes execution at the end of the enclosed
        block, allowing further test code to be executed.
        'u'Return a context manager that will return the enclosed block
        of code in a subtest identified by the optional message and
        keyword parameters.  A failure in the subtest marks the test
        case as failed but resumes execution at the end of the enclosed
        block, allowing further test code to be executed.
        'b'TestResult has no addExpectedFailure method, reporting as passes'u'TestResult has no addExpectedFailure method, reporting as passes'b'TestResult has no addUnexpectedSuccess method, reporting as failure'u'TestResult has no addUnexpectedSuccess method, reporting as failure'b'TestResult has no addDuration method'u'TestResult has no addDuration method'b'startTestRun'u'startTestRun'b'stopTestRun'u'stopTestRun'b'__unittest_skip__'u'__unittest_skip__'b'__unittest_skip_why__'u'__unittest_skip_why__'b'__unittest_expecting_failure__'u'__unittest_expecting_failure__'b'Execute all cleanup functions. Normally called for you after
        tearDown.'u'Execute all cleanup functions. Normally called for you after
        tearDown.'b'Execute all class cleanup functions. Normally called for you after
        tearDownClass.'u'Execute all class cleanup functions. Normally called for you after
        tearDownClass.'b'Run the test without collecting errors in a TestResult'u'Run the test without collecting errors in a TestResult'b'Skip this test.'u'Skip this test.'b'Fail immediately, with the given message.'u'Fail immediately, with the given message.'b'Check that the expression is false.'u'Check that the expression is false.'b'%s is not false'u'%s is not false'b'Check that the expression is true.'u'Check that the expression is true.'b'%s is not true'u'%s is not true'b'Honour the longMessage attribute when generating failure messages.
        If longMessage is False this means:
        * Use only an explicit message if it is provided
        * Otherwise use the standard message for the assert

        If longMessage is True:
        * Use the standard message
        * If an explicit message is provided, plus ' : ' and the explicit message
        'u'Honour the longMessage attribute when generating failure messages.
        If longMessage is False this means:
        * Use only an explicit message if it is provided
        * Otherwise use the standard message for the assert

        If longMessage is True:
        * Use the standard message
        * If an explicit message is provided, plus ' : ' and the explicit message
        'b'%s : %s'u'%s : %s'b'Fail unless an exception of class expected_exception is raised
           by the callable when invoked with specified positional and
           keyword arguments. If a different type of exception is
           raised, it will not be caught, and the test case will be
           deemed to have suffered an error, exactly as for an
           unexpected exception.

           If called with the callable and arguments omitted, will return a
           context object used like this::

                with self.assertRaises(SomeException):
                    do_something()

           An optional keyword argument 'msg' can be provided when assertRaises
           is used as a context object.

           The context manager keeps a reference to the exception as
           the 'exception' attribute. This allows you to inspect the
           exception after the assertion::

               with self.assertRaises(SomeException) as cm:
                   do_something()
               the_exception = cm.exception
               self.assertEqual(the_exception.error_code, 3)
        'u'Fail unless an exception of class expected_exception is raised
           by the callable when invoked with specified positional and
           keyword arguments. If a different type of exception is
           raised, it will not be caught, and the test case will be
           deemed to have suffered an error, exactly as for an
           unexpected exception.

           If called with the callable and arguments omitted, will return a
           context object used like this::

                with self.assertRaises(SomeException):
                    do_something()

           An optional keyword argument 'msg' can be provided when assertRaises
           is used as a context object.

           The context manager keeps a reference to the exception as
           the 'exception' attribute. This allows you to inspect the
           exception after the assertion::

               with self.assertRaises(SomeException) as cm:
                   do_something()
               the_exception = cm.exception
               self.assertEqual(the_exception.error_code, 3)
        'b'assertRaises'u'assertRaises'b'Fail unless a warning of class warnClass is triggered
           by the callable when invoked with specified positional and
           keyword arguments.  If a different type of warning is
           triggered, it will not be handled: depending on the other
           warning filtering rules in effect, it might be silenced, printed
           out, or raised as an exception.

           If called with the callable and arguments omitted, will return a
           context object used like this::

                with self.assertWarns(SomeWarning):
                    do_something()

           An optional keyword argument 'msg' can be provided when assertWarns
           is used as a context object.

           The context manager keeps a reference to the first matching
           warning as the 'warning' attribute; similarly, the 'filename'
           and 'lineno' attributes give you information about the line
           of Python code from which the warning was triggered.
           This allows you to inspect the warning after the assertion::

               with self.assertWarns(SomeWarning) as cm:
                   do_something()
               the_warning = cm.warning
               self.assertEqual(the_warning.some_attribute, 147)
        'u'Fail unless a warning of class warnClass is triggered
           by the callable when invoked with specified positional and
           keyword arguments.  If a different type of warning is
           triggered, it will not be handled: depending on the other
           warning filtering rules in effect, it might be silenced, printed
           out, or raised as an exception.

           If called with the callable and arguments omitted, will return a
           context object used like this::

                with self.assertWarns(SomeWarning):
                    do_something()

           An optional keyword argument 'msg' can be provided when assertWarns
           is used as a context object.

           The context manager keeps a reference to the first matching
           warning as the 'warning' attribute; similarly, the 'filename'
           and 'lineno' attributes give you information about the line
           of Python code from which the warning was triggered.
           This allows you to inspect the warning after the assertion::

               with self.assertWarns(SomeWarning) as cm:
                   do_something()
               the_warning = cm.warning
               self.assertEqual(the_warning.some_attribute, 147)
        'b'assertWarns'u'assertWarns'b'Fail unless a log message of level *level* or higher is emitted
        on *logger_name* or its children.  If omitted, *level* defaults to
        INFO and *logger* defaults to the root logger.

        This method must be used as a context manager, and will yield
        a recording object with two attributes: `output` and `records`.
        At the end of the context manager, the `output` attribute will
        be a list of the matching formatted log messages and the
        `records` attribute will be a list of the corresponding LogRecord
        objects.

        Example::

            with self.assertLogs('foo', level='INFO') as cm:
                logging.getLogger('foo').info('first message')
                logging.getLogger('foo.bar').error('second message')
            self.assertEqual(cm.output, ['INFO:foo:first message',
                                         'ERROR:foo.bar:second message'])
        'u'Fail unless a log message of level *level* or higher is emitted
        on *logger_name* or its children.  If omitted, *level* defaults to
        INFO and *logger* defaults to the root logger.

        This method must be used as a context manager, and will yield
        a recording object with two attributes: `output` and `records`.
        At the end of the context manager, the `output` attribute will
        be a list of the matching formatted log messages and the
        `records` attribute will be a list of the corresponding LogRecord
        objects.

        Example::

            with self.assertLogs('foo', level='INFO') as cm:
                logging.getLogger('foo').info('first message')
                logging.getLogger('foo.bar').error('second message')
            self.assertEqual(cm.output, ['INFO:foo:first message',
                                         'ERROR:foo.bar:second message'])
        'b' Fail unless no log messages of level *level* or higher are emitted
        on *logger_name* or its children.

        This method must be used as a context manager.
        'u' Fail unless no log messages of level *level* or higher are emitted
        on *logger_name* or its children.

        This method must be used as a context manager.
        'b'Get a detailed comparison function for the types of the two args.

        Returns: A callable accepting (first, second, msg=None) that will
        raise a failure exception if first != second with a useful human
        readable error message for those types.
        'u'Get a detailed comparison function for the types of the two args.

        Returns: A callable accepting (first, second, msg=None) that will
        raise a failure exception if first != second with a useful human
        readable error message for those types.
        'b'The default assertEqual implementation, not type specific.'u'The default assertEqual implementation, not type specific.'b'%s != %s'u'%s != %s'b'Fail if the two objects are unequal as determined by the '=='
           operator.
        'u'Fail if the two objects are unequal as determined by the '=='
           operator.
        'b'Fail if the two objects are equal as determined by the '!='
           operator.
        'u'Fail if the two objects are equal as determined by the '!='
           operator.
        'b'%s == %s'u'%s == %s'b'Fail if the two objects are unequal as determined by their
           difference rounded to the given number of decimal places
           (default 7) and comparing to zero, or by comparing that the
           difference between the two objects is more than the given
           delta.

           Note that decimal places (from zero) are usually not the same
           as significant digits (measured from the most significant digit).

           If the two objects compare equal then they will automatically
           compare almost equal.
        'u'Fail if the two objects are unequal as determined by their
           difference rounded to the given number of decimal places
           (default 7) and comparing to zero, or by comparing that the
           difference between the two objects is more than the given
           delta.

           Note that decimal places (from zero) are usually not the same
           as significant digits (measured from the most significant digit).

           If the two objects compare equal then they will automatically
           compare almost equal.
        'b'specify delta or places not both'u'specify delta or places not both'b'%s != %s within %s delta (%s difference)'u'%s != %s within %s delta (%s difference)'b'%s != %s within %r places (%s difference)'u'%s != %s within %r places (%s difference)'b'Fail if the two objects are equal as determined by their
           difference rounded to the given number of decimal places
           (default 7) and comparing to zero, or by comparing that the
           difference between the two objects is less than the given delta.

           Note that decimal places (from zero) are usually not the same
           as significant digits (measured from the most significant digit).

           Objects that are equal automatically fail.
        'u'Fail if the two objects are equal as determined by their
           difference rounded to the given number of decimal places
           (default 7) and comparing to zero, or by comparing that the
           difference between the two objects is less than the given delta.

           Note that decimal places (from zero) are usually not the same
           as significant digits (measured from the most significant digit).

           Objects that are equal automatically fail.
        'b'%s == %s within %s delta (%s difference)'u'%s == %s within %s delta (%s difference)'b'%s == %s within %r places'u'%s == %s within %r places'b'An equality assertion for ordered sequences (like lists and tuples).

        For the purposes of this function, a valid ordered sequence type is one
        which can be indexed, has a length, and has an equality operator.

        Args:
            seq1: The first sequence to compare.
            seq2: The second sequence to compare.
            seq_type: The expected datatype of the sequences, or None if no
                    datatype should be enforced.
            msg: Optional message to use on failure instead of a list of
                    differences.
        'u'An equality assertion for ordered sequences (like lists and tuples).

        For the purposes of this function, a valid ordered sequence type is one
        which can be indexed, has a length, and has an equality operator.

        Args:
            seq1: The first sequence to compare.
            seq2: The second sequence to compare.
            seq_type: The expected datatype of the sequences, or None if no
                    datatype should be enforced.
            msg: Optional message to use on failure instead of a list of
                    differences.
        'b'First sequence is not a %s: %s'u'First sequence is not a %s: %s'b'Second sequence is not a %s: %s'u'Second sequence is not a %s: %s'b'sequence'u'sequence'b'First %s has no length.    Non-sequence?'u'First %s has no length.    Non-sequence?'b'Second %s has no length.    Non-sequence?'u'Second %s has no length.    Non-sequence?'b'%ss differ: %s != %s
'u'%ss differ: %s != %s
'b'
Unable to index element %d of first %s
'u'
Unable to index element %d of first %s
'b'
Unable to index element %d of second %s
'u'
Unable to index element %d of second %s
'b'
First differing element %d:
%s
%s
'u'
First differing element %d:
%s
%s
'b'
First %s contains %d additional elements.
'u'
First %s contains %d additional elements.
'b'First extra element %d:
%s
'u'First extra element %d:
%s
'b'Unable to index element %d of first %s
'u'Unable to index element %d of first %s
'b'
Second %s contains %d additional elements.
'u'
Second %s contains %d additional elements.
'b'Unable to index element %d of second %s
'u'Unable to index element %d of second %s
'b'A list-specific equality assertion.

        Args:
            list1: The first list to compare.
            list2: The second list to compare.
            msg: Optional message to use on failure instead of a list of
                    differences.

        'u'A list-specific equality assertion.

        Args:
            list1: The first list to compare.
            list2: The second list to compare.
            msg: Optional message to use on failure instead of a list of
                    differences.

        'b'A tuple-specific equality assertion.

        Args:
            tuple1: The first tuple to compare.
            tuple2: The second tuple to compare.
            msg: Optional message to use on failure instead of a list of
                    differences.
        'u'A tuple-specific equality assertion.

        Args:
            tuple1: The first tuple to compare.
            tuple2: The second tuple to compare.
            msg: Optional message to use on failure instead of a list of
                    differences.
        'b'A set-specific equality assertion.

        Args:
            set1: The first set to compare.
            set2: The second set to compare.
            msg: Optional message to use on failure instead of a list of
                    differences.

        assertSetEqual uses ducktyping to support different types of sets, and
        is optimized for sets specifically (parameters must support a
        difference method).
        'u'A set-specific equality assertion.

        Args:
            set1: The first set to compare.
            set2: The second set to compare.
            msg: Optional message to use on failure instead of a list of
                    differences.

        assertSetEqual uses ducktyping to support different types of sets, and
        is optimized for sets specifically (parameters must support a
        difference method).
        'b'invalid type when attempting set difference: %s'u'invalid type when attempting set difference: %s'b'first argument does not support set difference: %s'u'first argument does not support set difference: %s'b'second argument does not support set difference: %s'u'second argument does not support set difference: %s'b'Items in the first set but not the second:'u'Items in the first set but not the second:'b'Items in the second set but not the first:'u'Items in the second set but not the first:'b'Just like self.assertTrue(a in b), but with a nicer default message.'u'Just like self.assertTrue(a in b), but with a nicer default message.'b'%s not found in %s'u'%s not found in %s'b'Just like self.assertTrue(a not in b), but with a nicer default message.'u'Just like self.assertTrue(a not in b), but with a nicer default message.'b'%s unexpectedly found in %s'u'%s unexpectedly found in %s'b'Just like self.assertTrue(a is b), but with a nicer default message.'u'Just like self.assertTrue(a is b), but with a nicer default message.'b'%s is not %s'u'%s is not %s'b'Just like self.assertTrue(a is not b), but with a nicer default message.'u'Just like self.assertTrue(a is not b), but with a nicer default message.'b'unexpectedly identical: %s'u'unexpectedly identical: %s'b'First argument is not a dictionary'u'First argument is not a dictionary'b'Second argument is not a dictionary'u'Second argument is not a dictionary'b'Asserts that two iterables have the same elements, the same number of
        times, without regard to order.

            self.assertEqual(Counter(list(first)),
                             Counter(list(second)))

         Example:
            - [0, 1, 1] and [1, 0, 1] compare equal.
            - [0, 0, 1] and [0, 1] compare unequal.

        'u'Asserts that two iterables have the same elements, the same number of
        times, without regard to order.

            self.assertEqual(Counter(list(first)),
                             Counter(list(second)))

         Example:
            - [0, 1, 1] and [1, 0, 1] compare equal.
            - [0, 0, 1] and [0, 1] compare unequal.

        'b'Element counts were not equal:
'u'Element counts were not equal:
'b'First has %d, Second has %d:  %r'u'First has %d, Second has %d:  %r'b'Assert that two multi-line strings are equal.'u'Assert that two multi-line strings are equal.'b'First argument is not a string'u'First argument is not a string'b'Second argument is not a string'u'Second argument is not a string'b'Just like self.assertTrue(a < b), but with a nicer default message.'u'Just like self.assertTrue(a < b), but with a nicer default message.'b'%s not less than %s'u'%s not less than %s'b'Just like self.assertTrue(a <= b), but with a nicer default message.'u'Just like self.assertTrue(a <= b), but with a nicer default message.'b'%s not less than or equal to %s'u'%s not less than or equal to %s'b'Just like self.assertTrue(a > b), but with a nicer default message.'u'Just like self.assertTrue(a > b), but with a nicer default message.'b'%s not greater than %s'u'%s not greater than %s'b'Just like self.assertTrue(a >= b), but with a nicer default message.'u'Just like self.assertTrue(a >= b), but with a nicer default message.'b'%s not greater than or equal to %s'u'%s not greater than or equal to %s'b'Same as self.assertTrue(obj is None), with a nicer default message.'u'Same as self.assertTrue(obj is None), with a nicer default message.'b'%s is not None'u'%s is not None'b'Included for symmetry with assertIsNone.'u'Included for symmetry with assertIsNone.'b'unexpectedly None'u'unexpectedly None'b'Same as self.assertTrue(isinstance(obj, cls)), with a nicer
        default message.'u'Same as self.assertTrue(isinstance(obj, cls)), with a nicer
        default message.'b'%s is not an instance of %r'u'%s is not an instance of %r'b'Included for symmetry with assertIsInstance.'u'Included for symmetry with assertIsInstance.'b'%s is an instance of %r'u'%s is an instance of %r'b'Asserts that the message in a raised exception matches a regex.

        Args:
            expected_exception: Exception class expected to be raised.
            expected_regex: Regex (re.Pattern object or string) expected
                    to be found in error message.
            args: Function to be called and extra positional args.
            kwargs: Extra kwargs.
            msg: Optional message used in case of failure. Can only be used
                    when assertRaisesRegex is used as a context manager.
        'u'Asserts that the message in a raised exception matches a regex.

        Args:
            expected_exception: Exception class expected to be raised.
            expected_regex: Regex (re.Pattern object or string) expected
                    to be found in error message.
            args: Function to be called and extra positional args.
            kwargs: Extra kwargs.
            msg: Optional message used in case of failure. Can only be used
                    when assertRaisesRegex is used as a context manager.
        'b'assertRaisesRegex'u'assertRaisesRegex'b'Asserts that the message in a triggered warning matches a regexp.
        Basic functioning is similar to assertWarns() with the addition
        that only warnings whose messages also match the regular expression
        are considered successful matches.

        Args:
            expected_warning: Warning class expected to be triggered.
            expected_regex: Regex (re.Pattern object or string) expected
                    to be found in error message.
            args: Function to be called and extra positional args.
            kwargs: Extra kwargs.
            msg: Optional message used in case of failure. Can only be used
                    when assertWarnsRegex is used as a context manager.
        'u'Asserts that the message in a triggered warning matches a regexp.
        Basic functioning is similar to assertWarns() with the addition
        that only warnings whose messages also match the regular expression
        are considered successful matches.

        Args:
            expected_warning: Warning class expected to be triggered.
            expected_regex: Regex (re.Pattern object or string) expected
                    to be found in error message.
            args: Function to be called and extra positional args.
            kwargs: Extra kwargs.
            msg: Optional message used in case of failure. Can only be used
                    when assertWarnsRegex is used as a context manager.
        'b'assertWarnsRegex'u'assertWarnsRegex'b'Fail the test unless the text matches the regular expression.'u'Fail the test unless the text matches the regular expression.'b'expected_regex must not be empty.'u'expected_regex must not be empty.'b'Regex didn't match: %r not found in %r'u'Regex didn't match: %r not found in %r'b'Fail the test if the text matches the regular expression.'u'Fail the test if the text matches the regular expression.'b'Regex matched: %r matches %r in %r'u'Regex matched: %r matches %r in %r'b'A test case that wraps a test function.

    This is useful for slipping pre-existing test functions into the
    unittest framework. Optionally, set-up and tidy-up functions can be
    supplied. As with TestCase, the tidy-up ('tearDown') function will
    always be called if the set-up ('setUp') function ran successfully.
    'u'A test case that wraps a test function.

    This is useful for slipping pre-existing test functions into the
    unittest framework. Optionally, set-up and tidy-up functions can be
    supplied. As with TestCase, the tidy-up ('tearDown') function will
    always be called if the set-up ('setUp') function ran successfully.
    'b'%s (%s)'u'%s (%s)'b'<%s tec=%s>'u'<%s tec=%s>'b'subtests cannot be run directly'u'subtests cannot be run directly'b'[{}]'u'[{}]'b'({})'u'({})'b'(<subtest>)'u'(<subtest>)'b'{} {}'u'{} {}'b'Returns a one-line description of the subtest, or None if no
        description has been provided.
        'u'Returns a one-line description of the subtest, or None if no
        description has been provided.
        'u'Lib.unittest.case'u'unittest.case'u'case'Charsetadd_aliasadd_charsetadd_codecemail.base64mimeemail.quoprimimeemail.encodersencode_7or8bitQPBASE64SHORTESTRFC2047_CHROME_LENus-asciiDEFAULT_CHARSETiso-8859-2iso-8859-3iso-8859-4iso-8859-9iso-8859-10iso-8859-13iso-8859-14iso-8859-15iso-8859-16windows-1252visciiiso-2022-jpeuc-jpkoi8-rCHARSETSlatin_2latin-2latin_3latin-3latin_4latin-4latin_5latin-5latin_6latin-6latin_7latin-7latin_8latin-8latin_9latin-9latin_10latin-10ks_c_5601-1987euc-krALIASESCODEC_MAPheader_encbody_encoutput_charsetAdd character set properties to the global registry.

    charset is the input character set, and must be the canonical name of a
    character set.

    Optional header_enc and body_enc is either charset.QP for
    quoted-printable, charset.BASE64 for base64 encoding, charset.SHORTEST for
    the shortest of qp or base64 encoding, or None for no encoding.  SHORTEST
    is only valid for header_enc.  It describes how message headers and
    message bodies in the input charset are to be encoded.  Default is no
    encoding.

    Optional output_charset is the character set that the output should be
    in.  Conversions will proceed from input charset, to Unicode, to the
    output charset when the method Charset.convert() is called.  The default
    is to output in the same character set as the input.

    Both input_charset and output_charset must have Unicode codec entries in
    the module's charset-to-codec mapping; use add_codec(charset, codecname)
    to add codecs the module does not know about.  See the codecs module's
    documentation for more information.
    SHORTEST not allowed for body_encAdd a character set alias.

    alias is the alias name, e.g. latin-1
    canonical is the character set's canonical name, e.g. iso-8859-1
    codecnameAdd a codec that map characters in the given charset to/from Unicode.

    charset is the canonical name of a character set.  codecname is the name
    of a Python codec, as appropriate for the second argument to the unicode()
    built-in, or to the encode() method of a Unicode string.
    _encodecodecMap character sets to their email properties.

    This class provides information about the requirements imposed on email
    for a specific character set.  It also provides convenience routines for
    converting between character sets, given the availability of the
    applicable codecs.  Given a character set, it will do its best to provide
    information on how to use that character set in an email in an
    RFC-compliant way.

    Certain character sets must be encoded with quoted-printable or base64
    when used in email headers or bodies.  Certain character sets must be
    converted outright, and are not allowed in email.  Instances of this
    module expose the following information about a character set:

    input_charset: The initial character set specified.  Common aliases
                   are converted to their `official' email names (e.g. latin_1
                   is converted to iso-8859-1).  Defaults to 7-bit us-ascii.

    header_encoding: If the character set must be encoded before it can be
                     used in an email header, this attribute will be set to
                     charset.QP (for quoted-printable), charset.BASE64 (for
                     base64 encoding), or charset.SHORTEST for the shortest of
                     QP or BASE64 encoding.  Otherwise, it will be None.

    body_encoding: Same as header_encoding, but describes the encoding for the
                   mail message's body, which indeed may be different than the
                   header encoding.  charset.SHORTEST is not allowed for
                   body_encoding.

    output_charset: Some character sets must be converted before they can be
                    used in email headers or bodies.  If the input_charset is
                    one of them, this attribute will contain the name of the
                    charset output will be converted to.  Otherwise, it will
                    be None.

    input_codec: The name of the Python codec used to convert the
                 input_charset to Unicode.  If no conversion codec is
                 necessary, this attribute will be None.

    output_codec: The name of the Python codec used to convert Unicode
                  to the output_charset.  If no conversion codec is necessary,
                  this attribute will have the same value as the input_codec.
    input_charsethencbencconvheader_encodingbody_encodinginput_codecoutput_codecget_body_encodingReturn the content-transfer-encoding used for body encoding.

        This is either the string `quoted-printable' or `base64' depending on
        the encoding used, or it is a function in which case you should call
        the function with a single argument, the Message object being
        encoded.  The function should then set the Content-Transfer-Encoding
        header itself to whatever is appropriate.

        Returns "quoted-printable" if self.body_encoding is QP.
        Returns "base64" if self.body_encoding is BASE64.
        Returns conversion function otherwise.
        quoted-printableget_output_charsetReturn the output character set.

        This is self.output_charset if that is not None, otherwise it is
        self.input_charset.
        Header-encode a string by converting it first to bytes.

        The type of encoding (base64 or quoted-printable) will be based on
        this charset's `header_encoding`.

        :param string: A unicode string for the header.  It must be possible
            to encode this string to bytes using the character set's
            output codec.
        :return: The encoded string, with RFC 2047 chrome.
        _get_encoderencoder_moduleheader_encode_linesmaxlengthsHeader-encode a string by converting it first to bytes.

        This is similar to `header_encode()` except that the string is fit
        into maximum line lengths as given by the argument.

        :param string: A unicode string for the header.  It must be possible
            to encode this string to bytes using the character set's
            output codec.
        :param maxlengths: Maximum line length iterator.  Each element
            returned from this iterator will provide the next maximum line
            length.  This parameter is used as an argument to built-in next()
            and should never be exhausted.  The maximum line lengths should
            not count the RFC 2047 chrome.  These line lengths are only a
            hint; the splitter does the best it can.
        :return: Lines of encoded strings, each with RFC 2047 chrome.
        encodercurrent_linethis_linejoined_linelen64lenqpBody-encode a string by converting it first to bytes.

        The type of encoding (base64 or quoted-printable) will be based on
        self.body_encoding.  If body_encoding is None, we assume the
        output charset is a 7bit encoding, so re-encoding the decoded
        string using the ascii codec produces the correct string version
        of the content.
        # Author: Ben Gertzfield, Barry Warsaw# Flags for types of header encodings# Quoted-Printable# the shorter of QP and base64, but only for headers# In "=?charset?q?hello_world?=", the =?, ?q?, and ?= add up to 7# Defaults# input        header enc  body enc output conv# iso-8859-5 is Cyrillic, and not especially used# iso-8859-6 is Arabic, also not particularly used# iso-8859-7 is Greek, QP will not make it readable# iso-8859-8 is Hebrew, QP will not make it readable# iso-8859-11 is Thai, QP will not make it readable# Aliases for other commonly-used names for character sets.  Map# them to the real ones used in email.# Map charsets to their Unicode codec strings.# Hack: We don't want *any* conversion for stuff marked us-ascii, as all# sorts of garbage might be sent to us in the guise of 7-bit us-ascii.# Let that stuff pass through without conversion to/from Unicode.# Convenience functions for extending the above mappings# Convenience function for encoding strings, taking into account# that they might be unknown-8bit (ie: have surrogate-escaped bytes)# RFC 2046, $4.1.2 says charsets are not case sensitive.  We coerce to# unicode because its .lower() is locale insensitive.  If the argument# is already a unicode, we leave it at that, but ensure that the# charset is ASCII, as the standard (RFC XXX) requires.# Set the input charset after filtering through the aliases# We can try to guess which encoding and conversion to use by the# charset_map dictionary.  Try that first, but let the user override# it.# Set the attributes, allowing the arguments to override the default.# Now set the codecs.  If one isn't defined for input_charset,# guess and try a Unicode codec with the same name as input_codec.# 7bit/8bit encodings return the string unchanged (modulo conversions)# See which encoding we should use.# Calculate the number of characters that the RFC 2047 chrome will# contribute to each line.# Now comes the hard part.  We must encode bytes but we can't split on# bytes because some character sets are variable length and each# encoded word must stand on its own.  So the problem is you have to# encode to bytes to figure out this word's length, but you must split# on characters.  This causes two problems: first, we don't know how# many octets a specific substring of unicode characters will get# encoded to, and second, we don't know how many ASCII characters# those octets will get encoded to.  Unless we try it.  Which seems# inefficient.  In the interest of being correct rather than fast (and# in the hope that there will be few encoded headers in any such# message), brute force it. :(# This last character doesn't fit so pop it off.# Does nothing fit on the first line?# quopromime.body_encode takes a string, but operates on it as if# it were a list of byte codes.  For a (minimal) history on why# this is so, see changeset 0cf700464177.  To correctly encode a# character set, then, we must turn it into pseudo bytes via the# latin1 charset, which will encode any byte as a single code point# between 0 and 255, which is what body_encode is expecting.b'Charset'u'Charset'b'add_alias'u'add_alias'b'add_charset'u'add_charset'b'add_codec'u'add_codec'b'us-ascii'u'us-ascii'b'iso-8859-2'u'iso-8859-2'b'iso-8859-3'u'iso-8859-3'b'iso-8859-4'u'iso-8859-4'b'iso-8859-9'u'iso-8859-9'b'iso-8859-10'u'iso-8859-10'b'iso-8859-13'u'iso-8859-13'b'iso-8859-14'u'iso-8859-14'b'iso-8859-15'u'iso-8859-15'b'iso-8859-16'u'iso-8859-16'b'windows-1252'u'windows-1252'b'viscii'u'viscii'b'iso-2022-jp'u'iso-2022-jp'b'euc-jp'u'euc-jp'b'koi8-r'u'koi8-r'b'latin_2'u'latin_2'b'latin-2'u'latin-2'b'latin_3'u'latin_3'b'latin-3'u'latin-3'b'latin_4'u'latin_4'b'latin-4'u'latin-4'b'latin_5'u'latin_5'b'latin-5'u'latin-5'b'latin_6'u'latin_6'b'latin-6'u'latin-6'b'latin_7'u'latin_7'b'latin-7'u'latin-7'b'latin_8'u'latin_8'b'latin-8'u'latin-8'b'latin_9'u'latin_9'b'latin-9'u'latin-9'b'latin_10'u'latin_10'b'latin-10'u'latin-10'b'ks_c_5601-1987'u'ks_c_5601-1987'b'euc-kr'u'euc-kr'b'Add character set properties to the global registry.

    charset is the input character set, and must be the canonical name of a
    character set.

    Optional header_enc and body_enc is either charset.QP for
    quoted-printable, charset.BASE64 for base64 encoding, charset.SHORTEST for
    the shortest of qp or base64 encoding, or None for no encoding.  SHORTEST
    is only valid for header_enc.  It describes how message headers and
    message bodies in the input charset are to be encoded.  Default is no
    encoding.

    Optional output_charset is the character set that the output should be
    in.  Conversions will proceed from input charset, to Unicode, to the
    output charset when the method Charset.convert() is called.  The default
    is to output in the same character set as the input.

    Both input_charset and output_charset must have Unicode codec entries in
    the module's charset-to-codec mapping; use add_codec(charset, codecname)
    to add codecs the module does not know about.  See the codecs module's
    documentation for more information.
    'u'Add character set properties to the global registry.

    charset is the input character set, and must be the canonical name of a
    character set.

    Optional header_enc and body_enc is either charset.QP for
    quoted-printable, charset.BASE64 for base64 encoding, charset.SHORTEST for
    the shortest of qp or base64 encoding, or None for no encoding.  SHORTEST
    is only valid for header_enc.  It describes how message headers and
    message bodies in the input charset are to be encoded.  Default is no
    encoding.

    Optional output_charset is the character set that the output should be
    in.  Conversions will proceed from input charset, to Unicode, to the
    output charset when the method Charset.convert() is called.  The default
    is to output in the same character set as the input.

    Both input_charset and output_charset must have Unicode codec entries in
    the module's charset-to-codec mapping; use add_codec(charset, codecname)
    to add codecs the module does not know about.  See the codecs module's
    documentation for more information.
    'b'SHORTEST not allowed for body_enc'u'SHORTEST not allowed for body_enc'b'Add a character set alias.

    alias is the alias name, e.g. latin-1
    canonical is the character set's canonical name, e.g. iso-8859-1
    'u'Add a character set alias.

    alias is the alias name, e.g. latin-1
    canonical is the character set's canonical name, e.g. iso-8859-1
    'b'Add a codec that map characters in the given charset to/from Unicode.

    charset is the canonical name of a character set.  codecname is the name
    of a Python codec, as appropriate for the second argument to the unicode()
    built-in, or to the encode() method of a Unicode string.
    'u'Add a codec that map characters in the given charset to/from Unicode.

    charset is the canonical name of a character set.  codecname is the name
    of a Python codec, as appropriate for the second argument to the unicode()
    built-in, or to the encode() method of a Unicode string.
    'b'Map character sets to their email properties.

    This class provides information about the requirements imposed on email
    for a specific character set.  It also provides convenience routines for
    converting between character sets, given the availability of the
    applicable codecs.  Given a character set, it will do its best to provide
    information on how to use that character set in an email in an
    RFC-compliant way.

    Certain character sets must be encoded with quoted-printable or base64
    when used in email headers or bodies.  Certain character sets must be
    converted outright, and are not allowed in email.  Instances of this
    module expose the following information about a character set:

    input_charset: The initial character set specified.  Common aliases
                   are converted to their `official' email names (e.g. latin_1
                   is converted to iso-8859-1).  Defaults to 7-bit us-ascii.

    header_encoding: If the character set must be encoded before it can be
                     used in an email header, this attribute will be set to
                     charset.QP (for quoted-printable), charset.BASE64 (for
                     base64 encoding), or charset.SHORTEST for the shortest of
                     QP or BASE64 encoding.  Otherwise, it will be None.

    body_encoding: Same as header_encoding, but describes the encoding for the
                   mail message's body, which indeed may be different than the
                   header encoding.  charset.SHORTEST is not allowed for
                   body_encoding.

    output_charset: Some character sets must be converted before they can be
                    used in email headers or bodies.  If the input_charset is
                    one of them, this attribute will contain the name of the
                    charset output will be converted to.  Otherwise, it will
                    be None.

    input_codec: The name of the Python codec used to convert the
                 input_charset to Unicode.  If no conversion codec is
                 necessary, this attribute will be None.

    output_codec: The name of the Python codec used to convert Unicode
                  to the output_charset.  If no conversion codec is necessary,
                  this attribute will have the same value as the input_codec.
    'u'Map character sets to their email properties.

    This class provides information about the requirements imposed on email
    for a specific character set.  It also provides convenience routines for
    converting between character sets, given the availability of the
    applicable codecs.  Given a character set, it will do its best to provide
    information on how to use that character set in an email in an
    RFC-compliant way.

    Certain character sets must be encoded with quoted-printable or base64
    when used in email headers or bodies.  Certain character sets must be
    converted outright, and are not allowed in email.  Instances of this
    module expose the following information about a character set:

    input_charset: The initial character set specified.  Common aliases
                   are converted to their `official' email names (e.g. latin_1
                   is converted to iso-8859-1).  Defaults to 7-bit us-ascii.

    header_encoding: If the character set must be encoded before it can be
                     used in an email header, this attribute will be set to
                     charset.QP (for quoted-printable), charset.BASE64 (for
                     base64 encoding), or charset.SHORTEST for the shortest of
                     QP or BASE64 encoding.  Otherwise, it will be None.

    body_encoding: Same as header_encoding, but describes the encoding for the
                   mail message's body, which indeed may be different than the
                   header encoding.  charset.SHORTEST is not allowed for
                   body_encoding.

    output_charset: Some character sets must be converted before they can be
                    used in email headers or bodies.  If the input_charset is
                    one of them, this attribute will contain the name of the
                    charset output will be converted to.  Otherwise, it will
                    be None.

    input_codec: The name of the Python codec used to convert the
                 input_charset to Unicode.  If no conversion codec is
                 necessary, this attribute will be None.

    output_codec: The name of the Python codec used to convert Unicode
                  to the output_charset.  If no conversion codec is necessary,
                  this attribute will have the same value as the input_codec.
    'b'Return the content-transfer-encoding used for body encoding.

        This is either the string `quoted-printable' or `base64' depending on
        the encoding used, or it is a function in which case you should call
        the function with a single argument, the Message object being
        encoded.  The function should then set the Content-Transfer-Encoding
        header itself to whatever is appropriate.

        Returns "quoted-printable" if self.body_encoding is QP.
        Returns "base64" if self.body_encoding is BASE64.
        Returns conversion function otherwise.
        'u'Return the content-transfer-encoding used for body encoding.

        This is either the string `quoted-printable' or `base64' depending on
        the encoding used, or it is a function in which case you should call
        the function with a single argument, the Message object being
        encoded.  The function should then set the Content-Transfer-Encoding
        header itself to whatever is appropriate.

        Returns "quoted-printable" if self.body_encoding is QP.
        Returns "base64" if self.body_encoding is BASE64.
        Returns conversion function otherwise.
        'b'quoted-printable'u'quoted-printable'b'Return the output character set.

        This is self.output_charset if that is not None, otherwise it is
        self.input_charset.
        'u'Return the output character set.

        This is self.output_charset if that is not None, otherwise it is
        self.input_charset.
        'b'Header-encode a string by converting it first to bytes.

        The type of encoding (base64 or quoted-printable) will be based on
        this charset's `header_encoding`.

        :param string: A unicode string for the header.  It must be possible
            to encode this string to bytes using the character set's
            output codec.
        :return: The encoded string, with RFC 2047 chrome.
        'u'Header-encode a string by converting it first to bytes.

        The type of encoding (base64 or quoted-printable) will be based on
        this charset's `header_encoding`.

        :param string: A unicode string for the header.  It must be possible
            to encode this string to bytes using the character set's
            output codec.
        :return: The encoded string, with RFC 2047 chrome.
        'b'Header-encode a string by converting it first to bytes.

        This is similar to `header_encode()` except that the string is fit
        into maximum line lengths as given by the argument.

        :param string: A unicode string for the header.  It must be possible
            to encode this string to bytes using the character set's
            output codec.
        :param maxlengths: Maximum line length iterator.  Each element
            returned from this iterator will provide the next maximum line
            length.  This parameter is used as an argument to built-in next()
            and should never be exhausted.  The maximum line lengths should
            not count the RFC 2047 chrome.  These line lengths are only a
            hint; the splitter does the best it can.
        :return: Lines of encoded strings, each with RFC 2047 chrome.
        'u'Header-encode a string by converting it first to bytes.

        This is similar to `header_encode()` except that the string is fit
        into maximum line lengths as given by the argument.

        :param string: A unicode string for the header.  It must be possible
            to encode this string to bytes using the character set's
            output codec.
        :param maxlengths: Maximum line length iterator.  Each element
            returned from this iterator will provide the next maximum line
            length.  This parameter is used as an argument to built-in next()
            and should never be exhausted.  The maximum line lengths should
            not count the RFC 2047 chrome.  These line lengths are only a
            hint; the splitter does the best it can.
        :return: Lines of encoded strings, each with RFC 2047 chrome.
        'b'Body-encode a string by converting it first to bytes.

        The type of encoding (base64 or quoted-printable) will be based on
        self.body_encoding.  If body_encoding is None, we assume the
        output charset is a 7bit encoding, so re-encoding the decoded
        string using the ascii codec produces the correct string version
        of the content.
        'u'Body-encode a string by converting it first to bytes.

        The type of encoding (base64 or quoted-printable) will be based on
        self.body_encoding.  If body_encoding is None, we assume the
        output charset is a 7bit encoding, so re-encoding the decoded
        string using the ascii codec produces the correct string version
        of the content.
        'u'Lib.email.charset'u'email.charset'
An XML-RPC client interface for Python.

The marshalling and response parser code can also be used to
implement XML-RPC servers.

Exported exceptions:

  Error          Base class for client errors
  ProtocolError  Indicates an HTTP protocol error
  ResponseError  Indicates a broken response package
  Fault          Indicates an XML-RPC fault package

Exported classes:

  ServerProxy    Represents a logical connection to an XML-RPC server

  MultiCall      Executor of boxcared xmlrpc requests
  DateTime       dateTime wrapper for an ISO 8601 string or time tuple or
                 localtime integer value to generate a "dateTime.iso8601"
                 XML-RPC value
  Binary         binary data wrapper

  Marshaller     Generate an XML-RPC params chunk from a Python data structure
  Unmarshaller   Unmarshal an XML-RPC response from incoming XML event message
  Transport      Handles an HTTP transaction to an XML-RPC server
  SafeTransport  Handles an HTTPS transaction to an XML-RPC server

Exported constants:

  (none)

Exported functions:

  getparser      Create instance of the fastest available parser & attach
                 to an unmarshalling object
  dumps          Convert an argument tuple or a Fault instance to an XML-RPC
                 request (or response, if the methodresponse option is used).
  loads          Convert an XML-RPC packet to unmarshalled data plus a method
                 name (None if not present).
httpxml.parsersexpatgzipMAXINTMININT32700PARSE_ERROR32600SERVER_ERROR32500APPLICATION_ERROR32400SYSTEM_ERROR32300TRANSPORT_ERRORNOT_WELLFORMED_ERROR32701UNSUPPORTED_ENCODING32702INVALID_ENCODING_CHARINVALID_XMLRPC32601METHOD_NOT_FOUND32602INVALID_METHOD_PARAMS32603INTERNAL_ERRORBase class for client errors.ProtocolErrorIndicates an HTTP protocol error.urlerrcodeerrmsg<%s for %s: %s %s>ResponseErrorIndicates a broken response package.FaultIndicates an XML-RPC fault package.faultCodefaultString<%s %s: %r>booleanBoolean_day0_try0001%Y_iso8601_format%Y%m%dT%H:%M:%S%4Y%4Y%m%dT%H:%M:%S_strftime%04d%02d%02dT%02d:%02d:%02dDateTimeDateTime wrapper for an ISO 8601 string or time tuple or
    localtime integer value to generate 'dateTime.iso8601' XML-RPC
    value.
    make_comparable<%s %r at %#x><value><dateTime.iso8601></dateTime.iso8601></value>
_datetime_typeBinaryWrapper for binary data.expected bytes or bytearray, not %s<value><base64>
</base64></value>
_binaryWRAPPERSExpatParserParserCreate_targetStartElementHandlerEndElementHandlerCharacterDataHandlerxmlfeedParseMarshallerGenerate an XML-RPC params chunk from a Python data structure.

    Create a Marshaller instance for each set of parameters, and use
    the "dumps" method to convert your data (represented as a tuple)
    to an XML-RPC params chunk.  To write a fault response, pass a
    Fault instance instead.  You may prefer to use the "dumps" module
    function for this purpose.
    allow_nonedispatch__dump<fault>
</fault>
<params>
<param>
</param>
</params>
cannot marshal %s objects_arbitrary_instancedump_nilcannot marshal None unless allow_none is enabled<value><nil/></value>dump_bool<value><boolean></boolean></value>
dump_longint exceeds XML-RPC limits<value><int></int></value>
dump_intdump_double<value><double></double></value>
dump_unicode<value><string></string></value>
dump_bytesdump_arraycannot marshal recursive sequences<value><array><data>
</data></array></value>
dump_structcannot marshal recursive dictionaries<value><struct>
<member>
dictionary key must be string<name>%s</name>
</member>
</struct></value>
dump_datetimedump_instanceUnmarshallerUnmarshal an XML-RPC response, based on incoming XML event
    messages (start, data, end).  Call close() to get the resulting
    data structure.

    Note that this reader is fairly tolerant, and gladly accepts bogus
    XML-RPC data without complaining (but not bogus XML).
    use_datetimeuse_builtin_types_type_stack_marks_data_value_methodname_use_datetime_use_bytesfaultgetmethodnamestandaloneunknown tag %rend_dispatchend_nilnilend_booleanbad boolean valueend_inti1i2i4i8bigintegerend_doubledoubleend_bigdecimalbigdecimalend_stringend_arraymarkend_structend_base64end_dateTimedateTime.iso8601end_valueend_paramsend_faultend_methodName_MultiCallMethodcall_list__call_list__nameMultiCallIteratorIterates over the results of a multicall. Exceptions are
    raised in response to xmlrpc faults.unexpected type in multicall resultMultiCallserver -> an object used to boxcar method calls

    server should be a ServerProxy object.

    Methods can be added to the MultiCall using normal
    method call syntax e.g.:

    multicall = MultiCall(server_proxy)
    multicall.add(2,3)
    multicall.get_address("Guido")

    To execute the multicall, call the MultiCall object e.g.:

    add_result, address = multicall()
    __server<%s at %#x>marshalled_listmulticallFastMarshallerFastParserFastUnmarshallergetparsergetparser() -> parser, unmarshaller

    Create an instance of the fastest available parser, and attach it
    to an unmarshalling object.  Return both objects.
    mkdatetimemkbytesmethodnamemethodresponsedata [,options] -> marshalled data

    Convert an argument tuple or a Fault instance to an XML-RPC
    request (or response, if the methodresponse option is used).

    In addition to the data object, the following options can be given
    as keyword arguments:

        methodname: the method name for a methodCall packet

        methodresponse: true to create a methodResponse packet.
        If this option is used with a tuple, the tuple must be
        a singleton (i.e. it can contain only one element).

        encoding: the packet encoding (default is UTF-8)

    All byte strings in the data structure are assumed to use the
    packet encoding.  Unicode strings are automatically converted,
    where necessary.
    argument must be tuple or Fault instanceresponse tuple must be a singleton<?xml version='1.0' encoding='%s'?>
xmlheader<?xml version='1.0'?>
<methodCall>
<methodName>"<methodCall>\n""<methodName>"</methodName>
</methodCall>
<methodResponse>
</methodResponse>
data -> unmarshalled data, method name

    Convert an XML-RPC packet to unmarshalled data plus a method
    name (None if not present).

    If the XML-RPC packet represents a fault condition, this function
    raises a Fault exception.
    gzip_encodedata -> gzip encoded data

    Encode data using the gzip content encoding as described in RFC 1952
    GzipFilegzfgzip_decode20971520max_decodegzip encoded data -> unencoded data

    Decode data using the gzip content encoding as described in RFC 1952
    invalid datamax gzipped payload length exceededGzipDecodedResponsea file-like object to decode a response encoded with the gzip
    method, as described in RFC 1952.
    response_Method__sendTransportHandles an HTTP transaction to an XML-RPC server.Python-xmlrpc/%suser_agentaccept_gzip_encodingencode_threshold_use_builtin_types_connection_headers_extra_headersrequestrequest_bodysingle_requestclientRemoteDisconnectedECONNRESETECONNABORTEDEPIPEsend_requesthttp_conngetresponserespparse_responsegetheadercontent-lengthgetheadersget_host_infox509_splituserauthunquote_to_bytesAuthorizationBasic extra_headersmake_connectionchostHTTPConnectionconnectionset_debuglevelputrequestskip_accept_encodingAccept-EncodingContent-Typetext/xmlUser-Agentsend_headerssend_contentputheaderContent-EncodingContent-Lengthendheadersbody:SafeTransportHandles an HTTPS transaction to an XML-RPC server.HTTPSConnectionyour version of http.client doesn't support HTTPSServerProxyuri [,options] -> a logical connection to an XML-RPC server

    uri is the connection point on the server, given as
    scheme://host/target.

    The standard implementation always supports the "http" scheme.  If
    SSL socket support is available (Python 2.0), it also supports
    "https".

    If the target part and the slash preceding it are both omitted,
    "/RPC2" is assumed.

    The following options can be given as keyword arguments:

        transport: a transport factory
        encoding: the request encoding (default is UTF-8)

    All 8-bit strings passed to the server proxy are assumed to use
    the given encoding.
    uriurlsplitschemehttpsunsupported XML-RPC protocolnetloc__hosturlunsplit__handler/RPC2extra_kwargs__transport__encoding__verbose__allow_none__close__request<%s for %s%s>A workaround to get special attributes on the ServerProxy
           without interfering with the magic __getattr__
        Attribute %r not foundhttp://localhost:8000currentTimegetCurrentTimemultigetData# XML-RPC CLIENT LIBRARY# $Id$# an XML-RPC client interface for Python.# the marshalling and response parser code can also be used to# implement XML-RPC servers.# Notes:# this version is designed to work with Python 2.1 or newer.# History:# 1999-01-14 fl  Created# 1999-01-15 fl  Changed dateTime to use localtime# 1999-01-16 fl  Added Binary/base64 element, default to RPC2 service# 1999-01-19 fl  Fixed array data element (from Skip Montanaro)# 1999-01-21 fl  Fixed dateTime constructor, etc.# 1999-02-02 fl  Added fault handling, handle empty sequences, etc.# 1999-02-10 fl  Fixed problem with empty responses (from Skip Montanaro)# 1999-06-20 fl  Speed improvements, pluggable parsers/transports (0.9.8)# 2000-11-28 fl  Changed boolean to check the truth value of its argument# 2001-02-24 fl  Added encoding/Unicode/SafeTransport patches# 2001-02-26 fl  Added compare support to wrappers (0.9.9/1.0b1)# 2001-03-28 fl  Make sure response tuple is a singleton# 2001-03-29 fl  Don't require empty params element (from Nicholas Riley)# 2001-06-10 fl  Folded in _xmlrpclib accelerator support (1.0b2)# 2001-08-20 fl  Base xmlrpclib.Error on built-in Exception (from Paul Prescod)# 2001-09-03 fl  Allow Transport subclass to override getparser# 2001-09-10 fl  Lazy import of urllib, cgi, xmllib (20x import speedup)# 2001-10-01 fl  Remove containers from memo cache when done with them# 2001-10-01 fl  Use faster escape method (80% dumps speedup)# 2001-10-02 fl  More dumps microtuning# 2001-10-04 fl  Make sure import expat gets a parser (from Guido van Rossum)# 2001-10-10 sm  Allow long ints to be passed as ints if they don't overflow# 2001-10-17 sm  Test for int and long overflow (allows use on 64-bit systems)# 2001-11-12 fl  Use repr() to marshal doubles (from Paul Felix)# 2002-03-17 fl  Avoid buffered read when possible (from James Rucker)# 2002-04-07 fl  Added pythondoc comments# 2002-04-16 fl  Added __str__ methods to datetime/binary wrappers# 2002-05-15 fl  Added error constants (from Andrew Kuchling)# 2002-06-27 fl  Merged with Python CVS version# 2002-10-22 fl  Added basic authentication (based on code from Phillip Eby)# 2003-01-22 sm  Add support for the bool type# 2003-02-27 gvr Remove apply calls# 2003-04-24 sm  Use cStringIO if available# 2003-04-25 ak  Add support for nil# 2003-06-15 gn  Add support for time.struct_time# 2003-07-12 gp  Correct marshalling of Faults# 2003-10-31 mvl Add multicall support# 2004-08-20 mvl Bump minimum supported Python version to 2.1# 2014-12-02 ch/doko  Add workaround for gzip bomb vulnerability# Copyright (c) 1999-2002 by Secret Labs AB.# Copyright (c) 1999-2002 by Fredrik Lundh.# info@pythonware.com# http://www.pythonware.com# The XML-RPC client interface is# Copyright (c) 1999-2002 by Secret Labs AB# Copyright (c) 1999-2002 by Fredrik Lundh# By obtaining, using, and/or copying this software and/or its# associated documentation, you agree that you have read, understood,# and will comply with the following terms and conditions:# Permission to use, copy, modify, and distribute this software and# its associated documentation for any purpose and without fee is# hereby granted, provided that the above copyright notice appears in# all copies, and that both that copyright notice and this permission# notice appear in supporting documentation, and that the name of# Secret Labs AB or the author not be used in advertising or publicity# pertaining to distribution of the software without specific, written# prior permission.# SECRET LABS AB AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD# TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANT-# ABILITY AND FITNESS.  IN NO EVENT SHALL SECRET LABS AB OR THE AUTHOR# BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY# DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,# WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE# OF THIS SOFTWARE.#python can be built without zlib/gzip support# Internal stuff# used in User-Agent header sent# xmlrpc integer limits# Error constants (from Dan Libby's specification at# http://xmlrpc-epi.sourceforge.net/specs/rfc.fault_codes.php)# Ranges of errors# Specific errors### Base class for all kinds of client-side errors.# Indicates an HTTP-level protocol error.  This is raised by the HTTP# transport layer, if the server returns an error code other than 200# (OK).# @param url The target URL.# @param errcode The HTTP error code.# @param errmsg The HTTP error message.# @param headers The HTTP header dictionary.# Indicates a broken XML-RPC response package.  This exception is# raised by the unmarshalling layer, if the XML-RPC response is# malformed.# Indicates an XML-RPC fault response package.  This exception is# raised by the unmarshalling layer, if the XML-RPC response contains# a fault string.  This exception can also be used as a class, to# generate a fault XML-RPC message.# @param faultCode The XML-RPC fault code.# @param faultString The XML-RPC fault string.# Special values# Backwards compatibility# Wrapper for XML-RPC DateTime values.  This converts a time value to# the format used by XML-RPC.# <p># The value can be given as a datetime object, as a string in the# format "yyyymmddThh:mm:ss", as a 9-item time tuple (as returned by# time.localtime()), or an integer value (as returned by time.time()).# The wrapper uses time.localtime() to convert an integer to a time# tuple.# @param value The time, given as a datetime object, an ISO 8601 string,#              a time tuple, or an integer time value.# Issue #13305: different format codes across platforms# Mac OS X# Linux# Get date/time value.# @return Date/time value, as an ISO 8601 string.# decode xml element contents into a DateTime structure.# Wrapper for binary data.  This can be used to transport any kind# of binary data over XML-RPC, using BASE64 encoding.# @param data An 8-bit string containing arbitrary data.# Make a copy of the bytes!# Get buffer contents.# @return Buffer contents, as an 8-bit string.# XXX encoding?!# decode xml element contents into a Binary structure# XML parsers# fast expat parser for Python 2.0 and later.# get rid of circular references# end of data# XML-RPC marshalling and unmarshalling code# XML-RPC marshaller.# @param encoding Default encoding for 8-bit strings.  The default#     value is None (interpreted as UTF-8).# @see dumps# by the way, if you don't understand what's going on in here,# that's perfectly ok.# fault instance# parameter block# FIXME: the xml-rpc specification allows us to leave out# the entire <params> block if there are no parameters.# however, changing this may break older code (including# old versions of xmlrpclib.py), so this is better left as# is for now.  See @XMLRPC3 for more information. /F# check if this object can be marshalled as a structure# check if this class is a sub-class of a basic type,# because we don't know how to marshal these types# (e.g. a string sub-class)# XXX(twouters): using "_arbitrary_instance" as key as a quick-fix# for the p3yk merge, this should probably be fixed more neatly.# backward compatible# check for special wrappers# store instance attributes as a struct (really?)# XML-RPC unmarshaller.# @see loads# and again, if you don't understand what's going on in here,# return response tuple and target method# event handlers# FIXME: assert standalone == 1 ???# prepare to handle this element# call the appropriate end tag handler# unknown tag ?# accelerator support# dispatch data# element decoders# struct keys are always strings# map arrays to Python lists# map structs to Python dictionaries# if we stumble upon a value element with no internal# elements, treat it as a string element# no params## Multicall support# some lesser magic to store calls made to a MultiCall object# for batch execution# convenience functions# Create a parser object, and connect it to an unmarshalling instance.# This function picks the fastest available XML parser.# return A (parser, unmarshaller) tuple.# Convert a Python tuple or a Fault instance to an XML-RPC packet.# @def dumps(params, **options)# @param params A tuple or Fault instance.# @keyparam methodname If given, create a methodCall request for#     this method name.# @keyparam methodresponse If given, create a methodResponse packet.#     If used with a tuple, the tuple must be a singleton (that is,#     it must contain exactly one element).# @keyparam encoding The packet encoding.# @return A string containing marshalled data.# utf-8 is default# standard XML-RPC wrappings# a method call# a method response, or a fault structure# return as is# Convert an XML-RPC packet to a Python object.  If the XML-RPC packet# represents a fault condition, this function raises a Fault exception.# @param data An XML-RPC packet, given as an 8-bit string.# @return A tuple containing the unpacked data, and the method name#     (None if not present).# @see Fault# Encode a string using the gzip content encoding such as specified by the# Content-Encoding: gzip# in the HTTP header, as described in RFC 1952# @param data the unencoded data# @return the encoded data# Decode a string using the gzip content encoding such as specified by the# @param data The encoded data# @keyparam max_decode Maximum bytes to decode (20 MiB default), use negative#    values for unlimited decoding# @return the unencoded data# @raises ValueError if data is not correctly coded.# @raises ValueError if max gzipped payload length exceeded# no limit# Return a decoded file-like object for the gzip encoding# as described in RFC 1952.# @param response A stream supporting a read() method# @return a file-like object that the decoded data can be read() from#response doesn't support tell() and read(), required by#GzipFile# request dispatcher# some magic to bind an XML-RPC method to an RPC server.# supports "nested" methods (e.g. examples.getStateName)# Standard transport class for XML-RPC over HTTP.# You can create custom transports by subclassing this method, and# overriding selected methods.# client identifier (may be overridden)#if true, we'll request gzip encoding# if positive, encode request using gzip if it exceeds this threshold# note that many servers will get confused, so only use it if you know# that they can decode such a request#None = don't encode# Send a complete request, and parse the response.# Retry request if a cached connection has disconnected.# @param host Target host.# @param handler Target PRC handler.# @param request_body XML-RPC request body.# @param verbose Debugging flag.# @return Parsed response.#retry request once if cached connection has gone cold# issue XML-RPC request#All unexpected errors leave connection in# a strange state, so we clear it.#We got an error response.#Discard any response data and raise exception# Create parser.# @return A 2-tuple containing a parser and an unmarshaller.# get parser and unmarshaller# Get authorization info from host parameter# Host may be a string, or a (host, x509-dict) tuple; if a string,# it is checked for a "user:pw@host" format, and a "Basic# Authentication" header is added if appropriate.# @param host Host descriptor (URL or (URL, x509 info) tuple).# @return A 3-tuple containing (actual host, extra headers,#     x509 info).  The header and x509 fields may be None.# get rid of whitespace# Connect to server.# @return An HTTPConnection object#return an existing connection if possible.  This allows#HTTP/1.1 keep-alive.# create a HTTP connection object from a host descriptor# Clear any cached connection object.# Used in the event of socket errors.# Send HTTP request.# @param handler Target RPC handler (a path relative to host)# @param request_body The XML-RPC request body# @param debug Enable debugging if debug is true.# @return An HTTPConnection.# Send request headers.# This function provides a useful hook for subclassing# @param connection httpConnection.# @param headers list of key,value pairs for HTTP headers# Send request body.#optionally encode the request# Parse response.# @param file Stream.# @return Response tuple and target method.# read response data from httpresponse, and parse it# Check for new http response object, otherwise it is a file object.# Standard transport class for XML-RPC over HTTPS.# FIXME: mostly untested# create a HTTPS connection object from a host descriptor# host may be a string, or a (host, x509-dict) tuple# Standard server proxy.  This class establishes a virtual connection# to an XML-RPC server.# This class is available as ServerProxy and Server.  New code should# use ServerProxy, to avoid confusion.# @def ServerProxy(uri, **options)# @param uri The connection point on the server.# @keyparam transport A transport factory, compatible with the#    standard transport class.# @keyparam encoding The default encoding used for 8-bit strings#    (default is UTF-8).# @keyparam verbose Use a true value to enable debugging output.#    (printed to standard output).# @see Transport# establish a "logical" server connection# get the url# call a method on the remote server# magic method dispatcher# note: to call a remote object with a non-standard name, use# result getattr(server, "strange-python-name")(args)# compatibility# test code# simple test program (from the XML-RPC specification)# local server, available from Lib/xmlrpc/server.pyb'
An XML-RPC client interface for Python.

The marshalling and response parser code can also be used to
implement XML-RPC servers.

Exported exceptions:

  Error          Base class for client errors
  ProtocolError  Indicates an HTTP protocol error
  ResponseError  Indicates a broken response package
  Fault          Indicates an XML-RPC fault package

Exported classes:

  ServerProxy    Represents a logical connection to an XML-RPC server

  MultiCall      Executor of boxcared xmlrpc requests
  DateTime       dateTime wrapper for an ISO 8601 string or time tuple or
                 localtime integer value to generate a "dateTime.iso8601"
                 XML-RPC value
  Binary         binary data wrapper

  Marshaller     Generate an XML-RPC params chunk from a Python data structure
  Unmarshaller   Unmarshal an XML-RPC response from incoming XML event message
  Transport      Handles an HTTP transaction to an XML-RPC server
  SafeTransport  Handles an HTTPS transaction to an XML-RPC server

Exported constants:

  (none)

Exported functions:

  getparser      Create instance of the fastest available parser & attach
                 to an unmarshalling object
  dumps          Convert an argument tuple or a Fault instance to an XML-RPC
                 request (or response, if the methodresponse option is used).
  loads          Convert an XML-RPC packet to unmarshalled data plus a method
                 name (None if not present).
'u'
An XML-RPC client interface for Python.

The marshalling and response parser code can also be used to
implement XML-RPC servers.

Exported exceptions:

  Error          Base class for client errors
  ProtocolError  Indicates an HTTP protocol error
  ResponseError  Indicates a broken response package
  Fault          Indicates an XML-RPC fault package

Exported classes:

  ServerProxy    Represents a logical connection to an XML-RPC server

  MultiCall      Executor of boxcared xmlrpc requests
  DateTime       dateTime wrapper for an ISO 8601 string or time tuple or
                 localtime integer value to generate a "dateTime.iso8601"
                 XML-RPC value
  Binary         binary data wrapper

  Marshaller     Generate an XML-RPC params chunk from a Python data structure
  Unmarshaller   Unmarshal an XML-RPC response from incoming XML event message
  Transport      Handles an HTTP transaction to an XML-RPC server
  SafeTransport  Handles an HTTPS transaction to an XML-RPC server

Exported constants:

  (none)

Exported functions:

  getparser      Create instance of the fastest available parser & attach
                 to an unmarshalling object
  dumps          Convert an argument tuple or a Fault instance to an XML-RPC
                 request (or response, if the methodresponse option is used).
  loads          Convert an XML-RPC packet to unmarshalled data plus a method
                 name (None if not present).
'b'Base class for client errors.'u'Base class for client errors.'b'Indicates an HTTP protocol error.'u'Indicates an HTTP protocol error.'b'<%s for %s: %s %s>'u'<%s for %s: %s %s>'b'Indicates a broken response package.'u'Indicates a broken response package.'b'Indicates an XML-RPC fault package.'u'Indicates an XML-RPC fault package.'b'<%s %s: %r>'u'<%s %s: %r>'b'0001'u'0001'b'%Y'u'%Y'b'%Y%m%dT%H:%M:%S'u'%Y%m%dT%H:%M:%S'b'%4Y'u'%4Y'b'%4Y%m%dT%H:%M:%S'u'%4Y%m%dT%H:%M:%S'b'%04d%02d%02dT%02d:%02d:%02d'u'%04d%02d%02dT%02d:%02d:%02d'b'DateTime wrapper for an ISO 8601 string or time tuple or
    localtime integer value to generate 'dateTime.iso8601' XML-RPC
    value.
    'u'DateTime wrapper for an ISO 8601 string or time tuple or
    localtime integer value to generate 'dateTime.iso8601' XML-RPC
    value.
    'b'timetuple'u'timetuple'b'<%s %r at %#x>'u'<%s %r at %#x>'b'<value><dateTime.iso8601>'u'<value><dateTime.iso8601>'b'</dateTime.iso8601></value>
'u'</dateTime.iso8601></value>
'b'Wrapper for binary data.'u'Wrapper for binary data.'b'expected bytes or bytearray, not %s'u'expected bytes or bytearray, not %s'b'<value><base64>
'u'<value><base64>
'b'</base64></value>
'u'</base64></value>
'b'Generate an XML-RPC params chunk from a Python data structure.

    Create a Marshaller instance for each set of parameters, and use
    the "dumps" method to convert your data (represented as a tuple)
    to an XML-RPC params chunk.  To write a fault response, pass a
    Fault instance instead.  You may prefer to use the "dumps" module
    function for this purpose.
    'u'Generate an XML-RPC params chunk from a Python data structure.

    Create a Marshaller instance for each set of parameters, and use
    the "dumps" method to convert your data (represented as a tuple)
    to an XML-RPC params chunk.  To write a fault response, pass a
    Fault instance instead.  You may prefer to use the "dumps" module
    function for this purpose.
    'b'<fault>
'u'<fault>
'b'faultCode'u'faultCode'b'faultString'u'faultString'b'</fault>
'u'</fault>
'b'<params>
'u'<params>
'b'<param>
'u'<param>
'b'</param>
'u'</param>
'b'</params>
'u'</params>
'b'cannot marshal %s objects'u'cannot marshal %s objects'b'_arbitrary_instance'u'_arbitrary_instance'b'cannot marshal None unless allow_none is enabled'u'cannot marshal None unless allow_none is enabled'b'<value><nil/></value>'u'<value><nil/></value>'b'<value><boolean>'u'<value><boolean>'b'</boolean></value>
'u'</boolean></value>
'b'int exceeds XML-RPC limits'u'int exceeds XML-RPC limits'b'<value><int>'u'<value><int>'b'</int></value>
'u'</int></value>
'b'<value><double>'u'<value><double>'b'</double></value>
'u'</double></value>
'b'<value><string>'u'<value><string>'b'</string></value>
'u'</string></value>
'b'cannot marshal recursive sequences'u'cannot marshal recursive sequences'b'<value><array><data>
'u'<value><array><data>
'b'</data></array></value>
'u'</data></array></value>
'b'cannot marshal recursive dictionaries'u'cannot marshal recursive dictionaries'b'<value><struct>
'u'<value><struct>
'b'<member>
'u'<member>
'b'dictionary key must be string'u'dictionary key must be string'b'<name>%s</name>
'u'<name>%s</name>
'b'</member>
'u'</member>
'b'</struct></value>
'u'</struct></value>
'b'Unmarshal an XML-RPC response, based on incoming XML event
    messages (start, data, end).  Call close() to get the resulting
    data structure.

    Note that this reader is fairly tolerant, and gladly accepts bogus
    XML-RPC data without complaining (but not bogus XML).
    'u'Unmarshal an XML-RPC response, based on incoming XML event
    messages (start, data, end).  Call close() to get the resulting
    data structure.

    Note that this reader is fairly tolerant, and gladly accepts bogus
    XML-RPC data without complaining (but not bogus XML).
    'b'fault'u'fault'b'array'b'struct'b'unknown tag %r'u'unknown tag %r'b'nil'u'nil'b'bad boolean value'u'bad boolean value'b'boolean'u'boolean'b'i1'u'i1'b'i2'u'i2'b'i4'u'i4'b'i8'u'i8'b'biginteger'u'biginteger'b'double'u'double'b'float'u'float'b'bigdecimal'u'bigdecimal'b'string'u'string'b'dateTime.iso8601'u'dateTime.iso8601'b'params'u'params'b'methodName'u'methodName'b'Iterates over the results of a multicall. Exceptions are
    raised in response to xmlrpc faults.'u'Iterates over the results of a multicall. Exceptions are
    raised in response to xmlrpc faults.'b'unexpected type in multicall result'u'unexpected type in multicall result'b'server -> an object used to boxcar method calls

    server should be a ServerProxy object.

    Methods can be added to the MultiCall using normal
    method call syntax e.g.:

    multicall = MultiCall(server_proxy)
    multicall.add(2,3)
    multicall.get_address("Guido")

    To execute the multicall, call the MultiCall object e.g.:

    add_result, address = multicall()
    'u'server -> an object used to boxcar method calls

    server should be a ServerProxy object.

    Methods can be added to the MultiCall using normal
    method call syntax e.g.:

    multicall = MultiCall(server_proxy)
    multicall.add(2,3)
    multicall.get_address("Guido")

    To execute the multicall, call the MultiCall object e.g.:

    add_result, address = multicall()
    'b'<%s at %#x>'u'<%s at %#x>'b'getparser() -> parser, unmarshaller

    Create an instance of the fastest available parser, and attach it
    to an unmarshalling object.  Return both objects.
    'u'getparser() -> parser, unmarshaller

    Create an instance of the fastest available parser, and attach it
    to an unmarshalling object.  Return both objects.
    'b'data [,options] -> marshalled data

    Convert an argument tuple or a Fault instance to an XML-RPC
    request (or response, if the methodresponse option is used).

    In addition to the data object, the following options can be given
    as keyword arguments:

        methodname: the method name for a methodCall packet

        methodresponse: true to create a methodResponse packet.
        If this option is used with a tuple, the tuple must be
        a singleton (i.e. it can contain only one element).

        encoding: the packet encoding (default is UTF-8)

    All byte strings in the data structure are assumed to use the
    packet encoding.  Unicode strings are automatically converted,
    where necessary.
    'u'data [,options] -> marshalled data

    Convert an argument tuple or a Fault instance to an XML-RPC
    request (or response, if the methodresponse option is used).

    In addition to the data object, the following options can be given
    as keyword arguments:

        methodname: the method name for a methodCall packet

        methodresponse: true to create a methodResponse packet.
        If this option is used with a tuple, the tuple must be
        a singleton (i.e. it can contain only one element).

        encoding: the packet encoding (default is UTF-8)

    All byte strings in the data structure are assumed to use the
    packet encoding.  Unicode strings are automatically converted,
    where necessary.
    'b'argument must be tuple or Fault instance'u'argument must be tuple or Fault instance'b'response tuple must be a singleton'u'response tuple must be a singleton'b'<?xml version='1.0' encoding='%s'?>
'u'<?xml version='1.0' encoding='%s'?>
'b'<?xml version='1.0'?>
'u'<?xml version='1.0'?>
'b'<methodCall>
<methodName>'u'<methodCall>
<methodName>'b'</methodName>
'u'</methodName>
'b'</methodCall>
'u'</methodCall>
'b'<methodResponse>
'u'<methodResponse>
'b'</methodResponse>
'u'</methodResponse>
'b'data -> unmarshalled data, method name

    Convert an XML-RPC packet to unmarshalled data plus a method
    name (None if not present).

    If the XML-RPC packet represents a fault condition, this function
    raises a Fault exception.
    'u'data -> unmarshalled data, method name

    Convert an XML-RPC packet to unmarshalled data plus a method
    name (None if not present).

    If the XML-RPC packet represents a fault condition, this function
    raises a Fault exception.
    'b'data -> gzip encoded data

    Encode data using the gzip content encoding as described in RFC 1952
    'u'data -> gzip encoded data

    Encode data using the gzip content encoding as described in RFC 1952
    'b'gzip encoded data -> unencoded data

    Decode data using the gzip content encoding as described in RFC 1952
    'u'gzip encoded data -> unencoded data

    Decode data using the gzip content encoding as described in RFC 1952
    'b'invalid data'u'invalid data'b'max gzipped payload length exceeded'u'max gzipped payload length exceeded'b'a file-like object to decode a response encoded with the gzip
    method, as described in RFC 1952.
    'u'a file-like object to decode a response encoded with the gzip
    method, as described in RFC 1952.
    'b'Handles an HTTP transaction to an XML-RPC server.'u'Handles an HTTP transaction to an XML-RPC server.'b'Python-xmlrpc/%s'u'Python-xmlrpc/%s'b'content-length'u'content-length'b'Authorization'u'Authorization'b'Basic 'u'Basic 'b'Accept-Encoding'u'Accept-Encoding'b'gzip'u'gzip'b'Content-Type'u'Content-Type'b'text/xml'u'text/xml'b'User-Agent'u'User-Agent'b'Content-Encoding'u'Content-Encoding'b'Content-Length'u'Content-Length'b'getheader'u'getheader'b'body:'u'body:'b'Handles an HTTPS transaction to an XML-RPC server.'u'Handles an HTTPS transaction to an XML-RPC server.'b'HTTPSConnection'u'HTTPSConnection'b'your version of http.client doesn't support HTTPS'u'your version of http.client doesn't support HTTPS'b'uri [,options] -> a logical connection to an XML-RPC server

    uri is the connection point on the server, given as
    scheme://host/target.

    The standard implementation always supports the "http" scheme.  If
    SSL socket support is available (Python 2.0), it also supports
    "https".

    If the target part and the slash preceding it are both omitted,
    "/RPC2" is assumed.

    The following options can be given as keyword arguments:

        transport: a transport factory
        encoding: the request encoding (default is UTF-8)

    All 8-bit strings passed to the server proxy are assumed to use
    the given encoding.
    'u'uri [,options] -> a logical connection to an XML-RPC server

    uri is the connection point on the server, given as
    scheme://host/target.

    The standard implementation always supports the "http" scheme.  If
    SSL socket support is available (Python 2.0), it also supports
    "https".

    If the target part and the slash preceding it are both omitted,
    "/RPC2" is assumed.

    The following options can be given as keyword arguments:

        transport: a transport factory
        encoding: the request encoding (default is UTF-8)

    All 8-bit strings passed to the server proxy are assumed to use
    the given encoding.
    'b'http'b'https'u'https'b'unsupported XML-RPC protocol'u'unsupported XML-RPC protocol'b'/RPC2'u'/RPC2'b'<%s for %s%s>'u'<%s for %s%s>'b'A workaround to get special attributes on the ServerProxy
           without interfering with the magic __getattr__
        'u'A workaround to get special attributes on the ServerProxy
           without interfering with the magic __getattr__
        'b'transport'u'transport'b'Attribute %r not found'u'Attribute %r not found'b'http://localhost:8000'u'http://localhost:8000'u'Lib.xmlrpc.client'u'client'HTTP/1.1 client library

<intro stuff goes here>
<other stuff, too>

HTTPConnection goes through a number of "states", which define when a client
may legally make another request or fetch the response for a particular
request. This diagram details these state transitions:

    (null)
      |
      | HTTPConnection()
      v
    Idle
      |
      | putrequest()
      v
    Request-started
      |
      | ( putheader() )*  endheaders()
      v
    Request-sent
      |\_____________________________
      |                              | getresponse() raises
      | response = getresponse()     | ConnectionError
      v                              v
    Unread-response                Idle
    [Response-headers-read]
      |\____________________
      |                     |
      | response.read()     | putrequest()
      v                     v
    Idle                  Req-started-unread-response
                     ______/|
                   /        |
   response.read() |        | ( putheader() )*  endheaders()
                   v        v
       Request-started    Req-sent-unread-response
                            |
                            | response.read()
                            v
                          Request-sent

This diagram presents the following rules:
  -- a second request may not be started until {response-headers-read}
  -- a response [object] cannot be retrieved until {request-sent}
  -- there is no differentiation between an unread response body and a
     partially read response body

Note: this enforcement is applied by the HTTPConnection class. The
      HTTPResponse class does not enforce this state machine, which
      implies sophisticated clients may accelerate the request/response
      pipeline. Caution should be taken, though: accelerating the states
      beyond the above pattern may imply knowledge of the server's
      connection-close behavior for certain requests. For example, it
      is impossible to tell whether the server will close the connection
      UNTIL the response headers have been read; this means that further
      requests cannot be placed into the pipeline until it is known that
      the server will NOT be closing the connection.

Logical State                  __state            __response
-------------                  -------            ----------
Idle                           _CS_IDLE           None
Request-started                _CS_REQ_STARTED    None
Request-sent                   _CS_REQ_SENT       None
Unread-response                _CS_IDLE           <response_class>
Req-started-unread-response    _CS_REQ_STARTED    <response_class>
Req-sent-unread-response       _CS_REQ_SENT       <response_class>
email.messageHTTPResponseHTTPExceptionNotConnectedUnknownProtocolUnknownTransferEncodingUnimplementedFileModeIncompleteReadInvalidURLImproperConnectionStateCannotSendRequestCannotSendHeaderResponseNotReadyBadStatusLineLineTooLongresponsesHTTP_PORT443HTTPS_PORTUNKNOWN_UNKNOWNIdle_CS_IDLERequest-started_CS_REQ_STARTEDRequest-sent_CS_REQ_SENT__members___MAXLINE_MAXHEADERS[^:\s][^:\r\n]*rb'_is_legal_header_name\n(?![ \t])|\r(?![ \t\n])_is_illegal_header_value[ - ]_contains_disallowed_url_pchar_re[ -]_contains_disallowed_method_pchar_re_METHODS_EXPECTING_BODYCall data.encode("latin-1") but show a better error message.%s (%.20r) is not valid Latin-1. Use %s.encode('utf-8') if you want to send it encoded in UTF-8."%s (%.20r) is not valid Latin-1. Use %s.encode('utf-8') ""if you want to send it encoded in UTF-8."_strip_ipv6_ifaceenc_nameRemove interface scope from IPv6 address.percentHTTPMessageMessagegetallmatchingheadersFind all header lines matching a given header name.

        Look through the list of headers and find all lines matching a given
        header name (and their continuation lines).  A list of the lines is
        returned, without interpretation.  If the header does not occur, an
        empty list is returned.  If the header occurs multiple times, all
        occurrences are returned.  Case is not important in the header name.

        lsthit_read_headersReads potential header lines into a list from a file pointer.

    Length of line is limited by _MAXLINE, and number of
    headers is limited by _MAXHEADERS.
    header linegot more than %d headers_parse_header_linesheader_lines_class
    Parses only RFC2822 headers from header lines.

    email Parser wants to see strings rather than bytes.
    But a TextIOWrapper around self.rfile would buffer too many bytes
    from the stream, bytes which we later need to read as bytes.
    So we read the correct bytes here, as bytes, for email Parser
    to parse.

    hstringparse_headersParses only RFC2822 headers from a file pointer.debuglevelmakefile_methodchunkedchunk_leftwill_close_read_statusstatus linereply:Remote end closed connection without response"Remote end closed connection without"" response"HTTP/_close_conn999beginskipped_headersheaders:HTTP/1.0HTTP/0.9HTTP/1.hdrheader:transfer-encodingtr_enc_check_closeconnkeep-aliveproxy-connectionpconnAlways returns TrueisclosedTrue if the connection is closed.amtRead and return the response body, or up to the next amt bytes._read_chunked_safe_readRead up to len(b) bytes into bytearray b and return the number
        of bytes read.
        _readinto_chunked_read_next_chunk_sizechunk size_read_and_discard_trailertrailer line_get_chunk_lefttotal_bytesmvb_safe_readintotemp_mvbRead the number of bytes requested.

        This function should be used when <amt> bytes "should" be present for
        reading. If the bytes are truly not available (due to EOF), then the
        IncompleteRead exception can be used to detect the problem.
        Same as _safe_read, but for reading into a buffer.Read with at most one underlying system call.  If at least one
        byte is buffered, return that instead.
        _read1_chunked_peek_chunkedReturns the value of the header matching *name*.

        If there are multiple matching headers, the values are
        combined into a single string separated by commas and spaces.

        If no matching header is found, returns *default* or None if
        the *default* is not specified.

        If the headers are unknown, raises http.client.ResponseNotReady.

        get_allReturn list of (header, value) tuples.Returns an instance of the class mimetools.Message containing
        meta-information associated with the URL.

        When the method is HTTP, these headers are those returned by
        the server at the head of the retrieved HTML page (including
        Content-Length and Content-Type).

        When the method is FTP, a Content-Length header will be
        present if (as is now usual) the server passed back a file
        length in response to the FTP retrieval request. A
        Content-Type header will be present if the MIME type can be
        guessed.

        When the method is local-file, returned headers will include
        a Date representing the file's last-modified time, a
        Content-Length giving file size, and a Content-Type
        containing a guess at the file's type. See also the
        description of the mimetools module.

        geturlReturn the real URL of the page.

        In some cases, the HTTP server redirects a client to another
        URL. The urlopen() function handles this transparently, but in
        some cases the caller needs to know which URL the client was
        redirected to. The geturl() method can be used to get at this
        redirected URL.

        getcodeReturn the HTTP status code that was sent with the response,
        or None if the URL is not an HTTP URL.

        _create_https_contexthttp_version_create_default_https_contextset_alpn_protocolshttp/1.1post_handshake_auth_http_vsnHTTP/1.1_http_vsn_strresponse_classdefault_portauto_open_is_textIOTest whether a file-like object is a text or a binary stream.
        TextIOBase_get_content_lengthGet the content-length based on the body.

        If the body is None, we set Content-Length: 0 for methods that expect
        a body (RFC 7230, Section 3.3.2). We also set the Content-Length for
        any method if the body is a str or bytes-like object and not a file.
        mv_GLOBAL_DEFAULT_TIMEOUTsource_address__response__state_tunnel_host_tunnel_port_tunnel_headers_raw_proxy_headers_get_hostport_validate_host_create_connectionset_tunnelSet up host and port for HTTP CONNECT tunnelling.

        In a connection that uses HTTP CONNECT tunnelling, the host passed to
        the constructor is used as a proxy server that relays all communication
        to the endpoint passed to `set_tunnel`. This done by sending an HTTP
        CONNECT request to the proxy server when the connection is established.

        This method must be called before the HTTP connection has been
        established.

        The headers argument should be a mapping of extra HTTP headers to send
        with the CONNECT request.

        As HTTP/1.1 is used for HTTP CONNECT tunnelling request, as per the RFC
        (https://tools.ietf.org/html/rfc7231#section-4.3.6), a HTTP Host:
        header must be provided, matching the authority-form of the request
        target provided as the destination for the CONNECT request. If a
        HTTP Host: header is not provided via the headers argument, one
        is generated and transmitted automatically.
        Can't set up tunnel for established connectionencoded_host%s:%dHostnonnumeric port: '%s'_wrap_ipv6ip_tunnelCONNECT %s:%d %s
connectTunnel connection failed: get_proxy_response_headers
        Returns a dictionary with the headers of the response
        received from the proxy server to the CONNECT request
        sent to set the tunnel.

        If the CONNECT request was not sent, the method returns None.
        Connect to the host and port specified in __init__.http.client.connectENOPROTOOPTClose the connection to the HTTP server.Send `data' to the server.
        ``data`` can be a string object, a bytes object, an array object, a
        file-like object that supports a .read() method, or an iterable object.
        send:sending a readableencoding file using iso-8859-1datablockhttp.client.sendsendalldata should be a bytes-like object or an iterable, got %r"data should be a bytes-like object ""or an iterable, got %r"_outputAdd a line of output to the current request buffer.

        Assumes that the line does *not* end with \r\n.
        _read_readablereading a readable_send_outputmessage_bodyencode_chunkedSend the currently buffered request and clear the buffer.

        Appends an extra \r\n to the buffer.
        A message_body may be specified, to be appended to the request.
        message_body should be a bytes-like object or an iterable, got %r"message_body should be a bytes-like ""object or an iterable, got %r"Zero length chunk ignored0

skip_hostSend a request to the server.

        `method' specifies an HTTP request method, e.g. 'GET'.
        `url' specifies the object being requested, e.g. '/index.html'.
        `skip_host' if True does not add automatically a 'Host:' header
        `skip_accept_encoding' if True does not add automatically an
           'Accept-Encoding:' header
        _validate_method_validate_path%s %s %s_encode_requestnetloc_enchost_enc%s:%sValidate a method name for putrequest.method can't contain control characters.  (found at least "(found at least "Validate a url for putrequest.URL can't contain control characters. Validate a host so it doesn't contain control characters.Send a request header line to the server.

        For example: h.putheader('Accept', 'text/html')
        Invalid header name %rone_valueInvalid header value %r
	Indicate that the last header line has been sent to the server.

        This method sends the request to the server.  The optional message_body
        argument can be used to pass a message body associated with the
        request.
        Send a complete request to the server._send_requestheader_namesskipsaccept-encodingcontent_lengthUnable to determine size of %rTransfer-EncodingGet the response from the server.

        If the HTTPConnection is in the correct state, returns an
        instance of HTTPResponse or of whatever object is returned by
        the response_class variable.

        If a request has not been sent or if a previous response has
        not be handled, ResponseNotReady is raised.  If the HTTP
        response indicates that the connection should be closed, then
        it will be closed before the response is returned.  When the
        connection is closed, the underlying socket is closed.
        This class allows communication via SSL._contextConnect to a host on a given (SSL) port.wrap_socket, %i more expected%s(%i bytes read%s)line_typegot more than %d bytes when reading %s# HTTPMessage, parse_headers(), and the HTTP status code constants are# intentionally omitted for simplicity# connection states# hack to maintain backwards compatibility# another hack to maintain backwards compatibility# Mapping status codes to official W3C names# maximal line length when calling readline().# Header name/value ABNF (http://tools.ietf.org/html/rfc7230#section-3.2)# VCHAR          = %x21-7E# obs-text       = %x80-FF# header-field   = field-name ":" OWS field-value OWS# field-name     = token# field-value    = *( field-content / obs-fold )# field-content  = field-vchar [ 1*( SP / HTAB ) field-vchar ]# field-vchar    = VCHAR / obs-text# obs-fold       = CRLF 1*( SP / HTAB )#                ; obsolete line folding#                ; see Section 3.2.4# token          = 1*tchar# tchar          = "!" / "#" / "$" / "%" / "&" / "'" / "*"#                / "+" / "-" / "." / "^" / "_" / "`" / "|" / "~"#                / DIGIT / ALPHA#                ; any VCHAR, except delimiters# VCHAR defined in http://tools.ietf.org/html/rfc5234#appendix-B.1# the patterns for both name and value are more lenient than RFC# definitions to allow for backwards compatibility# These characters are not allowed within HTTP URL paths.#  See https://tools.ietf.org/html/rfc3986#section-3.3 and the#  https://tools.ietf.org/html/rfc3986#appendix-A pchar definition.# Prevents CVE-2019-9740.  Includes control characters such as \r\n.# We don't restrict chars above \x7f as putrequest() limits us to ASCII.# Arguably only these _should_ allowed:#  _is_allowed_url_pchars_re = re.compile(r"^[/!$&'()*+,;=:@%a-zA-Z0-9._~-]+$")# We are more lenient for assumed real world compatibility purposes.# These characters are not allowed within HTTP method names# to prevent http header injection.# We always set the Content-Length header for these methods because some# servers will otherwise respond with a 411# XXX The only usage of this method is in# http.server.CGIHTTPRequestHandler.  Maybe move the code there so# that it doesn't need to be part of the public API.  The API has# never been defined so this could cause backwards compatibility# issues.# See RFC 2616 sec 19.6 and RFC 1945 sec 6 for details.# The bytes from the socket object are iso-8859-1 strings.# See RFC 2616 sec 2.2 which notes an exception for MIME-encoded# text following RFC 2047.  The basic status line parsing only# accepts iso-8859-1.# If the response includes a content-length header, we need to# make sure that the client doesn't read more than the# specified number of bytes.  If it does, it will block until# the server times out and closes the connection.  This will# happen if a self.fp.read() is done (without a size) whether# self.fp is buffered or not.  So, no self.fp.read() by# clients unless they know what they are doing.# The HTTPResponse object is returned via urllib.  The clients# of http and urllib expect different attributes for the# headers.  headers is used here and supports urllib.  msg is# provided as a backwards compatibility layer for http# clients.# from the Status-Line of the response# HTTP-Version# Status-Code# Reason-Phrase# is "chunked" being used?# bytes left to read in current chunk# number of bytes left in response# conn will close at end of response# Presumably, the server closed the connection before# sending a valid response.# empty version will cause next test to fail.# The status code is a three-digit number# we've already started reading the response# read until we get a non-100 response# skip the header from the 100 response# Some servers might still return "0.9", treat it as 1.0 anyway# use HTTP/1.1 code for HTTP/1.x where x>=1# are we using the chunked-style of transfer encoding?# will the connection close at the end of the response?# do we have a Content-Length?# NOTE: RFC 2616, S4.4, #3 says we ignore this if tr_enc is "chunked"# ignore nonsensical negative lengths# does the body have a fixed length? (of zero)# 1xx codes# if the connection remains open, and we aren't using chunked, and# a content-length was not provided, then assume that the connection# WILL close.# An HTTP/1.1 proxy is assumed to stay open unless# explicitly closed.# Some HTTP/1.0 implementations have support for persistent# connections, using rules different than HTTP/1.1.# For older HTTP, Keep-Alive indicates persistent connection.# At least Akamai returns a "Connection: Keep-Alive" header,# which was supposed to be sent by the client.# Proxy-Connection is a netscape hack.# otherwise, assume it will close# set "closed" flag# These implementations are for the benefit of io.BufferedReader.# XXX This class should probably be revised to act more like# the "raw stream" that BufferedReader expects.# End of "raw stream" methods# NOTE: it is possible that we will not ever call self.close(). This#       case occurs when will_close is TRUE, length is None, and we#       read up to the last byte, but NOT past it.# IMPLIES: if will_close is FALSE, then self.close() will ALWAYS be#          called, meaning self.isclosed() is meaningful.# clip the read to the "end of response"# Ideally, we would raise IncompleteRead if the content-length# wasn't satisfied, but it might break compatibility.# Amount is not given (unbounded read) so we must check self.length# we read everything# we do not use _safe_read() here because this may be a .will_close# connection, and the user is reading more bytes than will be provided# (for example, reading in 1k chunks)# Read the next chunk size from the file# strip chunk-extensions# close the connection as protocol synchronisation is# probably lost# read and discard trailer up to the CRLF terminator### note: we shouldn't have any trailers!# a vanishingly small number of sites EOF without# sending the trailer# return self.chunk_left, reading a new chunk if necessary.# chunk_left == 0: at the end of the current chunk, need to close it# chunk_left == None: No current chunk, should read next.# This function returns non-zero or None if the last chunk has# been read.# Can be 0 or None# We are at the end of chunk, discard chunk end# toss the CRLF at the end of the chunk# last chunk: 1*("0") [ chunk-extension ] CRLF# we read everything; close the "file"# Having this enables IOBase.readline() to read more than one# byte at a time# Fallback to IOBase readline which uses peek() and read()# Strictly speaking, _get_chunk_left() may cause more than one read,# but that is ok, since that is to satisfy the chunked protocol.# if n is negative or larger than chunk_left# peek doesn't worry about protocol# eof# peek is allowed to return more than requested.  Just request the# entire chunk, and truncate what we get.# We override IOBase.__iter__ so that it doesn't check for closed-ness# For compatibility with old-style urllib responses.# Function also used by urllib.request to be able to set the check_hostname# attribute on a context object.# send ALPN extension to indicate HTTP/1.1 protocol# enable PHA for TLS 1.3 connections if available# do an explicit check for not None here to distinguish# between unset and set but empty# file-like object.# does it implement the buffer protocol (bytes, bytearray, array)?# This is stored as an instance variable to allow unit# tests to replace it with a suitable mockup# ipv6 addresses have [...]# http://foo.com:/ == http://foo.com/# Making a single send() call instead of one per line encourages# the host OS to use a more optimal packet size instead of# potentially emitting a series of small packets.# Might fail in OSs that don't implement TCP_NODELAY# close it manually... there may be other refs# create a consistent interface to message_body# Let file-like take precedence over byte-like.  This# is needed to allow the current position of mmap'ed# files to be taken into account.# this is solely to check to see if message_body# implements the buffer API.  it /would/ be easier# to capture if PyObject_CheckBuffer was exposed# to Python.# the object implements the buffer interface and# can be passed directly into socket methods# chunked encoding# end chunked transfer# if a prior response has been completed, then forget about it.# in certain cases, we cannot issue another request on this connection.# this occurs when:#   1) we are in the process of sending a request.   (_CS_REQ_STARTED)#   2) a response to a previous request has signalled that it is going#      to close the connection upon completion.#   3) the headers for the previous response have not been read, thus#      we cannot determine whether point (2) is true.   (_CS_REQ_SENT)# if there is no prior response, then we can request at will.# if point (2) is true, then we will have passed the socket to the# response (effectively meaning, "there is no prior response"), and# will open a new one when a new request is made.# Note: if a prior response exists, then we *can* start a new request.#       We are not allowed to begin fetching the response to this new#       request, however, until that prior response is complete.# Save the method for use later in the response phase# Issue some standard headers for better HTTP/1.1 compliance# this header is issued *only* for HTTP/1.1# connections. more specifically, this means it is# only issued when the client uses the new# HTTPConnection() class. backwards-compat clients# will be using HTTP/1.0 and those clients may be# issuing this header themselves. we should NOT issue# it twice; some web servers (such as Apache) barf# when they see two Host: headers# If we need a non-standard port,include it in the# header.  If the request is going through a proxy,# but the host of the actual URL, not the host of the# proxy.# As per RFC 273, IPv6 address should be wrapped with []# when used as Host header# note: we are assuming that clients will not attempt to set these#       headers since *this* library must deal with the#       consequences. this also means that when the supporting#       libraries are updated to recognize other forms, then this#       code should be changed (removed or updated).# we only want a Content-Encoding of "identity" since we don't# support encodings such as x-gzip or x-deflate.# we can accept "chunked" Transfer-Encodings, but no others# NOTE: no TE header implies *only* "chunked"#self.putheader('TE', 'chunked')# if TE is supplied in the header, then it must appear in a# Connection header.#self.putheader('Connection', 'TE')# For HTTP/1.0, the server will assume "not chunked"# ASCII also helps prevent CVE-2019-9740.# prevent http header injection# Prevent CVE-2019-9740.# Prevent CVE-2019-18348.# Honor explicitly requested Host: and Accept-Encoding: headers.# chunked encoding will happen if HTTP/1.1 is used and either# the caller passes encode_chunked=True or the following# conditions hold:# 1. content-length has not been explicitly set# 2. the body is a file or iterable, but not a str or bytes-like# 3. Transfer-Encoding has NOT been explicitly set by the caller# only chunk body if not explicitly set for backwards# compatibility, assuming the client code is already handling the# chunking# if content-length cannot be automatically determined, fall# back to chunked encoding# RFC 2616 Section 3.7.1 says that text default has a# default charset of iso-8859-1.# if a prior response exists, then it must be completed (otherwise, we# cannot read this response's header to determine the connection-close# behavior)# note: if a prior response existed, but was connection-close, then the# socket and response were made independent of this HTTPConnection# object since a new request requires that we open a whole new# connection# this means the prior response had one of two states:#   1) will_close: this connection was reset and the prior socket and#                  response operate independently#   2) persistent: the response was retained and we await its#                  isclosed() status to become true.# this effectively passes the connection to the response# remember this, so we can tell when it is complete# Subclasses that define an __init__ must call Exception.__init__# or define self.args.  Otherwise, str() will fail.# for backwards compatibilityb'HTTP/1.1 client library

<intro stuff goes here>
<other stuff, too>

HTTPConnection goes through a number of "states", which define when a client
may legally make another request or fetch the response for a particular
request. This diagram details these state transitions:

    (null)
      |
      | HTTPConnection()
      v
    Idle
      |
      | putrequest()
      v
    Request-started
      |
      | ( putheader() )*  endheaders()
      v
    Request-sent
      |\_____________________________
      |                              | getresponse() raises
      | response = getresponse()     | ConnectionError
      v                              v
    Unread-response                Idle
    [Response-headers-read]
      |\____________________
      |                     |
      | response.read()     | putrequest()
      v                     v
    Idle                  Req-started-unread-response
                     ______/|
                   /        |
   response.read() |        | ( putheader() )*  endheaders()
                   v        v
       Request-started    Req-sent-unread-response
                            |
                            | response.read()
                            v
                          Request-sent

This diagram presents the following rules:
  -- a second request may not be started until {response-headers-read}
  -- a response [object] cannot be retrieved until {request-sent}
  -- there is no differentiation between an unread response body and a
     partially read response body

Note: this enforcement is applied by the HTTPConnection class. The
      HTTPResponse class does not enforce this state machine, which
      implies sophisticated clients may accelerate the request/response
      pipeline. Caution should be taken, though: accelerating the states
      beyond the above pattern may imply knowledge of the server's
      connection-close behavior for certain requests. For example, it
      is impossible to tell whether the server will close the connection
      UNTIL the response headers have been read; this means that further
      requests cannot be placed into the pipeline until it is known that
      the server will NOT be closing the connection.

Logical State                  __state            __response
-------------                  -------            ----------
Idle                           _CS_IDLE           None
Request-started                _CS_REQ_STARTED    None
Request-sent                   _CS_REQ_SENT       None
Unread-response                _CS_IDLE           <response_class>
Req-started-unread-response    _CS_REQ_STARTED    <response_class>
Req-sent-unread-response       _CS_REQ_SENT       <response_class>
'u'HTTP/1.1 client library

<intro stuff goes here>
<other stuff, too>

HTTPConnection goes through a number of "states", which define when a client
may legally make another request or fetch the response for a particular
request. This diagram details these state transitions:

    (null)
      |
      | HTTPConnection()
      v
    Idle
      |
      | putrequest()
      v
    Request-started
      |
      | ( putheader() )*  endheaders()
      v
    Request-sent
      |\_____________________________
      |                              | getresponse() raises
      | response = getresponse()     | ConnectionError
      v                              v
    Unread-response                Idle
    [Response-headers-read]
      |\____________________
      |                     |
      | response.read()     | putrequest()
      v                     v
    Idle                  Req-started-unread-response
                     ______/|
                   /        |
   response.read() |        | ( putheader() )*  endheaders()
                   v        v
       Request-started    Req-sent-unread-response
                            |
                            | response.read()
                            v
                          Request-sent

This diagram presents the following rules:
  -- a second request may not be started until {response-headers-read}
  -- a response [object] cannot be retrieved until {request-sent}
  -- there is no differentiation between an unread response body and a
     partially read response body

Note: this enforcement is applied by the HTTPConnection class. The
      HTTPResponse class does not enforce this state machine, which
      implies sophisticated clients may accelerate the request/response
      pipeline. Caution should be taken, though: accelerating the states
      beyond the above pattern may imply knowledge of the server's
      connection-close behavior for certain requests. For example, it
      is impossible to tell whether the server will close the connection
      UNTIL the response headers have been read; this means that further
      requests cannot be placed into the pipeline until it is known that
      the server will NOT be closing the connection.

Logical State                  __state            __response
-------------                  -------            ----------
Idle                           _CS_IDLE           None
Request-started                _CS_REQ_STARTED    None
Request-sent                   _CS_REQ_SENT       None
Unread-response                _CS_IDLE           <response_class>
Req-started-unread-response    _CS_REQ_STARTED    <response_class>
Req-sent-unread-response       _CS_REQ_SENT       <response_class>
'b'HTTPResponse'u'HTTPResponse'b'HTTPConnection'u'HTTPConnection'b'HTTPException'u'HTTPException'b'NotConnected'u'NotConnected'b'UnknownProtocol'u'UnknownProtocol'b'UnknownTransferEncoding'u'UnknownTransferEncoding'b'UnimplementedFileMode'u'UnimplementedFileMode'b'IncompleteRead'u'IncompleteRead'b'InvalidURL'u'InvalidURL'b'ImproperConnectionState'u'ImproperConnectionState'b'CannotSendRequest'u'CannotSendRequest'b'CannotSendHeader'u'CannotSendHeader'b'ResponseNotReady'u'ResponseNotReady'b'BadStatusLine'u'BadStatusLine'b'LineTooLong'u'LineTooLong'b'RemoteDisconnected'u'RemoteDisconnected'b'responses'u'responses'b'UNKNOWN'u'UNKNOWN'b'Idle'u'Idle'b'Request-started'u'Request-started'b'Request-sent'u'Request-sent'b'[^:\s][^:\r\n]*'b'\n(?![ \t])|\r(?![ \t\n])'b'[ - ]'u'[ - ]'b'[ -]'u'[ -]'b'Call data.encode("latin-1") but show a better error message.'u'Call data.encode("latin-1") but show a better error message.'b'%s (%.20r) is not valid Latin-1. Use %s.encode('utf-8') if you want to send it encoded in UTF-8.'u'%s (%.20r) is not valid Latin-1. Use %s.encode('utf-8') if you want to send it encoded in UTF-8.'b'Remove interface scope from IPv6 address.'u'Remove interface scope from IPv6 address.'b'Find all header lines matching a given header name.

        Look through the list of headers and find all lines matching a given
        header name (and their continuation lines).  A list of the lines is
        returned, without interpretation.  If the header does not occur, an
        empty list is returned.  If the header occurs multiple times, all
        occurrences are returned.  Case is not important in the header name.

        'u'Find all header lines matching a given header name.

        Look through the list of headers and find all lines matching a given
        header name (and their continuation lines).  A list of the lines is
        returned, without interpretation.  If the header does not occur, an
        empty list is returned.  If the header occurs multiple times, all
        occurrences are returned.  Case is not important in the header name.

        'b'Reads potential header lines into a list from a file pointer.

    Length of line is limited by _MAXLINE, and number of
    headers is limited by _MAXHEADERS.
    'u'Reads potential header lines into a list from a file pointer.

    Length of line is limited by _MAXLINE, and number of
    headers is limited by _MAXHEADERS.
    'b'header line'u'header line'b'got more than %d headers'u'got more than %d headers'b'
    Parses only RFC2822 headers from header lines.

    email Parser wants to see strings rather than bytes.
    But a TextIOWrapper around self.rfile would buffer too many bytes
    from the stream, bytes which we later need to read as bytes.
    So we read the correct bytes here, as bytes, for email Parser
    to parse.

    'u'
    Parses only RFC2822 headers from header lines.

    email Parser wants to see strings rather than bytes.
    But a TextIOWrapper around self.rfile would buffer too many bytes
    from the stream, bytes which we later need to read as bytes.
    So we read the correct bytes here, as bytes, for email Parser
    to parse.

    'b'Parses only RFC2822 headers from a file pointer.'u'Parses only RFC2822 headers from a file pointer.'b'status line'u'status line'b'reply:'u'reply:'b'Remote end closed connection without response'u'Remote end closed connection without response'b'HTTP/'u'HTTP/'b'headers:'u'headers:'b'HTTP/1.0'u'HTTP/1.0'b'HTTP/0.9'u'HTTP/0.9'b'HTTP/1.'u'HTTP/1.'b'header:'u'header:'b'transfer-encoding'u'transfer-encoding'b'chunked'u'chunked'b'connection'u'connection'b'keep-alive'u'keep-alive'b'proxy-connection'u'proxy-connection'b'Always returns True'u'Always returns True'b'True if the connection is closed.'u'True if the connection is closed.'b'Read and return the response body, or up to the next amt bytes.'u'Read and return the response body, or up to the next amt bytes.'b'Read up to len(b) bytes into bytearray b and return the number
        of bytes read.
        'u'Read up to len(b) bytes into bytearray b and return the number
        of bytes read.
        'b'chunk size'u'chunk size'b'trailer line'u'trailer line'b'Read the number of bytes requested.

        This function should be used when <amt> bytes "should" be present for
        reading. If the bytes are truly not available (due to EOF), then the
        IncompleteRead exception can be used to detect the problem.
        'u'Read the number of bytes requested.

        This function should be used when <amt> bytes "should" be present for
        reading. If the bytes are truly not available (due to EOF), then the
        IncompleteRead exception can be used to detect the problem.
        'b'Same as _safe_read, but for reading into a buffer.'u'Same as _safe_read, but for reading into a buffer.'b'Read with at most one underlying system call.  If at least one
        byte is buffered, return that instead.
        'u'Read with at most one underlying system call.  If at least one
        byte is buffered, return that instead.
        'b'Returns the value of the header matching *name*.

        If there are multiple matching headers, the values are
        combined into a single string separated by commas and spaces.

        If no matching header is found, returns *default* or None if
        the *default* is not specified.

        If the headers are unknown, raises http.client.ResponseNotReady.

        'u'Returns the value of the header matching *name*.

        If there are multiple matching headers, the values are
        combined into a single string separated by commas and spaces.

        If no matching header is found, returns *default* or None if
        the *default* is not specified.

        If the headers are unknown, raises http.client.ResponseNotReady.

        'b'Return list of (header, value) tuples.'u'Return list of (header, value) tuples.'b'Returns an instance of the class mimetools.Message containing
        meta-information associated with the URL.

        When the method is HTTP, these headers are those returned by
        the server at the head of the retrieved HTML page (including
        Content-Length and Content-Type).

        When the method is FTP, a Content-Length header will be
        present if (as is now usual) the server passed back a file
        length in response to the FTP retrieval request. A
        Content-Type header will be present if the MIME type can be
        guessed.

        When the method is local-file, returned headers will include
        a Date representing the file's last-modified time, a
        Content-Length giving file size, and a Content-Type
        containing a guess at the file's type. See also the
        description of the mimetools module.

        'u'Returns an instance of the class mimetools.Message containing
        meta-information associated with the URL.

        When the method is HTTP, these headers are those returned by
        the server at the head of the retrieved HTML page (including
        Content-Length and Content-Type).

        When the method is FTP, a Content-Length header will be
        present if (as is now usual) the server passed back a file
        length in response to the FTP retrieval request. A
        Content-Type header will be present if the MIME type can be
        guessed.

        When the method is local-file, returned headers will include
        a Date representing the file's last-modified time, a
        Content-Length giving file size, and a Content-Type
        containing a guess at the file's type. See also the
        description of the mimetools module.

        'b'Return the real URL of the page.

        In some cases, the HTTP server redirects a client to another
        URL. The urlopen() function handles this transparently, but in
        some cases the caller needs to know which URL the client was
        redirected to. The geturl() method can be used to get at this
        redirected URL.

        'u'Return the real URL of the page.

        In some cases, the HTTP server redirects a client to another
        URL. The urlopen() function handles this transparently, but in
        some cases the caller needs to know which URL the client was
        redirected to. The geturl() method can be used to get at this
        redirected URL.

        'b'Return the HTTP status code that was sent with the response,
        or None if the URL is not an HTTP URL.

        'u'Return the HTTP status code that was sent with the response,
        or None if the URL is not an HTTP URL.

        'b'http/1.1'u'http/1.1'b'HTTP/1.1'u'HTTP/1.1'b'Test whether a file-like object is a text or a binary stream.
        'u'Test whether a file-like object is a text or a binary stream.
        'b'Get the content-length based on the body.

        If the body is None, we set Content-Length: 0 for methods that expect
        a body (RFC 7230, Section 3.3.2). We also set the Content-Length for
        any method if the body is a str or bytes-like object and not a file.
        'u'Get the content-length based on the body.

        If the body is None, we set Content-Length: 0 for methods that expect
        a body (RFC 7230, Section 3.3.2). We also set the Content-Length for
        any method if the body is a str or bytes-like object and not a file.
        'b'Set up host and port for HTTP CONNECT tunnelling.

        In a connection that uses HTTP CONNECT tunnelling, the host passed to
        the constructor is used as a proxy server that relays all communication
        to the endpoint passed to `set_tunnel`. This done by sending an HTTP
        CONNECT request to the proxy server when the connection is established.

        This method must be called before the HTTP connection has been
        established.

        The headers argument should be a mapping of extra HTTP headers to send
        with the CONNECT request.

        As HTTP/1.1 is used for HTTP CONNECT tunnelling request, as per the RFC
        (https://tools.ietf.org/html/rfc7231#section-4.3.6), a HTTP Host:
        header must be provided, matching the authority-form of the request
        target provided as the destination for the CONNECT request. If a
        HTTP Host: header is not provided via the headers argument, one
        is generated and transmitted automatically.
        'u'Set up host and port for HTTP CONNECT tunnelling.

        In a connection that uses HTTP CONNECT tunnelling, the host passed to
        the constructor is used as a proxy server that relays all communication
        to the endpoint passed to `set_tunnel`. This done by sending an HTTP
        CONNECT request to the proxy server when the connection is established.

        This method must be called before the HTTP connection has been
        established.

        The headers argument should be a mapping of extra HTTP headers to send
        with the CONNECT request.

        As HTTP/1.1 is used for HTTP CONNECT tunnelling request, as per the RFC
        (https://tools.ietf.org/html/rfc7231#section-4.3.6), a HTTP Host:
        header must be provided, matching the authority-form of the request
        target provided as the destination for the CONNECT request. If a
        HTTP Host: header is not provided via the headers argument, one
        is generated and transmitted automatically.
        'b'Can't set up tunnel for established connection'u'Can't set up tunnel for established connection'b'host'u'host'b'%s:%d'u'%s:%d'b'Host'u'Host'b'nonnumeric port: '%s''u'nonnumeric port: '%s''b'CONNECT %s:%d %s
'b'Tunnel connection failed: 'u'Tunnel connection failed: 'b'
        Returns a dictionary with the headers of the response
        received from the proxy server to the CONNECT request
        sent to set the tunnel.

        If the CONNECT request was not sent, the method returns None.
        'u'
        Returns a dictionary with the headers of the response
        received from the proxy server to the CONNECT request
        sent to set the tunnel.

        If the CONNECT request was not sent, the method returns None.
        'b'Connect to the host and port specified in __init__.'u'Connect to the host and port specified in __init__.'b'http.client.connect'u'http.client.connect'b'Close the connection to the HTTP server.'u'Close the connection to the HTTP server.'b'Send `data' to the server.
        ``data`` can be a string object, a bytes object, an array object, a
        file-like object that supports a .read() method, or an iterable object.
        'u'Send `data' to the server.
        ``data`` can be a string object, a bytes object, an array object, a
        file-like object that supports a .read() method, or an iterable object.
        'b'send:'u'send:'b'sending a readable'u'sending a readable'b'encoding file using iso-8859-1'u'encoding file using iso-8859-1'b'http.client.send'u'http.client.send'b'data should be a bytes-like object or an iterable, got %r'u'data should be a bytes-like object or an iterable, got %r'b'Add a line of output to the current request buffer.

        Assumes that the line does *not* end with \r\n.
        'u'Add a line of output to the current request buffer.

        Assumes that the line does *not* end with \r\n.
        'b'reading a readable'u'reading a readable'b'Send the currently buffered request and clear the buffer.

        Appends an extra \r\n to the buffer.
        A message_body may be specified, to be appended to the request.
        'u'Send the currently buffered request and clear the buffer.

        Appends an extra \r\n to the buffer.
        A message_body may be specified, to be appended to the request.
        'b'message_body should be a bytes-like object or an iterable, got %r'u'message_body should be a bytes-like object or an iterable, got %r'b'Zero length chunk ignored'u'Zero length chunk ignored'b'0

'b'Send a request to the server.

        `method' specifies an HTTP request method, e.g. 'GET'.
        `url' specifies the object being requested, e.g. '/index.html'.
        `skip_host' if True does not add automatically a 'Host:' header
        `skip_accept_encoding' if True does not add automatically an
           'Accept-Encoding:' header
        'u'Send a request to the server.

        `method' specifies an HTTP request method, e.g. 'GET'.
        `url' specifies the object being requested, e.g. '/index.html'.
        `skip_host' if True does not add automatically a 'Host:' header
        `skip_accept_encoding' if True does not add automatically an
           'Accept-Encoding:' header
        'b'%s %s %s'u'%s %s %s'b'%s:%s'u'%s:%s'b'identity'u'identity'b'Validate a method name for putrequest.'u'Validate a method name for putrequest.'b'method can't contain control characters. 'u'method can't contain control characters. 'b' (found at least 'u' (found at least 'b'Validate a url for putrequest.'u'Validate a url for putrequest.'b'URL can't contain control characters. 'u'URL can't contain control characters. 'b'Validate a host so it doesn't contain control characters.'u'Validate a host so it doesn't contain control characters.'b'Send a request header line to the server.

        For example: h.putheader('Accept', 'text/html')
        'u'Send a request header line to the server.

        For example: h.putheader('Accept', 'text/html')
        'b'Invalid header name %r'u'Invalid header name %r'b'Invalid header value %r'u'Invalid header value %r'b'
	'b'Indicate that the last header line has been sent to the server.

        This method sends the request to the server.  The optional message_body
        argument can be used to pass a message body associated with the
        request.
        'u'Indicate that the last header line has been sent to the server.

        This method sends the request to the server.  The optional message_body
        argument can be used to pass a message body associated with the
        request.
        'b'Send a complete request to the server.'u'Send a complete request to the server.'b'skip_host'u'skip_host'b'accept-encoding'u'accept-encoding'b'skip_accept_encoding'u'skip_accept_encoding'b'Unable to determine size of %r'u'Unable to determine size of %r'b'Transfer-Encoding'u'Transfer-Encoding'b'body'b'Get the response from the server.

        If the HTTPConnection is in the correct state, returns an
        instance of HTTPResponse or of whatever object is returned by
        the response_class variable.

        If a request has not been sent or if a previous response has
        not be handled, ResponseNotReady is raised.  If the HTTP
        response indicates that the connection should be closed, then
        it will be closed before the response is returned.  When the
        connection is closed, the underlying socket is closed.
        'u'Get the response from the server.

        If the HTTPConnection is in the correct state, returns an
        instance of HTTPResponse or of whatever object is returned by
        the response_class variable.

        If a request has not been sent or if a previous response has
        not be handled, ResponseNotReady is raised.  If the HTTP
        response indicates that the connection should be closed, then
        it will be closed before the response is returned.  When the
        connection is closed, the underlying socket is closed.
        'b'This class allows communication via SSL.'u'This class allows communication via SSL.'b'Connect to a host on a given (SSL) port.'u'Connect to a host on a given (SSL) port.'b', %i more expected'u', %i more expected'b'%s(%i bytes read%s)'u'%s(%i bytes read%s)'b'got more than %d bytes when reading %s'u'got more than %d bytes when reading %s'u'Lib.http.client'A generic class to build line-oriented command interpreters.

Interpreters constructed with this class obey the following conventions:

1. End of file on input is processed as the command 'EOF'.
2. A command is parsed out of each line by collecting the prefix composed
   of characters in the identchars member.
3. A command `foo' is dispatched to a method 'do_foo()'; the do_ method
   is passed a single argument consisting of the remainder of the line.
4. Typing an empty line repeats the last command.  (Actually, it calls the
   method `emptyline', which may be overridden in a subclass.)
5. There is a predefined `help' method.  Given an argument `topic', it
   calls the command `help_topic'.  With no arguments, it lists all topics
   with defined help_ functions, broken into up to three topics; documented
   commands, miscellaneous help topics, and undocumented commands.
6. The command '?' is a synonym for `help'.  The command '!' is a synonym
   for `shell', if a do_shell method exists.
7. If completion is enabled, completing commands will be done automatically,
   and completing of commands args is done by calling complete_foo() with
   arguments text, line, begidx, endidx.  text is string we are matching
   against, all returned matches must begin with it.  line is the current
   input line (lstripped), begidx and endidx are the beginning and end
   indexes of the text being matched, which could be used to provide
   different completion depending upon which position the argument is in.

The `default' method may be overridden to intercept commands for which there
is no do_ method.

The `completedefault' method may be overridden to intercept completions for
commands that have no complete_ method.

The data member `self.ruler' sets the character used to draw separator lines
in the help messages.  If empty, no ruler line is drawn.  It defaults to "=".

If the value of `self.intro' is nonempty when the cmdloop method is called,
it is printed out on interpreter startup.  This value may be overridden
via an optional argument to the cmdloop() method.

The data members `self.doc_header', `self.misc_header', and
`self.undoc_header' set the headers used for the help function's
listings of documented functions, miscellaneous topics, and undocumented
functions respectively.
Cmd(Cmd) PROMPTIDENTCHARSA simple framework for writing line-oriented command interpreters.

    These are often useful for test harnesses, administrative tools, and
    prototypes that will later be wrapped in a more sophisticated interface.

    A Cmd instance or subclass instance is a line-oriented interpreter
    framework.  There is no good reason to instantiate Cmd itself; rather,
    it's useful as a superclass of an interpreter class you define yourself
    in order to inherit Cmd's methods and encapsulate action methods.

    promptidentcharsrulerlastcmdintrodoc_leaderDocumented commands (type help <topic>):doc_headerMiscellaneous help topics:misc_headerUndocumented commands:undoc_header*** No help on %snohelpuse_rawinputtabcompletekeyInstantiate a line-oriented interpreter framework.

        The optional argument 'completekey' is the readline name of a
        completion key; it defaults to the Tab key. If completekey is
        not None and the readline module is available, command completion
        is done automatically. The optional arguments stdin and stdout
        specify alternate input and output file objects; if not specified,
        sys.stdin and sys.stdout are used.

        cmdqueuecmdloopRepeatedly issue a prompt, accept input, parse an initial prefix
        off the received input, and dispatch to action methods, passing them
        the remainder of the line as argument.

        preloopget_completerold_completerset_completercompleteparse_and_bind: completeEOFprecmdonecmdpostcmdpostloopHook method executed just before the command line is
        interpreted, but after the input prompt is generated and issued.

        Hook method executed just after a command dispatch is finished.Hook method executed once when the cmdloop() method is called.Hook method executed once when the cmdloop() method is about to
        return.

        parselineParse the line into a command name and a string containing
        the arguments.  Returns a tuple containing (command, args, line).
        'command' and 'args' may be None if the line couldn't be parsed.
        help do_shellshell Interpret the argument as though it had been typed in response
        to the prompt.

        This may be overridden, but should not normally need to be;
        see the precmd() and postcmd() methods for useful execution hooks.
        The return value is a flag indicating whether interpretation of
        commands by the interpreter should stop.

        emptylinedo_Called when an empty line is entered in response to the prompt.

        If this method is not overridden, it repeats the last nonempty
        command entered.

        Called on an input line when the command prefix is not recognized.

        If this method is not overridden, it prints an error message and
        returns.

        *** Unknown syntax: %s
completedefaultignoredMethod called to complete an input line when no command-specific
        complete_*() method is available.

        By default, it returns an empty list.

        completenamesdotextget_namesReturn the next possible completion for 'text'.

        If a command has not been entered, then complete against command list.
        Otherwise try to call complete_<command> to get list of completions.
        get_line_bufferoriglinestrippedget_begidxbegidxget_endidxendidxcompfunccomplete_completion_matchescomplete_helphelp_topicsdo_helpList available commands with "help" or detailed help with "help cmd".%s
cmds_doccmds_undocprevnameprint_topicscmdscmdlenmaxcolcolumnizedisplaywidthDisplay a list of strings as a compact set of columns.

        Each column is only as wide as necessary.
        Columns are separated by two spaces (one was not legible enough).
        <empty>
nonstringslist[i] not a string for i in %snrowsncolscolwidthstotwidthcoltexts# This method used to pull in base class attributes# at a time dir() didn't do it yet.# XXX check arg syntax# There can be duplicates if routines overridden# Try every row count from 1 upwardsb'A generic class to build line-oriented command interpreters.

Interpreters constructed with this class obey the following conventions:

1. End of file on input is processed as the command 'EOF'.
2. A command is parsed out of each line by collecting the prefix composed
   of characters in the identchars member.
3. A command `foo' is dispatched to a method 'do_foo()'; the do_ method
   is passed a single argument consisting of the remainder of the line.
4. Typing an empty line repeats the last command.  (Actually, it calls the
   method `emptyline', which may be overridden in a subclass.)
5. There is a predefined `help' method.  Given an argument `topic', it
   calls the command `help_topic'.  With no arguments, it lists all topics
   with defined help_ functions, broken into up to three topics; documented
   commands, miscellaneous help topics, and undocumented commands.
6. The command '?' is a synonym for `help'.  The command '!' is a synonym
   for `shell', if a do_shell method exists.
7. If completion is enabled, completing commands will be done automatically,
   and completing of commands args is done by calling complete_foo() with
   arguments text, line, begidx, endidx.  text is string we are matching
   against, all returned matches must begin with it.  line is the current
   input line (lstripped), begidx and endidx are the beginning and end
   indexes of the text being matched, which could be used to provide
   different completion depending upon which position the argument is in.

The `default' method may be overridden to intercept commands for which there
is no do_ method.

The `completedefault' method may be overridden to intercept completions for
commands that have no complete_ method.

The data member `self.ruler' sets the character used to draw separator lines
in the help messages.  If empty, no ruler line is drawn.  It defaults to "=".

If the value of `self.intro' is nonempty when the cmdloop method is called,
it is printed out on interpreter startup.  This value may be overridden
via an optional argument to the cmdloop() method.

The data members `self.doc_header', `self.misc_header', and
`self.undoc_header' set the headers used for the help function's
listings of documented functions, miscellaneous topics, and undocumented
functions respectively.
'u'A generic class to build line-oriented command interpreters.

Interpreters constructed with this class obey the following conventions:

1. End of file on input is processed as the command 'EOF'.
2. A command is parsed out of each line by collecting the prefix composed
   of characters in the identchars member.
3. A command `foo' is dispatched to a method 'do_foo()'; the do_ method
   is passed a single argument consisting of the remainder of the line.
4. Typing an empty line repeats the last command.  (Actually, it calls the
   method `emptyline', which may be overridden in a subclass.)
5. There is a predefined `help' method.  Given an argument `topic', it
   calls the command `help_topic'.  With no arguments, it lists all topics
   with defined help_ functions, broken into up to three topics; documented
   commands, miscellaneous help topics, and undocumented commands.
6. The command '?' is a synonym for `help'.  The command '!' is a synonym
   for `shell', if a do_shell method exists.
7. If completion is enabled, completing commands will be done automatically,
   and completing of commands args is done by calling complete_foo() with
   arguments text, line, begidx, endidx.  text is string we are matching
   against, all returned matches must begin with it.  line is the current
   input line (lstripped), begidx and endidx are the beginning and end
   indexes of the text being matched, which could be used to provide
   different completion depending upon which position the argument is in.

The `default' method may be overridden to intercept commands for which there
is no do_ method.

The `completedefault' method may be overridden to intercept completions for
commands that have no complete_ method.

The data member `self.ruler' sets the character used to draw separator lines
in the help messages.  If empty, no ruler line is drawn.  It defaults to "=".

If the value of `self.intro' is nonempty when the cmdloop method is called,
it is printed out on interpreter startup.  This value may be overridden
via an optional argument to the cmdloop() method.

The data members `self.doc_header', `self.misc_header', and
`self.undoc_header' set the headers used for the help function's
listings of documented functions, miscellaneous topics, and undocumented
functions respectively.
'b'Cmd'u'Cmd'b'(Cmd) 'u'(Cmd) 'b'A simple framework for writing line-oriented command interpreters.

    These are often useful for test harnesses, administrative tools, and
    prototypes that will later be wrapped in a more sophisticated interface.

    A Cmd instance or subclass instance is a line-oriented interpreter
    framework.  There is no good reason to instantiate Cmd itself; rather,
    it's useful as a superclass of an interpreter class you define yourself
    in order to inherit Cmd's methods and encapsulate action methods.

    'u'A simple framework for writing line-oriented command interpreters.

    These are often useful for test harnesses, administrative tools, and
    prototypes that will later be wrapped in a more sophisticated interface.

    A Cmd instance or subclass instance is a line-oriented interpreter
    framework.  There is no good reason to instantiate Cmd itself; rather,
    it's useful as a superclass of an interpreter class you define yourself
    in order to inherit Cmd's methods and encapsulate action methods.

    'b'Documented commands (type help <topic>):'u'Documented commands (type help <topic>):'b'Miscellaneous help topics:'u'Miscellaneous help topics:'b'Undocumented commands:'u'Undocumented commands:'b'*** No help on %s'u'*** No help on %s'b'tab'u'tab'b'Instantiate a line-oriented interpreter framework.

        The optional argument 'completekey' is the readline name of a
        completion key; it defaults to the Tab key. If completekey is
        not None and the readline module is available, command completion
        is done automatically. The optional arguments stdin and stdout
        specify alternate input and output file objects; if not specified,
        sys.stdin and sys.stdout are used.

        'u'Instantiate a line-oriented interpreter framework.

        The optional argument 'completekey' is the readline name of a
        completion key; it defaults to the Tab key. If completekey is
        not None and the readline module is available, command completion
        is done automatically. The optional arguments stdin and stdout
        specify alternate input and output file objects; if not specified,
        sys.stdin and sys.stdout are used.

        'b'Repeatedly issue a prompt, accept input, parse an initial prefix
        off the received input, and dispatch to action methods, passing them
        the remainder of the line as argument.

        'u'Repeatedly issue a prompt, accept input, parse an initial prefix
        off the received input, and dispatch to action methods, passing them
        the remainder of the line as argument.

        'b': complete'u': complete'b'EOF'u'EOF'b'Hook method executed just before the command line is
        interpreted, but after the input prompt is generated and issued.

        'u'Hook method executed just before the command line is
        interpreted, but after the input prompt is generated and issued.

        'b'Hook method executed just after a command dispatch is finished.'u'Hook method executed just after a command dispatch is finished.'b'Hook method executed once when the cmdloop() method is called.'u'Hook method executed once when the cmdloop() method is called.'b'Hook method executed once when the cmdloop() method is about to
        return.

        'u'Hook method executed once when the cmdloop() method is about to
        return.

        'b'Parse the line into a command name and a string containing
        the arguments.  Returns a tuple containing (command, args, line).
        'command' and 'args' may be None if the line couldn't be parsed.
        'u'Parse the line into a command name and a string containing
        the arguments.  Returns a tuple containing (command, args, line).
        'command' and 'args' may be None if the line couldn't be parsed.
        'b'help 'u'help 'b'do_shell'u'do_shell'b'shell 'u'shell 'b'Interpret the argument as though it had been typed in response
        to the prompt.

        This may be overridden, but should not normally need to be;
        see the precmd() and postcmd() methods for useful execution hooks.
        The return value is a flag indicating whether interpretation of
        commands by the interpreter should stop.

        'u'Interpret the argument as though it had been typed in response
        to the prompt.

        This may be overridden, but should not normally need to be;
        see the precmd() and postcmd() methods for useful execution hooks.
        The return value is a flag indicating whether interpretation of
        commands by the interpreter should stop.

        'b'do_'u'do_'b'Called when an empty line is entered in response to the prompt.

        If this method is not overridden, it repeats the last nonempty
        command entered.

        'u'Called when an empty line is entered in response to the prompt.

        If this method is not overridden, it repeats the last nonempty
        command entered.

        'b'Called on an input line when the command prefix is not recognized.

        If this method is not overridden, it prints an error message and
        returns.

        'u'Called on an input line when the command prefix is not recognized.

        If this method is not overridden, it prints an error message and
        returns.

        'b'*** Unknown syntax: %s
'u'*** Unknown syntax: %s
'b'Method called to complete an input line when no command-specific
        complete_*() method is available.

        By default, it returns an empty list.

        'u'Method called to complete an input line when no command-specific
        complete_*() method is available.

        By default, it returns an empty list.

        'b'Return the next possible completion for 'text'.

        If a command has not been entered, then complete against command list.
        Otherwise try to call complete_<command> to get list of completions.
        'u'Return the next possible completion for 'text'.

        If a command has not been entered, then complete against command list.
        Otherwise try to call complete_<command> to get list of completions.
        'b'complete_'u'complete_'b'help_'u'help_'b'List available commands with "help" or detailed help with "help cmd".'u'List available commands with "help" or detailed help with "help cmd".'b'%s
'u'%s
'b'Display a list of strings as a compact set of columns.

        Each column is only as wide as necessary.
        Columns are separated by two spaces (one was not legible enough).
        'u'Display a list of strings as a compact set of columns.

        Each column is only as wide as necessary.
        Columns are separated by two spaces (one was not legible enough).
        'b'<empty>
'u'<empty>
'b'list[i] not a string for i in %s'u'list[i] not a string for i in %s'u'Lib.cmd'u'cmd'Utilities needed to emulate Python's interactive interpreter.

codeopCommandCompilercompile_commandInteractiveInterpreterInteractiveConsoleinteractBase class for InteractiveConsole.

    This class deals with parsing and interpreter state (the user's
    namespace); it doesn't deal with input buffering or prompting or
    input file naming (the filename is always passed in explicitly).

    Constructor.

        The optional 'locals' argument specifies the dictionary in
        which code will be executed; it defaults to a newly created
        dictionary with key "__name__" set to "__console__" and key
        "__doc__" set to None.

        __console__runsource<input>symbolCompile and run some source in the interpreter.

        Arguments are as for compile_command().

        One of several things can happen:

        1) The input is incorrect; compile_command() raised an
        exception (SyntaxError or OverflowError).  A syntax traceback
        will be printed by calling the showsyntaxerror() method.

        2) The input is incomplete, and more input is required;
        compile_command() returned None.  Nothing happens.

        3) The input is complete; compile_command() returned a code
        object.  The code is executed by calling self.runcode() (which
        also handles run-time exceptions, except for SystemExit).

        The return value is True in case 2, False in the other cases (unless
        an exception is raised).  The return value can be used to
        decide whether to use sys.ps1 or sys.ps2 to prompt the next
        line.

        showsyntaxerrorruncodeExecute a code object.

        When an exception occurs, self.showtraceback() is called to
        display a traceback.  All exceptions are caught except
        SystemExit, which is reraised.

        A note about KeyboardInterrupt: this exception may occur
        elsewhere in this code, and may not always be caught.  The
        caller should be prepared to deal with it.

        showtracebackDisplay the syntax error that just occurred.

        This doesn't display a stack trace because there isn't one.

        If a filename is given, it is stuffed in the exception instead
        of what was there before (because Python's parser always uses
        "<string>" when reading from a string).

        The output is written by self.write(), below.

        last_exclast_typelast_valuelast_tracebackdummy_filenameDisplay the exception that just occurred.

        We remove the first stack item because it is our own code.

        The output is written by self.write(), below.

        last_tbformat_exceptionWrite a string.

        The base implementation writes to sys.stderr; a subclass may
        replace this with a different implementation.

        Closely emulate the behavior of the interactive Python interpreter.

    This class builds on InteractiveInterpreter and adds prompting
    using the familiar sys.ps1 and sys.ps2, and input buffering.

    <console>Constructor.

        The optional locals argument will be passed to the
        InteractiveInterpreter base class.

        The optional filename argument should specify the (file)name
        of the input stream; it will show up in tracebacks.

        resetbufferReset the input buffer.bannerexitmsgClosely emulate the interactive Python console.

        The optional banner argument specifies the banner to print
        before the first interaction; by default it prints a banner
        similar to the one printed by the real Python interpreter,
        followed by the current class name in parentheses (so as not
        to confuse this with the real interpreter -- since it's so
        close!).

        The optional exitmsg argument specifies the exit message
        printed when exiting. Pass the empty string to suppress
        printing an exit message. If exitmsg is not given or None,
        a default message is printed.

        ps1>>> ps2... Type "help", "copyright", "credits" or "license" for more information.cprtPython %s on %s
%s
(%s)
moreraw_input
KeyboardInterrupt
now exiting %s...
Push a line to the interpreter.

        The line should not have a trailing newline; it may have
        internal newlines.  The line is appended to a buffer and the
        interpreter's runsource() method is called with the
        concatenated contents of the buffer as source.  If this
        indicates that the command was executed or invalid, the buffer
        is reset; otherwise, the command is incomplete, and the buffer
        is left as it was after the line was appended.  The return
        value is 1 if more input is required, 0 if the line was dealt
        with in some way (this is the same as runsource()).

        Write a prompt and read a line.

        The returned line does not include the trailing newline.
        When the user enters the EOF key sequence, EOFError is raised.

        The base implementation uses the built-in function
        input(); a subclass may replace this with a different
        implementation.

        readfuncClosely emulate the interactive Python interpreter.

    This is a backwards compatible interface to the InteractiveConsole
    class.  When readfunc is not specified, it attempts to import the
    readline module to enable GNU readline if it is available.

    Arguments (all optional, all default to None):

    banner -- passed to InteractiveConsole.interact()
    readfunc -- if not None, replaces InteractiveConsole.raw_input()
    local -- passed to InteractiveInterpreter.__init__()
    exitmsg -- passed to InteractiveConsole.interact()

    console-qdon't print version and copyright messages# Inspired by similar code by Jeff Epler and Fredrik Lundh.# Case 1# Case 2# Case 3# Work hard to stuff the correct filename in the exception# Not the format we expect; leave it alone# Stuff in the right filename# If someone has set sys.excepthook, we let that take precedence# over self.writeb'Utilities needed to emulate Python's interactive interpreter.

'u'Utilities needed to emulate Python's interactive interpreter.

'b'InteractiveInterpreter'u'InteractiveInterpreter'b'InteractiveConsole'u'InteractiveConsole'b'interact'u'interact'b'compile_command'u'compile_command'b'Base class for InteractiveConsole.

    This class deals with parsing and interpreter state (the user's
    namespace); it doesn't deal with input buffering or prompting or
    input file naming (the filename is always passed in explicitly).

    'u'Base class for InteractiveConsole.

    This class deals with parsing and interpreter state (the user's
    namespace); it doesn't deal with input buffering or prompting or
    input file naming (the filename is always passed in explicitly).

    'b'Constructor.

        The optional 'locals' argument specifies the dictionary in
        which code will be executed; it defaults to a newly created
        dictionary with key "__name__" set to "__console__" and key
        "__doc__" set to None.

        'u'Constructor.

        The optional 'locals' argument specifies the dictionary in
        which code will be executed; it defaults to a newly created
        dictionary with key "__name__" set to "__console__" and key
        "__doc__" set to None.

        'b'__console__'u'__console__'b'<input>'u'<input>'b'Compile and run some source in the interpreter.

        Arguments are as for compile_command().

        One of several things can happen:

        1) The input is incorrect; compile_command() raised an
        exception (SyntaxError or OverflowError).  A syntax traceback
        will be printed by calling the showsyntaxerror() method.

        2) The input is incomplete, and more input is required;
        compile_command() returned None.  Nothing happens.

        3) The input is complete; compile_command() returned a code
        object.  The code is executed by calling self.runcode() (which
        also handles run-time exceptions, except for SystemExit).

        The return value is True in case 2, False in the other cases (unless
        an exception is raised).  The return value can be used to
        decide whether to use sys.ps1 or sys.ps2 to prompt the next
        line.

        'u'Compile and run some source in the interpreter.

        Arguments are as for compile_command().

        One of several things can happen:

        1) The input is incorrect; compile_command() raised an
        exception (SyntaxError or OverflowError).  A syntax traceback
        will be printed by calling the showsyntaxerror() method.

        2) The input is incomplete, and more input is required;
        compile_command() returned None.  Nothing happens.

        3) The input is complete; compile_command() returned a code
        object.  The code is executed by calling self.runcode() (which
        also handles run-time exceptions, except for SystemExit).

        The return value is True in case 2, False in the other cases (unless
        an exception is raised).  The return value can be used to
        decide whether to use sys.ps1 or sys.ps2 to prompt the next
        line.

        'b'Execute a code object.

        When an exception occurs, self.showtraceback() is called to
        display a traceback.  All exceptions are caught except
        SystemExit, which is reraised.

        A note about KeyboardInterrupt: this exception may occur
        elsewhere in this code, and may not always be caught.  The
        caller should be prepared to deal with it.

        'u'Execute a code object.

        When an exception occurs, self.showtraceback() is called to
        display a traceback.  All exceptions are caught except
        SystemExit, which is reraised.

        A note about KeyboardInterrupt: this exception may occur
        elsewhere in this code, and may not always be caught.  The
        caller should be prepared to deal with it.

        'b'Display the syntax error that just occurred.

        This doesn't display a stack trace because there isn't one.

        If a filename is given, it is stuffed in the exception instead
        of what was there before (because Python's parser always uses
        "<string>" when reading from a string).

        The output is written by self.write(), below.

        'u'Display the syntax error that just occurred.

        This doesn't display a stack trace because there isn't one.

        If a filename is given, it is stuffed in the exception instead
        of what was there before (because Python's parser always uses
        "<string>" when reading from a string).

        The output is written by self.write(), below.

        'b'Display the exception that just occurred.

        We remove the first stack item because it is our own code.

        The output is written by self.write(), below.

        'u'Display the exception that just occurred.

        We remove the first stack item because it is our own code.

        The output is written by self.write(), below.

        'b'Write a string.

        The base implementation writes to sys.stderr; a subclass may
        replace this with a different implementation.

        'u'Write a string.

        The base implementation writes to sys.stderr; a subclass may
        replace this with a different implementation.

        'b'Closely emulate the behavior of the interactive Python interpreter.

    This class builds on InteractiveInterpreter and adds prompting
    using the familiar sys.ps1 and sys.ps2, and input buffering.

    'u'Closely emulate the behavior of the interactive Python interpreter.

    This class builds on InteractiveInterpreter and adds prompting
    using the familiar sys.ps1 and sys.ps2, and input buffering.

    'b'<console>'u'<console>'b'Constructor.

        The optional locals argument will be passed to the
        InteractiveInterpreter base class.

        The optional filename argument should specify the (file)name
        of the input stream; it will show up in tracebacks.

        'u'Constructor.

        The optional locals argument will be passed to the
        InteractiveInterpreter base class.

        The optional filename argument should specify the (file)name
        of the input stream; it will show up in tracebacks.

        'b'Reset the input buffer.'u'Reset the input buffer.'b'Closely emulate the interactive Python console.

        The optional banner argument specifies the banner to print
        before the first interaction; by default it prints a banner
        similar to the one printed by the real Python interpreter,
        followed by the current class name in parentheses (so as not
        to confuse this with the real interpreter -- since it's so
        close!).

        The optional exitmsg argument specifies the exit message
        printed when exiting. Pass the empty string to suppress
        printing an exit message. If exitmsg is not given or None,
        a default message is printed.

        'u'Closely emulate the interactive Python console.

        The optional banner argument specifies the banner to print
        before the first interaction; by default it prints a banner
        similar to the one printed by the real Python interpreter,
        followed by the current class name in parentheses (so as not
        to confuse this with the real interpreter -- since it's so
        close!).

        The optional exitmsg argument specifies the exit message
        printed when exiting. Pass the empty string to suppress
        printing an exit message. If exitmsg is not given or None,
        a default message is printed.

        'b'>>> 'u'>>> 'b'... 'u'... 'b'Type "help", "copyright", "credits" or "license" for more information.'u'Type "help", "copyright", "credits" or "license" for more information.'b'Python %s on %s
%s
(%s)
'u'Python %s on %s
%s
(%s)
'b'
KeyboardInterrupt
'u'
KeyboardInterrupt
'b'now exiting %s...
'u'now exiting %s...
'b'Push a line to the interpreter.

        The line should not have a trailing newline; it may have
        internal newlines.  The line is appended to a buffer and the
        interpreter's runsource() method is called with the
        concatenated contents of the buffer as source.  If this
        indicates that the command was executed or invalid, the buffer
        is reset; otherwise, the command is incomplete, and the buffer
        is left as it was after the line was appended.  The return
        value is 1 if more input is required, 0 if the line was dealt
        with in some way (this is the same as runsource()).

        'u'Push a line to the interpreter.

        The line should not have a trailing newline; it may have
        internal newlines.  The line is appended to a buffer and the
        interpreter's runsource() method is called with the
        concatenated contents of the buffer as source.  If this
        indicates that the command was executed or invalid, the buffer
        is reset; otherwise, the command is incomplete, and the buffer
        is left as it was after the line was appended.  The return
        value is 1 if more input is required, 0 if the line was dealt
        with in some way (this is the same as runsource()).

        'b'Write a prompt and read a line.

        The returned line does not include the trailing newline.
        When the user enters the EOF key sequence, EOFError is raised.

        The base implementation uses the built-in function
        input(); a subclass may replace this with a different
        implementation.

        'u'Write a prompt and read a line.

        The returned line does not include the trailing newline.
        When the user enters the EOF key sequence, EOFError is raised.

        The base implementation uses the built-in function
        input(); a subclass may replace this with a different
        implementation.

        'b'Closely emulate the interactive Python interpreter.

    This is a backwards compatible interface to the InteractiveConsole
    class.  When readfunc is not specified, it attempts to import the
    readline module to enable GNU readline if it is available.

    Arguments (all optional, all default to None):

    banner -- passed to InteractiveConsole.interact()
    readfunc -- if not None, replaces InteractiveConsole.raw_input()
    local -- passed to InteractiveInterpreter.__init__()
    exitmsg -- passed to InteractiveConsole.interact()

    'u'Closely emulate the interactive Python interpreter.

    This is a backwards compatible interface to the InteractiveConsole
    class.  When readfunc is not specified, it attempts to import the
    readline module to enable GNU readline if it is available.

    Arguments (all optional, all default to None):

    banner -- passed to InteractiveConsole.interact()
    readfunc -- if not None, replaces InteractiveConsole.raw_input()
    local -- passed to InteractiveInterpreter.__init__()
    exitmsg -- passed to InteractiveConsole.interact()

    'b'-q'u'-q'b'don't print version and copyright messages'u'don't print version and copyright messages'u'Lib.code'u'code' codecs -- Python Codec Registry, API and helpers.


Written by Marc-Andre Lemburg (mal@lemburg.com).

(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.

whyFailed to load the builtin codecs: %sEncodedFileBOMBOM_BEBOM_LEBOM32_BEBOM32_LEBOM64_BEBOM64_LEBOM_UTF8BOM_UTF16BOM_UTF16_LEBOM_UTF16_BEBOM_UTF32BOM_UTF32_LEBOM_UTF32_BECodecIncrementalEncoderIncrementalDecoderStreamReaderStreamWriterStreamReaderWriterStreamRecodergetencodergetdecodergetincrementalencodergetincrementaldecodergetreadergetwriteriterencodeiterdecodestrict_errorsignore_errorsreplace_errorsxmlcharrefreplace_errorsbackslashreplace_errorsnamereplace_errors    Codec details when looking up the codec registry_is_text_encodingstreamreaderstreamwriterincrementalencoderincrementaldecoder<%s.%s object for encoding %s at %#x> Defines the interface for stateless encoders/decoders.

        The .encode()/.decode() methods may use different error
        handling schemes by providing the errors argument. These
        string values are predefined:

         'strict' - raise a ValueError error (or a subclass)
         'ignore' - ignore the character and continue with the next
         'replace' - replace with a suitable replacement character;
                    Python will use the official U+FFFD REPLACEMENT
                    CHARACTER for the builtin Unicode codecs on
                    decoding and '?' on encoding.
         'surrogateescape' - replace with private code points U+DCnn.
         'xmlcharrefreplace' - Replace with the appropriate XML
                               character reference (only for encoding).
         'backslashreplace'  - Replace with backslashed escape sequences.
         'namereplace'       - Replace with \N{...} escape sequences
                               (only for encoding).

        The set of allowed values can be extended via register_error.

     Encodes the object input and returns a tuple (output
            object, length consumed).

            errors defines the error handling to apply. It defaults to
            'strict' handling.

            The method may not store state in the Codec instance. Use
            StreamWriter for codecs which have to keep state in order to
            make encoding efficient.

            The encoder must be able to handle zero length input and
            return an empty object of the output object type in this
            situation.

         Decodes the object input and returns a tuple (output
            object, length consumed).

            input must be an object which provides the bf_getreadbuf
            buffer slot. Python strings, buffer objects and memory
            mapped files are examples of objects providing this slot.

            errors defines the error handling to apply. It defaults to
            'strict' handling.

            The method may not store state in the Codec instance. Use
            StreamReader for codecs which have to keep state in order to
            make decoding efficient.

            The decoder must be able to handle zero length input and
            return an empty object of the output object type in this
            situation.

        
    An IncrementalEncoder encodes an input in multiple steps. The input can
    be passed piece by piece to the encode() method. The IncrementalEncoder
    remembers the state of the encoding process between calls to encode().
    
        Creates an IncrementalEncoder instance.

        The IncrementalEncoder may use different error handling schemes by
        providing the errors keyword argument. See the module docstring
        for a list of possible values.
        
        Encodes input and returns the resulting object.
        
        Resets the encoder to the initial state.
        
        Return the current state of the encoder.
        
        Set the current state of the encoder. state must have been
        returned by getstate().
        BufferedIncrementalEncoder
    This subclass of IncrementalEncoder can be used as the baseclass for an
    incremental encoder if the encoder must keep some of the output in a
    buffer between calls to encode().
    _buffer_encodeconsumed
    An IncrementalDecoder decodes an input in multiple steps. The input can
    be passed piece by piece to the decode() method. The IncrementalDecoder
    remembers the state of the decoding process between calls to decode().
    
        Create an IncrementalDecoder instance.

        The IncrementalDecoder may use different error handling schemes by
        providing the errors keyword argument. See the module docstring
        for a list of possible values.
        
        Decode input and returns the resulting object.
        
        Reset the decoder to the initial state.
        
        Return the current state of the decoder.

        This must be a (buffered_input, additional_state_info) tuple.
        buffered_input must be a bytes object containing bytes that
        were passed to decode() that have not yet been converted.
        additional_state_info must be a non-negative integer
        representing the state of the decoder WITHOUT yet having
        processed the contents of buffered_input.  In the initial state
        and after reset(), getstate() must return (b"", 0).
        
        Set the current state of the decoder.

        state must have been returned by getstate().  The effect of
        setstate((b"", 0)) must be equivalent to reset().
        BufferedIncrementalDecoder
    This subclass of IncrementalDecoder can be used as the baseclass for an
    incremental decoder if the decoder must be able to handle incomplete
    byte sequences.
    _buffer_decode Creates a StreamWriter instance.

            stream must be a file-like object open for writing.

            The StreamWriter may use different error handling
            schemes by providing the errors keyword argument. These
            parameters are predefined:

             'strict' - raise a ValueError (or a subclass)
             'ignore' - ignore the character and continue with the next
             'replace'- replace with a suitable replacement character
             'xmlcharrefreplace' - Replace with the appropriate XML
                                   character reference.
             'backslashreplace'  - Replace with backslashed escape
                                   sequences.
             'namereplace'       - Replace with \N{...} escape sequences.

            The set of allowed parameter values can be extended via
            register_error.
         Writes the object's contents encoded to self.stream.
         Writes the concatenated list of strings to the stream
            using .write().
         Resets the codec buffers used for keeping internal state.

            Calling this method should ensure that the data on the
            output is put into a clean state, that allows appending
            of new fresh data without having to rescan the whole
            stream to recover state.

         Inherit all other methods from the underlying stream.
        can't serialize %scharbuffertype Creates a StreamReader instance.

            stream must be a file-like object open for reading.

            The StreamReader may use different error handling
            schemes by providing the errors keyword argument. These
            parameters are predefined:

             'strict' - raise a ValueError (or a subclass)
             'ignore' - ignore the character and continue with the next
             'replace'- replace with a suitable replacement character
             'backslashreplace' - Replace with backslashed escape sequences;

            The set of allowed parameter values can be extended via
            register_error.
        bytebuffer_empty_charbuffercharbufferlinebufferfirstline Decodes data from the stream self.stream and returns the
            resulting object.

            chars indicates the number of decoded code points or bytes to
            return. read() will never return more data than requested,
            but it might return less, if there is not enough available.

            size indicates the approximate maximum number of decoded
            bytes or code points to read for decoding. The decoder
            can modify this setting as appropriate. The default value
            -1 indicates to read and decode as much as possible.  size
            is intended to prevent having to decode huge files in one
            step.

            If firstline is true, and a UnicodeDecodeError happens
            after the first line terminator in the input only the first line
            will be returned, the rest of the input will be kept until the
            next call to read().

            The method should use a greedy read strategy, meaning that
            it should read as much data as is allowed within the
            definition of the encoding and the given size, e.g.  if
            optional encoding endings or state markers are available
            on the stream, these should be read too.
        newcharsdecodedbytes Read one line from the input stream and return the
            decoded data.

            size, if given, is passed as size argument to the
            read() method.

        72readsizeline0withendline0withoutend8000sizehint Read all lines available on the input stream
            and return them as a list.

            Line breaks are implemented using the codec's decoder
            method and are included in the list entries.

            sizehint, if given, is ignored since there is no efficient
            way to finding the true end-of-line.

         Resets the codec buffers used for keeping internal state.

            Note that no stream repositioning should take place.
            This method is primarily intended to be able to recover
            from decoding errors.

         Set the input stream's current position.

            Resets the codec buffers used for keeping state.
         Return the next decoded line from the input stream. StreamReaderWriter instances allow wrapping streams which
        work in both read and write modes.

        The design is such that one can use the factory functions
        returned by the codec.lookup() function to construct the
        instance.

    unknownReaderWriter Creates a StreamReaderWriter instance.

            stream must be a Stream-like object.

            Reader, Writer must be factory functions or classes
            providing the StreamReader, StreamWriter interface resp.

            Error handling is done in the same way as defined for the
            StreamWriter/Readers.

        readerwriter StreamRecoder instances translate data from one encoding to another.

        They use the complete set of APIs returned by the
        codecs.lookup() function to implement their task.

        Data written to the StreamRecoder is first decoded into an
        intermediate format (depending on the "decode" codec) and then
        written to the underlying stream using an instance of the provided
        Writer class.

        In the other direction, data is read from the underlying stream using
        a Reader instance and then encoded and returned to the caller.

    data_encodingfile_encoding Creates a StreamRecoder instance which implements a two-way
            conversion: encode and decode work on the frontend (the
            data visible to .read() and .write()) while Reader and Writer
            work on the backend (the data in stream).

            You can use these objects to do transparent
            transcodings from e.g. latin-1 to utf-8 and back.

            stream must be a file-like object.

            encode and decode must adhere to the Codec interface; Reader and
            Writer must be factory functions or classes providing the
            StreamReader and StreamWriter interfaces resp.

            Error handling is done in the same way as defined for the
            StreamWriter/Readers.

        bytesencodedbytesdecodedbuffering Open an encoded file using the given mode and return
        a wrapped version providing transparent encoding/decoding.

        Note: The wrapped version will only accept the object format
        defined by the codecs, i.e. Unicode objects for most builtin
        codecs. Output is also codec dependent and will usually be
        Unicode as well.

        If encoding is not None, then the
        underlying encoded files are always opened in binary mode.
        The default file mode is 'r', meaning to open the file in read mode.

        encoding specifies the encoding which is to be used for the
        file.

        errors may be given to define the error handling. It defaults
        to 'strict' which causes ValueErrors to be raised in case an
        encoding error occurs.

        buffering has the same meaning as for the builtin open() API.
        It defaults to -1 which means that the default buffer size will
        be used.

        The returned wrapped file object provides an extra attribute
        .encoding which allows querying the used encoding. This
        attribute is only available if an encoding was specified as
        parameter.

    srw Return a wrapped version of file which provides transparent
        encoding translation.

        Data written to the wrapped file is decoded according
        to the given data_encoding and then encoded to the underlying
        file using file_encoding. The intermediate data type
        will usually be Unicode but depends on the specified codecs.

        Bytes read from the file are decoded using file_encoding and then
        passed back to the caller encoded using data_encoding.

        If file_encoding is not given, it defaults to data_encoding.

        errors may be given to define the error handling. It defaults
        to 'strict' which causes ValueErrors to be raised in case an
        encoding error occurs.

        The returned wrapped file object provides two extra attributes
        .data_encoding and .file_encoding which reflect the given
        parameters of the same name. The attributes can be used for
        introspection by Python programs.

    data_infofile_infosr Lookup up the codec for the given encoding and return
        its encoder function.

        Raises a LookupError in case the encoding cannot be found.

     Lookup up the codec for the given encoding and return
        its decoder function.

        Raises a LookupError in case the encoding cannot be found.

     Lookup up the codec for the given encoding and return
        its IncrementalEncoder class or factory function.

        Raises a LookupError in case the encoding cannot be found
        or the codecs doesn't provide an incremental encoder.

     Lookup up the codec for the given encoding and return
        its IncrementalDecoder class or factory function.

        Raises a LookupError in case the encoding cannot be found
        or the codecs doesn't provide an incremental decoder.

    decoder Lookup up the codec for the given encoding and return
        its StreamReader class or factory function.

        Raises a LookupError in case the encoding cannot be found.

     Lookup up the codec for the given encoding and return
        its StreamWriter class or factory function.

        Raises a LookupError in case the encoding cannot be found.

    iterator
    Encoding iterator.

    Encodes the input strings from the iterator using an IncrementalEncoder.

    errors and kwargs are passed through to the IncrementalEncoder
    constructor.
    
    Decoding iterator.

    Decodes the input strings from the iterator using an IncrementalDecoder.

    errors and kwargs are passed through to the IncrementalDecoder
    constructor.
    make_identity_dictrng make_identity_dict(rng) -> dict

        Return a dictionary where elements of the rng sequence are
        mapped to themselves.

    make_encoding_mapdecoding_map Creates an encoding map from a decoding map.

        If a target mapping in the decoding map occurs multiple
        times, then that target is mapped to None (undefined mapping),
        causing an exception when encountered by the charmap codec
        during translation.

        One example where this happens is cp875.py which decodes
        multiple character to \u001a.

    namereplace_false### Registry and builtin stateless codec functions### Constants# Byte Order Mark (BOM = ZERO WIDTH NO-BREAK SPACE = U+FEFF)# and its possible byte string values# for UTF8/UTF16/UTF32 output and little/big endian machines# UTF-8# UTF-16, little endian# UTF-16, big endian# UTF-32, little endian# UTF-32, big endian# UTF-16, native endianness# UTF-32, native endianness# Old broken names (don't use in new code)### Codec base classes (defining the API)# Private API to allow Python 3.4 to denylist the known non-Unicode# codecs in the standard library. A more general mechanism to# reliably distinguish test encodings from other codecs will hopefully# be defined for Python 3.5# See http://bugs.python.org/issue19619# Assume codecs are text encodings by default# unencoded input that is kept between calls to encode()# Overwrite this method in subclasses: It must encode input# and return an (output, length consumed) tuple# encode input (taking the buffer into account)# keep unencoded input until the next call# undecoded input that is kept between calls to decode()# Overwrite this method in subclasses: It must decode input# decode input (taking the buffer into account)# keep undecoded input until the next call# additional state info is always 0# ignore additional state info# The StreamWriter and StreamReader class provide generic working# interfaces which can be used to implement new encoding submodules# very easily. See encodings/utf_8.py for an example on how this is# done.#### If we have lines cached, first merge them back into characters# For compatibility with other read() methods that take a# single argument# read until we get the required number of characters (if available)# can the request be satisfied from the character buffer?# we need more data# decode bytes (those remaining from the last call included)# keep undecoded bytes until the next call# put new characters in the character buffer# there was no data available# Return everything we've got# Return the first chars characters# If we have lines cached from an earlier read, return# them unconditionally# revert to charbuffer mode; we might need more data# next time# If size is given, we call read() only once# If we're at a "\r" read one extra character (which might# be a "\n") to get a proper line ending. If the stream is# temporarily exhausted we return the wrong line ending.# More than one line result; the first line is a full line# to return# cache the remaining lines# only one remaining line, put it back into charbuffer# We really have a line end# Put the rest back together and keep it until the next call# we didn't get anything or this was our only try# Optional attributes set by the file wrappers below# these are needed to make "with StreamReaderWriter(...)" work properly# Seeks must be propagated to both the readers and writers# as they might need to reset their internal buffers.### Shortcuts# Force opening of the file in binary mode# Add attributes to simplify introspection### Helpers for codec lookup### Helpers for charmap-based codecs### error handlers# In --disable-unicode builds, these error handler are missing# Tell modulefinder that using codecs probably needs the encodings# packageb' codecs -- Python Codec Registry, API and helpers.


Written by Marc-Andre Lemburg (mal@lemburg.com).

(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.

'u' codecs -- Python Codec Registry, API and helpers.


Written by Marc-Andre Lemburg (mal@lemburg.com).

(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.

'b'Failed to load the builtin codecs: %s'u'Failed to load the builtin codecs: %s'b'register'u'register'b'lookup'u'lookup'b'EncodedFile'u'EncodedFile'b'BOM'u'BOM'b'BOM_BE'u'BOM_BE'b'BOM_LE'u'BOM_LE'b'BOM32_BE'u'BOM32_BE'b'BOM32_LE'u'BOM32_LE'b'BOM64_BE'u'BOM64_BE'b'BOM64_LE'u'BOM64_LE'b'BOM_UTF8'u'BOM_UTF8'b'BOM_UTF16'u'BOM_UTF16'b'BOM_UTF16_LE'u'BOM_UTF16_LE'b'BOM_UTF16_BE'u'BOM_UTF16_BE'b'BOM_UTF32'u'BOM_UTF32'b'BOM_UTF32_LE'u'BOM_UTF32_LE'b'BOM_UTF32_BE'u'BOM_UTF32_BE'b'CodecInfo'u'CodecInfo'b'Codec'u'Codec'b'IncrementalEncoder'u'IncrementalEncoder'b'IncrementalDecoder'u'IncrementalDecoder'b'StreamReader'u'StreamReader'b'StreamWriter'u'StreamWriter'b'StreamReaderWriter'u'StreamReaderWriter'b'StreamRecoder'u'StreamRecoder'b'getencoder'u'getencoder'b'getdecoder'u'getdecoder'b'getincrementalencoder'u'getincrementalencoder'b'getincrementaldecoder'u'getincrementaldecoder'b'getreader'u'getreader'b'getwriter'u'getwriter'b'iterencode'u'iterencode'b'iterdecode'u'iterdecode'b'strict_errors'u'strict_errors'b'ignore_errors'u'ignore_errors'b'replace_errors'u'replace_errors'b'xmlcharrefreplace_errors'u'xmlcharrefreplace_errors'b'backslashreplace_errors'u'backslashreplace_errors'b'namereplace_errors'u'namereplace_errors'b'register_error'u'register_error'b'lookup_error'u'lookup_error'b''b''b'  'b'  'b'Codec details when looking up the codec registry'u'Codec details when looking up the codec registry'b'<%s.%s object for encoding %s at %#x>'u'<%s.%s object for encoding %s at %#x>'b' Defines the interface for stateless encoders/decoders.

        The .encode()/.decode() methods may use different error
        handling schemes by providing the errors argument. These
        string values are predefined:

         'strict' - raise a ValueError error (or a subclass)
         'ignore' - ignore the character and continue with the next
         'replace' - replace with a suitable replacement character;
                    Python will use the official U+FFFD REPLACEMENT
                    CHARACTER for the builtin Unicode codecs on
                    decoding and '?' on encoding.
         'surrogateescape' - replace with private code points U+DCnn.
         'xmlcharrefreplace' - Replace with the appropriate XML
                               character reference (only for encoding).
         'backslashreplace'  - Replace with backslashed escape sequences.
         'namereplace'       - Replace with \N{...} escape sequences
                               (only for encoding).

        The set of allowed values can be extended via register_error.

    'u' Defines the interface for stateless encoders/decoders.

        The .encode()/.decode() methods may use different error
        handling schemes by providing the errors argument. These
        string values are predefined:

         'strict' - raise a ValueError error (or a subclass)
         'ignore' - ignore the character and continue with the next
         'replace' - replace with a suitable replacement character;
                    Python will use the official U+FFFD REPLACEMENT
                    CHARACTER for the builtin Unicode codecs on
                    decoding and '?' on encoding.
         'surrogateescape' - replace with private code points U+DCnn.
         'xmlcharrefreplace' - Replace with the appropriate XML
                               character reference (only for encoding).
         'backslashreplace'  - Replace with backslashed escape sequences.
         'namereplace'       - Replace with \N{...} escape sequences
                               (only for encoding).

        The set of allowed values can be extended via register_error.

    'b' Encodes the object input and returns a tuple (output
            object, length consumed).

            errors defines the error handling to apply. It defaults to
            'strict' handling.

            The method may not store state in the Codec instance. Use
            StreamWriter for codecs which have to keep state in order to
            make encoding efficient.

            The encoder must be able to handle zero length input and
            return an empty object of the output object type in this
            situation.

        'u' Encodes the object input and returns a tuple (output
            object, length consumed).

            errors defines the error handling to apply. It defaults to
            'strict' handling.

            The method may not store state in the Codec instance. Use
            StreamWriter for codecs which have to keep state in order to
            make encoding efficient.

            The encoder must be able to handle zero length input and
            return an empty object of the output object type in this
            situation.

        'b' Decodes the object input and returns a tuple (output
            object, length consumed).

            input must be an object which provides the bf_getreadbuf
            buffer slot. Python strings, buffer objects and memory
            mapped files are examples of objects providing this slot.

            errors defines the error handling to apply. It defaults to
            'strict' handling.

            The method may not store state in the Codec instance. Use
            StreamReader for codecs which have to keep state in order to
            make decoding efficient.

            The decoder must be able to handle zero length input and
            return an empty object of the output object type in this
            situation.

        'u' Decodes the object input and returns a tuple (output
            object, length consumed).

            input must be an object which provides the bf_getreadbuf
            buffer slot. Python strings, buffer objects and memory
            mapped files are examples of objects providing this slot.

            errors defines the error handling to apply. It defaults to
            'strict' handling.

            The method may not store state in the Codec instance. Use
            StreamReader for codecs which have to keep state in order to
            make decoding efficient.

            The decoder must be able to handle zero length input and
            return an empty object of the output object type in this
            situation.

        'b'
    An IncrementalEncoder encodes an input in multiple steps. The input can
    be passed piece by piece to the encode() method. The IncrementalEncoder
    remembers the state of the encoding process between calls to encode().
    'u'
    An IncrementalEncoder encodes an input in multiple steps. The input can
    be passed piece by piece to the encode() method. The IncrementalEncoder
    remembers the state of the encoding process between calls to encode().
    'b'
        Creates an IncrementalEncoder instance.

        The IncrementalEncoder may use different error handling schemes by
        providing the errors keyword argument. See the module docstring
        for a list of possible values.
        'u'
        Creates an IncrementalEncoder instance.

        The IncrementalEncoder may use different error handling schemes by
        providing the errors keyword argument. See the module docstring
        for a list of possible values.
        'b'
        Encodes input and returns the resulting object.
        'u'
        Encodes input and returns the resulting object.
        'b'
        Resets the encoder to the initial state.
        'u'
        Resets the encoder to the initial state.
        'b'
        Return the current state of the encoder.
        'u'
        Return the current state of the encoder.
        'b'
        Set the current state of the encoder. state must have been
        returned by getstate().
        'u'
        Set the current state of the encoder. state must have been
        returned by getstate().
        'b'
    This subclass of IncrementalEncoder can be used as the baseclass for an
    incremental encoder if the encoder must keep some of the output in a
    buffer between calls to encode().
    'u'
    This subclass of IncrementalEncoder can be used as the baseclass for an
    incremental encoder if the encoder must keep some of the output in a
    buffer between calls to encode().
    'b'
    An IncrementalDecoder decodes an input in multiple steps. The input can
    be passed piece by piece to the decode() method. The IncrementalDecoder
    remembers the state of the decoding process between calls to decode().
    'u'
    An IncrementalDecoder decodes an input in multiple steps. The input can
    be passed piece by piece to the decode() method. The IncrementalDecoder
    remembers the state of the decoding process between calls to decode().
    'b'
        Create an IncrementalDecoder instance.

        The IncrementalDecoder may use different error handling schemes by
        providing the errors keyword argument. See the module docstring
        for a list of possible values.
        'u'
        Create an IncrementalDecoder instance.

        The IncrementalDecoder may use different error handling schemes by
        providing the errors keyword argument. See the module docstring
        for a list of possible values.
        'b'
        Decode input and returns the resulting object.
        'u'
        Decode input and returns the resulting object.
        'b'
        Reset the decoder to the initial state.
        'u'
        Reset the decoder to the initial state.
        'b'
        Return the current state of the decoder.

        This must be a (buffered_input, additional_state_info) tuple.
        buffered_input must be a bytes object containing bytes that
        were passed to decode() that have not yet been converted.
        additional_state_info must be a non-negative integer
        representing the state of the decoder WITHOUT yet having
        processed the contents of buffered_input.  In the initial state
        and after reset(), getstate() must return (b"", 0).
        'u'
        Return the current state of the decoder.

        This must be a (buffered_input, additional_state_info) tuple.
        buffered_input must be a bytes object containing bytes that
        were passed to decode() that have not yet been converted.
        additional_state_info must be a non-negative integer
        representing the state of the decoder WITHOUT yet having
        processed the contents of buffered_input.  In the initial state
        and after reset(), getstate() must return (b"", 0).
        'b'
        Set the current state of the decoder.

        state must have been returned by getstate().  The effect of
        setstate((b"", 0)) must be equivalent to reset().
        'u'
        Set the current state of the decoder.

        state must have been returned by getstate().  The effect of
        setstate((b"", 0)) must be equivalent to reset().
        'b'
    This subclass of IncrementalDecoder can be used as the baseclass for an
    incremental decoder if the decoder must be able to handle incomplete
    byte sequences.
    'u'
    This subclass of IncrementalDecoder can be used as the baseclass for an
    incremental decoder if the decoder must be able to handle incomplete
    byte sequences.
    'b' Creates a StreamWriter instance.

            stream must be a file-like object open for writing.

            The StreamWriter may use different error handling
            schemes by providing the errors keyword argument. These
            parameters are predefined:

             'strict' - raise a ValueError (or a subclass)
             'ignore' - ignore the character and continue with the next
             'replace'- replace with a suitable replacement character
             'xmlcharrefreplace' - Replace with the appropriate XML
                                   character reference.
             'backslashreplace'  - Replace with backslashed escape
                                   sequences.
             'namereplace'       - Replace with \N{...} escape sequences.

            The set of allowed parameter values can be extended via
            register_error.
        'u' Creates a StreamWriter instance.

            stream must be a file-like object open for writing.

            The StreamWriter may use different error handling
            schemes by providing the errors keyword argument. These
            parameters are predefined:

             'strict' - raise a ValueError (or a subclass)
             'ignore' - ignore the character and continue with the next
             'replace'- replace with a suitable replacement character
             'xmlcharrefreplace' - Replace with the appropriate XML
                                   character reference.
             'backslashreplace'  - Replace with backslashed escape
                                   sequences.
             'namereplace'       - Replace with \N{...} escape sequences.

            The set of allowed parameter values can be extended via
            register_error.
        'b' Writes the object's contents encoded to self.stream.
        'u' Writes the object's contents encoded to self.stream.
        'b' Writes the concatenated list of strings to the stream
            using .write().
        'u' Writes the concatenated list of strings to the stream
            using .write().
        'b' Resets the codec buffers used for keeping internal state.

            Calling this method should ensure that the data on the
            output is put into a clean state, that allows appending
            of new fresh data without having to rescan the whole
            stream to recover state.

        'u' Resets the codec buffers used for keeping internal state.

            Calling this method should ensure that the data on the
            output is put into a clean state, that allows appending
            of new fresh data without having to rescan the whole
            stream to recover state.

        'b' Inherit all other methods from the underlying stream.
        'u' Inherit all other methods from the underlying stream.
        'b'can't serialize %s'u'can't serialize %s'b' Creates a StreamReader instance.

            stream must be a file-like object open for reading.

            The StreamReader may use different error handling
            schemes by providing the errors keyword argument. These
            parameters are predefined:

             'strict' - raise a ValueError (or a subclass)
             'ignore' - ignore the character and continue with the next
             'replace'- replace with a suitable replacement character
             'backslashreplace' - Replace with backslashed escape sequences;

            The set of allowed parameter values can be extended via
            register_error.
        'u' Creates a StreamReader instance.

            stream must be a file-like object open for reading.

            The StreamReader may use different error handling
            schemes by providing the errors keyword argument. These
            parameters are predefined:

             'strict' - raise a ValueError (or a subclass)
             'ignore' - ignore the character and continue with the next
             'replace'- replace with a suitable replacement character
             'backslashreplace' - Replace with backslashed escape sequences;

            The set of allowed parameter values can be extended via
            register_error.
        'b' Decodes data from the stream self.stream and returns the
            resulting object.

            chars indicates the number of decoded code points or bytes to
            return. read() will never return more data than requested,
            but it might return less, if there is not enough available.

            size indicates the approximate maximum number of decoded
            bytes or code points to read for decoding. The decoder
            can modify this setting as appropriate. The default value
            -1 indicates to read and decode as much as possible.  size
            is intended to prevent having to decode huge files in one
            step.

            If firstline is true, and a UnicodeDecodeError happens
            after the first line terminator in the input only the first line
            will be returned, the rest of the input will be kept until the
            next call to read().

            The method should use a greedy read strategy, meaning that
            it should read as much data as is allowed within the
            definition of the encoding and the given size, e.g.  if
            optional encoding endings or state markers are available
            on the stream, these should be read too.
        'u' Decodes data from the stream self.stream and returns the
            resulting object.

            chars indicates the number of decoded code points or bytes to
            return. read() will never return more data than requested,
            but it might return less, if there is not enough available.

            size indicates the approximate maximum number of decoded
            bytes or code points to read for decoding. The decoder
            can modify this setting as appropriate. The default value
            -1 indicates to read and decode as much as possible.  size
            is intended to prevent having to decode huge files in one
            step.

            If firstline is true, and a UnicodeDecodeError happens
            after the first line terminator in the input only the first line
            will be returned, the rest of the input will be kept until the
            next call to read().

            The method should use a greedy read strategy, meaning that
            it should read as much data as is allowed within the
            definition of the encoding and the given size, e.g.  if
            optional encoding endings or state markers are available
            on the stream, these should be read too.
        'b' Read one line from the input stream and return the
            decoded data.

            size, if given, is passed as size argument to the
            read() method.

        'u' Read one line from the input stream and return the
            decoded data.

            size, if given, is passed as size argument to the
            read() method.

        'b' Read all lines available on the input stream
            and return them as a list.

            Line breaks are implemented using the codec's decoder
            method and are included in the list entries.

            sizehint, if given, is ignored since there is no efficient
            way to finding the true end-of-line.

        'u' Read all lines available on the input stream
            and return them as a list.

            Line breaks are implemented using the codec's decoder
            method and are included in the list entries.

            sizehint, if given, is ignored since there is no efficient
            way to finding the true end-of-line.

        'b' Resets the codec buffers used for keeping internal state.

            Note that no stream repositioning should take place.
            This method is primarily intended to be able to recover
            from decoding errors.

        'u' Resets the codec buffers used for keeping internal state.

            Note that no stream repositioning should take place.
            This method is primarily intended to be able to recover
            from decoding errors.

        'b' Set the input stream's current position.

            Resets the codec buffers used for keeping state.
        'u' Set the input stream's current position.

            Resets the codec buffers used for keeping state.
        'b' Return the next decoded line from the input stream.'u' Return the next decoded line from the input stream.'b' StreamReaderWriter instances allow wrapping streams which
        work in both read and write modes.

        The design is such that one can use the factory functions
        returned by the codec.lookup() function to construct the
        instance.

    'u' StreamReaderWriter instances allow wrapping streams which
        work in both read and write modes.

        The design is such that one can use the factory functions
        returned by the codec.lookup() function to construct the
        instance.

    'b'unknown'u'unknown'b' Creates a StreamReaderWriter instance.

            stream must be a Stream-like object.

            Reader, Writer must be factory functions or classes
            providing the StreamReader, StreamWriter interface resp.

            Error handling is done in the same way as defined for the
            StreamWriter/Readers.

        'u' Creates a StreamReaderWriter instance.

            stream must be a Stream-like object.

            Reader, Writer must be factory functions or classes
            providing the StreamReader, StreamWriter interface resp.

            Error handling is done in the same way as defined for the
            StreamWriter/Readers.

        'b' StreamRecoder instances translate data from one encoding to another.

        They use the complete set of APIs returned by the
        codecs.lookup() function to implement their task.

        Data written to the StreamRecoder is first decoded into an
        intermediate format (depending on the "decode" codec) and then
        written to the underlying stream using an instance of the provided
        Writer class.

        In the other direction, data is read from the underlying stream using
        a Reader instance and then encoded and returned to the caller.

    'u' StreamRecoder instances translate data from one encoding to another.

        They use the complete set of APIs returned by the
        codecs.lookup() function to implement their task.

        Data written to the StreamRecoder is first decoded into an
        intermediate format (depending on the "decode" codec) and then
        written to the underlying stream using an instance of the provided
        Writer class.

        In the other direction, data is read from the underlying stream using
        a Reader instance and then encoded and returned to the caller.

    'b' Creates a StreamRecoder instance which implements a two-way
            conversion: encode and decode work on the frontend (the
            data visible to .read() and .write()) while Reader and Writer
            work on the backend (the data in stream).

            You can use these objects to do transparent
            transcodings from e.g. latin-1 to utf-8 and back.

            stream must be a file-like object.

            encode and decode must adhere to the Codec interface; Reader and
            Writer must be factory functions or classes providing the
            StreamReader and StreamWriter interfaces resp.

            Error handling is done in the same way as defined for the
            StreamWriter/Readers.

        'u' Creates a StreamRecoder instance which implements a two-way
            conversion: encode and decode work on the frontend (the
            data visible to .read() and .write()) while Reader and Writer
            work on the backend (the data in stream).

            You can use these objects to do transparent
            transcodings from e.g. latin-1 to utf-8 and back.

            stream must be a file-like object.

            encode and decode must adhere to the Codec interface; Reader and
            Writer must be factory functions or classes providing the
            StreamReader and StreamWriter interfaces resp.

            Error handling is done in the same way as defined for the
            StreamWriter/Readers.

        'b' Open an encoded file using the given mode and return
        a wrapped version providing transparent encoding/decoding.

        Note: The wrapped version will only accept the object format
        defined by the codecs, i.e. Unicode objects for most builtin
        codecs. Output is also codec dependent and will usually be
        Unicode as well.

        If encoding is not None, then the
        underlying encoded files are always opened in binary mode.
        The default file mode is 'r', meaning to open the file in read mode.

        encoding specifies the encoding which is to be used for the
        file.

        errors may be given to define the error handling. It defaults
        to 'strict' which causes ValueErrors to be raised in case an
        encoding error occurs.

        buffering has the same meaning as for the builtin open() API.
        It defaults to -1 which means that the default buffer size will
        be used.

        The returned wrapped file object provides an extra attribute
        .encoding which allows querying the used encoding. This
        attribute is only available if an encoding was specified as
        parameter.

    'u' Open an encoded file using the given mode and return
        a wrapped version providing transparent encoding/decoding.

        Note: The wrapped version will only accept the object format
        defined by the codecs, i.e. Unicode objects for most builtin
        codecs. Output is also codec dependent and will usually be
        Unicode as well.

        If encoding is not None, then the
        underlying encoded files are always opened in binary mode.
        The default file mode is 'r', meaning to open the file in read mode.

        encoding specifies the encoding which is to be used for the
        file.

        errors may be given to define the error handling. It defaults
        to 'strict' which causes ValueErrors to be raised in case an
        encoding error occurs.

        buffering has the same meaning as for the builtin open() API.
        It defaults to -1 which means that the default buffer size will
        be used.

        The returned wrapped file object provides an extra attribute
        .encoding which allows querying the used encoding. This
        attribute is only available if an encoding was specified as
        parameter.

    'b' Return a wrapped version of file which provides transparent
        encoding translation.

        Data written to the wrapped file is decoded according
        to the given data_encoding and then encoded to the underlying
        file using file_encoding. The intermediate data type
        will usually be Unicode but depends on the specified codecs.

        Bytes read from the file are decoded using file_encoding and then
        passed back to the caller encoded using data_encoding.

        If file_encoding is not given, it defaults to data_encoding.

        errors may be given to define the error handling. It defaults
        to 'strict' which causes ValueErrors to be raised in case an
        encoding error occurs.

        The returned wrapped file object provides two extra attributes
        .data_encoding and .file_encoding which reflect the given
        parameters of the same name. The attributes can be used for
        introspection by Python programs.

    'u' Return a wrapped version of file which provides transparent
        encoding translation.

        Data written to the wrapped file is decoded according
        to the given data_encoding and then encoded to the underlying
        file using file_encoding. The intermediate data type
        will usually be Unicode but depends on the specified codecs.

        Bytes read from the file are decoded using file_encoding and then
        passed back to the caller encoded using data_encoding.

        If file_encoding is not given, it defaults to data_encoding.

        errors may be given to define the error handling. It defaults
        to 'strict' which causes ValueErrors to be raised in case an
        encoding error occurs.

        The returned wrapped file object provides two extra attributes
        .data_encoding and .file_encoding which reflect the given
        parameters of the same name. The attributes can be used for
        introspection by Python programs.

    'b' Lookup up the codec for the given encoding and return
        its encoder function.

        Raises a LookupError in case the encoding cannot be found.

    'u' Lookup up the codec for the given encoding and return
        its encoder function.

        Raises a LookupError in case the encoding cannot be found.

    'b' Lookup up the codec for the given encoding and return
        its decoder function.

        Raises a LookupError in case the encoding cannot be found.

    'u' Lookup up the codec for the given encoding and return
        its decoder function.

        Raises a LookupError in case the encoding cannot be found.

    'b' Lookup up the codec for the given encoding and return
        its IncrementalEncoder class or factory function.

        Raises a LookupError in case the encoding cannot be found
        or the codecs doesn't provide an incremental encoder.

    'u' Lookup up the codec for the given encoding and return
        its IncrementalEncoder class or factory function.

        Raises a LookupError in case the encoding cannot be found
        or the codecs doesn't provide an incremental encoder.

    'b' Lookup up the codec for the given encoding and return
        its IncrementalDecoder class or factory function.

        Raises a LookupError in case the encoding cannot be found
        or the codecs doesn't provide an incremental decoder.

    'u' Lookup up the codec for the given encoding and return
        its IncrementalDecoder class or factory function.

        Raises a LookupError in case the encoding cannot be found
        or the codecs doesn't provide an incremental decoder.

    'b' Lookup up the codec for the given encoding and return
        its StreamReader class or factory function.

        Raises a LookupError in case the encoding cannot be found.

    'u' Lookup up the codec for the given encoding and return
        its StreamReader class or factory function.

        Raises a LookupError in case the encoding cannot be found.

    'b' Lookup up the codec for the given encoding and return
        its StreamWriter class or factory function.

        Raises a LookupError in case the encoding cannot be found.

    'u' Lookup up the codec for the given encoding and return
        its StreamWriter class or factory function.

        Raises a LookupError in case the encoding cannot be found.

    'b'
    Encoding iterator.

    Encodes the input strings from the iterator using an IncrementalEncoder.

    errors and kwargs are passed through to the IncrementalEncoder
    constructor.
    'u'
    Encoding iterator.

    Encodes the input strings from the iterator using an IncrementalEncoder.

    errors and kwargs are passed through to the IncrementalEncoder
    constructor.
    'b'
    Decoding iterator.

    Decodes the input strings from the iterator using an IncrementalDecoder.

    errors and kwargs are passed through to the IncrementalDecoder
    constructor.
    'u'
    Decoding iterator.

    Decodes the input strings from the iterator using an IncrementalDecoder.

    errors and kwargs are passed through to the IncrementalDecoder
    constructor.
    'b' make_identity_dict(rng) -> dict

        Return a dictionary where elements of the rng sequence are
        mapped to themselves.

    'u' make_identity_dict(rng) -> dict

        Return a dictionary where elements of the rng sequence are
        mapped to themselves.

    'b' Creates an encoding map from a decoding map.

        If a target mapping in the decoding map occurs multiple
        times, then that target is mapped to None (undefined mapping),
        causing an exception when encountered by the charmap codec
        during translation.

        One example where this happens is cp875.py which decodes
        multiple character to \u001a.

    'u' Creates an encoding map from a decoding map.

        If a target mapping in the decoding map occurs multiple
        times, then that target is mapped to None (undefined mapping),
        causing an exception when encountered by the charmap codec
        during translation.

        One example where this happens is cp875.py which decodes
        multiple character to \u001a.

    'b'replace'u'replace'b'namereplace'u'namereplace'u'Lib.codecs'u'codecs'Utilities to compile possibly incomplete Python source code.

This module provides two interfaces, broadly similar to the builtin
function compile(), which take program text, a filename and a 'mode'
and:

- Return code object if the command is complete and valid
- Return None if the command is incomplete
- Raise SyntaxError, ValueError or OverflowError if the command is a
  syntax error (OverflowError and ValueError can be produced by
  malformed literals).

The two interfaces are:

compile_command(source, filename, symbol):

    Compiles a single command in the manner described above.

CommandCompiler():

    Instances of this class have __call__ methods identical in
    signature to compile_command; the difference is that if the
    instance compiles program text containing a __future__ statement,
    the instance 'remembers' and compiles all subsequent program texts
    with the statement in force.

The module also provides another class:

Compile():

    Instances of this class act like the built-in function compile,
    but with 'memory' in the sense described above.
__future___featuresCompile0x200PyCF_DONT_IMPLY_DEDENT0x4000PyCF_ALLOW_INCOMPLETE_INPUT_maybe_compilecompilerincomplete inputincomplete_input_is_syntax_errorerr1err2rep1rep2was never closedCompile a command and determine whether it is incomplete.

    Arguments:

    source -- the source string; may contain \n characters
    filename -- optional filename from which source was read; default
                "<input>"
    symbol -- optional grammar start symbol; "single" (default), "exec"
              or "eval"

    Return value / exceptions raised:

    - Return a code object if the command is complete and valid
    - Return None if the command is incomplete
    - Raise SyntaxError, ValueError or OverflowError if the command is a
      syntax error (OverflowError and ValueError can be produced by
      malformed literals).
    Instances of this class behave much like the built-in compile
    function, but if one is used to compile text containing a future
    statement, it "remembers" and compiles all subsequent program texts
    with the statement in force.codeobfeatureInstances of this class have __call__ methods identical in
    signature to compile_command; the difference is that if the
    instance compiles program text containing a __future__ statement,
    the instance 'remembers' and compiles all subsequent program texts
    with the statement in force.Compile a command and determine whether it is incomplete.

        Arguments:

        source -- the source string; may contain \n characters
        filename -- optional filename from which source was read;
                    default "<input>"
        symbol -- optional grammar start symbol; "single" (default) or
                  "eval"

        Return value / exceptions raised:

        - Return a code object if the command is complete and valid
        - Return None if the command is incomplete
        - Raise SyntaxError, ValueError or OverflowError if the command is a
          syntax error (OverflowError and ValueError can be produced by
          malformed literals).
        # The following flags match the values from Include/cpython/compile.h# Caveat emptor: These flags are undocumented on purpose and depending# on their effect outside the standard library is **unsupported**.# Check for source consisting of only blank lines and comments.# Leave it alone.# Replace it with a 'pass' statement# Disable compiler warnings when checking for incomplete input.# Let other compile() errors propagate.# fallthroughb'Utilities to compile possibly incomplete Python source code.

This module provides two interfaces, broadly similar to the builtin
function compile(), which take program text, a filename and a 'mode'
and:

- Return code object if the command is complete and valid
- Return None if the command is incomplete
- Raise SyntaxError, ValueError or OverflowError if the command is a
  syntax error (OverflowError and ValueError can be produced by
  malformed literals).

The two interfaces are:

compile_command(source, filename, symbol):

    Compiles a single command in the manner described above.

CommandCompiler():

    Instances of this class have __call__ methods identical in
    signature to compile_command; the difference is that if the
    instance compiles program text containing a __future__ statement,
    the instance 'remembers' and compiles all subsequent program texts
    with the statement in force.

The module also provides another class:

Compile():

    Instances of this class act like the built-in function compile,
    but with 'memory' in the sense described above.
'u'Utilities to compile possibly incomplete Python source code.

This module provides two interfaces, broadly similar to the builtin
function compile(), which take program text, a filename and a 'mode'
and:

- Return code object if the command is complete and valid
- Return None if the command is incomplete
- Raise SyntaxError, ValueError or OverflowError if the command is a
  syntax error (OverflowError and ValueError can be produced by
  malformed literals).

The two interfaces are:

compile_command(source, filename, symbol):

    Compiles a single command in the manner described above.

CommandCompiler():

    Instances of this class have __call__ methods identical in
    signature to compile_command; the difference is that if the
    instance compiles program text containing a __future__ statement,
    the instance 'remembers' and compiles all subsequent program texts
    with the statement in force.

The module also provides another class:

Compile():

    Instances of this class act like the built-in function compile,
    but with 'memory' in the sense described above.
'b'Compile'u'Compile'b'CommandCompiler'u'CommandCompiler'b'incomplete input'u'incomplete input'b'was never closed'u'was never closed'b'Compile a command and determine whether it is incomplete.

    Arguments:

    source -- the source string; may contain \n characters
    filename -- optional filename from which source was read; default
                "<input>"
    symbol -- optional grammar start symbol; "single" (default), "exec"
              or "eval"

    Return value / exceptions raised:

    - Return a code object if the command is complete and valid
    - Return None if the command is incomplete
    - Raise SyntaxError, ValueError or OverflowError if the command is a
      syntax error (OverflowError and ValueError can be produced by
      malformed literals).
    'u'Compile a command and determine whether it is incomplete.

    Arguments:

    source -- the source string; may contain \n characters
    filename -- optional filename from which source was read; default
                "<input>"
    symbol -- optional grammar start symbol; "single" (default), "exec"
              or "eval"

    Return value / exceptions raised:

    - Return a code object if the command is complete and valid
    - Return None if the command is incomplete
    - Raise SyntaxError, ValueError or OverflowError if the command is a
      syntax error (OverflowError and ValueError can be produced by
      malformed literals).
    'b'Instances of this class behave much like the built-in compile
    function, but if one is used to compile text containing a future
    statement, it "remembers" and compiles all subsequent program texts
    with the statement in force.'u'Instances of this class behave much like the built-in compile
    function, but if one is used to compile text containing a future
    statement, it "remembers" and compiles all subsequent program texts
    with the statement in force.'b'incomplete_input'u'incomplete_input'b'Instances of this class have __call__ methods identical in
    signature to compile_command; the difference is that if the
    instance compiles program text containing a __future__ statement,
    the instance 'remembers' and compiles all subsequent program texts
    with the statement in force.'u'Instances of this class have __call__ methods identical in
    signature to compile_command; the difference is that if the
    instance compiles program text containing a __future__ statement,
    the instance 'remembers' and compiles all subsequent program texts
    with the statement in force.'b'Compile a command and determine whether it is incomplete.

        Arguments:

        source -- the source string; may contain \n characters
        filename -- optional filename from which source was read;
                    default "<input>"
        symbol -- optional grammar start symbol; "single" (default) or
                  "eval"

        Return value / exceptions raised:

        - Return a code object if the command is complete and valid
        - Return None if the command is incomplete
        - Raise SyntaxError, ValueError or OverflowError if the command is a
          syntax error (OverflowError and ValueError can be produced by
          malformed literals).
        'u'Compile a command and determine whether it is incomplete.

        Arguments:

        source -- the source string; may contain \n characters
        filename -- optional filename from which source was read;
                    default "<input>"
        symbol -- optional grammar start symbol; "single" (default) or
                  "eval"

        Return value / exceptions raised:

        - Return a code object if the command is complete and valid
        - Return None if the command is incomplete
        - Raise SyntaxError, ValueError or OverflowError if the command is a
          syntax error (OverflowError and ValueError can be produced by
          malformed literals).
        'u'Lib.codeop'u'codeop'ClientListenerPipereductionForkingPickler_ForkingPicklerBUFSIZE20.020.CONNECTION_TIMEOUT_mmap_counterdefault_familyfamiliesAF_PIPE_init_timeout_check_timeoutarbitrary_address
    Return an arbitrary free address for the given family
    localhostmktemplistener-get_temp_dir\\.\pipe\pyc-%d-%d-unrecognized family_validate_family
    Checks if the family is valid for the current environment.
    Family %s is not recognized.address_type
    Return the types of the address

    This can be 'AF_INET', 'AF_UNIX', or 'AF_PIPE'
    is_abstract_socket_namespaceaddress type of %r unrecognized_ConnectionBase_handleinvalid handleat least one of `readable` and `writable` must be True_readable_writablehandle is closed_check_readableconnection is write-only_check_writableconnection is read-only_bad_message_lengthbad message lengthTrue if the connection is closedTrue if the connection is readableTrue if the connection is writableFile descriptor or handle of the connectionClose the connectionsend_bytesSend the bytes data from a bytes-like objectoffset is negativebuffer length < offsetsize is negativebuffer length < offset + size_send_bytesSend a (picklable) objectrecv_bytesmaxlength
        Receive bytes data as a bytes object.
        negative maxlength_recv_bytesrecv_bytes_into
        Receive bytes data into a writeable bytes-like object.
        Return the number of bytes read.
        bytesizenegative offsetoffset too largerecvReceive a (picklable) objectWhether there is any input available to be read_pollPipeConnection
        Connection class based on a Windows named pipe.
        Overlapped I/O is used, so the handles must have been created
        with FILE_FLAG_OVERLAPPED.
        _got_empty_message_send_ov_CloseHandleovconcurrent send_bytes() calls are not supported"concurrent send_bytes() calls ""are not supported"overlappedwaitresnwrittenbsizenread_get_more_datashouldn't get here; expected KeyboardInterruptrbytes
    Connection class based on an arbitrary file descriptor (Unix only), or
    a socket handle (Windows).
    closesocket_write_read_sendremaining_recvgot end of file during message21474836470x7fffffff!ipre_header!Q
    Returns a listener object.

    This is a wrapper for a bound socket which is 'listening' for
    connections, or for a Windows named pipe.
    authkeyPipeListener_listenerSocketListenerauthkey should be a byte string_authkeyaccept
        Accept a connection on the bound socket or named pipe of `self`.

        Returns a `Connection` object.
        listener is closeddeliver_challengeanswer_challenge
        Close the bound socket or named pipe of `self`.
        listener_addresslast_accepted_last_accepted
    Returns a connection to the address of a `Listener`
    PipeClientSocketClientduplex
        Returns pair of connection objects at either end of a pipe
        socketpairs1s2c1c2fd1fd2openmodeaccessobsizeibsizeh1h2
    Representation of a socket which is bound to an address and listening
    getsockname_familyFinalizeexitpriority_unlink
    Return a connection object connected to the socket given by `address`
    
        Representation of a named pipe
        _new_handle_handle_queuesub_debuglistener created with address=%r_finalize_pipe_listenerclosing listener with address=%r
        Return a connection object connected to the pipe given by `address`
        MESSAGE_LENGTH#CHALLENGE#_CHALLENGE#WELCOME#_WELCOME#FAILURE#_FAILURE_ALLOWED_DIGESTS_MAX_DIGEST_LEN_MD5ONLY_MESSAGE_LENGTH_MD5_DIGEST_LEN_LEGACY_LENGTHS_get_digest_name_and_payloadReturns a digest name and the payload for a response hash.

    If a legacy protocol is detected based on the message length
    or contents the digest name returned will be empty to indicate
    legacy mode where MD5 and no digest prefix should be sent.
    curlyunsupported message length, missing digest prefix, or unsupported digest: 'unsupported message length, missing digest prefix, ''or unsupported digest: '_create_responseCreate a MAC based on authkey and message

    The MAC algorithm defaults to HMAC-MD5, unless MD5 is not available or
    the message has a '{digest_name}' prefix. For legacy HMAC-MD5, the response
    is the raw MAC, otherwise the response is prefixed with '{digest_name}',
    e.g. b'{sha256}abcdefg...'

    Note: The MAC protects the entire message including the digest_name prefix.
    hmacdigest_name{%s}%s_verify_challengeVerify MAC challenge

    If our message did not include a digest_name prefix, the client is allowed
    to select a stronger digest_name from _ALLOWED_DIGESTS.

    In case our message is prefixed, a client cannot downgrade to a weaker
    algorithm, because the MAC is calculated over the entire message
    including the '{digest_name}' prefix.
    response_digestresponse_mac unsupportedexpected  of length  got compare_digestdigest received was wrongAuthkey must be bytes, not {0!s}protocol constrainturandomProtocol error, expected challenge: challenge too short: {len(message)} bytesdigest sent was rejectedConnectionWrapper_conn_dumps_loads_xml_dumps_xml_loadsXmlListenerXmlClient_exhaustive_waithandlesreadyShould not get here_ready_errorsobject_list
        Wait till an object in object_list is ready/readable.

        Returns list of those objects in object_list which are ready/readable.
        waithandle_to_objov_listready_objectsready_handlesselectorsPollSelector_WaitSelectorSelectSelectorselectorEVENT_READdeadlinereduce_connectionresource_sharerDupSocketdsrebuild_connectionreduce_pipe_connectionDupHandledhrebuild_pipe_connectionDupFddf# A higher level module for using sockets (or Windows named pipes)# multiprocessing/connection.py# A very generous timeout when it comes to local connections...# double check# Connection classes# XXX should we use util.Finalize instead of a __del__?# Get bytesize of arbitrary buffer# Message can fit in dest# Interrupt WaitForMultipleObjects() in _send_bytes()# A connection should only be used by a single thread# close() was called by another thread while# WaitForMultipleObjects() was waiting for the overlapped# operation.# For wire compatibility with 3.7 and lower# The payload is large so Nagle's algorithm won't be triggered# and we'd better avoid the cost of concatenation.# Issue #20540: concatenate before sending, to avoid delays due# to Nagle's algorithm on a TCP socket.# Also note we want to avoid sending a 0-length buffer separately,# to avoid "broken pipe" errors if the other end closed the pipe.# Public functions# default security descriptor: the handle cannot be inherited# Definitions for connections based on sockets# SO_REUSEADDR has different semantics on Windows (issue #2550).# Linux abstract socket namespaces do not need to be explicitly unlinked# Definitions for connections based on named pipes# ERROR_NO_DATA can occur if a client has already connected,# written data and then disconnected -- see Issue 14725.# Authentication stuff# MUST be > 20# multiprocessing.connection Authentication Handshake Protocol Description# (as documented for reference after reading the existing code)# =============================================================================# On Windows: native pipes with "overlapped IO" are used to send the bytes,# instead of the length prefix SIZE scheme described below. (ie: the OS deals# with message sizes for us)# Protocol error behaviors:# On POSIX, any failure to receive the length prefix into SIZE, for SIZE greater# than the requested maxsize to receive, or receiving fewer than SIZE bytes# results in the connection being closed and auth to fail.# On Windows, receiving too few bytes is never a low level _recv_bytes read# error, receiving too many will trigger an error only if receive maxsize# value was larger than 128 OR the if the data arrived in smaller pieces.#      Serving side                           Client side#     ------------------------------  ---------------------------------------# 0.                                  Open a connection on the pipe.# 1.  Accept connection.# 2.  Random 20+ bytes -> MESSAGE#     Modern servers always send#     more than 20 bytes and include#     a {digest} prefix on it with#     their preferred HMAC digest.#     Legacy ones send ==20 bytes.# 3.  send 4 byte length (net order)#     prefix followed by:#       b'#CHALLENGE#' + MESSAGE# 4.                                  Receive 4 bytes, parse as network byte#                                     order integer. If it is -1, receive an#                                     additional 8 bytes, parse that as network#                                     byte order. The result is the length of#                                     the data that follows -> SIZE.# 5.                                  Receive min(SIZE, 256) bytes -> M1# 6.                                  Assert that M1 starts with:#                                       b'#CHALLENGE#'# 7.                                  Strip that prefix from M1 into -> M2# 7.1.                                Parse M2: if it is exactly 20 bytes in#                                     length this indicates a legacy server#                                     supporting only HMAC-MD5. Otherwise the# 7.2.                                preferred digest is looked up from an#                                     expected "{digest}" prefix on M2. No prefix#                                     or unsupported digest? <- AuthenticationError# 7.3.                                Put divined algorithm name in -> D_NAME# 8.                                  Compute HMAC-D_NAME of AUTHKEY, M2 -> C_DIGEST# 9.                                  Send 4 byte length prefix (net order)#                                     followed by C_DIGEST bytes.# 10. Receive 4 or 4+8 byte length#     prefix (#4 dance) -> SIZE.# 11. Receive min(SIZE, 256) -> C_D.# 11.1. Parse C_D: legacy servers#     accept it as is, "md5" -> D_NAME# 11.2. modern servers check the length#     of C_D, IF it is 16 bytes?# 11.2.1. "md5" -> D_NAME#         and skip to step 12.# 11.3. longer? expect and parse a "{digest}"#     prefix into -> D_NAME.#     Strip the prefix and store remaining#     bytes in -> C_D.# 11.4. Don't like D_NAME? <- AuthenticationError# 12. Compute HMAC-D_NAME of AUTHKEY,#     MESSAGE into -> M_DIGEST.# 13. Compare M_DIGEST == C_D:# 14a: Match? Send length prefix &#       b'#WELCOME#'#    <- RETURN# 14b: Mismatch? Send len prefix &#       b'#FAILURE#'#    <- CLOSE & AuthenticationError# 15.                                 Receive 4 or 4+8 byte length prefix (net#                                     order) again as in #4 into -> SIZE.# 16.                                 Receive min(SIZE, 256) bytes -> M3.# 17.                                 Compare M3 == b'#WELCOME#':# 17a.                                Match? <- RETURN# 17b.                                Mismatch? <- CLOSE & AuthenticationError# If this RETURNed, the connection remains open: it has been authenticated.# Length prefixes are used consistently. Even on the legacy protocol, this# was good fortune and allowed us to evolve the protocol by using the length# of the opening challenge or length of the returned digest as a signal as# to which protocol the other end supports.# Old hmac-md5 only server versions from Python <=3.11 sent a message of this# length. It happens to not match the length of any supported digest so we can# use a message of this length to indicate that we should work in backwards# compatible md5-only mode without a {digest_name} prefix on our response.# modern message format: b"{digest}payload" longer than 20 bytes# legacy message format: 16 or 20 byte b"payload"# Either this was a legacy server challenge, or we're processing# a reply from a legacy client that sent an unprefixed 16-byte# HMAC-MD5 response. All messages using the modern protocol will# be longer than either of these lengths.# The MAC protects the entire message: digest header and payload.# Legacy server without a {digest} prefix on message.# Generate a legacy non-prefixed HMAC-MD5 reply.# HMAC-MD5 is not available (FIPS mode?), fall back to# HMAC-SHA2-256 modern protocol. The legacy server probably# doesn't support it and will reject us anyways. :shrug:# Modern protocol, indicate the digest used in the reply.# Even when sending a challenge to a legacy client that does not support# digest prefixes, they'll take the entire thing as a challenge and# respond to it with a raw HMAC-MD5.# reject large message# Support for using xmlrpclib for serialization# Wait# Return ALL handles which are currently signalled.  (Only# returning the first signalled might create starvation issues.)# start an overlapped read of length zero# If o.fileno() is an overlapped pipe handle and# err == 0 then there is a zero length message# in the pipe, but it HAS NOT been consumed...# ... except on Windows 8 and later, where# the message HAS been consumed.# request that overlapped reads stop# wait for all overlapped reads to stop# If o.fileno() is an overlapped pipe handle then# a zero length message HAS been consumed.# poll/select have the advantage of not requiring any extra file# descriptor, contrarily to epoll/kqueue (also, they require a single# syscall).# Make connection and socket objects shareable if possibleb'Client'u'Client'b'Listener'u'Listener'b'Pipe'u'Pipe'b'AF_INET'u'AF_INET'b'AF_PIPE'u'AF_PIPE'b'
    Return an arbitrary free address for the given family
    'u'
    Return an arbitrary free address for the given family
    'b'localhost'u'localhost'b'listener-'u'listener-'b'\\.\pipe\pyc-%d-%d-'u'\\.\pipe\pyc-%d-%d-'b'unrecognized family'u'unrecognized family'b'
    Checks if the family is valid for the current environment.
    'u'
    Checks if the family is valid for the current environment.
    'b'Family %s is not recognized.'u'Family %s is not recognized.'b'
    Return the types of the address

    This can be 'AF_INET', 'AF_UNIX', or 'AF_PIPE'
    'u'
    Return the types of the address

    This can be 'AF_INET', 'AF_UNIX', or 'AF_PIPE'
    'b'address type of %r unrecognized'u'address type of %r unrecognized'b'invalid handle'u'invalid handle'b'at least one of `readable` and `writable` must be True'u'at least one of `readable` and `writable` must be True'b'handle is closed'u'handle is closed'b'connection is write-only'u'connection is write-only'b'connection is read-only'u'connection is read-only'b'bad message length'u'bad message length'b'True if the connection is closed'u'True if the connection is closed'b'True if the connection is readable'u'True if the connection is readable'b'True if the connection is writable'u'True if the connection is writable'b'File descriptor or handle of the connection'u'File descriptor or handle of the connection'b'Close the connection'u'Close the connection'b'Send the bytes data from a bytes-like object'u'Send the bytes data from a bytes-like object'b'offset is negative'u'offset is negative'b'buffer length < offset'u'buffer length < offset'b'size is negative'u'size is negative'b'buffer length < offset + size'u'buffer length < offset + size'b'Send a (picklable) object'u'Send a (picklable) object'b'
        Receive bytes data as a bytes object.
        'u'
        Receive bytes data as a bytes object.
        'b'negative maxlength'u'negative maxlength'b'
        Receive bytes data into a writeable bytes-like object.
        Return the number of bytes read.
        'u'
        Receive bytes data into a writeable bytes-like object.
        Return the number of bytes read.
        'b'negative offset'u'negative offset'b'offset too large'u'offset too large'b'Receive a (picklable) object'u'Receive a (picklable) object'b'Whether there is any input available to be read'u'Whether there is any input available to be read'b'
        Connection class based on a Windows named pipe.
        Overlapped I/O is used, so the handles must have been created
        with FILE_FLAG_OVERLAPPED.
        'u'
        Connection class based on a Windows named pipe.
        Overlapped I/O is used, so the handles must have been created
        with FILE_FLAG_OVERLAPPED.
        'b'concurrent send_bytes() calls are not supported'u'concurrent send_bytes() calls are not supported'b'shouldn't get here; expected KeyboardInterrupt'u'shouldn't get here; expected KeyboardInterrupt'b'
    Connection class based on an arbitrary file descriptor (Unix only), or
    a socket handle (Windows).
    'u'
    Connection class based on an arbitrary file descriptor (Unix only), or
    a socket handle (Windows).
    'b'got end of file during message'u'got end of file during message'b'!i'u'!i'b'!Q'u'!Q'b'
    Returns a listener object.

    This is a wrapper for a bound socket which is 'listening' for
    connections, or for a Windows named pipe.
    'u'
    Returns a listener object.

    This is a wrapper for a bound socket which is 'listening' for
    connections, or for a Windows named pipe.
    'b'authkey should be a byte string'u'authkey should be a byte string'b'
        Accept a connection on the bound socket or named pipe of `self`.

        Returns a `Connection` object.
        'u'
        Accept a connection on the bound socket or named pipe of `self`.

        Returns a `Connection` object.
        'b'listener is closed'u'listener is closed'b'
        Close the bound socket or named pipe of `self`.
        'u'
        Close the bound socket or named pipe of `self`.
        'b'
    Returns a connection to the address of a `Listener`
    'u'
    Returns a connection to the address of a `Listener`
    'b'
        Returns pair of connection objects at either end of a pipe
        'u'
        Returns pair of connection objects at either end of a pipe
        'b'
    Representation of a socket which is bound to an address and listening
    'u'
    Representation of a socket which is bound to an address and listening
    'b'
    Return a connection object connected to the socket given by `address`
    'u'
    Return a connection object connected to the socket given by `address`
    'b'
        Representation of a named pipe
        'u'
        Representation of a named pipe
        'b'listener created with address=%r'u'listener created with address=%r'b'closing listener with address=%r'u'closing listener with address=%r'b'
        Return a connection object connected to the pipe given by `address`
        'u'
        Return a connection object connected to the pipe given by `address`
        'b'#CHALLENGE#'b'#WELCOME#'b'#FAILURE#'b'md5'b'sha256'b'sha384'b'sha3_256'b'sha3_384'b'Returns a digest name and the payload for a response hash.

    If a legacy protocol is detected based on the message length
    or contents the digest name returned will be empty to indicate
    legacy mode where MD5 and no digest prefix should be sent.
    'u'Returns a digest name and the payload for a response hash.

    If a legacy protocol is detected based on the message length
    or contents the digest name returned will be empty to indicate
    legacy mode where MD5 and no digest prefix should be sent.
    'b'unsupported message length, missing digest prefix, or unsupported digest: 'u'unsupported message length, missing digest prefix, or unsupported digest: 'b'Create a MAC based on authkey and message

    The MAC algorithm defaults to HMAC-MD5, unless MD5 is not available or
    the message has a '{digest_name}' prefix. For legacy HMAC-MD5, the response
    is the raw MAC, otherwise the response is prefixed with '{digest_name}',
    e.g. b'{sha256}abcdefg...'

    Note: The MAC protects the entire message including the digest_name prefix.
    'u'Create a MAC based on authkey and message

    The MAC algorithm defaults to HMAC-MD5, unless MD5 is not available or
    the message has a '{digest_name}' prefix. For legacy HMAC-MD5, the response
    is the raw MAC, otherwise the response is prefixed with '{digest_name}',
    e.g. b'{sha256}abcdefg...'

    Note: The MAC protects the entire message including the digest_name prefix.
    'u'md5'u'sha256'b'{%s}%s'b'Verify MAC challenge

    If our message did not include a digest_name prefix, the client is allowed
    to select a stronger digest_name from _ALLOWED_DIGESTS.

    In case our message is prefixed, a client cannot downgrade to a weaker
    algorithm, because the MAC is calculated over the entire message
    including the '{digest_name}' prefix.
    'u'Verify MAC challenge

    If our message did not include a digest_name prefix, the client is allowed
    to select a stronger digest_name from _ALLOWED_DIGESTS.

    In case our message is prefixed, a client cannot downgrade to a weaker
    algorithm, because the MAC is calculated over the entire message
    including the '{digest_name}' prefix.
    'b' unsupported'u' unsupported'b'expected 'u'expected 'b' of length 'u' of length 'b' got 'u' got 'b'digest received was wrong'u'digest received was wrong'b'Authkey must be bytes, not {0!s}'u'Authkey must be bytes, not {0!s}'b'protocol constraint'u'protocol constraint'b'Protocol error, expected challenge: 'u'Protocol error, expected challenge: 'b'challenge too short: {len(message)} bytes'u'challenge too short: {len(message)} bytes'b'digest sent was rejected'u'digest sent was rejected'b'fileno'u'fileno'b'poll'u'poll'b'recv_bytes'u'recv_bytes'b'send_bytes'u'send_bytes'b'Should not get here'u'Should not get here'b'
        Wait till an object in object_list is ready/readable.

        Returns list of those objects in object_list which are ready/readable.
        'u'
        Wait till an object in object_list is ready/readable.

        Returns list of those objects in object_list which are ready/readable.
        'b'_got_empty_message'u'_got_empty_message'b'PollSelector'u'PollSelector'u'Lib.multiprocessing.connection'LOG_THRESHOLD_FOR_CONNLOST_WRITESACCEPT_RETRY_DELAY60.0SSL_HANDSHAKE_TIMEOUT30.0SSL_SHUTDOWN_TIMEOUTFLOW_CONTROL_HIGH_WATER_SSL_READFLOW_CONTROL_HIGH_WATER_SSL_WRITETHREAD_JOIN_TIMEOUTEnumFALLBACK# Contains code from https://github.com/MagicStack/uvloop/tree/v0.16.0# SPDX-License-Identifier: PSF-2.0 AND (MIT OR Apache-2.0)# SPDX-FileCopyrightText: Copyright (c) 2015-2021 MagicStack Inc.  http://magic.io# After the connection is lost, log warnings after this many write()s.# Seconds to wait before retrying accept().# Number of stack entries to capture in debug mode.# The larger the number, the slower the operation in debug mode# (see extract_stack() in format_helpers.py).# Number of seconds to wait for SSL handshake to complete# The default timeout matches that of Nginx.# Number of seconds to wait for SSL shutdown to complete# The default timeout mimics lingering_time# Used in sendfile fallback code.  We use fallback for platforms# that don't support sendfile, or for TLS connections.# KiB# Default timeout for joining the threads in the threadpool# The enum should be here to break circular dependencies between# base_events and sslprotou'Lib.asyncio.constants'u'asyncio.constants'u'constants'BaseContextparent_processactive_childrencpu_countReturns the number of CPUs in the systemcannot determine number of cpusReturns a manager associated with a running server process

        The managers methods such as `Lock()`, `Condition()` and `Queue()`
        can be used to create shared objects.
        managersSyncManagerReturns two connection object connected by a pipeReturns a non-recursive lock objectsynchronizeReturns a recursive lock objectReturns a condition objectSemaphoreReturns a semaphore objectBoundedSemaphoreReturns a bounded semaphore objectReturns an event objectBarrierpartiesReturns a barrier objectReturns a queue objectJoinableQueueSimpleQueuePoolprocessesinitializerinitargsmaxtasksperchildReturns a process pool objectpoolRawValuetypecode_or_typeReturns a shared objectsharedctypesRawArraysize_or_initializerReturns a shared arrayValueReturns a synchronized shared objectArrayReturns a synchronized shared arrayfreeze_supportCheck whether this is a fake forked process in a frozen executable.
        If so then run code specified by commandline and exit.
        spawnget_loggerReturn package logger -- if it does not already exist then
        it is created.
        log_to_stderrTurn on logging and add a handler which prints to stderrallow_connection_picklingInstall support for sending connections and sockets
        between processes
        set_executableSets the path to a python.exe or pythonw.exe binary used to run
        child processes instead of sys.executable when using the 'spawn'
        start method.  Useful for people embedding Python.
        set_forkserver_preloadmodule_namesSet list of module names to try to load in forkserver process.
        This is really just a hint.
        forkserver_concrete_contextscannot find context for %r_check_availableget_start_methodset_start_methodcannot set start method of concrete contextreducerControls how objects will be reduced to a form that can be
        shared with other processes.BaseProcess_start_method_Popenprocess_obj_after_fork_actual_contextcontext has already been setget_all_start_methodsReturns a list of the supported start methods, default first.forkHAVE_SEND_HANDLEForkProcesspopen_forkSpawnProcesspopen_spawn_posixForkServerProcesspopen_forkserverForkContextSpawnContextForkServerContextforkserver start method not availablepopen_spawn_win32_force_start_method_tlsget_spawning_popenspawning_popenset_spawning_popenpopenassert_spawning%s objects should only be shared between processes through inheritance'%s objects should only be shared between processes'' through inheritance'# Base type for contexts. Bound methods of an instance of this type are included in __all__ of __init__.py# This is undocumented.  In previous versions of multiprocessing# its only effect was to make socket objects inheritable on Windows.# Type of default context -- underlying context can be set at most once# Context types for fixed start method# process is spawned, nothing to do# bpo-33725: running arbitrary code after fork() is no longer reliable# on macOS since macOS 10.14 (Mojave). Use spawn by default instead.# Force the start method# Check that the current thread is spawning a child processb'Returns the number of CPUs in the system'u'Returns the number of CPUs in the system'b'cannot determine number of cpus'u'cannot determine number of cpus'b'Returns a manager associated with a running server process

        The managers methods such as `Lock()`, `Condition()` and `Queue()`
        can be used to create shared objects.
        'u'Returns a manager associated with a running server process

        The managers methods such as `Lock()`, `Condition()` and `Queue()`
        can be used to create shared objects.
        'b'Returns two connection object connected by a pipe'u'Returns two connection object connected by a pipe'b'Returns a non-recursive lock object'u'Returns a non-recursive lock object'b'Returns a recursive lock object'u'Returns a recursive lock object'b'Returns a condition object'u'Returns a condition object'b'Returns a semaphore object'u'Returns a semaphore object'b'Returns a bounded semaphore object'u'Returns a bounded semaphore object'b'Returns an event object'u'Returns an event object'b'Returns a barrier object'u'Returns a barrier object'b'Returns a queue object'u'Returns a queue object'b'Returns a process pool object'u'Returns a process pool object'b'Returns a shared object'u'Returns a shared object'b'Returns a shared array'u'Returns a shared array'b'Returns a synchronized shared object'u'Returns a synchronized shared object'b'Returns a synchronized shared array'u'Returns a synchronized shared array'b'Check whether this is a fake forked process in a frozen executable.
        If so then run code specified by commandline and exit.
        'u'Check whether this is a fake forked process in a frozen executable.
        If so then run code specified by commandline and exit.
        'b'Return package logger -- if it does not already exist then
        it is created.
        'u'Return package logger -- if it does not already exist then
        it is created.
        'b'Turn on logging and add a handler which prints to stderr'u'Turn on logging and add a handler which prints to stderr'b'Install support for sending connections and sockets
        between processes
        'u'Install support for sending connections and sockets
        between processes
        'b'Sets the path to a python.exe or pythonw.exe binary used to run
        child processes instead of sys.executable when using the 'spawn'
        start method.  Useful for people embedding Python.
        'u'Sets the path to a python.exe or pythonw.exe binary used to run
        child processes instead of sys.executable when using the 'spawn'
        start method.  Useful for people embedding Python.
        'b'Set list of module names to try to load in forkserver process.
        This is really just a hint.
        'u'Set list of module names to try to load in forkserver process.
        This is really just a hint.
        'b'cannot find context for %r'u'cannot find context for %r'b'cannot set start method of concrete context'u'cannot set start method of concrete context'b'Controls how objects will be reduced to a form that can be
        shared with other processes.'u'Controls how objects will be reduced to a form that can be
        shared with other processes.'b'reduction'u'reduction'b'context has already been set'u'context has already been set'b'Returns a list of the supported start methods, default first.'u'Returns a list of the supported start methods, default first.'b'spawn'u'spawn'b'fork'u'fork'b'forkserver'u'forkserver'b'forkserver start method not available'u'forkserver start method not available'b'spawning_popen'u'spawning_popen'b'%s objects should only be shared between processes through inheritance'u'%s objects should only be shared between processes through inheritance'u'Lib.multiprocessing.context'Utilities for with-statement contexts.  See PEP 343.asynccontextmanagerAbstractContextManagerAbstractAsyncContextManagerAsyncExitStackContextDecoratorExitStackredirect_stdoutredirect_stderraclosingchdirAn abstract base class for context managers.Return `self` upon entering the runtime context.Raise any exception triggered within the runtime context.An abstract base class for asynchronous context managers.A base class or mixin that enables context managers to work as decorators._recreate_cmReturn a recreated instance of self.

        Allows an otherwise one-shot context manager like
        _GeneratorContextManager to support use as
        a decorator via implicit recreation.

        This is a private interface just for _GeneratorContextManager.
        See issue #11647 for details.
        AsyncContextDecoratorA base class or mixin that enables async context managers to work as decorators.Return a recreated instance of self.
        _GeneratorContextManagerBaseShared functionality for @contextmanager and @asynccontextmanager._GeneratorContextManagerHelper for @contextmanager decorator.generator didn't yieldgenerator didn't stopgenerator didn't stop after throw()_AsyncGeneratorContextManagerHelper for @asynccontextmanager decorator.generator didn't stop after athrow()@contextmanager decorator.

    Typical usage:

        @contextmanager
        def some_generator(<arguments>):
            <setup>
            try:
                yield <value>
            finally:
                <cleanup>

    This makes this:

        with some_generator(<arguments>) as <variable>:
            <body>

    equivalent to this:

        <setup>
        try:
            <variable> = <value>
            <body>
        finally:
            <cleanup>
    helper@asynccontextmanager decorator.

    Typical usage:

        @asynccontextmanager
        async def some_async_generator(<arguments>):
            <setup>
            try:
                yield <value>
            finally:
                <cleanup>

    This makes this:

        async with some_async_generator(<arguments>) as <variable>:
            <body>

    equivalent to this:

        <setup>
        try:
            <variable> = <value>
            <body>
        finally:
            <cleanup>
    Context to automatically close something at the end of a block.

    Code like this:

        with closing(<module>.open(<arguments>)) as f:
            <block>

    is equivalent to this:

        f = <module>.open(<arguments>)
        try:
            <block>
        finally:
            f.close()

    Async context manager for safely finalizing an asynchronously cleaned-up
    resource such as an async generator, calling its ``aclose()`` method.

    Code like this:

        async with aclosing(<module>.fetch(<arguments>)) as agen:
            <block>

    is equivalent to this:

        agen = <module>.fetch(<arguments>)
        try:
            <block>
        finally:
            await agen.aclose()

    _RedirectStream_streamnew_target_new_target_old_targetsexctypeexcinstexctbContext manager for temporarily redirecting stdout to another file.

        # How to send help() to stderr
        with redirect_stdout(sys.stderr):
            help(dir)

        # How to write help() to a file
        with open('help.txt', 'w') as f:
            with redirect_stdout(f):
                help(pow)
    Context manager for temporarily redirecting stderr to another file.Context manager to suppress specified exceptions

    After the exception is suppressed, execution proceeds with the next
    statement following the with statement.

         with suppress(FileNotFoundError):
             os.remove(somefile)
         # Execution still resumes here if the file was already removed
    _exceptions_BaseExitStackA base class for ExitStack and AsyncExitStack._create_exit_wrappercm_exit_create_cb_wrapper_exit_wrapper_exit_callbackspop_allPreserve the context stack by transferring it to a new instance.new_stackRegisters a callback with the standard __exit__ method signature.

        Can suppress exceptions the same way __exit__ method can.
        Also accepts any object with an __exit__ method (registering a call
        to the method instead of the object itself).
        _cb_typeexit_method_push_cm_exit_push_exit_callbackenter_contextEnters the supplied context manager.

        If successful, also pushes its __exit__ method as a callback and
        returns the result of the __enter__ method.
        _enter_exitRegisters an arbitrary callback and arguments.

        Cannot suppress exceptions.
        Helper to correctly register callbacks to __exit__ methods.is_syncContext manager for dynamic management of a stack of exit callbacks.

    For example:
        with ExitStack() as stack:
            files = [stack.enter_context(open(fname)) for fname in filenames]
            # All opened files will automatically be closed at the end of
            # the with statement, even if attempts to open files later
            # in the list raise an exception.
    received_excframe_exc_fix_exception_contextnew_excold_excexc_contextsuppressed_excpending_raisenew_exc_detailsfixed_ctxImmediately unwind the context stack.Async context manager for dynamic management of a stack of exit
    callbacks.

    For example:
        async with AsyncExitStack() as stack:
            connections = [await stack.enter_async_context(get_connection())
                for i in range(5)]
            # All opened connections will automatically be released at the
            # end of the async with statement, even if attempts to open a
            # connection later in the list raise an exception.
    _create_async_exit_wrapper_create_async_cb_wrapperenter_async_contextEnters the supplied async context manager.

        If successful, also pushes its __aexit__ method as a callback and
        returns the result of the __aenter__ method.
        _push_async_cm_exitpush_async_exitRegisters a coroutine function with the standard __aexit__ method
        signature.

        Can suppress exceptions the same way __aexit__ method can.
        Also accepts any object with an __aexit__ method (registering a call
        to the method instead of the object itself).
        push_async_callbackRegisters an arbitrary coroutine function and arguments.

        Cannot suppress exceptions.
        Helper to correctly register coroutine function to __aexit__
        method.cb_suppressContext manager that does no additional processing.

    Used as a stand-in for a normal context manager, when a particular
    block of code is only sometimes used with a normal context manager:

    cm = optional_cm if condition else nullcontext()
    with cm:
        # Perform operation, using optional_cm if condition is True
    enter_resultexcinfoNon thread-safe context manager to change the current working directory._old_cwd# Issue 19330: ensure context manager instances have good docstrings# Unfortunately, this still doesn't provide good help output when# inspecting the created context manager instances, since pydoc# currently bypasses the instance docstring and shows the docstring# for the class instead.# See http://bugs.python.org/issue19404 for more details.# _GCMB instances are one-shot context managers, so the# CM must be recreated each time a decorated function is# called# do not keep args and kwds alive unnecessarily# they are only needed for recreation, which is not possible anymore# Need to force instantiation so we can reliably# tell if we get the same exception back# Suppress StopIteration *unless* it's the same exception that# was passed to throw().  This prevents a StopIteration# raised inside the "with" statement from being suppressed.# Don't re-raise the passed in exception. (issue27122)# Avoid suppressing if a StopIteration exception# was passed to throw() and later wrapped into a RuntimeError# (see PEP 479 for sync generators; async generators also# have this behavior). But do this only if the exception wrapped# by the RuntimeError is actually Stop(Async)Iteration (see# issue29692).# only re-raise if it's *not* the exception that was# passed to throw(), because __exit__() must not raise# an exception unless __exit__() itself failed.  But throw()# has to raise the exception to signal propagation, so this# fixes the impedance mismatch between the throw() protocol# and the __exit__() protocol.# Avoid suppressing if a Stop(Async)Iteration exception# was passed to athrow() and later wrapped into a RuntimeError# We use a list of old targets to make this CM re-entrant# Unlike isinstance and issubclass, CPython exception handling# currently only looks at the concrete type hierarchy (ignoring# the instance and subclass checking hooks). While Guido considers# that a bug rather than a feature, it's a fairly hard one to fix# due to various internal implementation details. suppress provides# the simpler issubclass based semantics, rather than trying to# exactly reproduce the limitations of the CPython interpreter.# See http://bugs.python.org/issue12029 for more details# We use an unbound method rather than a bound method to follow# the standard lookup behaviour for special methods.# Not a context manager, so assume it's a callable.# Allow use as a decorator.# We changed the signature, so using @wraps is not appropriate, but# setting __wrapped__ may still help with introspection.# Allow use as a decorator# Inspired by discussions on http://bugs.python.org/issue13585# We manipulate the exception state so it behaves as though# we were actually nesting multiple with statements# Context may not be correct, so find the end of the chain# Context is already set correctly (see issue 20317)# Change the end of the chain to point to the exception# we expect it to reference# Callbacks are invoked in LIFO order to match the behaviour of# nested context managers# simulate the stack of exceptions by setting the context# bare "raise exc_details[1]" replaces our carefully# set-up context# Inspired by discussions on https://bugs.python.org/issue29302# Not an async context manager, so assume it's a coroutine functionb'Utilities for with-statement contexts.  See PEP 343.'u'Utilities for with-statement contexts.  See PEP 343.'b'asynccontextmanager'u'asynccontextmanager'b'contextmanager'u'contextmanager'b'closing'u'closing'b'nullcontext'u'nullcontext'b'AbstractContextManager'u'AbstractContextManager'b'AbstractAsyncContextManager'u'AbstractAsyncContextManager'b'AsyncExitStack'u'AsyncExitStack'b'ContextDecorator'u'ContextDecorator'b'ExitStack'u'ExitStack'b'redirect_stdout'u'redirect_stdout'b'redirect_stderr'u'redirect_stderr'b'suppress'u'suppress'b'aclosing'u'aclosing'b'chdir'u'chdir'b'An abstract base class for context managers.'u'An abstract base class for context managers.'b'Return `self` upon entering the runtime context.'u'Return `self` upon entering the runtime context.'b'Raise any exception triggered within the runtime context.'u'Raise any exception triggered within the runtime context.'b'__enter__'u'__enter__'b'__exit__'u'__exit__'b'An abstract base class for asynchronous context managers.'u'An abstract base class for asynchronous context managers.'b'__aenter__'u'__aenter__'b'__aexit__'u'__aexit__'b'A base class or mixin that enables context managers to work as decorators.'u'A base class or mixin that enables context managers to work as decorators.'b'Return a recreated instance of self.

        Allows an otherwise one-shot context manager like
        _GeneratorContextManager to support use as
        a decorator via implicit recreation.

        This is a private interface just for _GeneratorContextManager.
        See issue #11647 for details.
        'u'Return a recreated instance of self.

        Allows an otherwise one-shot context manager like
        _GeneratorContextManager to support use as
        a decorator via implicit recreation.

        This is a private interface just for _GeneratorContextManager.
        See issue #11647 for details.
        'b'A base class or mixin that enables async context managers to work as decorators.'u'A base class or mixin that enables async context managers to work as decorators.'b'Return a recreated instance of self.
        'u'Return a recreated instance of self.
        'b'Shared functionality for @contextmanager and @asynccontextmanager.'u'Shared functionality for @contextmanager and @asynccontextmanager.'b'Helper for @contextmanager decorator.'u'Helper for @contextmanager decorator.'b'generator didn't yield'u'generator didn't yield'b'generator didn't stop'u'generator didn't stop'b'generator didn't stop after throw()'u'generator didn't stop after throw()'b'Helper for @asynccontextmanager decorator.'u'Helper for @asynccontextmanager decorator.'b'generator didn't stop after athrow()'u'generator didn't stop after athrow()'b'@contextmanager decorator.

    Typical usage:

        @contextmanager
        def some_generator(<arguments>):
            <setup>
            try:
                yield <value>
            finally:
                <cleanup>

    This makes this:

        with some_generator(<arguments>) as <variable>:
            <body>

    equivalent to this:

        <setup>
        try:
            <variable> = <value>
            <body>
        finally:
            <cleanup>
    'u'@contextmanager decorator.

    Typical usage:

        @contextmanager
        def some_generator(<arguments>):
            <setup>
            try:
                yield <value>
            finally:
                <cleanup>

    This makes this:

        with some_generator(<arguments>) as <variable>:
            <body>

    equivalent to this:

        <setup>
        try:
            <variable> = <value>
            <body>
        finally:
            <cleanup>
    'b'@asynccontextmanager decorator.

    Typical usage:

        @asynccontextmanager
        async def some_async_generator(<arguments>):
            <setup>
            try:
                yield <value>
            finally:
                <cleanup>

    This makes this:

        async with some_async_generator(<arguments>) as <variable>:
            <body>

    equivalent to this:

        <setup>
        try:
            <variable> = <value>
            <body>
        finally:
            <cleanup>
    'u'@asynccontextmanager decorator.

    Typical usage:

        @asynccontextmanager
        async def some_async_generator(<arguments>):
            <setup>
            try:
                yield <value>
            finally:
                <cleanup>

    This makes this:

        async with some_async_generator(<arguments>) as <variable>:
            <body>

    equivalent to this:

        <setup>
        try:
            <variable> = <value>
            <body>
        finally:
            <cleanup>
    'b'Context to automatically close something at the end of a block.

    Code like this:

        with closing(<module>.open(<arguments>)) as f:
            <block>

    is equivalent to this:

        f = <module>.open(<arguments>)
        try:
            <block>
        finally:
            f.close()

    'u'Context to automatically close something at the end of a block.

    Code like this:

        with closing(<module>.open(<arguments>)) as f:
            <block>

    is equivalent to this:

        f = <module>.open(<arguments>)
        try:
            <block>
        finally:
            f.close()

    'b'Async context manager for safely finalizing an asynchronously cleaned-up
    resource such as an async generator, calling its ``aclose()`` method.

    Code like this:

        async with aclosing(<module>.fetch(<arguments>)) as agen:
            <block>

    is equivalent to this:

        agen = <module>.fetch(<arguments>)
        try:
            <block>
        finally:
            await agen.aclose()

    'u'Async context manager for safely finalizing an asynchronously cleaned-up
    resource such as an async generator, calling its ``aclose()`` method.

    Code like this:

        async with aclosing(<module>.fetch(<arguments>)) as agen:
            <block>

    is equivalent to this:

        agen = <module>.fetch(<arguments>)
        try:
            <block>
        finally:
            await agen.aclose()

    'b'Context manager for temporarily redirecting stdout to another file.

        # How to send help() to stderr
        with redirect_stdout(sys.stderr):
            help(dir)

        # How to write help() to a file
        with open('help.txt', 'w') as f:
            with redirect_stdout(f):
                help(pow)
    'u'Context manager for temporarily redirecting stdout to another file.

        # How to send help() to stderr
        with redirect_stdout(sys.stderr):
            help(dir)

        # How to write help() to a file
        with open('help.txt', 'w') as f:
            with redirect_stdout(f):
                help(pow)
    'b'stdout'u'stdout'b'Context manager for temporarily redirecting stderr to another file.'u'Context manager for temporarily redirecting stderr to another file.'b'stderr'u'stderr'b'Context manager to suppress specified exceptions

    After the exception is suppressed, execution proceeds with the next
    statement following the with statement.

         with suppress(FileNotFoundError):
             os.remove(somefile)
         # Execution still resumes here if the file was already removed
    'u'Context manager to suppress specified exceptions

    After the exception is suppressed, execution proceeds with the next
    statement following the with statement.

         with suppress(FileNotFoundError):
             os.remove(somefile)
         # Execution still resumes here if the file was already removed
    'b'A base class for ExitStack and AsyncExitStack.'u'A base class for ExitStack and AsyncExitStack.'b'Preserve the context stack by transferring it to a new instance.'u'Preserve the context stack by transferring it to a new instance.'b'Registers a callback with the standard __exit__ method signature.

        Can suppress exceptions the same way __exit__ method can.
        Also accepts any object with an __exit__ method (registering a call
        to the method instead of the object itself).
        'u'Registers a callback with the standard __exit__ method signature.

        Can suppress exceptions the same way __exit__ method can.
        Also accepts any object with an __exit__ method (registering a call
        to the method instead of the object itself).
        'b'Enters the supplied context manager.

        If successful, also pushes its __exit__ method as a callback and
        returns the result of the __enter__ method.
        'u'Enters the supplied context manager.

        If successful, also pushes its __exit__ method as a callback and
        returns the result of the __enter__ method.
        'b'Registers an arbitrary callback and arguments.

        Cannot suppress exceptions.
        'u'Registers an arbitrary callback and arguments.

        Cannot suppress exceptions.
        'b'Helper to correctly register callbacks to __exit__ methods.'u'Helper to correctly register callbacks to __exit__ methods.'b'Context manager for dynamic management of a stack of exit callbacks.

    For example:
        with ExitStack() as stack:
            files = [stack.enter_context(open(fname)) for fname in filenames]
            # All opened files will automatically be closed at the end of
            # the with statement, even if attempts to open files later
            # in the list raise an exception.
    'u'Context manager for dynamic management of a stack of exit callbacks.

    For example:
        with ExitStack() as stack:
            files = [stack.enter_context(open(fname)) for fname in filenames]
            # All opened files will automatically be closed at the end of
            # the with statement, even if attempts to open files later
            # in the list raise an exception.
    'b'Immediately unwind the context stack.'u'Immediately unwind the context stack.'b'Async context manager for dynamic management of a stack of exit
    callbacks.

    For example:
        async with AsyncExitStack() as stack:
            connections = [await stack.enter_async_context(get_connection())
                for i in range(5)]
            # All opened connections will automatically be released at the
            # end of the async with statement, even if attempts to open a
            # connection later in the list raise an exception.
    'u'Async context manager for dynamic management of a stack of exit
    callbacks.

    For example:
        async with AsyncExitStack() as stack:
            connections = [await stack.enter_async_context(get_connection())
                for i in range(5)]
            # All opened connections will automatically be released at the
            # end of the async with statement, even if attempts to open a
            # connection later in the list raise an exception.
    'b'Enters the supplied async context manager.

        If successful, also pushes its __aexit__ method as a callback and
        returns the result of the __aenter__ method.
        'u'Enters the supplied async context manager.

        If successful, also pushes its __aexit__ method as a callback and
        returns the result of the __aenter__ method.
        'b'Registers a coroutine function with the standard __aexit__ method
        signature.

        Can suppress exceptions the same way __aexit__ method can.
        Also accepts any object with an __aexit__ method (registering a call
        to the method instead of the object itself).
        'u'Registers a coroutine function with the standard __aexit__ method
        signature.

        Can suppress exceptions the same way __aexit__ method can.
        Also accepts any object with an __aexit__ method (registering a call
        to the method instead of the object itself).
        'b'Registers an arbitrary coroutine function and arguments.

        Cannot suppress exceptions.
        'u'Registers an arbitrary coroutine function and arguments.

        Cannot suppress exceptions.
        'b'Helper to correctly register coroutine function to __aexit__
        method.'u'Helper to correctly register coroutine function to __aexit__
        method.'b'Context manager that does no additional processing.

    Used as a stand-in for a normal context manager, when a particular
    block of code is only sometimes used with a normal context manager:

    cm = optional_cm if condition else nullcontext()
    with cm:
        # Perform operation, using optional_cm if condition is True
    'u'Context manager that does no additional processing.

    Used as a stand-in for a normal context manager, when a particular
    block of code is only sometimes used with a normal context manager:

    cm = optional_cm if condition else nullcontext()
    with cm:
        # Perform operation, using optional_cm if condition is True
    'b'Non thread-safe context manager to change the current working directory.'u'Non thread-safe context manager to change the current working directory.'u'Lib.contextlib'u'contextlib'b'ContextVar'u'ContextVar'b'Token'u'Token'b'copy_context'u'copy_context'u'Lib.contextvars'u'contextvars'Generic (shallow and deep) copying operations.

Interface summary:

        import copy

        x = copy.copy(y)        # make a shallow copy of y
        x = copy.deepcopy(y)    # make a deep copy of y

For module specific errors, copy.Error is raised.

The difference between shallow and deep copying is only relevant for
compound objects (objects that contain other objects, like lists or
class instances).

- A shallow copy constructs a new compound object and then (to the
  extent possible) inserts *the same objects* into it that the
  original contains.

- A deep copy constructs a new compound object and then, recursively,
  inserts *copies* into it of the objects found in the original.

Two problems often exist with deep copy operations that don't exist
with shallow copy operations:

 a) recursive objects (compound objects that, directly or indirectly,
    contain a reference to themselves) may cause a recursive loop

 b) because deep copy copies *everything* it may copy too much, e.g.
    administrative data structures that should be shared even between
    copies

Python's deep copy operation avoids these problems by:

 a) keeping a table of objects already copied during the current
    copying pass

 b) letting user-defined classes override the copying operation or the
    set of components copied

This version does not copy types like module, class, function, method,
nor stack trace, stack frame, nor file, socket, window, nor any
similar types.

Classes can use the same interfaces to control copying that they use
to control pickling: they can define methods called __getinitargs__(),
__getstate__() and __setstate__().  See the documentation for module
"pickle" for information on these methods.
deepcopyShallow copy operation on arbitrary Python objects.

    See the module's __doc__ string for more info.
    _copy_dispatchcopier_copy_immutablereductorun(shallow)copyable object of type %s_reconstructCodeType_nilDeep copy operation on arbitrary Python objects.

    See the module's __doc__ string for more info.
    _deepcopy_dispatch_deepcopy_atomicun(deep)copyable object of type %s_keep_alive_deepcopy_list_deepcopy_tuple_deepcopy_dict_deepcopy_methodKeeps a reference to the object x in the memo.

    Because we remember objects by their id, we have
    to assure that possibly temporary objects are kept
    alive by referencing them.
    We store a reference at the id of the memo, which should
    normally not be used unless someone tries to deepcopy
    the memo itself...
    listiterdictiterdeepslotstate# backward compatibility# treat it as a regular class:# If is its own copy, don't memoize.# Make sure x lives at least as long as d# We're not going to put the tuple in the memo, but it's still important we# check for it, in case the tuple contains recursive mutable structures.# Copy instance methods# aha, this is the first one :-)b'Generic (shallow and deep) copying operations.

Interface summary:

        import copy

        x = copy.copy(y)        # make a shallow copy of y
        x = copy.deepcopy(y)    # make a deep copy of y

For module specific errors, copy.Error is raised.

The difference between shallow and deep copying is only relevant for
compound objects (objects that contain other objects, like lists or
class instances).

- A shallow copy constructs a new compound object and then (to the
  extent possible) inserts *the same objects* into it that the
  original contains.

- A deep copy constructs a new compound object and then, recursively,
  inserts *copies* into it of the objects found in the original.

Two problems often exist with deep copy operations that don't exist
with shallow copy operations:

 a) recursive objects (compound objects that, directly or indirectly,
    contain a reference to themselves) may cause a recursive loop

 b) because deep copy copies *everything* it may copy too much, e.g.
    administrative data structures that should be shared even between
    copies

Python's deep copy operation avoids these problems by:

 a) keeping a table of objects already copied during the current
    copying pass

 b) letting user-defined classes override the copying operation or the
    set of components copied

This version does not copy types like module, class, function, method,
nor stack trace, stack frame, nor file, socket, window, nor any
similar types.

Classes can use the same interfaces to control copying that they use
to control pickling: they can define methods called __getinitargs__(),
__getstate__() and __setstate__().  See the documentation for module
"pickle" for information on these methods.
'u'Generic (shallow and deep) copying operations.

Interface summary:

        import copy

        x = copy.copy(y)        # make a shallow copy of y
        x = copy.deepcopy(y)    # make a deep copy of y

For module specific errors, copy.Error is raised.

The difference between shallow and deep copying is only relevant for
compound objects (objects that contain other objects, like lists or
class instances).

- A shallow copy constructs a new compound object and then (to the
  extent possible) inserts *the same objects* into it that the
  original contains.

- A deep copy constructs a new compound object and then, recursively,
  inserts *copies* into it of the objects found in the original.

Two problems often exist with deep copy operations that don't exist
with shallow copy operations:

 a) recursive objects (compound objects that, directly or indirectly,
    contain a reference to themselves) may cause a recursive loop

 b) because deep copy copies *everything* it may copy too much, e.g.
    administrative data structures that should be shared even between
    copies

Python's deep copy operation avoids these problems by:

 a) keeping a table of objects already copied during the current
    copying pass

 b) letting user-defined classes override the copying operation or the
    set of components copied

This version does not copy types like module, class, function, method,
nor stack trace, stack frame, nor file, socket, window, nor any
similar types.

Classes can use the same interfaces to control copying that they use
to control pickling: they can define methods called __getinitargs__(),
__getstate__() and __setstate__().  See the documentation for module
"pickle" for information on these methods.
'b'Error'u'Error'b'copy'u'copy'b'deepcopy'u'deepcopy'b'Shallow copy operation on arbitrary Python objects.

    See the module's __doc__ string for more info.
    'u'Shallow copy operation on arbitrary Python objects.

    See the module's __doc__ string for more info.
    'b'__copy__'u'__copy__'b'__reduce_ex__'u'__reduce_ex__'b'__reduce__'u'__reduce__'b'un(shallow)copyable object of type %s'u'un(shallow)copyable object of type %s'b'Deep copy operation on arbitrary Python objects.

    See the module's __doc__ string for more info.
    'u'Deep copy operation on arbitrary Python objects.

    See the module's __doc__ string for more info.
    'b'__deepcopy__'u'__deepcopy__'b'un(deep)copyable object of type %s'u'un(deep)copyable object of type %s'b'Keeps a reference to the object x in the memo.

    Because we remember objects by their id, we have
    to assure that possibly temporary objects are kept
    alive by referencing them.
    We store a reference at the id of the memo, which should
    normally not be used unless someone tries to deepcopy
    the memo itself...
    'u'Keeps a reference to the object x in the memo.

    Because we remember objects by their id, we have
    to assure that possibly temporary objects are kept
    alive by referencing them.
    We store a reference at the id of the memo, which should
    normally not be used unless someone tries to deepcopy
    the memo itself...
    'b'__setstate__'u'__setstate__'u'Lib.copy'Helper to provide extensibility for pickle.

This is only useful to add pickle support for extension types defined in
C, not for instances of user-defined classes.
constructoradd_extensionremove_extensionclear_extension_cacheob_typepickle_functionconstructor_obreduction functions must be callableconstructors must be callablepickle_complexpickle_union_reconstructor_HEAPTYPE_new_type_reduce_excannot pickle  objecta class that defines __slots__ without defining __getstate__ cannot be pickled"a class that defines __slots__ without ""defining __getstate__ cannot be pickled" object: a class that defines __slots__ without defining __getstate__ cannot be pickled with protocol " object: ""defining __getstate__ cannot be pickled ""with protocol "__newobj____newobj_ex__Used by pickle protocol 4, instead of __newobj__ to allow classes with
    keyword-only arguments to be pickled correctly.
    _slotnamesReturn a list of slot names for a given class.

    This needs to find slots defined by the class and its bases, so we
    can't simply return the __slots__ attribute.  We must walk down
    the Method Resolution Order and concatenate the __slots__ of each
    class found there.  (This assumes classes don't modify their
    __slots__ attribute to misrepresent their slots after the class is
    defined.)
    __slotnames_____%s%s_extension_registry_inverted_registry_extension_cacheRegister an extension code.code out of rangekey %s is already registered with code %scode %s is already in use for key %sUnregister an extension code.  For testing only.key %s is not registered with code %s# The constructor_ob function is a vestige of safe for unpickling.# There is no reason for the caller to pass it anymore.# Example: provide pickling support for complex numbers.# Support for pickling new-style objects# Python code for object.__reduce_ex__ for protocols 0 and 1# not really reachable# Helper for __reduce_ex__ protocol 2# Get the value from a cache in the class if possible# Not cached -- calculate the value# This class has no slots# Slots found -- gather slot names from all base classes# if class has a single slot, it can be given as a string# special descriptors# mangled names# Cache the outcome in the class if at all possible# But don't die if we can't# A registry of extension codes.  This is an ad-hoc compression# mechanism.  Whenever a global reference to <module>, <name> is about# to be pickled, the (<module>, <name>) tuple is looked up here to see# if it is a registered extension code for it.  Extension codes are# universal, so that the meaning of a pickle does not depend on# context.  (There are also some codes reserved for local use that# don't have this restriction.)  Codes are positive ints; 0 is# reserved.# key -> code# code -> key# code -> object# Don't ever rebind those names:  pickling grabs a reference to them when# it's initialized, and won't see a rebinding.# Redundant registrations are benign# Standard extension code assignments# Reserved ranges# First  Last Count  Purpose#     1   127   127  Reserved for Python standard library#   128   191    64  Reserved for Zope#   192   239    48  Reserved for 3rd parties#   240   255    16  Reserved for private use (will never be assigned)#   256   Inf   Inf  Reserved for future assignment# Extension codes are assigned by the Python Software Foundation.b'Helper to provide extensibility for pickle.

This is only useful to add pickle support for extension types defined in
C, not for instances of user-defined classes.
'u'Helper to provide extensibility for pickle.

This is only useful to add pickle support for extension types defined in
C, not for instances of user-defined classes.
'b'constructor'u'constructor'b'add_extension'u'add_extension'b'remove_extension'u'remove_extension'b'clear_extension_cache'u'clear_extension_cache'b'reduction functions must be callable'u'reduction functions must be callable'b'constructors must be callable'u'constructors must be callable'b'__flags__'u'__flags__'b'cannot pickle 'u'cannot pickle 'b' object'u' object'b'a class that defines __slots__ without defining __getstate__ cannot be pickled'u'a class that defines __slots__ without defining __getstate__ cannot be pickled'b' object: a class that defines __slots__ without defining __getstate__ cannot be pickled with protocol 'u' object: a class that defines __slots__ without defining __getstate__ cannot be pickled with protocol 'b'Used by pickle protocol 4, instead of __newobj__ to allow classes with
    keyword-only arguments to be pickled correctly.
    'u'Used by pickle protocol 4, instead of __newobj__ to allow classes with
    keyword-only arguments to be pickled correctly.
    'b'Return a list of slot names for a given class.

    This needs to find slots defined by the class and its bases, so we
    can't simply return the __slots__ attribute.  We must walk down
    the Method Resolution Order and concatenate the __slots__ of each
    class found there.  (This assumes classes don't modify their
    __slots__ attribute to misrepresent their slots after the class is
    defined.)
    'u'Return a list of slot names for a given class.

    This needs to find slots defined by the class and its bases, so we
    can't simply return the __slots__ attribute.  We must walk down
    the Method Resolution Order and concatenate the __slots__ of each
    class found there.  (This assumes classes don't modify their
    __slots__ attribute to misrepresent their slots after the class is
    defined.)
    'b'__slotnames__'u'__slotnames__'b'__'u'__'b'_%s%s'u'_%s%s'b'Register an extension code.'u'Register an extension code.'b'code out of range'u'code out of range'b'key %s is already registered with code %s'u'key %s is already registered with code %s'b'code %s is already in use for key %s'u'code %s is already in use for key %s'b'Unregister an extension code.  For testing only.'u'Unregister an extension code.  For testing only.'b'key %s is not registered with code %s'u'key %s is not registered with code %s'u'Lib.copyreg'PYTHONASYNCIODEBUG_is_coroutineReturn True if func is a decorated coroutine function.CoroutineType_COROUTINE_TYPES_iscoroutine_typecacheReturn True if obj is a coroutine object.coro_name without __name__>cr_runningcoro_codecr_code runningcoro_frame<empty co_filename> running at coro_repr done, defined at # See: https://docs.python.org/3/library/asyncio-dev.html#asyncio-debug-mode.# A marker for iscoroutinefunction.# Prioritize native coroutine check to speed-up# asyncio.iscoroutine.# Just in case we don't want to cache more than 100# positive types.  That shouldn't ever happen, unless# someone stressing the system on purpose.# Coroutines compiled with Cython sometimes don't have# proper __qualname__ or __name__.  While that is a bug# in Cython, asyncio shouldn't crash with an AttributeError# in its __repr__ functions.# Stop masking Cython bugs, expose them in a friendly way.# Built-in types might not have __qualname__ or __name__.# If Cython's coroutine has a fake code object without proper# co_filename -- expose that.b'iscoroutinefunction'u'iscoroutinefunction'b'iscoroutine'u'iscoroutine'b'PYTHONASYNCIODEBUG'u'PYTHONASYNCIODEBUG'b'Return True if func is a decorated coroutine function.'u'Return True if func is a decorated coroutine function.'b'_is_coroutine'u'_is_coroutine'b'Return True if obj is a coroutine object.'u'Return True if obj is a coroutine object.'b' without __name__>'u' without __name__>'b'cr_code'u'cr_code'b'gi_code'u'gi_code'b' running'u' running'b'<empty co_filename>'u'<empty co_filename>'b' running at 'u' running at 'b' done, defined at 'u' done, defined at 'u'Lib.asyncio.coroutines'u'asyncio.coroutines'u'coroutines'dataclassFieldFrozenInstanceErrorInitVarKW_ONLYasdictastuplemake_dataclassis_dataclass_HAS_DEFAULT_FACTORY_CLASS<factory>_HAS_DEFAULT_FACTORY_MISSING_TYPE_KW_ONLY_TYPEMappingProxyType_EMPTY_METADATA_FIELD_BASE_FIELD_FIELD_CLASSVAR_FIELD_INITVAR__dataclass_fields___FIELDS__dataclass_params___PARAMS__post_init___POST_INIT_NAME^(?:\s*(\w+)\s*\.)?\s*(\w+)_MODULE_IDENTIFIER_RE_ATOMIC_TYPESuser_functionrepr_runningwrapperdataclasses.InitVar[initmetadatakw_only_field_typeField(name='Field(''name=',type=',''type=',default='default=',default_factory='default_factory=',init='init=',repr='repr=',hash='hash=',compare='compare=',metadata='metadata=',kw_only='kw_only=',_field_type='_field_type='')'_DataclassParamsorderunsafe_hashmatch_argsweakref_slot_DataclassParams(init='_DataclassParams(',eq='eq=',order='order=',unsafe_hash='unsafe_hash=',frozen='frozen=',match_args='match_args=',slots='slots=',weakref_slot='weakref_slot='Return an object to identify dataclass fields.

    default is the default value of the field.  default_factory is a
    0-argument function called to initialize a field's value.  If init
    is true, the field will be a parameter to the class's __init__()
    function.  If repr is true, the field will be included in the
    object's repr().  If hash is true, the field will be included in the
    object's hash().  If compare is true, the field will be used in
    comparison functions.  metadata, if specified, must be a mapping
    which is stored but not otherwise examined by dataclass.  If kw_only
    is true, the field will become a keyword-only parameter to
    __init__().

    It is an error to specify both default and default_factory.
    cannot specify both default and default_factory_fields_in_init_order_tuple_str,)_create_fnreturn_typereturn_annotation__dataclass_return_type__->__dataclass_return_type__ def :
txtlocal_varsdef __create_fn__():

 return __create_fn___field_assignself_name__dataclass_builtins_object__.__setattr__(_field_init__dataclass_dflt_default_name() if '() ''if ' is __dataclass_HAS_DEFAULT_FACTORY__ else ' is __dataclass_HAS_DEFAULT_FACTORY__ ''else '_init_param=__dataclass_dflt_=__dataclass_HAS_DEFAULT_FACTORY__:__dataclass_type__init_fnstd_fieldskw_only_fieldshas_post_initseen_defaultnon-default argument  follows default argument'follows default argument'__dataclass_type___dataclass_HAS_DEFAULT_FACTORY____dataclass_builtins_object__body_linesparams_str_init_params_repr_fnreturn self.__class__.__qualname__ + f"(={{self.!r}})"_frozen_get_del_attrtype(self) is cls or name in { raise FrozenInstanceError(f"cannot assign to field {name!r}")super(cls, self).__setattr__(name, value) raise FrozenInstanceError(f"cannot delete field {name!r}")super(cls, self).__delattr__(name)_cmp_fnself_tupleother_tupleif other.__class__ is self.__class__: return return NotImplemented_hash_fnreturn hash(_is_classvara_typeClassVar_GenericAlias_is_initvardataclasses_is_kw_only_is_typea_moduleis_type_predicate_get_fielda_namedefault_kw_onlyMemberDescriptorTypefield  cannot have a default factory' cannot have a ''default factory' is a ClassVar but specifies kw_only' is a ClassVar but specifies ''kw_only'mutable default  for field ' for field ' is not allowed: use default_factory_set_qualname_set_new_attribute_hash_set_none_hash_addflds_hash_exceptionCannot overwrite attribute __hash__ in class 'Cannot overwrite attribute __hash__ ''in class '_hash_action_process_classany_frozen_basehas_dataclass_basesbase_fieldsget_annotationscls_annotationscls_fieldsKW_ONLY_seen is KW_ONLY, but KW_ONLY has already been specified' is KW_ONLY, but KW_ONLY ''has already been specified' is a field but has no type annotationcannot inherit non-frozen dataclass from a frozen one'cannot inherit non-frozen dataclass from a ''frozen one'cannot inherit frozen dataclass from a non-frozen one'cannot inherit frozen dataclass from a ''non-frozen one'class_hashhas_explicit_hasheq must be true if order is trueall_init_fieldsstd_init_fieldskw_only_init_fields__dataclass_self__field_listCannot overwrite attribute  in class . Consider using functools.total_ordering'. Consider using ''functools.total_ordering'hash_actionsignature -> Nonetext_sigweakref_slot is True but slots is False_add_slots_dataclass_getstate_dataclass_setstate_get_slots__dictrefoffset__slotSlots of '' cannot be determined already specifies __slots__cls_dictinherited_slotsqualnameAdd dunder methods based on the fields defined in the class.

    Examines PEP 526 __annotations__ to determine fields.

    If init is true, an __init__() method is added to the class. If repr
    is true, a __repr__() method is added. If order is true, rich
    comparison dunder methods are added. If unsafe_hash is true, a
    __hash__() method is added. If frozen is true, fields may not be
    assigned to after instance creation. If match_args is true, the
    __match_args__ tuple is added. If kw_only is true, then by default
    all fields are keyword-only. If slots is true, a new class with a
    __slots__ attribute is returned.
    class_or_instanceReturn a tuple describing the fields of this dataclass.

    Accepts a dataclass or an instance of one. Tuple elements are of
    type Field.
    must be called with a dataclass type or instance_is_dataclass_instanceReturns True if obj is an instance of a dataclass.Returns True if obj is a dataclass or an instance of a
    dataclass.dict_factoryReturn the fields of a dataclass instance as a new dictionary mapping
    field names to field values.

    Example usage::

      @dataclass
      class C:
          x: int
          y: int

      c = C(1, 2)
      assert asdict(c) == {'x': 1, 'y': 2}

    If given, 'dict_factory' will be used instead of built-in dict.
    The function applies recursively to field values that are
    dataclass instances. This will also look into built-in containers:
    tuples, lists, and dicts. Other objects are copied with 'copy.deepcopy()'.
    asdict() should be called on dataclass instances_asdict_innertuple_factoryReturn the fields of a dataclass instance as a new tuple of field values.

    Example usage::

      @dataclass
      class C:
          x: int
          y: int

      c = C(1, 2)
      assert astuple(c) == (1, 2)

    If given, 'tuple_factory' will be used instead of built-in tuple.
    The function applies recursively to field values that are
    dataclass instances. This will also look into built-in containers:
    tuples, lists, and dicts. Other objects are copied with 'copy.deepcopy()'.
    astuple() should be called on dataclass instances_astuple_innerobj_typecls_nameReturn a new dynamically created dataclass.

    The dataclass name will be 'cls_name'.  'fields' is an iterable
    of either (name), (name, type) or (name, type, Field) objects. If type is
    omitted, use the string 'typing.Any'.  Field objects are created by
    the equivalent of calling 'field(name, type [, Field-info])'.::

      C = make_dataclass('C', ['x', ('y', int), ('z', int, field(init=False))], bases=(Base,))

    is equivalent to::

      @dataclass
      class C(Base):
          x: 'typing.Any'
          y: int
          z: int = field(init=False)

    For the bases and namespace parameters, see the builtin type() function.

    The parameters init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only,
    slots, and weakref_slot are passed to dataclass().

    If module parameter is defined, the '__module__' attribute of the dataclass is
    set to that value.
    typing.AnyInvalid field: Field names must be valid identifiers: Field names must not be keywords: Field name duplicated: exec_body_callbacknew_classchangesReturn a new object replacing specified fields with new values.

    This is especially useful for frozen classes.  Example usage::

      @dataclass(frozen=True)
      class C:
          x: int
          y: int

      c = C(1, 2)
      c1 = replace(c, x=3)
      assert c1.x == 3 and c1.y == 2
    replace() should be called on dataclass instances is declared with init=False, it cannot be specified with replace()' is declared with ''init=False, it cannot be specified with ''replace()'InitVar  must be specified with replace()'must be specified with replace()'# Helper functions.# Conditions for adding methods.  The boxes indicate what action the# dataclass decorator takes.  For all of these tables, when I talk# about init=, repr=, eq=, order=, unsafe_hash=, or frozen=, I'm# referring to the arguments to the @dataclass decorator.  When# checking if a dunder method already exists, I mean check for an# entry in the class's __dict__.  I never check to see if an attribute# is defined in a base class.# Key:# +=========+=========================================+# + Value   | Meaning                                 |# | <blank> | No action: no method is added.          |# +---------+-----------------------------------------+# | add     | Generated method is added.              |# | raise   | TypeError is raised.                    |# | None    | Attribute is set to None.               |# __init__#   +--- init= parameter#   |#   v     |       |       |#         |  no   |  yes  |  <--- class has __init__ in __dict__?# +=======+=======+=======+# | False |       |       |# +-------+-------+-------+# | True  | add   |       |  <- the default# __repr__#    +--- repr= parameter#    |#    v    |       |       |#         |  no   |  yes  |  <--- class has __repr__ in __dict__?# __setattr__# __delattr__#    +--- frozen= parameter#         |  no   |  yes  |  <--- class has __setattr__ or __delattr__ in __dict__?# | False |       |       |  <- the default# | True  | add   | raise |# Raise because not adding these methods would break the "frozen-ness"# of the class.# __eq__#    +--- eq= parameter#         |  no   |  yes  |  <--- class has __eq__ in __dict__?# __lt__# __le__# __gt__# __ge__#    +--- order= parameter#         |  no   |  yes  |  <--- class has any comparison method in __dict__?# Raise because to allow this case would interfere with using# functools.total_ordering.# __hash__#    +------------------- unsafe_hash= parameter#    |       +----------- eq= parameter#    |       |       +--- frozen= parameter#    |       |       |#    v       v       v    |        |        |#                         |   no   |  yes   |  <--- class has explicitly defined __hash__# +=======+=======+=======+========+========+# | False | False | False |        |        | No __eq__, use the base class __hash__# +-------+-------+-------+--------+--------+# | False | False | True  |        |        | No __eq__, use the base class __hash__# | False | True  | False | None   |        | <-- the default, not hashable# | False | True  | True  | add    |        | Frozen, so hashable, allows override# | True  | False | False | add    | raise  | Has no __eq__, but hashable# | True  | False | True  | add    | raise  | Has no __eq__, but hashable# | True  | True  | False | add    | raise  | Not frozen, but hashable# | True  | True  | True  | add    | raise  | Frozen, so hashable# For boxes that are blank, __hash__ is untouched and therefore# inherited from the base class.  If the base is object, then# id-based hashing is used.# Note that a class may already have __hash__=None if it specified an# __eq__ method in the class body (not one that was created by# @dataclass).# See _hash_action (below) for a coded version of this table.# __match_args__#    +--- match_args= parameter#         |  no   |  yes  |  <--- class has __match_args__ in __dict__?# __match_args__ is always added unless the class already defines it. It is a# tuple of __init__ parameter names; non-init fields must be matched by keyword.# Raised when an attempt is made to modify a frozen class.# A sentinel object for default values to signal that a default# factory will be used.  This is given a nice repr() which will appear# in the function signature of dataclasses' constructors.# A sentinel object to detect if a parameter is supplied or not.  Use# a class to give it a better repr.# A sentinel object to indicate that following fields are keyword-only by# default.  Use a class to give it a better repr.# Since most per-field metadata will be unused, create an empty# read-only proxy that can be shared among all fields.# Markers for the various kinds of fields and pseudo-fields.# The name of an attribute on the class where we store the Field# objects.  Also used to check if a class is a Data Class.# The name of an attribute on the class that stores the parameters to# @dataclass.# The name of the function, that if it exists, is called at the end of# __init__.# String regex that string annotations for ClassVar or InitVar must match.# Allows "identifier.identifier[" or "identifier[".# https://bugs.python.org/issue33453 for details.# Atomic immutable types which don't require any recursive handling and for which deepcopy# returns the same object. We can provide a fast-path for these types in asdict and astuple.# Common JSON Serializable types# Other common types# Other types that are also unaffected by deepcopy# This function's logic is copied from "recursive_repr" function in# reprlib module to avoid dependency.# Decorator to make a repr function return "..." for a recursive# call.# typing objects, e.g. List[int]# Instances of Field are only ever created from within this module,# and only from the field() function, although Field instances are# exposed externally as (conceptually) read-only objects.# name and type are filled in after the fact, not in __init__.# They're not known at the time this class is instantiated, but it's# convenient if they're available later.# When cls._FIELDS is filled in with a list of Field objects, the name# and type fields will have been populated.# Private: not to be used by user code.# This is used to support the PEP 487 __set_name__ protocol in the# case where we're using a field that contains a descriptor as a# default value.  For details on __set_name__, see# https://peps.python.org/pep-0487/#implementation-details.# Note that in _process_class, this Field object is overwritten# with the default value, so the end result is a descriptor that# had __set_name__ called on it at the right time.# There is a __set_name__ method on the descriptor, call# This function is used instead of exposing Field creation directly,# so that a type checker can be told (via overloads) that this is a# function whose type depends on its parameters.# Returns the fields as __init__ will output them.  It returns 2 tuples:# the first for normal args, and the second for keyword args.# Return a string representing each field of obj_name as a tuple# member.  So, if fields is ['x', 'y'] and obj_name is "self",# return "(self.x,self.y)".# Special case for the 0-tuple.# Note the trailing comma, needed if this turns out to be a 1-tuple.# Note that we may mutate locals. Callers beware!# The only callers are internal to this module, so no# worries about external callers.# Compute the text of the entire function.# Free variables in exec are resolved in the global namespace.# The global namespace we have is user-provided, so we can't modify it for# our purposes. So we put the things we need into locals and introduce a# scope to allow the function we're creating to close over them.# If we're a frozen class, then assign to our fields in __init__# via object.__setattr__.  Otherwise, just use a simple# assignment.# self_name is what "self" is called in this function: don't# hard-code "self", since that might be a field name.# Return the text of the line in the body of __init__ that will# initialize this field.# This field has a default factory.  If a parameter is# given, use it.  If not, call the factory.# This is a field that's not in the __init__ params, but# has a default factory function.  It needs to be# initialized here by calling the factory function,# because there's no other way to initialize it.# For a field initialized with a default=defaultvalue, the# class dict just has the default value# (cls.fieldname=defaultvalue).  But that won't work for a# default factory, the factory must be called in __init__# and we must assign that to self.fieldname.  We can't# fall back to the class dict's value, both because it's# not set, and because it might be different per-class# (which, after all, is why we have a factory function!).# No default factory.# There's no default, just do an assignment.# If the class has slots, then initialize this field.# This field does not need initialization: reading from it will# just use the class attribute that contains the default.# Signify that to the caller by returning None.# Only test this now, so that we can create variables for the# default.  However, return None to signify that we're not going# to actually do the assignment statement for InitVars.# Now, actually generate the field assignment.# Return the __init__ parameter string for this field.  For# example, the equivalent of 'x:int=3' (except instead of 'int',# reference a variable set to int, and instead of '3', reference a# variable set to 3).# There's no default, and no default_factory, just output the# variable name and type.# There's a default, this will be the name that's used to look# it up.# There's a factory function.  Set a marker.# fields contains both real fields and InitVar pseudo-fields.# Make sure we don't have fields without defaults following fields# with defaults.  This actually would be caught when exec-ing the# function source code, but catching it here gives a better error# message, and future-proofs us in case we build up the function# using ast.# Only consider the non-kw-only fields in the __init__ call.# line is None means that this field doesn't require# initialization (it's a pseudo-field).  Just skip it.# Does this class have a post-init function?# If no body lines, use 'pass'.# Add the keyword-only args.  Because the * can only be added if# there's at least one keyword-only arg, there needs to be a test here# (instead of just concatenting the lists together).# Create a comparison function.  If the fields in the object are# named 'x' and 'y', then self_tuple is the string# '(self.x,self.y)' and other_tuple is the string# '(other.x,other.y)'.# This test uses a typing internal class, but it's the best way to# test if this is a ClassVar.# The module we're checking against is the module we're# currently in (dataclasses.py).# Given a type annotation string, does it refer to a_type in# a_module?  For example, when checking that annotation denotes a# ClassVar, then a_module is typing, and a_type is# typing.ClassVar.# It's possible to look up a_module given a_type, but it involves# looking in sys.modules (again!), and seems like a waste since# the caller already knows a_module.# - annotation is a string type annotation# - cls is the class that this annotation was found in# - a_module is the module we want to match# - a_type is the type in that module we want to match# - is_type_predicate is a function called with (obj, a_module)#   that determines if obj is of the desired type.# Since this test does not do a local namespace lookup (and# instead only a module (global) lookup), there are some things it# gets wrong.# With string annotations, cv0 will be detected as a ClassVar:#   CV = ClassVar#   @dataclass#   class C0:#     cv0: CV# But in this example cv1 will not be detected as a ClassVar:#   class C1:#     CV = ClassVar#     cv1: CV# In C1, the code in this function (_is_type) will look up "CV" in# the module and not find it, so it will not consider cv1 as a# ClassVar.  This is a fairly obscure corner case, and the best# way to fix it would be to eval() the string "CV" with the# correct global and local namespaces.  However that would involve# a eval() penalty for every single field of every dataclass# that's defined.  It was judged not worth it.# No module name, assume the class's module did# "from dataclasses import InitVar".# Look up module_name in the class's module.# Return a Field object for this field name and type.  ClassVars and# InitVars are also returned, but marked as such (see f._field_type).# default_kw_only is the value of kw_only to use if there isn't a field()# that defines it.# If the default value isn't derived from Field, then it's only a# normal default value.  Convert it to a Field().# This is a field in __slots__, so it has no default value.# Only at this point do we know the name and the type.  Set them.# Assume it's a normal field until proven otherwise.  We're next# going to decide if it's a ClassVar or InitVar, everything else# is just a normal field.# In addition to checking for actual types here, also check for# string annotations.  get_type_hints() won't always work for us# (see https://github.com/python/typing/issues/508 for example),# plus it's expensive and would require an eval for every string# annotation.  So, make a best effort to see if this is a ClassVar# or InitVar using regex's and checking that the thing referenced# is actually of the correct type.# For the complete discussion, see https://bugs.python.org/issue33453# If typing has not been imported, then it's impossible for any# annotation to be a ClassVar.  So, only look for ClassVar if# typing has been imported by any module (not necessarily cls's# module).# If the type is InitVar, or if it's a matching string annotation,# then it's an InitVar.# Validations for individual fields.  This is delayed until now,# instead of in the Field() constructor, since only here do we# know the field name, which allows for better error reporting.# Special restrictions for ClassVar and InitVar.# Should I check for other field settings? default_factory# seems the most serious to check for.  Maybe add others.  For# example, how about init=False (or really,# init=<not-the-default-init-value>)?  It makes no sense for# ClassVar and InitVar to specify init=<anything>.# kw_only validation and assignment.# For real and InitVar fields, if kw_only wasn't specified use the# default value.# Make sure kw_only isn't set for ClassVars# For real fields, disallow mutable defaults.  Use unhashable as a proxy# indicator for mutability.  Read the __hash__ attribute from the class,# not the instance.# Ensure that the functions returned from _create_fn uses the proper# __qualname__ (the class they belong to).# Never overwrites an existing attribute.  Returns True if the# attribute already exists.# Decide if/how we're going to create a hash function.  Key is# (unsafe_hash, eq, frozen, does-hash-exist).  Value is the action to# take.  The common case is to do nothing, so instead of providing a# function that is a no-op, use None to signify that.# Raise an exception.#                +-------------------------------------- unsafe_hash?#                |      +------------------------------- eq?#                |      |      +------------------------ frozen?#                |      |      |      +----------------  has-explicit-hash?#                |      |      |      |#                |      |      |      |        +-------  action#                |      |      |      |        |#                v      v      v      v        v# See https://bugs.python.org/issue32929#msg312829 for an if-statement# version of this table.# Now that dicts retain insertion order, there's no reason to use# an ordered dict.  I am leveraging that ordering here, because# derived class fields overwrite base class fields, but the order# is defined by the base class, which is found first.# Theoretically this can happen if someone writes# a custom string to cls.__module__.  In which case# such dataclass won't be fully introspectable# (w.r.t. typing.get_type_hints) but will still function# correctly.# Find our base classes in reverse MRO order, and exclude# ourselves.  In reversed order so that more derived classes# override earlier field definitions in base classes.  As long as# we're iterating over them, see if any are frozen.# Only process classes that have been processed by our# decorator.  That is, they have a _FIELDS attribute.# Annotations defined specifically in this class (not in base classes).# Fields are found from cls_annotations, which is guaranteed to be# ordered.  Default values are from class attributes, if a field# has a default.  If the default value is a Field(), then it# contains additional info beyond (and possibly including) the# actual default value.  Pseudo-fields ClassVars and InitVars are# included, despite the fact that they're not real fields.  That's# dealt with later.# Now find fields in our class.  While doing so, validate some# things, and set the default values (as class attributes) where# we can.# Get a reference to this module for the _is_kw_only() test.# See if this is a marker to change the value of kw_only.# Switch the default to kw_only=True, and ignore this# annotation: it's not a real field.# Otherwise it's a field of some type.# If the class attribute (which is the default value for this# field) exists and is of type 'Field', replace it with the# real default.  This is so that normal class introspection# sees a real default value, not a Field.# If there's no default, delete the class attribute.# This happens if we specify field(repr=False), for# example (that is, we specified a field object, but# no default value).  Also if we're using a default# factory.  The class attribute should not be set at# all in the post-processed class.# Do we have any Field members that don't also have annotations?# Check rules that apply if we are derived from any dataclasses.# Raise an exception if any of our bases are frozen, but we're not.# Raise an exception if we're frozen, but none of our bases are.# Remember all of the fields on our class (including bases).  This# also marks this class as being a dataclass.# Was this class defined with an explicit __hash__?  Note that if# __eq__ is defined in this class, then python will automatically# set __hash__ to None.  This is a heuristic, as it's possible# that such a __hash__ == None was not auto-generated, but it# close enough.# If we're generating ordering methods, we must be generating the# eq methods.# Include InitVars and regular fields (so, not ClassVars).  This is# initialized here, outside of the "if init:" test, because std_init_fields# is used with match_args, below.# The name to use for the "self"# param in __init__.  Use "self"# if possible.# Get the fields as a list, and include only real fields.  This is# used in all of the following methods.# Create __eq__ method.  There's no need for a __ne__ method,# since python will call __eq__ and negate it.# Create and set the ordering methods.# Decide if/how we're going to create a hash function.# No need to call _set_new_attribute here, since by the time# we're here the overwriting is unconditional.# Create a class doc-string.# In some cases fetching a signature is not possible.# But, we surely should not fail in this case.# I could probably compute this once# It's an error to specify weakref_slot if slots is False.# _dataclass_getstate and _dataclass_setstate are needed for pickling frozen# classes with slots.  These could be slightly more performant if we generated# the code instead of iterating over fields.  But that can be a project for# another day, if performance becomes an issue.# use setattr because dataclass may be frozen# `__dictoffset__` and `__weakrefoffset__` can tell us whether# the base type has dict/weakref slots, in a way that works correctly# for both Python classes and C extension types. Extension types# don't use `__slots__` for slot creation# Slots may be any iterable, but we cannot handle an iterator# because it will already be (partially) consumed.# Need to create a new class, since we can't set __slots__#  after a class has been created.# Make sure __slots__ isn't already set.# Create a new dict for our new class.# Make sure slots don't overlap with those in base classes.# The slots for our class.  Remove slots from our base classes.  Add# '__weakref__' if weakref_slot was given, unless it is already present.# gh-93521: '__weakref__' also needs to be filtered out if# already present in inherited_slots# Remove our attributes, if present. They'll still be#  available in _MARKER.# Remove __dict__ itself.# Clear existing `__weakref__` descriptor, it belongs to a previous type:# gh-102069# And finally create the class.# Need this for pickling frozen classes with slots.# See if we're being called as @dataclass or @dataclass().# We're called with parens.# We're called as @dataclass without parens.# Might it be worth caching this, per class?# Exclude pseudo-fields.  Note that fields is sorted by insertion# order, so the order of the tuple is as the fields were defined.# fast path for the common case# obj is a namedtuple.  Recurse into it, but the returned# object is another namedtuple of the same type.  This is# similar to how other list- or tuple-derived classes are# treated (see below), but we just need to create them# differently because a namedtuple's __init__ needs to be# called differently (see bpo-34363).# I'm not using namedtuple's _asdict()# method, because:# - it does not recurse in to the namedtuple fields and#   convert them to dicts (using dict_factory).# - I don't actually want to return a dict here.  The main#   use case here is json.dumps, and it handles converting#   namedtuples to lists.  Admittedly we're losing some#   information here when we produce a json list instead of a#   dict.  Note that if we returned dicts here instead of#   namedtuples, we could no longer call asdict() on a data#   structure where a namedtuple was used as a dict key.# Assume we can create an object of this type by passing in a# generator (which is not true for namedtuples, handled# above).# obj is a defaultdict, which has a different constructor from# dict as it requires the default_factory as its first arg.# While we're looking through the field names, validate that they# are identifiers, are not keywords, and not duplicates.# Update 'ns' with the user-supplied namespace plus our calculated values.# We use `types.new_class()` instead of simply `type()` to allow dynamic creation# of generic dataclasses.# where the dataclass is created.# Apply the normal decorator.# We're going to mutate 'changes', but that's okay because it's a# new dict, even if called with 'replace(obj, **my_changes)'.# It's an error to have init=False fields in 'changes'.# If a field is not in 'changes', read its value from the provided obj.# Only consider normal fields or InitVars.# Error if this field is specified in changes.# Create the new object, which calls __init__() and# __post_init__() (if defined), using all of the init fields we've# added and/or left in 'changes'.  If there are values supplied in# changes that aren't fields, this will correctly raise a# TypeError.b'dataclass'u'dataclass'b'field'u'field'b'Field'u'Field'b'FrozenInstanceError'u'FrozenInstanceError'b'InitVar'u'InitVar'b'KW_ONLY'u'KW_ONLY'b'MISSING'u'MISSING'b'fields'u'fields'b'asdict'u'asdict'b'astuple'u'astuple'b'make_dataclass'u'make_dataclass'b'is_dataclass'u'is_dataclass'b'<factory>'u'<factory>'b'_FIELD'u'_FIELD'b'_FIELD_CLASSVAR'u'_FIELD_CLASSVAR'b'_FIELD_INITVAR'u'_FIELD_INITVAR'b'__dataclass_fields__'u'__dataclass_fields__'b'__dataclass_params__'u'__dataclass_params__'b'__post_init__'u'__post_init__'b'^(?:\s*(\w+)\s*\.)?\s*(\w+)'u'^(?:\s*(\w+)\s*\.)?\s*(\w+)'b'dataclasses.InitVar['u'dataclasses.InitVar['b'default_factory'u'default_factory'b'hash'u'hash'b'init'u'init'b'compare'u'compare'b'metadata'u'metadata'b'kw_only'u'kw_only'b'_field_type'u'_field_type'b'Field(name='u'Field(name='b',type='u',type='b',default='u',default='b',default_factory='u',default_factory='b',init='u',init='b',repr='u',repr='b',hash='u',hash='b',compare='u',compare='b',metadata='u',metadata='b',kw_only='u',kw_only='b',_field_type='u',_field_type='b'__set_name__'u'__set_name__'b'eq'u'eq'b'order'u'order'b'unsafe_hash'u'unsafe_hash'b'match_args'u'match_args'b'slots'u'slots'b'weakref_slot'u'weakref_slot'b'_DataclassParams(init='u'_DataclassParams(init='b',eq='u',eq='b',order='u',order='b',unsafe_hash='u',unsafe_hash='b',frozen='u',frozen='b',match_args='u',match_args='b',slots='u',slots='b',weakref_slot='u',weakref_slot='b'Return an object to identify dataclass fields.

    default is the default value of the field.  default_factory is a
    0-argument function called to initialize a field's value.  If init
    is true, the field will be a parameter to the class's __init__()
    function.  If repr is true, the field will be included in the
    object's repr().  If hash is true, the field will be included in the
    object's hash().  If compare is true, the field will be used in
    comparison functions.  metadata, if specified, must be a mapping
    which is stored but not otherwise examined by dataclass.  If kw_only
    is true, the field will become a keyword-only parameter to
    __init__().

    It is an error to specify both default and default_factory.
    'u'Return an object to identify dataclass fields.

    default is the default value of the field.  default_factory is a
    0-argument function called to initialize a field's value.  If init
    is true, the field will be a parameter to the class's __init__()
    function.  If repr is true, the field will be included in the
    object's repr().  If hash is true, the field will be included in the
    object's hash().  If compare is true, the field will be used in
    comparison functions.  metadata, if specified, must be a mapping
    which is stored but not otherwise examined by dataclass.  If kw_only
    is true, the field will become a keyword-only parameter to
    __init__().

    It is an error to specify both default and default_factory.
    'b'cannot specify both default and default_factory'u'cannot specify both default and default_factory'b',)'u',)'b'__dataclass_return_type__'u'__dataclass_return_type__'b'->__dataclass_return_type__'u'->__dataclass_return_type__'b' def 'u' def 'b':
'u':
'b'def __create_fn__('u'def __create_fn__('b'):
'u'):
'b'
 return 'u'
 return 'b'__create_fn__'u'__create_fn__'b'__dataclass_builtins_object__.__setattr__('u'__dataclass_builtins_object__.__setattr__('b'__dataclass_dflt_'u'__dataclass_dflt_'b'() if 'u'() if 'b' is __dataclass_HAS_DEFAULT_FACTORY__ else 'u' is __dataclass_HAS_DEFAULT_FACTORY__ else 'b'=__dataclass_dflt_'u'=__dataclass_dflt_'b'=__dataclass_HAS_DEFAULT_FACTORY__'u'=__dataclass_HAS_DEFAULT_FACTORY__'b':__dataclass_type_'u':__dataclass_type_'b'non-default argument 'u'non-default argument 'b' follows default argument'u' follows default argument'b'__dataclass_type_'u'__dataclass_type_'b'__dataclass_HAS_DEFAULT_FACTORY__'u'__dataclass_HAS_DEFAULT_FACTORY__'b'__dataclass_builtins_object__'u'__dataclass_builtins_object__'b'self'u'self'b'return self.__class__.__qualname__ + f"('u'return self.__class__.__qualname__ + f"('b'={{self.'u'={{self.'b'!r}}'u'!r}}'b')"'u')"'b'cls'b'type(self) is cls'u'type(self) is cls'b' or name in {'u' or name in {'b'__setattr__'u'__setattr__'b' raise FrozenInstanceError(f"cannot assign to field {name!r}")'u' raise FrozenInstanceError(f"cannot assign to field {name!r}")'b'super(cls, self).__setattr__(name, value)'u'super(cls, self).__setattr__(name, value)'b'__delattr__'u'__delattr__'b' raise FrozenInstanceError(f"cannot delete field {name!r}")'u' raise FrozenInstanceError(f"cannot delete field {name!r}")'b'super(cls, self).__delattr__(name)'u'super(cls, self).__delattr__(name)'b'other'u'other'b'if other.__class__ is self.__class__:'u'if other.__class__ is self.__class__:'b' return 'u' return 'b'return NotImplemented'u'return NotImplemented'b'return hash('u'return hash('b'field 'u'field 'b' cannot have a default factory'u' cannot have a default factory'b' is a ClassVar but specifies kw_only'u' is a ClassVar but specifies kw_only'b'mutable default 'u'mutable default 'b' for field 'u' for field 'b' is not allowed: use default_factory'u' is not allowed: use default_factory'b'Cannot overwrite attribute __hash__ in class 'u'Cannot overwrite attribute __hash__ in class 'b' is KW_ONLY, but KW_ONLY has already been specified'u' is KW_ONLY, but KW_ONLY has already been specified'b' is a field but has no type annotation'u' is a field but has no type annotation'b'cannot inherit non-frozen dataclass from a frozen one'u'cannot inherit non-frozen dataclass from a frozen one'b'cannot inherit frozen dataclass from a non-frozen one'u'cannot inherit frozen dataclass from a non-frozen one'b'__eq__'u'__eq__'b'eq must be true if order is true'u'eq must be true if order is true'b'__dataclass_self__'u'__dataclass_self__'b'__lt__'u'__lt__'b'__le__'u'__le__'b'__gt__'u'__gt__'b'__ge__'u'__ge__'b'Cannot overwrite attribute 'u'Cannot overwrite attribute 'b' in class 'u' in class 'b'. Consider using functools.total_ordering'u'. Consider using functools.total_ordering'b' -> None'u' -> None'b'weakref_slot is True but slots is False'u'weakref_slot is True but slots is False'b'__weakrefoffset__'u'__weakrefoffset__'b'__dictrefoffset__'u'__dictrefoffset__'b'Slots of ''u'Slots of ''b'' cannot be determined'u'' cannot be determined'b' already specifies __slots__'u' already specifies __slots__'b'__getstate__'u'__getstate__'b'Add dunder methods based on the fields defined in the class.

    Examines PEP 526 __annotations__ to determine fields.

    If init is true, an __init__() method is added to the class. If repr
    is true, a __repr__() method is added. If order is true, rich
    comparison dunder methods are added. If unsafe_hash is true, a
    __hash__() method is added. If frozen is true, fields may not be
    assigned to after instance creation. If match_args is true, the
    __match_args__ tuple is added. If kw_only is true, then by default
    all fields are keyword-only. If slots is true, a new class with a
    __slots__ attribute is returned.
    'u'Add dunder methods based on the fields defined in the class.

    Examines PEP 526 __annotations__ to determine fields.

    If init is true, an __init__() method is added to the class. If repr
    is true, a __repr__() method is added. If order is true, rich
    comparison dunder methods are added. If unsafe_hash is true, a
    __hash__() method is added. If frozen is true, fields may not be
    assigned to after instance creation. If match_args is true, the
    __match_args__ tuple is added. If kw_only is true, then by default
    all fields are keyword-only. If slots is true, a new class with a
    __slots__ attribute is returned.
    'b'Return a tuple describing the fields of this dataclass.

    Accepts a dataclass or an instance of one. Tuple elements are of
    type Field.
    'u'Return a tuple describing the fields of this dataclass.

    Accepts a dataclass or an instance of one. Tuple elements are of
    type Field.
    'b'must be called with a dataclass type or instance'u'must be called with a dataclass type or instance'b'Returns True if obj is an instance of a dataclass.'u'Returns True if obj is an instance of a dataclass.'b'Returns True if obj is a dataclass or an instance of a
    dataclass.'u'Returns True if obj is a dataclass or an instance of a
    dataclass.'b'Return the fields of a dataclass instance as a new dictionary mapping
    field names to field values.

    Example usage::

      @dataclass
      class C:
          x: int
          y: int

      c = C(1, 2)
      assert asdict(c) == {'x': 1, 'y': 2}

    If given, 'dict_factory' will be used instead of built-in dict.
    The function applies recursively to field values that are
    dataclass instances. This will also look into built-in containers:
    tuples, lists, and dicts. Other objects are copied with 'copy.deepcopy()'.
    'u'Return the fields of a dataclass instance as a new dictionary mapping
    field names to field values.

    Example usage::

      @dataclass
      class C:
          x: int
          y: int

      c = C(1, 2)
      assert asdict(c) == {'x': 1, 'y': 2}

    If given, 'dict_factory' will be used instead of built-in dict.
    The function applies recursively to field values that are
    dataclass instances. This will also look into built-in containers:
    tuples, lists, and dicts. Other objects are copied with 'copy.deepcopy()'.
    'b'asdict() should be called on dataclass instances'u'asdict() should be called on dataclass instances'b'Return the fields of a dataclass instance as a new tuple of field values.

    Example usage::

      @dataclass
      class C:
          x: int
          y: int

      c = C(1, 2)
      assert astuple(c) == (1, 2)

    If given, 'tuple_factory' will be used instead of built-in tuple.
    The function applies recursively to field values that are
    dataclass instances. This will also look into built-in containers:
    tuples, lists, and dicts. Other objects are copied with 'copy.deepcopy()'.
    'u'Return the fields of a dataclass instance as a new tuple of field values.

    Example usage::

      @dataclass
      class C:
          x: int
          y: int

      c = C(1, 2)
      assert astuple(c) == (1, 2)

    If given, 'tuple_factory' will be used instead of built-in tuple.
    The function applies recursively to field values that are
    dataclass instances. This will also look into built-in containers:
    tuples, lists, and dicts. Other objects are copied with 'copy.deepcopy()'.
    'b'astuple() should be called on dataclass instances'u'astuple() should be called on dataclass instances'b'Return a new dynamically created dataclass.

    The dataclass name will be 'cls_name'.  'fields' is an iterable
    of either (name), (name, type) or (name, type, Field) objects. If type is
    omitted, use the string 'typing.Any'.  Field objects are created by
    the equivalent of calling 'field(name, type [, Field-info])'.::

      C = make_dataclass('C', ['x', ('y', int), ('z', int, field(init=False))], bases=(Base,))

    is equivalent to::

      @dataclass
      class C(Base):
          x: 'typing.Any'
          y: int
          z: int = field(init=False)

    For the bases and namespace parameters, see the builtin type() function.

    The parameters init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only,
    slots, and weakref_slot are passed to dataclass().

    If module parameter is defined, the '__module__' attribute of the dataclass is
    set to that value.
    'u'Return a new dynamically created dataclass.

    The dataclass name will be 'cls_name'.  'fields' is an iterable
    of either (name), (name, type) or (name, type, Field) objects. If type is
    omitted, use the string 'typing.Any'.  Field objects are created by
    the equivalent of calling 'field(name, type [, Field-info])'.::

      C = make_dataclass('C', ['x', ('y', int), ('z', int, field(init=False))], bases=(Base,))

    is equivalent to::

      @dataclass
      class C(Base):
          x: 'typing.Any'
          y: int
          z: int = field(init=False)

    For the bases and namespace parameters, see the builtin type() function.

    The parameters init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only,
    slots, and weakref_slot are passed to dataclass().

    If module parameter is defined, the '__module__' attribute of the dataclass is
    set to that value.
    'b'typing.Any'u'typing.Any'b'Invalid field: 'u'Invalid field: 'b'Field names must be valid identifiers: 'u'Field names must be valid identifiers: 'b'Field names must not be keywords: 'u'Field names must not be keywords: 'b'Field name duplicated: 'u'Field name duplicated: 'b'__annotations__'u'__annotations__'b'Return a new object replacing specified fields with new values.

    This is especially useful for frozen classes.  Example usage::

      @dataclass(frozen=True)
      class C:
          x: int
          y: int

      c = C(1, 2)
      c1 = replace(c, x=3)
      assert c1.x == 3 and c1.y == 2
    'u'Return a new object replacing specified fields with new values.

    This is especially useful for frozen classes.  Example usage::

      @dataclass(frozen=True)
      class C:
          x: int
          y: int

      c = C(1, 2)
      c1 = replace(c, x=3)
      assert c1.x == 3 and c1.y == 2
    'b'replace() should be called on dataclass instances'u'replace() should be called on dataclass instances'b' is declared with init=False, it cannot be specified with replace()'u' is declared with init=False, it cannot be specified with replace()'b'InitVar 'u'InitVar 'b' must be specified with replace()'u' must be specified with replace()'u'Lib.dataclasses'u'dataclasses'u'Lib.datetime'Decimal fixed point and floating point arithmetic.

This is an implementation of decimal floating point arithmetic based on
the General Decimal Arithmetic Specification:

    http://speleotrove.com/decimal/decarith.html

and IEEE standard 854-1987:

    http://en.wikipedia.org/wiki/IEEE_854-1987

Decimal floating point has finite precision with arbitrarily large bounds.

The purpose of this module is to support arithmetic using familiar
"schoolhouse" rules and to avoid some of the tricky representation
issues associated with binary floating point.  The package is especially
useful for financial applications or for contexts where users have
expectations that are at odds with binary floating point (for instance,
in binary floating point, 1.00 % 0.1 gives 0.09999999999999995 instead
of 0.0; Decimal('1.00') % Decimal('0.1') returns the expected
Decimal('0.00')).

Here are some examples of using the decimal module:

>>> from decimal import *
>>> setcontext(ExtendedContext)
>>> Decimal(0)
Decimal('0')
>>> Decimal('1')
Decimal('1')
>>> Decimal('-.0123')
Decimal('-0.0123')
>>> Decimal(123456)
Decimal('123456')
>>> Decimal('123.45e12345678')
Decimal('1.2345E+12345680')
>>> Decimal('1.33') + Decimal('1.27')
Decimal('2.60')
>>> Decimal('12.34') + Decimal('3.87') - Decimal('18.41')
Decimal('-2.20')
>>> dig = Decimal(1)
>>> print(dig / Decimal(3))
0.333333333
>>> getcontext().prec = 18
>>> print(dig / Decimal(3))
0.333333333333333333
>>> print(dig.sqrt())
1
>>> print(Decimal(3).sqrt())
1.73205080756887729
>>> print(Decimal(3) ** 123)
4.85192780976896427E+58
>>> inf = Decimal(1) / Decimal(0)
>>> print(inf)
Infinity
>>> neginf = Decimal(-1) / Decimal(0)
>>> print(neginf)
-Infinity
>>> print(neginf + inf)
NaN
>>> print(neginf * inf)
-Infinity
>>> print(dig / 0)
Infinity
>>> getcontext().traps[DivisionByZero] = 1
>>> print(dig / 0)
Traceback (most recent call last):
  ...
  ...
  ...
decimal.DivisionByZero: x / 0
>>> c = Context()
>>> c.traps[InvalidOperation] = 0
>>> print(c.flags[InvalidOperation])
0
>>> c.divide(Decimal(0), Decimal(0))
Decimal('NaN')
>>> c.traps[InvalidOperation] = 1
>>> print(c.flags[InvalidOperation])
1
>>> c.flags[InvalidOperation] = 0
>>> print(c.flags[InvalidOperation])
0
>>> print(c.divide(Decimal(0), Decimal(0)))
Traceback (most recent call last):
  ...
  ...
  ...
decimal.InvalidOperation: 0 / 0
>>> print(c.flags[InvalidOperation])
1
>>> c.flags[InvalidOperation] = 0
>>> c.traps[InvalidOperation] = 0
>>> print(c.divide(Decimal(0), Decimal(0)))
NaN
>>> print(c.flags[InvalidOperation])
1
>>>
_decimal_pydecimalb'Decimal fixed point and floating point arithmetic.

This is an implementation of decimal floating point arithmetic based on
the General Decimal Arithmetic Specification:

    http://speleotrove.com/decimal/decarith.html

and IEEE standard 854-1987:

    http://en.wikipedia.org/wiki/IEEE_854-1987

Decimal floating point has finite precision with arbitrarily large bounds.

The purpose of this module is to support arithmetic using familiar
"schoolhouse" rules and to avoid some of the tricky representation
issues associated with binary floating point.  The package is especially
useful for financial applications or for contexts where users have
expectations that are at odds with binary floating point (for instance,
in binary floating point, 1.00 % 0.1 gives 0.09999999999999995 instead
of 0.0; Decimal('1.00') % Decimal('0.1') returns the expected
Decimal('0.00')).

Here are some examples of using the decimal module:

>>> from decimal import *
>>> setcontext(ExtendedContext)
>>> Decimal(0)
Decimal('0')
>>> Decimal('1')
Decimal('1')
>>> Decimal('-.0123')
Decimal('-0.0123')
>>> Decimal(123456)
Decimal('123456')
>>> Decimal('123.45e12345678')
Decimal('1.2345E+12345680')
>>> Decimal('1.33') + Decimal('1.27')
Decimal('2.60')
>>> Decimal('12.34') + Decimal('3.87') - Decimal('18.41')
Decimal('-2.20')
>>> dig = Decimal(1)
>>> print(dig / Decimal(3))
0.333333333
>>> getcontext().prec = 18
>>> print(dig / Decimal(3))
0.333333333333333333
>>> print(dig.sqrt())
1
>>> print(Decimal(3).sqrt())
1.73205080756887729
>>> print(Decimal(3) ** 123)
4.85192780976896427E+58
>>> inf = Decimal(1) / Decimal(0)
>>> print(inf)
Infinity
>>> neginf = Decimal(-1) / Decimal(0)
>>> print(neginf)
-Infinity
>>> print(neginf + inf)
NaN
>>> print(neginf * inf)
-Infinity
>>> print(dig / 0)
Infinity
>>> getcontext().traps[DivisionByZero] = 1
>>> print(dig / 0)
Traceback (most recent call last):
  ...
  ...
  ...
decimal.DivisionByZero: x / 0
>>> c = Context()
>>> c.traps[InvalidOperation] = 0
>>> print(c.flags[InvalidOperation])
0
>>> c.divide(Decimal(0), Decimal(0))
Decimal('NaN')
>>> c.traps[InvalidOperation] = 1
>>> print(c.flags[InvalidOperation])
1
>>> c.flags[InvalidOperation] = 0
>>> print(c.flags[InvalidOperation])
0
>>> print(c.divide(Decimal(0), Decimal(0)))
Traceback (most recent call last):
  ...
  ...
  ...
decimal.InvalidOperation: 0 / 0
>>> print(c.flags[InvalidOperation])
1
>>> c.flags[InvalidOperation] = 0
>>> c.traps[InvalidOperation] = 0
>>> print(c.divide(Decimal(0), Decimal(0)))
NaN
>>> print(c.flags[InvalidOperation])
1
>>>
'u'Decimal fixed point and floating point arithmetic.

This is an implementation of decimal floating point arithmetic based on
the General Decimal Arithmetic Specification:

    http://speleotrove.com/decimal/decarith.html

and IEEE standard 854-1987:

    http://en.wikipedia.org/wiki/IEEE_854-1987

Decimal floating point has finite precision with arbitrarily large bounds.

The purpose of this module is to support arithmetic using familiar
"schoolhouse" rules and to avoid some of the tricky representation
issues associated with binary floating point.  The package is especially
useful for financial applications or for contexts where users have
expectations that are at odds with binary floating point (for instance,
in binary floating point, 1.00 % 0.1 gives 0.09999999999999995 instead
of 0.0; Decimal('1.00') % Decimal('0.1') returns the expected
Decimal('0.00')).

Here are some examples of using the decimal module:

>>> from decimal import *
>>> setcontext(ExtendedContext)
>>> Decimal(0)
Decimal('0')
>>> Decimal('1')
Decimal('1')
>>> Decimal('-.0123')
Decimal('-0.0123')
>>> Decimal(123456)
Decimal('123456')
>>> Decimal('123.45e12345678')
Decimal('1.2345E+12345680')
>>> Decimal('1.33') + Decimal('1.27')
Decimal('2.60')
>>> Decimal('12.34') + Decimal('3.87') - Decimal('18.41')
Decimal('-2.20')
>>> dig = Decimal(1)
>>> print(dig / Decimal(3))
0.333333333
>>> getcontext().prec = 18
>>> print(dig / Decimal(3))
0.333333333333333333
>>> print(dig.sqrt())
1
>>> print(Decimal(3).sqrt())
1.73205080756887729
>>> print(Decimal(3) ** 123)
4.85192780976896427E+58
>>> inf = Decimal(1) / Decimal(0)
>>> print(inf)
Infinity
>>> neginf = Decimal(-1) / Decimal(0)
>>> print(neginf)
-Infinity
>>> print(neginf + inf)
NaN
>>> print(neginf * inf)
-Infinity
>>> print(dig / 0)
Infinity
>>> getcontext().traps[DivisionByZero] = 1
>>> print(dig / 0)
Traceback (most recent call last):
  ...
  ...
  ...
decimal.DivisionByZero: x / 0
>>> c = Context()
>>> c.traps[InvalidOperation] = 0
>>> print(c.flags[InvalidOperation])
0
>>> c.divide(Decimal(0), Decimal(0))
Decimal('NaN')
>>> c.traps[InvalidOperation] = 1
>>> print(c.flags[InvalidOperation])
1
>>> c.flags[InvalidOperation] = 0
>>> print(c.flags[InvalidOperation])
0
>>> print(c.divide(Decimal(0), Decimal(0)))
Traceback (most recent call last):
  ...
  ...
  ...
decimal.InvalidOperation: 0 / 0
>>> print(c.flags[InvalidOperation])
1
>>> c.flags[InvalidOperation] = 0
>>> c.traps[InvalidOperation] = 0
>>> print(c.divide(Decimal(0), Decimal(0)))
NaN
>>> print(c.flags[InvalidOperation])
1
>>>
'u'Lib.decimal'
Module difflib -- helpers for computing deltas between objects.

Function get_close_matches(word, possibilities, n=3, cutoff=0.6):
    Use SequenceMatcher to return list of the best "good enough" matches.

Function context_diff(a, b):
    For two lists of strings, return a delta in context diff format.

Function ndiff(a, b):
    Return a delta: the difference between `a` and `b` (lists of strings).

Function restore(delta, which):
    Return one of the two sequences that generated an ndiff delta.

Function unified_diff(a, b):
    For two lists of strings, return a delta in unified diff format.

Class SequenceMatcher:
    A flexible class for comparing pairs of sequences of any type.

Class Differ:
    For producing human-readable deltas from sequences of lines of text.

Class HtmlDiff:
    For producing HTML side by side comparison with change highlights.
get_close_matchesSequenceMatcherDifferIS_CHARACTER_JUNKIS_LINE_JUNKcontext_diffunified_diffdiff_bytesHtmlDiff_nlargesta b size_calculate_ratio
    SequenceMatcher is a flexible class for comparing pairs of sequences of
    any type, so long as the sequence elements are hashable.  The basic
    algorithm predates, and is a little fancier than, an algorithm
    published in the late 1980's by Ratcliff and Obershelp under the
    hyperbolic name "gestalt pattern matching".  The basic idea is to find
    the longest contiguous matching subsequence that contains no "junk"
    elements (R-O doesn't address junk).  The same idea is then applied
    recursively to the pieces of the sequences to the left and to the right
    of the matching subsequence.  This does not yield minimal edit
    sequences, but does tend to yield matches that "look right" to people.

    SequenceMatcher tries to compute a "human-friendly diff" between two
    sequences.  Unlike e.g. UNIX(tm) diff, the fundamental notion is the
    longest *contiguous* & junk-free matching subsequence.  That's what
    catches peoples' eyes.  The Windows(tm) windiff has another interesting
    notion, pairing up elements that appear uniquely in each sequence.
    That, and the method here, appear to yield more intuitive difference
    reports than does diff.  This method appears to be the least vulnerable
    to syncing up on blocks of "junk lines", though (like blank lines in
    ordinary text files, or maybe "<P>" lines in HTML files).  That may be
    because this is the only method of the 3 that has a *concept* of
    "junk" <wink>.

    Example, comparing two strings, and considering blanks to be "junk":

    >>> s = SequenceMatcher(lambda x: x == " ",
    ...                     "private Thread currentThread;",
    ...                     "private volatile Thread currentThread;")
    >>>

    .ratio() returns a float in [0, 1], measuring the "similarity" of the
    sequences.  As a rule of thumb, a .ratio() value over 0.6 means the
    sequences are close matches:

    >>> print(round(s.ratio(), 3))
    0.866
    >>>

    If you're only interested in where the sequences match,
    .get_matching_blocks() is handy:

    >>> for block in s.get_matching_blocks():
    ...     print("a[%d] and b[%d] match for %d elements" % block)
    a[0] and b[0] match for 8 elements
    a[8] and b[17] match for 21 elements
    a[29] and b[38] match for 0 elements

    Note that the last tuple returned by .get_matching_blocks() is always a
    dummy, (len(a), len(b), 0), and this is the only case in which the last
    tuple element (number of elements matched) is 0.

    If you want to know how to change the first sequence into the second,
    use .get_opcodes():

    >>> for opcode in s.get_opcodes():
    ...     print("%6s a[%d:%d] b[%d:%d]" % opcode)
     equal a[0:8] b[0:8]
    insert a[8:8] b[8:17]
     equal a[8:29] b[17:38]

    See the Differ class for a fancy human-friendly file differencer, which
    uses SequenceMatcher both to compare sequences of lines, and to compare
    sequences of characters within similar (near-matching) lines.

    See also function get_close_matches() in this module, which shows how
    simple code building on SequenceMatcher can be used to do useful work.

    Timing:  Basic R-O is cubic time worst case and quadratic time expected
    case.  SequenceMatcher is quadratic time for the worst case and has
    expected-case behavior dependent in a complicated way on how many
    elements the sequences have in common; best case time is linear.
    isjunkautojunkConstruct a SequenceMatcher.

        Optional arg isjunk is None (the default), or a one-argument
        function that takes a sequence element and returns true iff the
        element is junk.  None is equivalent to passing "lambda x: 0", i.e.
        no elements are considered to be junk.  For example, pass
            lambda x: x in " \t"
        if you're comparing lines as sequences of characters, and don't
        want to synch up on blanks or hard tabs.

        Optional arg a is the first of two sequences to be compared.  By
        default, an empty string.  The elements of a must be hashable.  See
        also .set_seqs() and .set_seq1().

        Optional arg b is the second of two sequences to be compared.  By
        default, an empty string.  The elements of b must be hashable. See
        also .set_seqs() and .set_seq2().

        Optional arg autojunk should be set to False to disable the
        "automatic junk heuristic" that treats popular elements as junk
        (see module documentation for more information).
        set_seqsSet the two sequences to be compared.

        >>> s = SequenceMatcher()
        >>> s.set_seqs("abcd", "bcde")
        >>> s.ratio()
        0.75
        set_seq1set_seq2Set the first sequence to be compared.

        The second sequence to be compared is not changed.

        >>> s = SequenceMatcher(None, "abcd", "bcde")
        >>> s.ratio()
        0.75
        >>> s.set_seq1("bcde")
        >>> s.ratio()
        1.0
        >>>

        SequenceMatcher computes and caches detailed information about the
        second sequence, so if you want to compare one sequence S against
        many sequences, use .set_seq2(S) once and call .set_seq1(x)
        repeatedly for each of the other sequences.

        See also set_seqs() and set_seq2().
        matching_blocksopcodesSet the second sequence to be compared.

        The first sequence to be compared is not changed.

        >>> s = SequenceMatcher(None, "abcd", "bcde")
        >>> s.ratio()
        0.75
        >>> s.set_seq2("abcd")
        >>> s.ratio()
        1.0
        >>>

        SequenceMatcher computes and caches detailed information about the
        second sequence, so if you want to compare one sequence S against
        many sequences, use .set_seq2(S) once and call .set_seq1(x)
        repeatedly for each of the other sequences.

        See also set_seqs() and set_seq1().
        fullbcount__chain_bb2jbjunkjunkbpopularpopularntestidxsfind_longest_matchaloahiblobhiFind longest matching block in a[alo:ahi] and b[blo:bhi].

        By default it will find the longest match in the entirety of a and b.

        If isjunk is not defined:

        Return (i,j,k) such that a[i:i+k] is equal to b[j:j+k], where
            alo <= i <= i+k <= ahi
            blo <= j <= j+k <= bhi
        and for all (i',j',k') meeting those conditions,
            k >= k'
            i <= i'
            and if i == i', j <= j'

        In other words, of all maximal matching blocks, return one that
        starts earliest in a, and of all those maximal matching blocks that
        start earliest in a, return the one that starts earliest in b.

        >>> s = SequenceMatcher(None, " abcd", "abcd abcd")
        >>> s.find_longest_match(0, 5, 0, 9)
        Match(a=0, b=4, size=5)

        If isjunk is defined, first the longest matching block is
        determined as above, but with the additional restriction that no
        junk element appears in the block.  Then that block is extended as
        far as possible by matching (only) junk elements on both sides.  So
        the resulting block never matches on junk except as identical junk
        happens to be adjacent to an "interesting" match.

        Here's the same example as before, but considering blanks to be
        junk.  That prevents " abcd" from matching the " abcd" at the tail
        end of the second sequence directly.  Instead only the "abcd" can
        match, and matches the leftmost "abcd" in the second sequence:

        >>> s = SequenceMatcher(lambda x: x==" ", " abcd", "abcd abcd")
        >>> s.find_longest_match(0, 5, 0, 9)
        Match(a=1, b=0, size=4)

        If no blocks match, return (alo, blo, 0).

        >>> s = SequenceMatcher(None, "ab", "c")
        >>> s.find_longest_match(0, 2, 0, 1)
        Match(a=0, b=0, size=0)
        isbjunkbestibestjbestsizej2lennothingj2lengetnewj2lenget_matching_blocksReturn list of triples describing matching subsequences.

        Each triple is of the form (i, j, n), and means that
        a[i:i+n] == b[j:j+n].  The triples are monotonically increasing in
        i and in j.  New in Python 2.5, it's also guaranteed that if
        (i, j, n) and (i', j', n') are adjacent triples in the list, and
        the second is not the last triple in the list, then i+n != i' or
        j+n != j'.  IOW, adjacent triples never describe adjacent equal
        blocks.

        The last triple is a dummy, (len(a), len(b), 0), and is the only
        triple with n==0.

        >>> s = SequenceMatcher(None, "abxcd", "abcd")
        >>> list(s.get_matching_blocks())
        [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)]
        lalbj1k1non_adjacentj2k2get_opcodesReturn list of 5-tuples describing how to turn a into b.

        Each tuple is of the form (tag, i1, i2, j1, j2).  The first tuple
        has i1 == j1 == 0, and remaining tuples have i1 == the i2 from the
        tuple preceding it, and likewise for j1 == the previous j2.

        The tags are strings, with these meanings:

        'replace':  a[i1:i2] should be replaced by b[j1:j2]
        'delete':   a[i1:i2] should be deleted.
                    Note that j1==j2 in this case.
        'insert':   b[j1:j2] should be inserted at a[i1:i1].
                    Note that i1==i2 in this case.
        'equal':    a[i1:i2] == b[j1:j2]

        >>> a = "qabxcd"
        >>> b = "abycdf"
        >>> s = SequenceMatcher(None, a, b)
        >>> for tag, i1, i2, j1, j2 in s.get_opcodes():
        ...    print(("%7s a[%d:%d] (%s) b[%d:%d] (%s)" %
        ...           (tag, i1, i2, a[i1:i2], j1, j2, b[j1:j2])))
         delete a[0:1] (q) b[0:0] ()
          equal a[1:3] (ab) b[0:2] (ab)
        replace a[3:4] (x) b[2:3] (y)
          equal a[4:6] (cd) b[3:5] (cd)
         insert a[6:6] () b[5:6] (f)
        answeraibjdeleteequalget_grouped_opcodes Isolate change clusters by eliminating ranges with no changes.

        Return a generator of groups with up to n lines of context.
        Each group is in the same format as returned by get_opcodes().

        >>> from pprint import pprint
        >>> a = list(map(str, range(1,40)))
        >>> b = a[:]
        >>> b[8:8] = ['i']     # Make an insertion
        >>> b[20] += 'x'       # Make a replacement
        >>> b[23:28] = []      # Make a deletion
        >>> b[30] += 'y'       # Make another replacement
        >>> pprint(list(SequenceMatcher(None,a,b).get_grouped_opcodes()))
        [[('equal', 5, 8, 5, 8), ('insert', 8, 8, 8, 9), ('equal', 8, 11, 9, 12)],
         [('equal', 16, 19, 17, 20),
          ('replace', 19, 20, 20, 21),
          ('equal', 20, 22, 21, 23),
          ('delete', 22, 27, 23, 23),
          ('equal', 27, 30, 23, 26)],
         [('equal', 31, 34, 27, 30),
          ('replace', 34, 35, 30, 31),
          ('equal', 35, 38, 31, 34)]]
        codesnnratioReturn a measure of the sequences' similarity (float in [0,1]).

        Where T is the total number of elements in both sequences, and
        M is the number of matches, this is 2.0*M / T.
        Note that this is 1 if the sequences are identical, and 0 if
        they have nothing in common.

        .ratio() is expensive to compute if you haven't already computed
        .get_matching_blocks() or .get_opcodes(), in which case you may
        want to try .quick_ratio() or .real_quick_ratio() first to get an
        upper bound.

        >>> s = SequenceMatcher(None, "abcd", "bcde")
        >>> s.ratio()
        0.75
        >>> s.quick_ratio()
        0.75
        >>> s.real_quick_ratio()
        1.0
        triplequick_ratioReturn an upper bound on ratio() relatively quickly.

        This isn't defined beyond that it is an upper bound on .ratio(), and
        is faster to compute.
        availavailhasnumbreal_quick_ratioReturn an upper bound on ratio() very quickly.

        This isn't defined beyond that it is an upper bound on .ratio(), and
        is faster to compute than either .ratio() or .quick_ratio().
        0.6possibilitiesUse SequenceMatcher to return list of the best "good enough" matches.

    word is a sequence for which close matches are desired (typically a
    string).

    possibilities is a list of sequences against which to match word
    (typically a list of strings).

    Optional arg n (default 3) is the maximum number of close matches to
    return.  n must be > 0.

    Optional arg cutoff (default 0.6) is a float in [0, 1].  Possibilities
    that don't score at least that similar to word are ignored.

    The best (no more than n) matches among the possibilities are returned
    in a list, sorted by similarity score, most similar first.

    >>> get_close_matches("appel", ["ape", "apple", "peach", "puppy"])
    ['apple', 'ape']
    >>> import keyword as _keyword
    >>> get_close_matches("wheel", _keyword.kwlist)
    ['while']
    >>> get_close_matches("Apple", _keyword.kwlist)
    []
    >>> get_close_matches("accept", _keyword.kwlist)
    ['except']
    n must be > 0: %rcutoff must be in [0.0, 1.0]: %rscore_keep_original_wstag_sReplace whitespace with the original whitespace characters in `s`tag_c
    Differ is a class for comparing sequences of lines of text, and
    producing human-readable differences or deltas.  Differ uses
    SequenceMatcher both to compare sequences of lines, and to compare
    sequences of characters within similar (near-matching) lines.

    Each line of a Differ delta begins with a two-letter code:

        '- '    line unique to sequence 1
        '+ '    line unique to sequence 2
        '  '    line common to both sequences
        '? '    line not present in either input sequence

    Lines beginning with '? ' attempt to guide the eye to intraline
    differences, and were not present in either input sequence.  These lines
    can be confusing if the sequences contain tab characters.

    Note that Differ makes no claim to produce a *minimal* diff.  To the
    contrary, minimal diffs are often counter-intuitive, because they synch
    up anywhere possible, sometimes accidental matches 100 pages apart.
    Restricting synch points to contiguous matches preserves some notion of
    locality, at the occasional cost of producing a longer diff.

    Example: Comparing two texts.

    First we set up the texts, sequences of individual single-line strings
    ending with newlines (such sequences can also be obtained from the
    `readlines()` method of file-like objects):

    >>> text1 = '''  1. Beautiful is better than ugly.
    ...   2. Explicit is better than implicit.
    ...   3. Simple is better than complex.
    ...   4. Complex is better than complicated.
    ... '''.splitlines(keepends=True)
    >>> len(text1)
    4
    >>> text1[0][-1]
    '\n'
    >>> text2 = '''  1. Beautiful is better than ugly.
    ...   3.   Simple is better than complex.
    ...   4. Complicated is better than complex.
    ...   5. Flat is better than nested.
    ... '''.splitlines(keepends=True)

    Next we instantiate a Differ object:

    >>> d = Differ()

    Note that when instantiating a Differ object we may pass functions to
    filter out line and character 'junk'.  See Differ.__init__ for details.

    Finally, we compare the two:

    >>> result = list(d.compare(text1, text2))

    'result' is a list of strings, so let's pretty-print it:

    >>> from pprint import pprint as _pprint
    >>> _pprint(result)
    ['    1. Beautiful is better than ugly.\n',
     '-   2. Explicit is better than implicit.\n',
     '-   3. Simple is better than complex.\n',
     '+   3.   Simple is better than complex.\n',
     '?     ++\n',
     '-   4. Complex is better than complicated.\n',
     '?            ^                     ---- ^\n',
     '+   4. Complicated is better than complex.\n',
     '?           ++++ ^                      ^\n',
     '+   5. Flat is better than nested.\n']

    As a single multi-line string it looks like this:

    >>> print(''.join(result), end="")
        1. Beautiful is better than ugly.
    -   2. Explicit is better than implicit.
    -   3. Simple is better than complex.
    +   3.   Simple is better than complex.
    ?     ++
    -   4. Complex is better than complicated.
    ?            ^                     ---- ^
    +   4. Complicated is better than complex.
    ?           ++++ ^                      ^
    +   5. Flat is better than nested.
    linejunkcharjunk
        Construct a text differencer, with optional filters.

        The two optional keyword parameters are for filter functions:

        - `linejunk`: A function that should accept a single string argument,
          and return true iff the string is junk. The module-level function
          `IS_LINE_JUNK` may be used to filter out lines without visible
          characters, except for at most one splat ('#').  It is recommended
          to leave linejunk None; the underlying SequenceMatcher class has
          an adaptive notion of "noise" lines that's better than any static
          definition the author has ever been able to craft.

        - `charjunk`: A function that should accept a string of length 1. The
          module-level function `IS_CHARACTER_JUNK` may be used to filter out
          whitespace characters (a blank or tab; **note**: bad idea to include
          newline in this!).  Use of IS_CHARACTER_JUNK is recommended.
        
        Compare two sequences of lines; generate the resulting delta.

        Each sequence must contain individual single-line strings ending with
        newlines. Such sequences can be obtained from the `readlines()` method
        of file-like objects.  The delta generated also consists of newline-
        terminated strings, ready to be printed as-is via the writelines()
        method of a file-like object.

        Example:

        >>> print(''.join(Differ().compare('one\ntwo\nthree\n'.splitlines(True),
        ...                                'ore\ntree\nemu\n'.splitlines(True))),
        ...       end="")
        - one
        ?  ^
        + ore
        ?  ^
        - two
        - three
        ?  -
        + tree
        + emu
        cruncher_fancy_replace_dumpGenerate comparison results for a same-tagged range._plain_replace
        When replacing one block of lines with another, search the blocks
        for *similar* lines; the best-matching pair (if any) is used as a
        synch point, and intraline difference marking is done on the
        similar pair. Lots of work, but often worth it.

        Example:

        >>> d = Differ()
        >>> results = d._fancy_replace(['abcDefghiJkl\n'], 0, 1,
        ...                            ['abcdefGhijkl\n'], 0, 1)
        >>> print(''.join(results), end="")
        - abcDefghiJkl
        ?    ^  ^  ^
        + abcdefGhijkl
        ?    ^  ^  ^
        0.74best_ratioeqieqjbest_ibest_j_fancy_helperaeltbeltatagsbtagsai1ai2bj1bj2_qformatalinebline
        Format "?" output and deal with tabs.

        Example:

        >>> d = Differ()
        >>> results = d._qformat('\tabcDefghiJkl\n', '\tabcdefGhijkl\n',
        ...                      '  ^ ^  ^      ', '  ^ ^  ^      ')
        >>> for line in results: print(repr(line))
        ...
        '- \tabcDefghiJkl\n'
        '? \t ^ ^  ^\n'
        '+ \tabcdefGhijkl\n'
        '? \t ^ ^  ^\n'
        - ? + \s*(?:#\s*)?$pat
    Return True for ignorable line: iff `line` is blank or contains a single '#'.

    Examples:

    >>> IS_LINE_JUNK('\n')
    True
    >>> IS_LINE_JUNK('  #   \n')
    True
    >>> IS_LINE_JUNK('hello\n')
    False
    
    Return True for ignorable character: iff `ch` is a space or tab.

    Examples:

    >>> IS_CHARACTER_JUNK(' ')
    True
    >>> IS_CHARACTER_JUNK('\t')
    True
    >>> IS_CHARACTER_JUNK('\n')
    False
    >>> IS_CHARACTER_JUNK('x')
    False
    _format_range_unifiedConvert range to the "ed" formatbeginning{},{}fromfiledatetofiledatelineterm
    Compare two sequences of lines; generate the delta as a unified diff.

    Unified diffs are a compact way of showing line changes and a few
    lines of context.  The number of context lines is set by 'n' which
    defaults to three.

    By default, the diff control lines (those with ---, +++, or @@) are
    created with a trailing newline.  This is helpful so that inputs
    created from file.readlines() result in diffs that are suitable for
    file.writelines() since both the inputs and outputs have trailing
    newlines.

    For inputs that do not have trailing newlines, set the lineterm
    argument to "" so that the output will be uniformly newline free.

    The unidiff format normally has a header for filenames and modification
    times.  Any or all of these may be specified using strings for
    'fromfile', 'tofile', 'fromfiledate', and 'tofiledate'.
    The modification times are normally expressed in the ISO 8601 format.

    Example:

    >>> for line in unified_diff('one two three four'.split(),
    ...             'zero one tree four'.split(), 'Original', 'Current',
    ...             '2005-01-26 23:30:50', '2010-04-02 10:20:52',
    ...             lineterm=''):
    ...     print(line)                 # doctest: +NORMALIZE_WHITESPACE
    --- Original        2005-01-26 23:30:50
    +++ Current         2010-04-02 10:20:52
    @@ -1,4 +1,4 @@
    +zero
     one
    -two
    -three
    +tree
     four
    _check_typesstarted	{}fromdatetodate--- {}{}{}+++ {}{}{}file1_rangefile2_range@@ -{} +{} @@{}_format_range_context
    Compare two sequences of lines; generate the delta as a context diff.

    Context diffs are a compact way of showing line changes and a few
    lines of context.  The number of context lines is set by 'n' which
    defaults to three.

    By default, the diff control lines (those with *** or ---) are
    created with a trailing newline.  This is helpful so that inputs
    created from file.readlines() result in diffs that are suitable for
    file.writelines() since both the inputs and outputs have trailing
    newlines.

    For inputs that do not have trailing newlines, set the lineterm
    argument to "" so that the output will be uniformly newline free.

    The context diff format normally has a header for filenames and
    modification times.  Any or all of these may be specified using
    strings for 'fromfile', 'tofile', 'fromfiledate', and 'tofiledate'.
    The modification times are normally expressed in the ISO 8601 format.
    If not specified, the strings default to blanks.

    Example:

    >>> print(''.join(context_diff('one\ntwo\nthree\nfour\n'.splitlines(True),
    ...       'zero\none\ntree\nfour\n'.splitlines(True), 'Original', 'Current')),
    ...       end="")
    *** Original
    --- Current
    ***************
    *** 1,4 ****
      one
    ! two
    ! three
      four
    --- 1,4 ----
    + zero
      one
    ! tree
      four
    ! *** {}{}{}****************** {} ****{}--- {} ----{}lines to compare must be str, not %s (%r)all arguments must be str, not: %rdfunc
    Compare `a` and `b`, two sequences of lines represented as bytes rather
    than str. This is a wrapper for `dfunc`, which is typically either
    unified_diff() or context_diff(). Inputs are losslessly converted to
    strings so that `dfunc` only has to worry about strings, and encoded
    back to bytes on return. This is necessary to compare files with
    unknown or inconsistent encoding. All other inputs (except `n`) must be
    bytes rather than str.
    all arguments must be bytes, not %s (%r)
    Compare `a` and `b` (lists of strings); return a `Differ`-style delta.

    Optional keyword parameters `linejunk` and `charjunk` are for filter
    functions, or can be None:

    - linejunk: A function that should accept a single string argument and
      return true iff the string is junk.  The default is None, and is
      recommended; the underlying SequenceMatcher class has an adaptive
      notion of "noise" lines.

    - charjunk: A function that accepts a character (string of length
      1), and returns true iff the character is junk. The default is
      the module-level function IS_CHARACTER_JUNK, which filters out
      whitespace characters (a blank or tab; note: it's a bad idea to
      include newline in this!).

    Tools/scripts/ndiff.py is a command-line front-end to this function.

    Example:

    >>> diff = ndiff('one\ntwo\nthree\n'.splitlines(keepends=True),
    ...              'ore\ntree\nemu\n'.splitlines(keepends=True))
    >>> print(''.join(diff), end="")
    - one
    ?  ^
    + ore
    ?  ^
    - two
    - three
    ?  -
    + tree
    + emu
    _mdifffromlinestolinesReturns generator yielding marked up from/to side by side differences.

    Arguments:
    fromlines -- list of text lines to compared to tolines
    tolines -- list of text lines to be compared to fromlines
    context -- number of context lines to display on each side of difference,
               if None, all from/to text lines will be generated.
    linejunk -- passed on to ndiff (see ndiff documentation)
    charjunk -- passed on to ndiff (see ndiff documentation)

    This function returns an iterator which returns a tuple:
    (from line tuple, to line tuple, boolean flag)

    from/to line tuple -- (line num, line text)
        line num -- integer or None (to indicate a context separation)
        line text -- original line text with following markers inserted:
            '\0+' -- marks start of added text
            '\0-' -- marks start of deleted text
            '\0^' -- marks start of changed text
            '\1' -- marks end of added/deleted/changed text

    boolean flag -- None indicates context separation, True indicates
        either "from" or "to" line contains a change, otherwise False.

    This function/iterator was originally developed to generate side by side
    file difference for making HTML pages (see HtmlDiff class for example
    usage).

    Note, this function utilizes the ndiff function to generate the side by
    side difference markup.  Optional ndiff arguments may be passed to this
    function and they in turn will be passed to ndiff.
    (\++|\-+|\^+)change_rediff_lines_iterator_make_lineformat_keysidenum_linesReturns line of text with user's change markup and line formatting.

        lines -- list of lines from the ndiff generator to produce a line of
                 text from.  When producing the line of text to return, the
                 lines used are removed from this list.
        format_key -- '+' return first line in list with "add" markup around
                          the entire line.
                      '-' return first line in list with "delete" markup around
                          the entire line.
                      '?' return first line in list with add/delete/change
                          intraline markup (indices obtained from second line)
                      None return first line in list with no markup
        side -- indice into the num_lines list (0=from,1=to)
        num_lines -- from/to current line number.  This is NOT intended to be a
                     passed parameter.  It is present as a keyword argument to
                     maintain memory of the current line numbers between calls
                     of this function.

        Note, this function is purposefully not defined at the module scope so
        that data it needs from its parent function (within whose context it
        is defined) does not need to be of module scope.
        markerssub_inforecord_sub_infomatch_objectspan_line_iteratorYields from/to lines of text with a change indication.

        This function is an iterator.  It itself pulls lines from a
        differencing iterator, processes them and yields them.  When it can
        it yields both a "from" and a "to" line, otherwise it will yield one
        or the other.  In addition to yielding the lines of from/to text, a
        boolean flag is yielded to indicate if the text line(s) have
        differences in them.

        Note, this function is purposefully not defined at the module scope so
        that data it needs from its parent function (within whose context it
        is defined) does not need to be of module scope.
        num_blanks_pendingnum_blanks_to_yield-?+?--++--?+--+from_lineto_line-+?-?++--+-_line_pair_iteratorYields from/to lines of text with a change indication.

        This function is an iterator.  It itself pulls lines from the line
        iterator.  Its difference from that iterator is that this function
        always yields a pair of from/to text lines (with the change
        indication).  If necessary it will collect single from/to lines
        until it has a matching pair from/to pair to yield.

        Note, this function is purposefully not defined at the module scope so
        that data it needs from its parent function (within whose context it
        is defined) does not need to be of module scope.
        line_iteratorfound_difffromDiffto_diffline_pair_iteratorlines_to_writecontextLines
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
          "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html>

<head>
    <meta http-equiv="Content-Type"
          content="text/html; charset=%(charset)s" />
    <title></title>
    <style type="text/css">%(styles)s
    </style>
</head>

<body>
    %(table)s%(legend)s
</body>

</html>_file_template
        table.diff {font-family:Courier; border:medium;}
        .diff_header {background-color:#e0e0e0}
        td.diff_header {text-align:right}
        .diff_next {background-color:#c0c0c0}
        .diff_add {background-color:#aaffaa}
        .diff_chg {background-color:#ffff77}
        .diff_sub {background-color:#ffaaaa}_styles
    <table class="diff" id="difflib_chg_%(prefix)s_top"
           cellspacing="0" cellpadding="0" rules="groups" >
        <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
        <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
        %(header_row)s
        <tbody>
%(data_rows)s        </tbody>
    </table>_table_template
    <table class="diff" summary="Legends">
        <tr> <th colspan="2"> Legends </th> </tr>
        <tr> <td> <table border="" summary="Colors">
                      <tr><th> Colors </th> </tr>
                      <tr><td class="diff_add">&nbsp;Added&nbsp;</td></tr>
                      <tr><td class="diff_chg">Changed</td> </tr>
                      <tr><td class="diff_sub">Deleted</td> </tr>
                  </table></td>
             <td> <table border="" summary="Links">
                      <tr><th colspan="2"> Links </th> </tr>
                      <tr><td>(f)irst change</td> </tr>
                      <tr><td>(n)ext change</td> </tr>
                      <tr><td>(t)op</td> </tr>
                  </table></td> </tr>
    </table>_legendFor producing HTML side by side comparison with change highlights.

    This class can be used to create an HTML table (or a complete HTML file
    containing the table) showing a side by side, line by line comparison
    of text with inter-line and intra-line change highlights.  The table can
    be generated in either full or contextual difference mode.

    The following methods are provided for HTML generation:

    make_table -- generates HTML for a single side by side table
    make_file -- generates complete HTML file with a single side by side table

    See tools/scripts/diff.py for an example usage of this class.
    _default_prefixwrapcolumnHtmlDiff instance initializer

        Arguments:
        tabsize -- tab stop spacing, defaults to 8.
        wrapcolumn -- column number where lines are broken and wrapped,
            defaults to None where lines are not wrapped.
        linejunk,charjunk -- keyword arguments passed into ndiff() (used by
            HtmlDiff() to generate the side by side HTML differences).  See
            ndiff() documentation for argument default values and descriptions.
        _tabsize_wrapcolumn_linejunk_charjunkmake_filefromdesctodescnumlinesReturns HTML file of side by side comparison with change highlights

        Arguments:
        fromlines -- list of "from" lines
        tolines -- list of "to" lines
        fromdesc -- "from" file column header string
        todesc -- "to" file column header string
        context -- set to True for contextual differences (defaults to False
            which shows full differences).
        numlines -- number of context lines.  When context is set True,
            controls number of lines displayed before and after the change.
            When context is False, controls the number of lines to place
            the "next" link anchors before the next change (so click of
            "next" link jumps to just before the change).
        charset -- charset of the HTML document
        styleslegendmake_table_tab_newline_replaceReturns from/to line lists with tabs expanded and newlines removed.

        Instead of tab characters being replaced by the number of spaces
        needed to fill in to the next tab stop, this function will fill
        the space with tab characters.  This is done so that the difference
        algorithms can identify changes in a file when tabs are replaced by
        spaces and vice versa.  At the end of the HTML generation, the tab
        characters will be replaced with a nonbreakable space.
        expand_tabs_split_linedata_listline_numBuilds list of text lines by splitting text lines at wrap point

        This function will determine if the input text line needs to be
        wrapped (split) into separate lines.  If so, the first wrap point
        will be determined and the first line appended to the output
        text line list.  This function is used recursively to handle
        the second part of the split line to further split it.
        line1line2_line_wrapperdiffsReturns iterator that splits (wraps) mdiff text linesfromdatatodatafromlinefromtexttolinetotext_collect_linesCollects mdiff output into separate lists

        Before storing the mdiff from/to data into a list, it is converted
        into a single line of text with HTML markup.
        flaglist_format_linelinenumReturns HTML markup of "from" / "to" text lines

        side -- 0 or 1 indicating "from" or "to" text
        flag -- indicates if difference on line
        linenum -- line number (used for line number column)
        text -- line text to be marked up
        %d id="%s%s"_prefix&nbsp;<td class="diff_header"%s>%s</td><td nowrap="nowrap">%s</td>_make_prefixCreate unique anchor prefixesfrom%d_fromprefixto%d_toprefix_convert_flagsMakes list of "next" linksnext_idnext_hrefnum_chgin_change id="difflib_chg_%s_%d"<a href="#difflib_chg_%s_%d">n</a><td></td><td>&nbsp;No Differences Found&nbsp;</td><td></td><td>&nbsp;Empty File&nbsp;</td><a href="#difflib_chg_%s_0">f</a><a href="#difflib_chg_%s_top">t</a>Returns HTML table of side by side comparison with change highlights

        Arguments:
        fromlines -- list of "from" lines
        tolines -- list of "to" lines
        fromdesc -- "from" file column header string
        todesc -- "to" file column header string
        context -- set to True for contextual differences (defaults to False
            which shows full differences).
        numlines -- number of context lines.  When context is set True,
            controls number of lines displayed before and after the change.
            When context is False, controls the number of lines to place
            the "next" link anchors before the next change (so click of
            "next" link jumps to just before the change).
        context_lines            <tr><td class="diff_next"%s>%s</td>%s<td class="diff_next">%s</td>%s</tr>
        </tbody>        
        <tbody>
<thead><tr>%s%s%s%s</tr></thead><th class="diff_next"><br /></th><th colspan="2" class="diff_header">%s</th>header_rowdata_rows +<span class="diff_add"> -<span class="diff_sub"> ^<span class="diff_chg"></span>which
    Generate one of the two sequences that generated a delta.

    Given a `delta` produced by `Differ.compare()` or `ndiff()`, extract
    lines originating from file 1 or 2 (parameter `which`), stripping off line
    prefixes.

    Examples:

    >>> diff = ndiff('one\ntwo\nthree\n'.splitlines(keepends=True),
    ...              'ore\ntree\nemu\n'.splitlines(keepends=True))
    >>> diff = list(diff)
    >>> print(''.join(restore(diff, 1)), end="")
    one
    two
    three
    >>> print(''.join(restore(diff, 2)), end="")
    ore
    tree
    emu
    unknown delta choice (must be 1 or 2): %rprefixes_testdoctesttestmod# Members:# a#      first sequence# b#      second sequence; differences are computed as "what do#      we need to do to 'a' to change it into 'b'?"# b2j#      for x in b, b2j[x] is a list of the indices (into b)#      at which x appears; junk and popular elements do not appear# fullbcount#      for x in b, fullbcount[x] == the number of times x#      appears in b; only materialized if really needed (used#      only for computing quick_ratio())# matching_blocks#      a list of (i, j, k) triples, where a[i:i+k] == b[j:j+k];#      ascending & non-overlapping in i and in j; terminated by#      a dummy (len(a), len(b), 0) sentinel# opcodes#      a list of (tag, i1, i2, j1, j2) tuples, where tag is#      one of#          'replace'   a[i1:i2] should be replaced by b[j1:j2]#          'delete'    a[i1:i2] should be deleted#          'insert'    b[j1:j2] should be inserted#          'equal'     a[i1:i2] == b[j1:j2]# isjunk#      a user-supplied function taking a sequence element and#      returning true iff the element is "junk" -- this has#      subtle but helpful effects on the algorithm, which I'll#      get around to writing up someday <0.9 wink>.#      DON'T USE!  Only __chain_b uses this.  Use "in self.bjunk".# bjunk#      the items in b for which isjunk is True.# bpopular#      nonjunk items in b treated as junk by the heuristic (if used).# For each element x in b, set b2j[x] to a list of the indices in# b where x appears; the indices are in increasing order; note that# the number of times x appears in b is len(b2j[x]) ...# when self.isjunk is defined, junk elements don't show up in this# map at all, which stops the central find_longest_match method# from starting any matching block at a junk element ...# b2j also does not contain entries for "popular" elements, meaning# elements that account for more than 1 + 1% of the total elements, and# when the sequence is reasonably large (>= 200 elements); this can# be viewed as an adaptive notion of semi-junk, and yields an enormous# speedup when, e.g., comparing program files with hundreds of# instances of "return NULL;" ...# note that this is only called when b changes; so for cross-product# kinds of matches, it's best to call set_seq2 once, then set_seq1# repeatedly# Because isjunk is a user-defined (not C) function, and we test# for junk a LOT, it's important to minimize the number of calls.# Before the tricks described here, __chain_b was by far the most# time-consuming routine in the whole module!  If anyone sees# Jim Roskind, thank him again for profile.py -- I never would# have guessed that.# The first trick is to build b2j ignoring the possibility# of junk.  I.e., we don't call isjunk at all yet.  Throwing# out the junk later is much cheaper than building b2j "right"# from the start.# Purge junk elements# separate loop avoids separate list of keys# Purge popular elements that are not junk# ditto; as fast for 1% deletion# CAUTION:  stripping common prefix or suffix would be incorrect.# E.g.,#    ab#    acab# Longest matching block is "ab", but if common prefix is# stripped, it's "a" (tied with "b").  UNIX(tm) diff does so# strip, so ends up claiming that ab is changed to acab by# inserting "ca" in the middle.  That's minimal but unintuitive:# "it's obvious" that someone inserted "ac" at the front.# Windiff ends up at the same place as diff, but by pairing up# the unique 'b's and then matching the first two 'a's.# find longest junk-free match# during an iteration of the loop, j2len[j] = length of longest# junk-free match ending with a[i-1] and b[j]# look at all instances of a[i] in b; note that because# b2j has no junk keys, the loop is skipped if a[i] is junk# a[i] matches b[j]# Extend the best by non-junk elements on each end.  In particular,# "popular" non-junk elements aren't in b2j, which greatly speeds# the inner loop above, but also means "the best" match so far# doesn't contain any junk *or* popular non-junk elements.# Now that we have a wholly interesting match (albeit possibly# empty!), we may as well suck up the matching junk on each# side of it too.  Can't think of a good reason not to, and it# saves post-processing the (possibly considerable) expense of# figuring out what to do with it.  In the case of an empty# interesting match, this is clearly the right thing to do,# because no other kind of match is possible in the regions.# This is most naturally expressed as a recursive algorithm, but# at least one user bumped into extreme use cases that exceeded# the recursion limit on their box.  So, now we maintain a list# ('queue`) of blocks we still need to look at, and append partial# results to `matching_blocks` in a loop; the matches are sorted# at the end.# a[alo:i] vs b[blo:j] unknown# a[i:i+k] same as b[j:j+k]# a[i+k:ahi] vs b[j+k:bhi] unknown# if k is 0, there was no matching block# It's possible that we have adjacent equal blocks in the# matching_blocks list now.  Starting with 2.5, this code was added# to collapse them.# Is this block adjacent to i1, j1, k1?# Yes, so collapse them -- this just increases the length of# the first block by the length of the second, and the first# block so lengthened remains the block to compare against.# Not adjacent.  Remember the first block (k1==0 means it's# the dummy we started with), and make the second block the# new block to compare against.# invariant:  we've pumped out correct diffs to change# a[:i] into b[:j], and the next matching block is# a[ai:ai+size] == b[bj:bj+size].  So we need to pump# out a diff to change a[i:ai] into b[j:bj], pump out# the matching block, and move (i,j) beyond the match# the list of matching blocks is terminated by a# sentinel with size 0# Fixup leading and trailing groups if they show no changes.# End the current group and start a new one whenever# there is a large range with no changes.# viewing a and b as multisets, set matches to the cardinality# of their intersection; this counts the number of matches# without regard to order, so is clearly an upper bound# avail[x] is the number of times x appears in 'b' less the# number of times we've seen it in 'a' so far ... kinda# can't have more matches than the number of elements in the# shorter sequence# Move the best scorers to head of list# Strip scores for the best n matches# dump the shorter block first -- reduces the burden on short-term# memory if the blocks are of very different sizes# don't synch up unless the lines have a similarity score of at# least cutoff; best_ratio tracks the best score seen so far# 1st indices of equal lines (if any)# search for the pair that matches best without being identical# (identical lines must be junk lines, & we don't want to synch up# on junk -- unless we have to)# computing similarity is expensive, so use the quick# upper bounds first -- have seen this speed up messy# compares by a factor of 3.# note that ratio() is only expensive to compute the first# time it's called on a sequence pair; the expensive part# of the computation is cached by cruncher# no non-identical "pretty close" pair# no identical pair either -- treat it as a straight replace# no close pair, but an identical pair -- synch up on that# there's a close pair, so forget the identical pair (if any)# a[best_i] very similar to b[best_j]; eqi is None iff they're not# identical# pump out diffs from before the synch point# do intraline marking on the synch pair# pump out a '-', '?', '+', '?' quad for the synched lines# the synch pair is identical# pump out diffs from after the synch point# With respect to junk, an earlier version of ndiff simply refused to# *start* a match with a junk element.  The result was cases like this:#     before: private Thread currentThread;#     after:  private volatile Thread currentThread;# If you consider whitespace to be junk, the longest contiguous match# not starting with junk is "e Thread currentThread".  So ndiff reported# that "e volatil" was inserted between the 't' and the 'e' in "private".# While an accurate view, to people that's absurd.  The current version# looks for matching blocks that are entirely junk-free, then extends the# longest one of those as far as possible but only with matching junk.# So now "currentThread" is matched, then extended to suck up the# preceding blank; then "private" is matched, and extended to suck up the# following blank; then "Thread" is matched; and finally ndiff reports# that "volatile " was inserted before "Thread".  The only quibble# remaining is that perhaps it was really the case that " volatile"# was inserted after "private".  I can live with that <wink>.###  Unified Diff# Per the diff spec at http://www.unix.org/single_unix_specification/# lines start numbering with one# empty ranges begin at line just before the range###  Context Diff# See http://www.unix.org/single_unix_specification/# Checking types is weird, but the alternative is garbled output when# someone passes mixed bytes and str to {unified,context}_diff(). E.g.# without this check, passing filenames as bytes results in output like#   --- b'oldfile.txt'#   +++ b'newfile.txt'# because of how str.format() incorporates bytes objects.# regular expression for finding intraline change indices# create the difference iterator to generate the differences# Handle case where no user markup is to be added, just return line of# text with user's line format to allow for usage of the line number.# Handle case of intraline changes# find intraline changes (store change type and indices in tuples)# process each tuple inserting our special marks that won't be# noticed by an xml/html escaper.# Handle case of add/delete entire line# if line of text is just a newline, insert a space so there is# something for the user to highlight and see.# insert marks that won't be noticed by an xml/html escaper.# Return line of text, first allow user's line formatter to do its# thing (such as adding the line number) then replace the special# marks with what the user's change markup.# Load up next 4 lines so we can look ahead, create strings which# are a concatenation of the first character of each of the 4 lines# so we can do some very readable comparisons.# When no more lines, pump out any remaining blank lines so the# corresponding add/delete lines get a matching blank line so# all line pairs get yielded at the next level.# simple intraline change# in delete block, add block coming: we do NOT want to get# caught up on blank lines yet, just process the delete line# in delete block and see an intraline change or unchanged line# coming: yield the delete line and then blanks# intraline change# delete FROM line# in add block, delete block coming: we do NOT want to get# caught up on blank lines yet, just process the add line# will be leaving an add block: yield blanks then add line# inside an add block, yield the add line# unchanged text, yield it to both sides# Catch up on the blank lines so when we yield the next from/to# pair, they are lined up.# Collecting lines of text until we have a from/to pair# Once we have a pair, remove them from the collection and yield it# Handle case where user does not want context differencing, just yield# them up without doing anything else with them.# Handle case where user wants context differencing.  We must do some# storage of lines until we know for sure that they are to be yielded.# Store lines up until we find a difference, note use of a# circular queue because we only need to keep around what# we need for context.# Yield lines that we have collected so far, but first yield# the user's separator.# Now yield the context lines after the change# If another change within the context, extend the context# Catch exception from next() and return normally# hide real spaces# expand tabs into spaces# replace spaces from expanded tabs back into tab characters# (we'll replace them with markup after we do differencing)# if blank line or context separator, just add it to the output list# if line text doesn't need wrapping, just add it to the output list# scan text looking for the wrap point, keeping track if the wrap# point is inside markers# wrap point is inside text, break it up into separate lines# if wrap point is inside markers, place end marker at end of first# line and start marker at beginning of second line because each# line will have its own table tag markup around it.# tack on first line onto the output list# use this routine again to wrap the remaining text# pull from/to data and flags from mdiff iterator# check for context separators and pass them through# for each from/to line split it at the wrap column to form# list of text lines.# yield from/to line in pairs inserting blank lines as# necessary when one side has more wrapped lines# pull from/to data and flags from mdiff style iterator# store HTML markup of the lines into the lists# exceptions occur for lines where context separators go# handle blank lines where linenum is '>' or ''# replace those things that would get confused with HTML symbols# make space non-breakable so they don't get compressed or line wrapped# Generate a unique anchor prefix so multiple tables# can exist on the same HTML page without conflicts.# store prefixes so line format method has access# all anchor names will be generated using the unique "to" prefix# process change flags, generating middle column of next anchors/links# at the beginning of a change, drop an anchor a few lines# (the context lines) before the change for the previous# link# at the beginning of a change, drop a link to the next# change# check for cases where there is no content to avoid exceptions# if not a change on first line, drop a link# redo the last link to link to the top# make unique anchor prefixes so that multiple tables may exist# on the same page without conflict.# change tabs to spaces before it gets more difficult after we insert# markup# create diffs iterator which generates side by side from/to data# set up iterator to wrap lines that exceed desired width# collect up from/to lines and flags into lists (also format the lines)# mdiff yields None on separator lines skip the bogus ones# generated for the first lineb'
Module difflib -- helpers for computing deltas between objects.

Function get_close_matches(word, possibilities, n=3, cutoff=0.6):
    Use SequenceMatcher to return list of the best "good enough" matches.

Function context_diff(a, b):
    For two lists of strings, return a delta in context diff format.

Function ndiff(a, b):
    Return a delta: the difference between `a` and `b` (lists of strings).

Function restore(delta, which):
    Return one of the two sequences that generated an ndiff delta.

Function unified_diff(a, b):
    For two lists of strings, return a delta in unified diff format.

Class SequenceMatcher:
    A flexible class for comparing pairs of sequences of any type.

Class Differ:
    For producing human-readable deltas from sequences of lines of text.

Class HtmlDiff:
    For producing HTML side by side comparison with change highlights.
'u'
Module difflib -- helpers for computing deltas between objects.

Function get_close_matches(word, possibilities, n=3, cutoff=0.6):
    Use SequenceMatcher to return list of the best "good enough" matches.

Function context_diff(a, b):
    For two lists of strings, return a delta in context diff format.

Function ndiff(a, b):
    Return a delta: the difference between `a` and `b` (lists of strings).

Function restore(delta, which):
    Return one of the two sequences that generated an ndiff delta.

Function unified_diff(a, b):
    For two lists of strings, return a delta in unified diff format.

Class SequenceMatcher:
    A flexible class for comparing pairs of sequences of any type.

Class Differ:
    For producing human-readable deltas from sequences of lines of text.

Class HtmlDiff:
    For producing HTML side by side comparison with change highlights.
'b'get_close_matches'u'get_close_matches'b'ndiff'u'ndiff'b'restore'u'restore'b'SequenceMatcher'u'SequenceMatcher'b'Differ'u'Differ'b'IS_CHARACTER_JUNK'u'IS_CHARACTER_JUNK'b'IS_LINE_JUNK'u'IS_LINE_JUNK'b'context_diff'u'context_diff'b'unified_diff'u'unified_diff'b'diff_bytes'u'diff_bytes'b'HtmlDiff'u'HtmlDiff'b'a b size'u'a b size'b'
    SequenceMatcher is a flexible class for comparing pairs of sequences of
    any type, so long as the sequence elements are hashable.  The basic
    algorithm predates, and is a little fancier than, an algorithm
    published in the late 1980's by Ratcliff and Obershelp under the
    hyperbolic name "gestalt pattern matching".  The basic idea is to find
    the longest contiguous matching subsequence that contains no "junk"
    elements (R-O doesn't address junk).  The same idea is then applied
    recursively to the pieces of the sequences to the left and to the right
    of the matching subsequence.  This does not yield minimal edit
    sequences, but does tend to yield matches that "look right" to people.

    SequenceMatcher tries to compute a "human-friendly diff" between two
    sequences.  Unlike e.g. UNIX(tm) diff, the fundamental notion is the
    longest *contiguous* & junk-free matching subsequence.  That's what
    catches peoples' eyes.  The Windows(tm) windiff has another interesting
    notion, pairing up elements that appear uniquely in each sequence.
    That, and the method here, appear to yield more intuitive difference
    reports than does diff.  This method appears to be the least vulnerable
    to syncing up on blocks of "junk lines", though (like blank lines in
    ordinary text files, or maybe "<P>" lines in HTML files).  That may be
    because this is the only method of the 3 that has a *concept* of
    "junk" <wink>.

    Example, comparing two strings, and considering blanks to be "junk":

    >>> s = SequenceMatcher(lambda x: x == " ",
    ...                     "private Thread currentThread;",
    ...                     "private volatile Thread currentThread;")
    >>>

    .ratio() returns a float in [0, 1], measuring the "similarity" of the
    sequences.  As a rule of thumb, a .ratio() value over 0.6 means the
    sequences are close matches:

    >>> print(round(s.ratio(), 3))
    0.866
    >>>

    If you're only interested in where the sequences match,
    .get_matching_blocks() is handy:

    >>> for block in s.get_matching_blocks():
    ...     print("a[%d] and b[%d] match for %d elements" % block)
    a[0] and b[0] match for 8 elements
    a[8] and b[17] match for 21 elements
    a[29] and b[38] match for 0 elements

    Note that the last tuple returned by .get_matching_blocks() is always a
    dummy, (len(a), len(b), 0), and this is the only case in which the last
    tuple element (number of elements matched) is 0.

    If you want to know how to change the first sequence into the second,
    use .get_opcodes():

    >>> for opcode in s.get_opcodes():
    ...     print("%6s a[%d:%d] b[%d:%d]" % opcode)
     equal a[0:8] b[0:8]
    insert a[8:8] b[8:17]
     equal a[8:29] b[17:38]

    See the Differ class for a fancy human-friendly file differencer, which
    uses SequenceMatcher both to compare sequences of lines, and to compare
    sequences of characters within similar (near-matching) lines.

    See also function get_close_matches() in this module, which shows how
    simple code building on SequenceMatcher can be used to do useful work.

    Timing:  Basic R-O is cubic time worst case and quadratic time expected
    case.  SequenceMatcher is quadratic time for the worst case and has
    expected-case behavior dependent in a complicated way on how many
    elements the sequences have in common; best case time is linear.
    'u'
    SequenceMatcher is a flexible class for comparing pairs of sequences of
    any type, so long as the sequence elements are hashable.  The basic
    algorithm predates, and is a little fancier than, an algorithm
    published in the late 1980's by Ratcliff and Obershelp under the
    hyperbolic name "gestalt pattern matching".  The basic idea is to find
    the longest contiguous matching subsequence that contains no "junk"
    elements (R-O doesn't address junk).  The same idea is then applied
    recursively to the pieces of the sequences to the left and to the right
    of the matching subsequence.  This does not yield minimal edit
    sequences, but does tend to yield matches that "look right" to people.

    SequenceMatcher tries to compute a "human-friendly diff" between two
    sequences.  Unlike e.g. UNIX(tm) diff, the fundamental notion is the
    longest *contiguous* & junk-free matching subsequence.  That's what
    catches peoples' eyes.  The Windows(tm) windiff has another interesting
    notion, pairing up elements that appear uniquely in each sequence.
    That, and the method here, appear to yield more intuitive difference
    reports than does diff.  This method appears to be the least vulnerable
    to syncing up on blocks of "junk lines", though (like blank lines in
    ordinary text files, or maybe "<P>" lines in HTML files).  That may be
    because this is the only method of the 3 that has a *concept* of
    "junk" <wink>.

    Example, comparing two strings, and considering blanks to be "junk":

    >>> s = SequenceMatcher(lambda x: x == " ",
    ...                     "private Thread currentThread;",
    ...                     "private volatile Thread currentThread;")
    >>>

    .ratio() returns a float in [0, 1], measuring the "similarity" of the
    sequences.  As a rule of thumb, a .ratio() value over 0.6 means the
    sequences are close matches:

    >>> print(round(s.ratio(), 3))
    0.866
    >>>

    If you're only interested in where the sequences match,
    .get_matching_blocks() is handy:

    >>> for block in s.get_matching_blocks():
    ...     print("a[%d] and b[%d] match for %d elements" % block)
    a[0] and b[0] match for 8 elements
    a[8] and b[17] match for 21 elements
    a[29] and b[38] match for 0 elements

    Note that the last tuple returned by .get_matching_blocks() is always a
    dummy, (len(a), len(b), 0), and this is the only case in which the last
    tuple element (number of elements matched) is 0.

    If you want to know how to change the first sequence into the second,
    use .get_opcodes():

    >>> for opcode in s.get_opcodes():
    ...     print("%6s a[%d:%d] b[%d:%d]" % opcode)
     equal a[0:8] b[0:8]
    insert a[8:8] b[8:17]
     equal a[8:29] b[17:38]

    See the Differ class for a fancy human-friendly file differencer, which
    uses SequenceMatcher both to compare sequences of lines, and to compare
    sequences of characters within similar (near-matching) lines.

    See also function get_close_matches() in this module, which shows how
    simple code building on SequenceMatcher can be used to do useful work.

    Timing:  Basic R-O is cubic time worst case and quadratic time expected
    case.  SequenceMatcher is quadratic time for the worst case and has
    expected-case behavior dependent in a complicated way on how many
    elements the sequences have in common; best case time is linear.
    'b'Construct a SequenceMatcher.

        Optional arg isjunk is None (the default), or a one-argument
        function that takes a sequence element and returns true iff the
        element is junk.  None is equivalent to passing "lambda x: 0", i.e.
        no elements are considered to be junk.  For example, pass
            lambda x: x in " \t"
        if you're comparing lines as sequences of characters, and don't
        want to synch up on blanks or hard tabs.

        Optional arg a is the first of two sequences to be compared.  By
        default, an empty string.  The elements of a must be hashable.  See
        also .set_seqs() and .set_seq1().

        Optional arg b is the second of two sequences to be compared.  By
        default, an empty string.  The elements of b must be hashable. See
        also .set_seqs() and .set_seq2().

        Optional arg autojunk should be set to False to disable the
        "automatic junk heuristic" that treats popular elements as junk
        (see module documentation for more information).
        'u'Construct a SequenceMatcher.

        Optional arg isjunk is None (the default), or a one-argument
        function that takes a sequence element and returns true iff the
        element is junk.  None is equivalent to passing "lambda x: 0", i.e.
        no elements are considered to be junk.  For example, pass
            lambda x: x in " \t"
        if you're comparing lines as sequences of characters, and don't
        want to synch up on blanks or hard tabs.

        Optional arg a is the first of two sequences to be compared.  By
        default, an empty string.  The elements of a must be hashable.  See
        also .set_seqs() and .set_seq1().

        Optional arg b is the second of two sequences to be compared.  By
        default, an empty string.  The elements of b must be hashable. See
        also .set_seqs() and .set_seq2().

        Optional arg autojunk should be set to False to disable the
        "automatic junk heuristic" that treats popular elements as junk
        (see module documentation for more information).
        'b'Set the two sequences to be compared.

        >>> s = SequenceMatcher()
        >>> s.set_seqs("abcd", "bcde")
        >>> s.ratio()
        0.75
        'u'Set the two sequences to be compared.

        >>> s = SequenceMatcher()
        >>> s.set_seqs("abcd", "bcde")
        >>> s.ratio()
        0.75
        'b'Set the first sequence to be compared.

        The second sequence to be compared is not changed.

        >>> s = SequenceMatcher(None, "abcd", "bcde")
        >>> s.ratio()
        0.75
        >>> s.set_seq1("bcde")
        >>> s.ratio()
        1.0
        >>>

        SequenceMatcher computes and caches detailed information about the
        second sequence, so if you want to compare one sequence S against
        many sequences, use .set_seq2(S) once and call .set_seq1(x)
        repeatedly for each of the other sequences.

        See also set_seqs() and set_seq2().
        'u'Set the first sequence to be compared.

        The second sequence to be compared is not changed.

        >>> s = SequenceMatcher(None, "abcd", "bcde")
        >>> s.ratio()
        0.75
        >>> s.set_seq1("bcde")
        >>> s.ratio()
        1.0
        >>>

        SequenceMatcher computes and caches detailed information about the
        second sequence, so if you want to compare one sequence S against
        many sequences, use .set_seq2(S) once and call .set_seq1(x)
        repeatedly for each of the other sequences.

        See also set_seqs() and set_seq2().
        'b'Set the second sequence to be compared.

        The first sequence to be compared is not changed.

        >>> s = SequenceMatcher(None, "abcd", "bcde")
        >>> s.ratio()
        0.75
        >>> s.set_seq2("abcd")
        >>> s.ratio()
        1.0
        >>>

        SequenceMatcher computes and caches detailed information about the
        second sequence, so if you want to compare one sequence S against
        many sequences, use .set_seq2(S) once and call .set_seq1(x)
        repeatedly for each of the other sequences.

        See also set_seqs() and set_seq1().
        'u'Set the second sequence to be compared.

        The first sequence to be compared is not changed.

        >>> s = SequenceMatcher(None, "abcd", "bcde")
        >>> s.ratio()
        0.75
        >>> s.set_seq2("abcd")
        >>> s.ratio()
        1.0
        >>>

        SequenceMatcher computes and caches detailed information about the
        second sequence, so if you want to compare one sequence S against
        many sequences, use .set_seq2(S) once and call .set_seq1(x)
        repeatedly for each of the other sequences.

        See also set_seqs() and set_seq1().
        'b'Find longest matching block in a[alo:ahi] and b[blo:bhi].

        By default it will find the longest match in the entirety of a and b.

        If isjunk is not defined:

        Return (i,j,k) such that a[i:i+k] is equal to b[j:j+k], where
            alo <= i <= i+k <= ahi
            blo <= j <= j+k <= bhi
        and for all (i',j',k') meeting those conditions,
            k >= k'
            i <= i'
            and if i == i', j <= j'

        In other words, of all maximal matching blocks, return one that
        starts earliest in a, and of all those maximal matching blocks that
        start earliest in a, return the one that starts earliest in b.

        >>> s = SequenceMatcher(None, " abcd", "abcd abcd")
        >>> s.find_longest_match(0, 5, 0, 9)
        Match(a=0, b=4, size=5)

        If isjunk is defined, first the longest matching block is
        determined as above, but with the additional restriction that no
        junk element appears in the block.  Then that block is extended as
        far as possible by matching (only) junk elements on both sides.  So
        the resulting block never matches on junk except as identical junk
        happens to be adjacent to an "interesting" match.

        Here's the same example as before, but considering blanks to be
        junk.  That prevents " abcd" from matching the " abcd" at the tail
        end of the second sequence directly.  Instead only the "abcd" can
        match, and matches the leftmost "abcd" in the second sequence:

        >>> s = SequenceMatcher(lambda x: x==" ", " abcd", "abcd abcd")
        >>> s.find_longest_match(0, 5, 0, 9)
        Match(a=1, b=0, size=4)

        If no blocks match, return (alo, blo, 0).

        >>> s = SequenceMatcher(None, "ab", "c")
        >>> s.find_longest_match(0, 2, 0, 1)
        Match(a=0, b=0, size=0)
        'u'Find longest matching block in a[alo:ahi] and b[blo:bhi].

        By default it will find the longest match in the entirety of a and b.

        If isjunk is not defined:

        Return (i,j,k) such that a[i:i+k] is equal to b[j:j+k], where
            alo <= i <= i+k <= ahi
            blo <= j <= j+k <= bhi
        and for all (i',j',k') meeting those conditions,
            k >= k'
            i <= i'
            and if i == i', j <= j'

        In other words, of all maximal matching blocks, return one that
        starts earliest in a, and of all those maximal matching blocks that
        start earliest in a, return the one that starts earliest in b.

        >>> s = SequenceMatcher(None, " abcd", "abcd abcd")
        >>> s.find_longest_match(0, 5, 0, 9)
        Match(a=0, b=4, size=5)

        If isjunk is defined, first the longest matching block is
        determined as above, but with the additional restriction that no
        junk element appears in the block.  Then that block is extended as
        far as possible by matching (only) junk elements on both sides.  So
        the resulting block never matches on junk except as identical junk
        happens to be adjacent to an "interesting" match.

        Here's the same example as before, but considering blanks to be
        junk.  That prevents " abcd" from matching the " abcd" at the tail
        end of the second sequence directly.  Instead only the "abcd" can
        match, and matches the leftmost "abcd" in the second sequence:

        >>> s = SequenceMatcher(lambda x: x==" ", " abcd", "abcd abcd")
        >>> s.find_longest_match(0, 5, 0, 9)
        Match(a=1, b=0, size=4)

        If no blocks match, return (alo, blo, 0).

        >>> s = SequenceMatcher(None, "ab", "c")
        >>> s.find_longest_match(0, 2, 0, 1)
        Match(a=0, b=0, size=0)
        'b'Return list of triples describing matching subsequences.

        Each triple is of the form (i, j, n), and means that
        a[i:i+n] == b[j:j+n].  The triples are monotonically increasing in
        i and in j.  New in Python 2.5, it's also guaranteed that if
        (i, j, n) and (i', j', n') are adjacent triples in the list, and
        the second is not the last triple in the list, then i+n != i' or
        j+n != j'.  IOW, adjacent triples never describe adjacent equal
        blocks.

        The last triple is a dummy, (len(a), len(b), 0), and is the only
        triple with n==0.

        >>> s = SequenceMatcher(None, "abxcd", "abcd")
        >>> list(s.get_matching_blocks())
        [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)]
        'u'Return list of triples describing matching subsequences.

        Each triple is of the form (i, j, n), and means that
        a[i:i+n] == b[j:j+n].  The triples are monotonically increasing in
        i and in j.  New in Python 2.5, it's also guaranteed that if
        (i, j, n) and (i', j', n') are adjacent triples in the list, and
        the second is not the last triple in the list, then i+n != i' or
        j+n != j'.  IOW, adjacent triples never describe adjacent equal
        blocks.

        The last triple is a dummy, (len(a), len(b), 0), and is the only
        triple with n==0.

        >>> s = SequenceMatcher(None, "abxcd", "abcd")
        >>> list(s.get_matching_blocks())
        [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)]
        'b'Return list of 5-tuples describing how to turn a into b.

        Each tuple is of the form (tag, i1, i2, j1, j2).  The first tuple
        has i1 == j1 == 0, and remaining tuples have i1 == the i2 from the
        tuple preceding it, and likewise for j1 == the previous j2.

        The tags are strings, with these meanings:

        'replace':  a[i1:i2] should be replaced by b[j1:j2]
        'delete':   a[i1:i2] should be deleted.
                    Note that j1==j2 in this case.
        'insert':   b[j1:j2] should be inserted at a[i1:i1].
                    Note that i1==i2 in this case.
        'equal':    a[i1:i2] == b[j1:j2]

        >>> a = "qabxcd"
        >>> b = "abycdf"
        >>> s = SequenceMatcher(None, a, b)
        >>> for tag, i1, i2, j1, j2 in s.get_opcodes():
        ...    print(("%7s a[%d:%d] (%s) b[%d:%d] (%s)" %
        ...           (tag, i1, i2, a[i1:i2], j1, j2, b[j1:j2])))
         delete a[0:1] (q) b[0:0] ()
          equal a[1:3] (ab) b[0:2] (ab)
        replace a[3:4] (x) b[2:3] (y)
          equal a[4:6] (cd) b[3:5] (cd)
         insert a[6:6] () b[5:6] (f)
        'u'Return list of 5-tuples describing how to turn a into b.

        Each tuple is of the form (tag, i1, i2, j1, j2).  The first tuple
        has i1 == j1 == 0, and remaining tuples have i1 == the i2 from the
        tuple preceding it, and likewise for j1 == the previous j2.

        The tags are strings, with these meanings:

        'replace':  a[i1:i2] should be replaced by b[j1:j2]
        'delete':   a[i1:i2] should be deleted.
                    Note that j1==j2 in this case.
        'insert':   b[j1:j2] should be inserted at a[i1:i1].
                    Note that i1==i2 in this case.
        'equal':    a[i1:i2] == b[j1:j2]

        >>> a = "qabxcd"
        >>> b = "abycdf"
        >>> s = SequenceMatcher(None, a, b)
        >>> for tag, i1, i2, j1, j2 in s.get_opcodes():
        ...    print(("%7s a[%d:%d] (%s) b[%d:%d] (%s)" %
        ...           (tag, i1, i2, a[i1:i2], j1, j2, b[j1:j2])))
         delete a[0:1] (q) b[0:0] ()
          equal a[1:3] (ab) b[0:2] (ab)
        replace a[3:4] (x) b[2:3] (y)
          equal a[4:6] (cd) b[3:5] (cd)
         insert a[6:6] () b[5:6] (f)
        'b'delete'u'delete'b'insert'u'insert'b'equal'u'equal'b' Isolate change clusters by eliminating ranges with no changes.

        Return a generator of groups with up to n lines of context.
        Each group is in the same format as returned by get_opcodes().

        >>> from pprint import pprint
        >>> a = list(map(str, range(1,40)))
        >>> b = a[:]
        >>> b[8:8] = ['i']     # Make an insertion
        >>> b[20] += 'x'       # Make a replacement
        >>> b[23:28] = []      # Make a deletion
        >>> b[30] += 'y'       # Make another replacement
        >>> pprint(list(SequenceMatcher(None,a,b).get_grouped_opcodes()))
        [[('equal', 5, 8, 5, 8), ('insert', 8, 8, 8, 9), ('equal', 8, 11, 9, 12)],
         [('equal', 16, 19, 17, 20),
          ('replace', 19, 20, 20, 21),
          ('equal', 20, 22, 21, 23),
          ('delete', 22, 27, 23, 23),
          ('equal', 27, 30, 23, 26)],
         [('equal', 31, 34, 27, 30),
          ('replace', 34, 35, 30, 31),
          ('equal', 35, 38, 31, 34)]]
        'u' Isolate change clusters by eliminating ranges with no changes.

        Return a generator of groups with up to n lines of context.
        Each group is in the same format as returned by get_opcodes().

        >>> from pprint import pprint
        >>> a = list(map(str, range(1,40)))
        >>> b = a[:]
        >>> b[8:8] = ['i']     # Make an insertion
        >>> b[20] += 'x'       # Make a replacement
        >>> b[23:28] = []      # Make a deletion
        >>> b[30] += 'y'       # Make another replacement
        >>> pprint(list(SequenceMatcher(None,a,b).get_grouped_opcodes()))
        [[('equal', 5, 8, 5, 8), ('insert', 8, 8, 8, 9), ('equal', 8, 11, 9, 12)],
         [('equal', 16, 19, 17, 20),
          ('replace', 19, 20, 20, 21),
          ('equal', 20, 22, 21, 23),
          ('delete', 22, 27, 23, 23),
          ('equal', 27, 30, 23, 26)],
         [('equal', 31, 34, 27, 30),
          ('replace', 34, 35, 30, 31),
          ('equal', 35, 38, 31, 34)]]
        'b'Return a measure of the sequences' similarity (float in [0,1]).

        Where T is the total number of elements in both sequences, and
        M is the number of matches, this is 2.0*M / T.
        Note that this is 1 if the sequences are identical, and 0 if
        they have nothing in common.

        .ratio() is expensive to compute if you haven't already computed
        .get_matching_blocks() or .get_opcodes(), in which case you may
        want to try .quick_ratio() or .real_quick_ratio() first to get an
        upper bound.

        >>> s = SequenceMatcher(None, "abcd", "bcde")
        >>> s.ratio()
        0.75
        >>> s.quick_ratio()
        0.75
        >>> s.real_quick_ratio()
        1.0
        'u'Return a measure of the sequences' similarity (float in [0,1]).

        Where T is the total number of elements in both sequences, and
        M is the number of matches, this is 2.0*M / T.
        Note that this is 1 if the sequences are identical, and 0 if
        they have nothing in common.

        .ratio() is expensive to compute if you haven't already computed
        .get_matching_blocks() or .get_opcodes(), in which case you may
        want to try .quick_ratio() or .real_quick_ratio() first to get an
        upper bound.

        >>> s = SequenceMatcher(None, "abcd", "bcde")
        >>> s.ratio()
        0.75
        >>> s.quick_ratio()
        0.75
        >>> s.real_quick_ratio()
        1.0
        'b'Return an upper bound on ratio() relatively quickly.

        This isn't defined beyond that it is an upper bound on .ratio(), and
        is faster to compute.
        'u'Return an upper bound on ratio() relatively quickly.

        This isn't defined beyond that it is an upper bound on .ratio(), and
        is faster to compute.
        'b'Return an upper bound on ratio() very quickly.

        This isn't defined beyond that it is an upper bound on .ratio(), and
        is faster to compute than either .ratio() or .quick_ratio().
        'u'Return an upper bound on ratio() very quickly.

        This isn't defined beyond that it is an upper bound on .ratio(), and
        is faster to compute than either .ratio() or .quick_ratio().
        'b'Use SequenceMatcher to return list of the best "good enough" matches.

    word is a sequence for which close matches are desired (typically a
    string).

    possibilities is a list of sequences against which to match word
    (typically a list of strings).

    Optional arg n (default 3) is the maximum number of close matches to
    return.  n must be > 0.

    Optional arg cutoff (default 0.6) is a float in [0, 1].  Possibilities
    that don't score at least that similar to word are ignored.

    The best (no more than n) matches among the possibilities are returned
    in a list, sorted by similarity score, most similar first.

    >>> get_close_matches("appel", ["ape", "apple", "peach", "puppy"])
    ['apple', 'ape']
    >>> import keyword as _keyword
    >>> get_close_matches("wheel", _keyword.kwlist)
    ['while']
    >>> get_close_matches("Apple", _keyword.kwlist)
    []
    >>> get_close_matches("accept", _keyword.kwlist)
    ['except']
    'u'Use SequenceMatcher to return list of the best "good enough" matches.

    word is a sequence for which close matches are desired (typically a
    string).

    possibilities is a list of sequences against which to match word
    (typically a list of strings).

    Optional arg n (default 3) is the maximum number of close matches to
    return.  n must be > 0.

    Optional arg cutoff (default 0.6) is a float in [0, 1].  Possibilities
    that don't score at least that similar to word are ignored.

    The best (no more than n) matches among the possibilities are returned
    in a list, sorted by similarity score, most similar first.

    >>> get_close_matches("appel", ["ape", "apple", "peach", "puppy"])
    ['apple', 'ape']
    >>> import keyword as _keyword
    >>> get_close_matches("wheel", _keyword.kwlist)
    ['while']
    >>> get_close_matches("Apple", _keyword.kwlist)
    []
    >>> get_close_matches("accept", _keyword.kwlist)
    ['except']
    'b'n must be > 0: %r'u'n must be > 0: %r'b'cutoff must be in [0.0, 1.0]: %r'u'cutoff must be in [0.0, 1.0]: %r'b'Replace whitespace with the original whitespace characters in `s`'u'Replace whitespace with the original whitespace characters in `s`'b'
    Differ is a class for comparing sequences of lines of text, and
    producing human-readable differences or deltas.  Differ uses
    SequenceMatcher both to compare sequences of lines, and to compare
    sequences of characters within similar (near-matching) lines.

    Each line of a Differ delta begins with a two-letter code:

        '- '    line unique to sequence 1
        '+ '    line unique to sequence 2
        '  '    line common to both sequences
        '? '    line not present in either input sequence

    Lines beginning with '? ' attempt to guide the eye to intraline
    differences, and were not present in either input sequence.  These lines
    can be confusing if the sequences contain tab characters.

    Note that Differ makes no claim to produce a *minimal* diff.  To the
    contrary, minimal diffs are often counter-intuitive, because they synch
    up anywhere possible, sometimes accidental matches 100 pages apart.
    Restricting synch points to contiguous matches preserves some notion of
    locality, at the occasional cost of producing a longer diff.

    Example: Comparing two texts.

    First we set up the texts, sequences of individual single-line strings
    ending with newlines (such sequences can also be obtained from the
    `readlines()` method of file-like objects):

    >>> text1 = '''  1. Beautiful is better than ugly.
    ...   2. Explicit is better than implicit.
    ...   3. Simple is better than complex.
    ...   4. Complex is better than complicated.
    ... '''.splitlines(keepends=True)
    >>> len(text1)
    4
    >>> text1[0][-1]
    '\n'
    >>> text2 = '''  1. Beautiful is better than ugly.
    ...   3.   Simple is better than complex.
    ...   4. Complicated is better than complex.
    ...   5. Flat is better than nested.
    ... '''.splitlines(keepends=True)

    Next we instantiate a Differ object:

    >>> d = Differ()

    Note that when instantiating a Differ object we may pass functions to
    filter out line and character 'junk'.  See Differ.__init__ for details.

    Finally, we compare the two:

    >>> result = list(d.compare(text1, text2))

    'result' is a list of strings, so let's pretty-print it:

    >>> from pprint import pprint as _pprint
    >>> _pprint(result)
    ['    1. Beautiful is better than ugly.\n',
     '-   2. Explicit is better than implicit.\n',
     '-   3. Simple is better than complex.\n',
     '+   3.   Simple is better than complex.\n',
     '?     ++\n',
     '-   4. Complex is better than complicated.\n',
     '?            ^                     ---- ^\n',
     '+   4. Complicated is better than complex.\n',
     '?           ++++ ^                      ^\n',
     '+   5. Flat is better than nested.\n']

    As a single multi-line string it looks like this:

    >>> print(''.join(result), end="")
        1. Beautiful is better than ugly.
    -   2. Explicit is better than implicit.
    -   3. Simple is better than complex.
    +   3.   Simple is better than complex.
    ?     ++
    -   4. Complex is better than complicated.
    ?            ^                     ---- ^
    +   4. Complicated is better than complex.
    ?           ++++ ^                      ^
    +   5. Flat is better than nested.
    'u'
    Differ is a class for comparing sequences of lines of text, and
    producing human-readable differences or deltas.  Differ uses
    SequenceMatcher both to compare sequences of lines, and to compare
    sequences of characters within similar (near-matching) lines.

    Each line of a Differ delta begins with a two-letter code:

        '- '    line unique to sequence 1
        '+ '    line unique to sequence 2
        '  '    line common to both sequences
        '? '    line not present in either input sequence

    Lines beginning with '? ' attempt to guide the eye to intraline
    differences, and were not present in either input sequence.  These lines
    can be confusing if the sequences contain tab characters.

    Note that Differ makes no claim to produce a *minimal* diff.  To the
    contrary, minimal diffs are often counter-intuitive, because they synch
    up anywhere possible, sometimes accidental matches 100 pages apart.
    Restricting synch points to contiguous matches preserves some notion of
    locality, at the occasional cost of producing a longer diff.

    Example: Comparing two texts.

    First we set up the texts, sequences of individual single-line strings
    ending with newlines (such sequences can also be obtained from the
    `readlines()` method of file-like objects):

    >>> text1 = '''  1. Beautiful is better than ugly.
    ...   2. Explicit is better than implicit.
    ...   3. Simple is better than complex.
    ...   4. Complex is better than complicated.
    ... '''.splitlines(keepends=True)
    >>> len(text1)
    4
    >>> text1[0][-1]
    '\n'
    >>> text2 = '''  1. Beautiful is better than ugly.
    ...   3.   Simple is better than complex.
    ...   4. Complicated is better than complex.
    ...   5. Flat is better than nested.
    ... '''.splitlines(keepends=True)

    Next we instantiate a Differ object:

    >>> d = Differ()

    Note that when instantiating a Differ object we may pass functions to
    filter out line and character 'junk'.  See Differ.__init__ for details.

    Finally, we compare the two:

    >>> result = list(d.compare(text1, text2))

    'result' is a list of strings, so let's pretty-print it:

    >>> from pprint import pprint as _pprint
    >>> _pprint(result)
    ['    1. Beautiful is better than ugly.\n',
     '-   2. Explicit is better than implicit.\n',
     '-   3. Simple is better than complex.\n',
     '+   3.   Simple is better than complex.\n',
     '?     ++\n',
     '-   4. Complex is better than complicated.\n',
     '?            ^                     ---- ^\n',
     '+   4. Complicated is better than complex.\n',
     '?           ++++ ^                      ^\n',
     '+   5. Flat is better than nested.\n']

    As a single multi-line string it looks like this:

    >>> print(''.join(result), end="")
        1. Beautiful is better than ugly.
    -   2. Explicit is better than implicit.
    -   3. Simple is better than complex.
    +   3.   Simple is better than complex.
    ?     ++
    -   4. Complex is better than complicated.
    ?            ^                     ---- ^
    +   4. Complicated is better than complex.
    ?           ++++ ^                      ^
    +   5. Flat is better than nested.
    'b'
        Construct a text differencer, with optional filters.

        The two optional keyword parameters are for filter functions:

        - `linejunk`: A function that should accept a single string argument,
          and return true iff the string is junk. The module-level function
          `IS_LINE_JUNK` may be used to filter out lines without visible
          characters, except for at most one splat ('#').  It is recommended
          to leave linejunk None; the underlying SequenceMatcher class has
          an adaptive notion of "noise" lines that's better than any static
          definition the author has ever been able to craft.

        - `charjunk`: A function that should accept a string of length 1. The
          module-level function `IS_CHARACTER_JUNK` may be used to filter out
          whitespace characters (a blank or tab; **note**: bad idea to include
          newline in this!).  Use of IS_CHARACTER_JUNK is recommended.
        'u'
        Construct a text differencer, with optional filters.

        The two optional keyword parameters are for filter functions:

        - `linejunk`: A function that should accept a single string argument,
          and return true iff the string is junk. The module-level function
          `IS_LINE_JUNK` may be used to filter out lines without visible
          characters, except for at most one splat ('#').  It is recommended
          to leave linejunk None; the underlying SequenceMatcher class has
          an adaptive notion of "noise" lines that's better than any static
          definition the author has ever been able to craft.

        - `charjunk`: A function that should accept a string of length 1. The
          module-level function `IS_CHARACTER_JUNK` may be used to filter out
          whitespace characters (a blank or tab; **note**: bad idea to include
          newline in this!).  Use of IS_CHARACTER_JUNK is recommended.
        'b'
        Compare two sequences of lines; generate the resulting delta.

        Each sequence must contain individual single-line strings ending with
        newlines. Such sequences can be obtained from the `readlines()` method
        of file-like objects.  The delta generated also consists of newline-
        terminated strings, ready to be printed as-is via the writelines()
        method of a file-like object.

        Example:

        >>> print(''.join(Differ().compare('one\ntwo\nthree\n'.splitlines(True),
        ...                                'ore\ntree\nemu\n'.splitlines(True))),
        ...       end="")
        - one
        ?  ^
        + ore
        ?  ^
        - two
        - three
        ?  -
        + tree
        + emu
        'u'
        Compare two sequences of lines; generate the resulting delta.

        Each sequence must contain individual single-line strings ending with
        newlines. Such sequences can be obtained from the `readlines()` method
        of file-like objects.  The delta generated also consists of newline-
        terminated strings, ready to be printed as-is via the writelines()
        method of a file-like object.

        Example:

        >>> print(''.join(Differ().compare('one\ntwo\nthree\n'.splitlines(True),
        ...                                'ore\ntree\nemu\n'.splitlines(True))),
        ...       end="")
        - one
        ?  ^
        + ore
        ?  ^
        - two
        - three
        ?  -
        + tree
        + emu
        'b'Generate comparison results for a same-tagged range.'u'Generate comparison results for a same-tagged range.'b'
        When replacing one block of lines with another, search the blocks
        for *similar* lines; the best-matching pair (if any) is used as a
        synch point, and intraline difference marking is done on the
        similar pair. Lots of work, but often worth it.

        Example:

        >>> d = Differ()
        >>> results = d._fancy_replace(['abcDefghiJkl\n'], 0, 1,
        ...                            ['abcdefGhijkl\n'], 0, 1)
        >>> print(''.join(results), end="")
        - abcDefghiJkl
        ?    ^  ^  ^
        + abcdefGhijkl
        ?    ^  ^  ^
        'u'
        When replacing one block of lines with another, search the blocks
        for *similar* lines; the best-matching pair (if any) is used as a
        synch point, and intraline difference marking is done on the
        similar pair. Lots of work, but often worth it.

        Example:

        >>> d = Differ()
        >>> results = d._fancy_replace(['abcDefghiJkl\n'], 0, 1,
        ...                            ['abcdefGhijkl\n'], 0, 1)
        >>> print(''.join(results), end="")
        - abcDefghiJkl
        ?    ^  ^  ^
        + abcdefGhijkl
        ?    ^  ^  ^
        'b'
        Format "?" output and deal with tabs.

        Example:

        >>> d = Differ()
        >>> results = d._qformat('\tabcDefghiJkl\n', '\tabcdefGhijkl\n',
        ...                      '  ^ ^  ^      ', '  ^ ^  ^      ')
        >>> for line in results: print(repr(line))
        ...
        '- \tabcDefghiJkl\n'
        '? \t ^ ^  ^\n'
        '+ \tabcdefGhijkl\n'
        '? \t ^ ^  ^\n'
        'u'
        Format "?" output and deal with tabs.

        Example:

        >>> d = Differ()
        >>> results = d._qformat('\tabcDefghiJkl\n', '\tabcdefGhijkl\n',
        ...                      '  ^ ^  ^      ', '  ^ ^  ^      ')
        >>> for line in results: print(repr(line))
        ...
        '- \tabcDefghiJkl\n'
        '? \t ^ ^  ^\n'
        '+ \tabcdefGhijkl\n'
        '? \t ^ ^  ^\n'
        'b'- 'u'- 'b'? 'u'? 'b'+ 'u'+ 'b'\s*(?:#\s*)?$'u'\s*(?:#\s*)?$'b'
    Return True for ignorable line: iff `line` is blank or contains a single '#'.

    Examples:

    >>> IS_LINE_JUNK('\n')
    True
    >>> IS_LINE_JUNK('  #   \n')
    True
    >>> IS_LINE_JUNK('hello\n')
    False
    'u'
    Return True for ignorable line: iff `line` is blank or contains a single '#'.

    Examples:

    >>> IS_LINE_JUNK('\n')
    True
    >>> IS_LINE_JUNK('  #   \n')
    True
    >>> IS_LINE_JUNK('hello\n')
    False
    'b'
    Return True for ignorable character: iff `ch` is a space or tab.

    Examples:

    >>> IS_CHARACTER_JUNK(' ')
    True
    >>> IS_CHARACTER_JUNK('\t')
    True
    >>> IS_CHARACTER_JUNK('\n')
    False
    >>> IS_CHARACTER_JUNK('x')
    False
    'u'
    Return True for ignorable character: iff `ch` is a space or tab.

    Examples:

    >>> IS_CHARACTER_JUNK(' ')
    True
    >>> IS_CHARACTER_JUNK('\t')
    True
    >>> IS_CHARACTER_JUNK('\n')
    False
    >>> IS_CHARACTER_JUNK('x')
    False
    'b'Convert range to the "ed" format'u'Convert range to the "ed" format'b'{},{}'u'{},{}'b'
    Compare two sequences of lines; generate the delta as a unified diff.

    Unified diffs are a compact way of showing line changes and a few
    lines of context.  The number of context lines is set by 'n' which
    defaults to three.

    By default, the diff control lines (those with ---, +++, or @@) are
    created with a trailing newline.  This is helpful so that inputs
    created from file.readlines() result in diffs that are suitable for
    file.writelines() since both the inputs and outputs have trailing
    newlines.

    For inputs that do not have trailing newlines, set the lineterm
    argument to "" so that the output will be uniformly newline free.

    The unidiff format normally has a header for filenames and modification
    times.  Any or all of these may be specified using strings for
    'fromfile', 'tofile', 'fromfiledate', and 'tofiledate'.
    The modification times are normally expressed in the ISO 8601 format.

    Example:

    >>> for line in unified_diff('one two three four'.split(),
    ...             'zero one tree four'.split(), 'Original', 'Current',
    ...             '2005-01-26 23:30:50', '2010-04-02 10:20:52',
    ...             lineterm=''):
    ...     print(line)                 # doctest: +NORMALIZE_WHITESPACE
    --- Original        2005-01-26 23:30:50
    +++ Current         2010-04-02 10:20:52
    @@ -1,4 +1,4 @@
    +zero
     one
    -two
    -three
    +tree
     four
    'u'
    Compare two sequences of lines; generate the delta as a unified diff.

    Unified diffs are a compact way of showing line changes and a few
    lines of context.  The number of context lines is set by 'n' which
    defaults to three.

    By default, the diff control lines (those with ---, +++, or @@) are
    created with a trailing newline.  This is helpful so that inputs
    created from file.readlines() result in diffs that are suitable for
    file.writelines() since both the inputs and outputs have trailing
    newlines.

    For inputs that do not have trailing newlines, set the lineterm
    argument to "" so that the output will be uniformly newline free.

    The unidiff format normally has a header for filenames and modification
    times.  Any or all of these may be specified using strings for
    'fromfile', 'tofile', 'fromfiledate', and 'tofiledate'.
    The modification times are normally expressed in the ISO 8601 format.

    Example:

    >>> for line in unified_diff('one two three four'.split(),
    ...             'zero one tree four'.split(), 'Original', 'Current',
    ...             '2005-01-26 23:30:50', '2010-04-02 10:20:52',
    ...             lineterm=''):
    ...     print(line)                 # doctest: +NORMALIZE_WHITESPACE
    --- Original        2005-01-26 23:30:50
    +++ Current         2010-04-02 10:20:52
    @@ -1,4 +1,4 @@
    +zero
     one
    -two
    -three
    +tree
     four
    'b'	{}'u'	{}'b'--- {}{}{}'u'--- {}{}{}'b'+++ {}{}{}'u'+++ {}{}{}'b'@@ -{} +{} @@{}'u'@@ -{} +{} @@{}'b'
    Compare two sequences of lines; generate the delta as a context diff.

    Context diffs are a compact way of showing line changes and a few
    lines of context.  The number of context lines is set by 'n' which
    defaults to three.

    By default, the diff control lines (those with *** or ---) are
    created with a trailing newline.  This is helpful so that inputs
    created from file.readlines() result in diffs that are suitable for
    file.writelines() since both the inputs and outputs have trailing
    newlines.

    For inputs that do not have trailing newlines, set the lineterm
    argument to "" so that the output will be uniformly newline free.

    The context diff format normally has a header for filenames and
    modification times.  Any or all of these may be specified using
    strings for 'fromfile', 'tofile', 'fromfiledate', and 'tofiledate'.
    The modification times are normally expressed in the ISO 8601 format.
    If not specified, the strings default to blanks.

    Example:

    >>> print(''.join(context_diff('one\ntwo\nthree\nfour\n'.splitlines(True),
    ...       'zero\none\ntree\nfour\n'.splitlines(True), 'Original', 'Current')),
    ...       end="")
    *** Original
    --- Current
    ***************
    *** 1,4 ****
      one
    ! two
    ! three
      four
    --- 1,4 ----
    + zero
      one
    ! tree
      four
    'u'
    Compare two sequences of lines; generate the delta as a context diff.

    Context diffs are a compact way of showing line changes and a few
    lines of context.  The number of context lines is set by 'n' which
    defaults to three.

    By default, the diff control lines (those with *** or ---) are
    created with a trailing newline.  This is helpful so that inputs
    created from file.readlines() result in diffs that are suitable for
    file.writelines() since both the inputs and outputs have trailing
    newlines.

    For inputs that do not have trailing newlines, set the lineterm
    argument to "" so that the output will be uniformly newline free.

    The context diff format normally has a header for filenames and
    modification times.  Any or all of these may be specified using
    strings for 'fromfile', 'tofile', 'fromfiledate', and 'tofiledate'.
    The modification times are normally expressed in the ISO 8601 format.
    If not specified, the strings default to blanks.

    Example:

    >>> print(''.join(context_diff('one\ntwo\nthree\nfour\n'.splitlines(True),
    ...       'zero\none\ntree\nfour\n'.splitlines(True), 'Original', 'Current')),
    ...       end="")
    *** Original
    --- Current
    ***************
    *** 1,4 ****
      one
    ! two
    ! three
      four
    --- 1,4 ----
    + zero
      one
    ! tree
      four
    'b'! 'u'! 'b'*** {}{}{}'u'*** {}{}{}'b'***************'u'***************'b'*** {} ****{}'u'*** {} ****{}'b'--- {} ----{}'u'--- {} ----{}'b'lines to compare must be str, not %s (%r)'u'lines to compare must be str, not %s (%r)'b'all arguments must be str, not: %r'u'all arguments must be str, not: %r'b'
    Compare `a` and `b`, two sequences of lines represented as bytes rather
    than str. This is a wrapper for `dfunc`, which is typically either
    unified_diff() or context_diff(). Inputs are losslessly converted to
    strings so that `dfunc` only has to worry about strings, and encoded
    back to bytes on return. This is necessary to compare files with
    unknown or inconsistent encoding. All other inputs (except `n`) must be
    bytes rather than str.
    'u'
    Compare `a` and `b`, two sequences of lines represented as bytes rather
    than str. This is a wrapper for `dfunc`, which is typically either
    unified_diff() or context_diff(). Inputs are losslessly converted to
    strings so that `dfunc` only has to worry about strings, and encoded
    back to bytes on return. This is necessary to compare files with
    unknown or inconsistent encoding. All other inputs (except `n`) must be
    bytes rather than str.
    'b'all arguments must be bytes, not %s (%r)'u'all arguments must be bytes, not %s (%r)'b'
    Compare `a` and `b` (lists of strings); return a `Differ`-style delta.

    Optional keyword parameters `linejunk` and `charjunk` are for filter
    functions, or can be None:

    - linejunk: A function that should accept a single string argument and
      return true iff the string is junk.  The default is None, and is
      recommended; the underlying SequenceMatcher class has an adaptive
      notion of "noise" lines.

    - charjunk: A function that accepts a character (string of length
      1), and returns true iff the character is junk. The default is
      the module-level function IS_CHARACTER_JUNK, which filters out
      whitespace characters (a blank or tab; note: it's a bad idea to
      include newline in this!).

    Tools/scripts/ndiff.py is a command-line front-end to this function.

    Example:

    >>> diff = ndiff('one\ntwo\nthree\n'.splitlines(keepends=True),
    ...              'ore\ntree\nemu\n'.splitlines(keepends=True))
    >>> print(''.join(diff), end="")
    - one
    ?  ^
    + ore
    ?  ^
    - two
    - three
    ?  -
    + tree
    + emu
    'u'
    Compare `a` and `b` (lists of strings); return a `Differ`-style delta.

    Optional keyword parameters `linejunk` and `charjunk` are for filter
    functions, or can be None:

    - linejunk: A function that should accept a single string argument and
      return true iff the string is junk.  The default is None, and is
      recommended; the underlying SequenceMatcher class has an adaptive
      notion of "noise" lines.

    - charjunk: A function that accepts a character (string of length
      1), and returns true iff the character is junk. The default is
      the module-level function IS_CHARACTER_JUNK, which filters out
      whitespace characters (a blank or tab; note: it's a bad idea to
      include newline in this!).

    Tools/scripts/ndiff.py is a command-line front-end to this function.

    Example:

    >>> diff = ndiff('one\ntwo\nthree\n'.splitlines(keepends=True),
    ...              'ore\ntree\nemu\n'.splitlines(keepends=True))
    >>> print(''.join(diff), end="")
    - one
    ?  ^
    + ore
    ?  ^
    - two
    - three
    ?  -
    + tree
    + emu
    'b'Returns generator yielding marked up from/to side by side differences.

    Arguments:
    fromlines -- list of text lines to compared to tolines
    tolines -- list of text lines to be compared to fromlines
    context -- number of context lines to display on each side of difference,
               if None, all from/to text lines will be generated.
    linejunk -- passed on to ndiff (see ndiff documentation)
    charjunk -- passed on to ndiff (see ndiff documentation)

    This function returns an iterator which returns a tuple:
    (from line tuple, to line tuple, boolean flag)

    from/to line tuple -- (line num, line text)
        line num -- integer or None (to indicate a context separation)
        line text -- original line text with following markers inserted:
            '\0+' -- marks start of added text
            '\0-' -- marks start of deleted text
            '\0^' -- marks start of changed text
            '\1' -- marks end of added/deleted/changed text

    boolean flag -- None indicates context separation, True indicates
        either "from" or "to" line contains a change, otherwise False.

    This function/iterator was originally developed to generate side by side
    file difference for making HTML pages (see HtmlDiff class for example
    usage).

    Note, this function utilizes the ndiff function to generate the side by
    side difference markup.  Optional ndiff arguments may be passed to this
    function and they in turn will be passed to ndiff.
    'u'Returns generator yielding marked up from/to side by side differences.

    Arguments:
    fromlines -- list of text lines to compared to tolines
    tolines -- list of text lines to be compared to fromlines
    context -- number of context lines to display on each side of difference,
               if None, all from/to text lines will be generated.
    linejunk -- passed on to ndiff (see ndiff documentation)
    charjunk -- passed on to ndiff (see ndiff documentation)

    This function returns an iterator which returns a tuple:
    (from line tuple, to line tuple, boolean flag)

    from/to line tuple -- (line num, line text)
        line num -- integer or None (to indicate a context separation)
        line text -- original line text with following markers inserted:
            '\0+' -- marks start of added text
            '\0-' -- marks start of deleted text
            '\0^' -- marks start of changed text
            '\1' -- marks end of added/deleted/changed text

    boolean flag -- None indicates context separation, True indicates
        either "from" or "to" line contains a change, otherwise False.

    This function/iterator was originally developed to generate side by side
    file difference for making HTML pages (see HtmlDiff class for example
    usage).

    Note, this function utilizes the ndiff function to generate the side by
    side difference markup.  Optional ndiff arguments may be passed to this
    function and they in turn will be passed to ndiff.
    'b'(\++|\-+|\^+)'u'(\++|\-+|\^+)'b'Returns line of text with user's change markup and line formatting.

        lines -- list of lines from the ndiff generator to produce a line of
                 text from.  When producing the line of text to return, the
                 lines used are removed from this list.
        format_key -- '+' return first line in list with "add" markup around
                          the entire line.
                      '-' return first line in list with "delete" markup around
                          the entire line.
                      '?' return first line in list with add/delete/change
                          intraline markup (indices obtained from second line)
                      None return first line in list with no markup
        side -- indice into the num_lines list (0=from,1=to)
        num_lines -- from/to current line number.  This is NOT intended to be a
                     passed parameter.  It is present as a keyword argument to
                     maintain memory of the current line numbers between calls
                     of this function.

        Note, this function is purposefully not defined at the module scope so
        that data it needs from its parent function (within whose context it
        is defined) does not need to be of module scope.
        'u'Returns line of text with user's change markup and line formatting.

        lines -- list of lines from the ndiff generator to produce a line of
                 text from.  When producing the line of text to return, the
                 lines used are removed from this list.
        format_key -- '+' return first line in list with "add" markup around
                          the entire line.
                      '-' return first line in list with "delete" markup around
                          the entire line.
                      '?' return first line in list with add/delete/change
                          intraline markup (indices obtained from second line)
                      None return first line in list with no markup
        side -- indice into the num_lines list (0=from,1=to)
        num_lines -- from/to current line number.  This is NOT intended to be a
                     passed parameter.  It is present as a keyword argument to
                     maintain memory of the current line numbers between calls
                     of this function.

        Note, this function is purposefully not defined at the module scope so
        that data it needs from its parent function (within whose context it
        is defined) does not need to be of module scope.
        'b''u''b'Yields from/to lines of text with a change indication.

        This function is an iterator.  It itself pulls lines from a
        differencing iterator, processes them and yields them.  When it can
        it yields both a "from" and a "to" line, otherwise it will yield one
        or the other.  In addition to yielding the lines of from/to text, a
        boolean flag is yielded to indicate if the text line(s) have
        differences in them.

        Note, this function is purposefully not defined at the module scope so
        that data it needs from its parent function (within whose context it
        is defined) does not need to be of module scope.
        'u'Yields from/to lines of text with a change indication.

        This function is an iterator.  It itself pulls lines from a
        differencing iterator, processes them and yields them.  When it can
        it yields both a "from" and a "to" line, otherwise it will yield one
        or the other.  In addition to yielding the lines of from/to text, a
        boolean flag is yielded to indicate if the text line(s) have
        differences in them.

        Note, this function is purposefully not defined at the module scope so
        that data it needs from its parent function (within whose context it
        is defined) does not need to be of module scope.
        'b'-?+?'u'-?+?'b'--++'u'--++'b'--?+'u'--?+'b'--+'u'--+'b'-+?'u'-+?'b'-?+'u'-?+'b'+--'u'+--'b'+-'u'+-'b'Yields from/to lines of text with a change indication.

        This function is an iterator.  It itself pulls lines from the line
        iterator.  Its difference from that iterator is that this function
        always yields a pair of from/to text lines (with the change
        indication).  If necessary it will collect single from/to lines
        until it has a matching pair from/to pair to yield.

        Note, this function is purposefully not defined at the module scope so
        that data it needs from its parent function (within whose context it
        is defined) does not need to be of module scope.
        'u'Yields from/to lines of text with a change indication.

        This function is an iterator.  It itself pulls lines from the line
        iterator.  Its difference from that iterator is that this function
        always yields a pair of from/to text lines (with the change
        indication).  If necessary it will collect single from/to lines
        until it has a matching pair from/to pair to yield.

        Note, this function is purposefully not defined at the module scope so
        that data it needs from its parent function (within whose context it
        is defined) does not need to be of module scope.
        'b'
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
          "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html>

<head>
    <meta http-equiv="Content-Type"
          content="text/html; charset=%(charset)s" />
    <title></title>
    <style type="text/css">%(styles)s
    </style>
</head>

<body>
    %(table)s%(legend)s
</body>

</html>'u'
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
          "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html>

<head>
    <meta http-equiv="Content-Type"
          content="text/html; charset=%(charset)s" />
    <title></title>
    <style type="text/css">%(styles)s
    </style>
</head>

<body>
    %(table)s%(legend)s
</body>

</html>'b'
        table.diff {font-family:Courier; border:medium;}
        .diff_header {background-color:#e0e0e0}
        td.diff_header {text-align:right}
        .diff_next {background-color:#c0c0c0}
        .diff_add {background-color:#aaffaa}
        .diff_chg {background-color:#ffff77}
        .diff_sub {background-color:#ffaaaa}'u'
        table.diff {font-family:Courier; border:medium;}
        .diff_header {background-color:#e0e0e0}
        td.diff_header {text-align:right}
        .diff_next {background-color:#c0c0c0}
        .diff_add {background-color:#aaffaa}
        .diff_chg {background-color:#ffff77}
        .diff_sub {background-color:#ffaaaa}'b'
    <table class="diff" id="difflib_chg_%(prefix)s_top"
           cellspacing="0" cellpadding="0" rules="groups" >
        <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
        <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
        %(header_row)s
        <tbody>
%(data_rows)s        </tbody>
    </table>'u'
    <table class="diff" id="difflib_chg_%(prefix)s_top"
           cellspacing="0" cellpadding="0" rules="groups" >
        <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
        <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
        %(header_row)s
        <tbody>
%(data_rows)s        </tbody>
    </table>'b'
    <table class="diff" summary="Legends">
        <tr> <th colspan="2"> Legends </th> </tr>
        <tr> <td> <table border="" summary="Colors">
                      <tr><th> Colors </th> </tr>
                      <tr><td class="diff_add">&nbsp;Added&nbsp;</td></tr>
                      <tr><td class="diff_chg">Changed</td> </tr>
                      <tr><td class="diff_sub">Deleted</td> </tr>
                  </table></td>
             <td> <table border="" summary="Links">
                      <tr><th colspan="2"> Links </th> </tr>
                      <tr><td>(f)irst change</td> </tr>
                      <tr><td>(n)ext change</td> </tr>
                      <tr><td>(t)op</td> </tr>
                  </table></td> </tr>
    </table>'u'
    <table class="diff" summary="Legends">
        <tr> <th colspan="2"> Legends </th> </tr>
        <tr> <td> <table border="" summary="Colors">
                      <tr><th> Colors </th> </tr>
                      <tr><td class="diff_add">&nbsp;Added&nbsp;</td></tr>
                      <tr><td class="diff_chg">Changed</td> </tr>
                      <tr><td class="diff_sub">Deleted</td> </tr>
                  </table></td>
             <td> <table border="" summary="Links">
                      <tr><th colspan="2"> Links </th> </tr>
                      <tr><td>(f)irst change</td> </tr>
                      <tr><td>(n)ext change</td> </tr>
                      <tr><td>(t)op</td> </tr>
                  </table></td> </tr>
    </table>'b'For producing HTML side by side comparison with change highlights.

    This class can be used to create an HTML table (or a complete HTML file
    containing the table) showing a side by side, line by line comparison
    of text with inter-line and intra-line change highlights.  The table can
    be generated in either full or contextual difference mode.

    The following methods are provided for HTML generation:

    make_table -- generates HTML for a single side by side table
    make_file -- generates complete HTML file with a single side by side table

    See tools/scripts/diff.py for an example usage of this class.
    'u'For producing HTML side by side comparison with change highlights.

    This class can be used to create an HTML table (or a complete HTML file
    containing the table) showing a side by side, line by line comparison
    of text with inter-line and intra-line change highlights.  The table can
    be generated in either full or contextual difference mode.

    The following methods are provided for HTML generation:

    make_table -- generates HTML for a single side by side table
    make_file -- generates complete HTML file with a single side by side table

    See tools/scripts/diff.py for an example usage of this class.
    'b'HtmlDiff instance initializer

        Arguments:
        tabsize -- tab stop spacing, defaults to 8.
        wrapcolumn -- column number where lines are broken and wrapped,
            defaults to None where lines are not wrapped.
        linejunk,charjunk -- keyword arguments passed into ndiff() (used by
            HtmlDiff() to generate the side by side HTML differences).  See
            ndiff() documentation for argument default values and descriptions.
        'u'HtmlDiff instance initializer

        Arguments:
        tabsize -- tab stop spacing, defaults to 8.
        wrapcolumn -- column number where lines are broken and wrapped,
            defaults to None where lines are not wrapped.
        linejunk,charjunk -- keyword arguments passed into ndiff() (used by
            HtmlDiff() to generate the side by side HTML differences).  See
            ndiff() documentation for argument default values and descriptions.
        'b'Returns HTML file of side by side comparison with change highlights

        Arguments:
        fromlines -- list of "from" lines
        tolines -- list of "to" lines
        fromdesc -- "from" file column header string
        todesc -- "to" file column header string
        context -- set to True for contextual differences (defaults to False
            which shows full differences).
        numlines -- number of context lines.  When context is set True,
            controls number of lines displayed before and after the change.
            When context is False, controls the number of lines to place
            the "next" link anchors before the next change (so click of
            "next" link jumps to just before the change).
        charset -- charset of the HTML document
        'u'Returns HTML file of side by side comparison with change highlights

        Arguments:
        fromlines -- list of "from" lines
        tolines -- list of "to" lines
        fromdesc -- "from" file column header string
        todesc -- "to" file column header string
        context -- set to True for contextual differences (defaults to False
            which shows full differences).
        numlines -- number of context lines.  When context is set True,
            controls number of lines displayed before and after the change.
            When context is False, controls the number of lines to place
            the "next" link anchors before the next change (so click of
            "next" link jumps to just before the change).
        charset -- charset of the HTML document
        'b'Returns from/to line lists with tabs expanded and newlines removed.

        Instead of tab characters being replaced by the number of spaces
        needed to fill in to the next tab stop, this function will fill
        the space with tab characters.  This is done so that the difference
        algorithms can identify changes in a file when tabs are replaced by
        spaces and vice versa.  At the end of the HTML generation, the tab
        characters will be replaced with a nonbreakable space.
        'u'Returns from/to line lists with tabs expanded and newlines removed.

        Instead of tab characters being replaced by the number of spaces
        needed to fill in to the next tab stop, this function will fill
        the space with tab characters.  This is done so that the difference
        algorithms can identify changes in a file when tabs are replaced by
        spaces and vice versa.  At the end of the HTML generation, the tab
        characters will be replaced with a nonbreakable space.
        'b'Builds list of text lines by splitting text lines at wrap point

        This function will determine if the input text line needs to be
        wrapped (split) into separate lines.  If so, the first wrap point
        will be determined and the first line appended to the output
        text line list.  This function is used recursively to handle
        the second part of the split line to further split it.
        'u'Builds list of text lines by splitting text lines at wrap point

        This function will determine if the input text line needs to be
        wrapped (split) into separate lines.  If so, the first wrap point
        will be determined and the first line appended to the output
        text line list.  This function is used recursively to handle
        the second part of the split line to further split it.
        'b'Returns iterator that splits (wraps) mdiff text lines'u'Returns iterator that splits (wraps) mdiff text lines'b'Collects mdiff output into separate lists

        Before storing the mdiff from/to data into a list, it is converted
        into a single line of text with HTML markup.
        'u'Collects mdiff output into separate lists

        Before storing the mdiff from/to data into a list, it is converted
        into a single line of text with HTML markup.
        'b'Returns HTML markup of "from" / "to" text lines

        side -- 0 or 1 indicating "from" or "to" text
        flag -- indicates if difference on line
        linenum -- line number (used for line number column)
        text -- line text to be marked up
        'u'Returns HTML markup of "from" / "to" text lines

        side -- 0 or 1 indicating "from" or "to" text
        flag -- indicates if difference on line
        linenum -- line number (used for line number column)
        text -- line text to be marked up
        'b'%d'u'%d'b' id="%s%s"'u' id="%s%s"'b'&nbsp;'u'&nbsp;'b'<td class="diff_header"%s>%s</td><td nowrap="nowrap">%s</td>'u'<td class="diff_header"%s>%s</td><td nowrap="nowrap">%s</td>'b'Create unique anchor prefixes'u'Create unique anchor prefixes'b'from%d_'u'from%d_'b'to%d_'u'to%d_'b'Makes list of "next" links'u'Makes list of "next" links'b' id="difflib_chg_%s_%d"'u' id="difflib_chg_%s_%d"'b'<a href="#difflib_chg_%s_%d">n</a>'u'<a href="#difflib_chg_%s_%d">n</a>'b'<td></td><td>&nbsp;No Differences Found&nbsp;</td>'u'<td></td><td>&nbsp;No Differences Found&nbsp;</td>'b'<td></td><td>&nbsp;Empty File&nbsp;</td>'u'<td></td><td>&nbsp;Empty File&nbsp;</td>'b'<a href="#difflib_chg_%s_0">f</a>'u'<a href="#difflib_chg_%s_0">f</a>'b'<a href="#difflib_chg_%s_top">t</a>'u'<a href="#difflib_chg_%s_top">t</a>'b'Returns HTML table of side by side comparison with change highlights

        Arguments:
        fromlines -- list of "from" lines
        tolines -- list of "to" lines
        fromdesc -- "from" file column header string
        todesc -- "to" file column header string
        context -- set to True for contextual differences (defaults to False
            which shows full differences).
        numlines -- number of context lines.  When context is set True,
            controls number of lines displayed before and after the change.
            When context is False, controls the number of lines to place
            the "next" link anchors before the next change (so click of
            "next" link jumps to just before the change).
        'u'Returns HTML table of side by side comparison with change highlights

        Arguments:
        fromlines -- list of "from" lines
        tolines -- list of "to" lines
        fromdesc -- "from" file column header string
        todesc -- "to" file column header string
        context -- set to True for contextual differences (defaults to False
            which shows full differences).
        numlines -- number of context lines.  When context is set True,
            controls number of lines displayed before and after the change.
            When context is False, controls the number of lines to place
            the "next" link anchors before the next change (so click of
            "next" link jumps to just before the change).
        'b'            <tr><td class="diff_next"%s>%s</td>%s'u'            <tr><td class="diff_next"%s>%s</td>%s'b'<td class="diff_next">%s</td>%s</tr>
'u'<td class="diff_next">%s</td>%s</tr>
'b'        </tbody>        
        <tbody>
'u'        </tbody>        
        <tbody>
'b'<thead><tr>%s%s%s%s</tr></thead>'u'<thead><tr>%s%s%s%s</tr></thead>'b'<th class="diff_next"><br /></th>'u'<th class="diff_next"><br /></th>'b'<th colspan="2" class="diff_header">%s</th>'u'<th colspan="2" class="diff_header">%s</th>'b' +'u' +'b'<span class="diff_add">'u'<span class="diff_add">'b' -'u' -'b'<span class="diff_sub">'u'<span class="diff_sub">'b' ^'u' ^'b'<span class="diff_chg">'u'<span class="diff_chg">'b'</span>'u'</span>'b'
    Generate one of the two sequences that generated a delta.

    Given a `delta` produced by `Differ.compare()` or `ndiff()`, extract
    lines originating from file 1 or 2 (parameter `which`), stripping off line
    prefixes.

    Examples:

    >>> diff = ndiff('one\ntwo\nthree\n'.splitlines(keepends=True),
    ...              'ore\ntree\nemu\n'.splitlines(keepends=True))
    >>> diff = list(diff)
    >>> print(''.join(restore(diff, 1)), end="")
    one
    two
    three
    >>> print(''.join(restore(diff, 2)), end="")
    ore
    tree
    emu
    'u'
    Generate one of the two sequences that generated a delta.

    Given a `delta` produced by `Differ.compare()` or `ndiff()`, extract
    lines originating from file 1 or 2 (parameter `which`), stripping off line
    prefixes.

    Examples:

    >>> diff = ndiff('one\ntwo\nthree\n'.splitlines(keepends=True),
    ...              'ore\ntree\nemu\n'.splitlines(keepends=True))
    >>> diff = list(diff)
    >>> print(''.join(restore(diff, 1)), end="")
    one
    two
    three
    >>> print(''.join(restore(diff, 2)), end="")
    ore
    tree
    emu
    'b'unknown delta choice (must be 1 or 2): %r'u'unknown delta choice (must be 1 or 2): %r'u'Lib.difflib'u'difflib'Disassembler of Python byte code into mnemonics.opcode_opcodes_all_cache_format_inline_cache_entries_nb_ops_intrinsic_1_descs_intrinsic_2_descs_specializations_specialized_instructionscode_infodisassembledistbdiscofindlinestartsfindlabelsshow_codeget_instructionsInstructionBytecode_have_codeopmapFORMAT_VALUEFORMAT_VALUE_CONVERTERSMAKE_FUNCTIONkwdefaultsclosureMAKE_FUNCTION_FLAGSLOAD_CONSTRETURN_CONSTLOAD_GLOBALBINARY_OPJUMP_BACKWARDFOR_ITERSENDLOAD_ATTRLOAD_SUPER_ATTRCALL_INTRINSIC_1CALL_INTRINSIC_2CACHEopname_all_opname_all_opmap_empty_slotspec_opspecializeddeoptmap_try_compileAttempts to compile the given source, first as an expression and
       then as a statement if the first approach fails.

       Utility function to accept strings in functions that otherwise
       expect code objects
    depthshow_cachesadaptiveDisassemble classes, methods, functions, and other compiled objects.

    With no argument, disassemble the last traceback.

    Compiled objects currently include generator objects, async generator
    objects, and coroutine objects, all of which store their code object
    in a special attribute.
    ag_codex1Disassembly of %s:Sorry:co_code_disassemble_recursive_disassemble_bytes_disassemble_strdon't know how to disassemble %s objectsDisassemble a traceback (default: last traceback).no last traceback to disassembletb_lastiOPTIMIZEDNEWLOCALSVARARGSVARKEYWORDSNESTEDGENERATORNOFREECOROUTINEITERABLE_COROUTINEASYNC_GENERATORCOMPILER_FLAG_NAMESpretty_flagsReturn pretty representation of code flags._Unknown_get_code_objectHelper to handle methods, compiled or raw code objects, and strings.<disassembly>_deoptop_get_code_array_co_code_adaptiveFormatted details of methods, functions, or code._format_code_infoName:              %sFilename:          %sArgument count:    %sco_argcountPositional-only arguments: %sco_posonlyargcountKw-only arguments: %sco_kwonlyargcountNumber of locals:  %sco_nlocalsStack size:        %sco_stacksizeFlags:             %sco_constsConstants:i_c%4d: %rco_namesNames:i_n%4d: %sco_varnamesVariable names:co_freevarsFree variables:co_cellvarsCell variables:Print details of methods, functions, or code to *file*.

    If *file* is not provided, the output is printed on stdout.
    Positions_Instructionargvalargreprstarts_lineis_jump_targetpositionsHuman readable name for operationNumeric code for operationNumeric argument to operation (if any), otherwise NoneResolved arg value (if known), otherwise same as argHuman readable description of operation argumentStart index of operation within bytecode sequenceLine started by this opcode (if any), otherwise NoneTrue if other code jumps to here, otherwise Falsedis.Positions object holding the span of source code covered by this instruction_ExceptionTableEntrystart end target depth lasti_OPNAME_WIDTH_OPARG_WIDTHDetails for a bytecode operation

       Defined fields:
         opname - human readable name for operation
         opcode - numeric code for operation
         arg - numeric argument to operation (if any), otherwise None
         argval - resolved arg value (if known), otherwise same as arg
         argrepr - human readable description of operation argument
         offset - start index of operation within bytecode sequence
         starts_line - line started by this opcode (if any), otherwise None
         is_jump_target - True if other code jumps to here, otherwise False
         positions - Optional dis.Positions object holding the span of source code
                     covered by this instruction
    _disassemblelineno_widthmark_as_currentFormat instruction details for inclusion in disassembly output

        *lineno_width* sets the width of the line number field (0 omits it)
        *mark_as_current* inserts a '-->' marker arrow as part of the line
        *offset_width* sets the width of the instruction offset field
        %%%ddlineno_fmt-->   first_lineIterator for the opcodes in methods, functions or code

    Generates a series of Instruction named tuples giving the details of
    each operations in the supplied code.

    If *first_line* is not None, it indicates the line number that should
    be reported for the first source line in the disassembled code.
    Otherwise, the source line information (if any) is taken directly from
    the disassembled code object.
    linestartsline_offset_get_instructions_bytes_varname_from_opargco_positions_get_const_valueHelper to get the value of the const in a hasconst op.

       Returns the dereferenced constant if this is possible.
       Otherwise (if it is a LOAD_CONST and co_consts is not
       provided) returns the dis.UNKNOWN sentinel.
    hasconst_get_const_infoHelper to get optional details about const references

       Returns the dereferenced constant and its repr if the value
       can be calculated.
       Otherwise returns the sentinel value dis.UNKNOWN for the value
       and an empty string for its repr.
    _get_name_infoname_indexextrainfoHelper to get optional details about named references

       Returns the dereferenced name as both value and repr if the name
       list is defined.
       Otherwise returns the sentinel value dis.UNKNOWN for the value
       and an empty string for its repr.
    _parse_varint_parse_exception_tableco_exceptiontableentriesdllasti_is_backward_jumpvarname_from_opargexception_entriesIterate over the instructions in a bytecode string.

    Generates a sequence of Instruction namedtuples giving the details of each
    opcode.  Additional information about the code's runtime environment
    (e.g. variable names, co_consts) can be specified using optional
    arguments.

    _unpack_opargsdeopcacheshasnameNULL + NULL|self + hasjabsto hasjrelsigned_arghaslocalhasfreehascomparecmp_opwith formatDisassemble a code object.Disassembly of %r:show_linenomaxlinenomaxoffsetinstrnew_source_lineis_current_instrExceptionTable: lasti to Compile the source string, then disassemble the code object.<dis>_INT_BITS_INT_OVERFLOWextended_arghasargEXTENDED_ARGDetect all offsets in a byte code which are jump targets.

    Return the list of offsets.

    Find the offsets in a byte code which are start of lines in the source.

    Generate pairs (offset, lineno)
    lastlineco_lines_find_importsFind import statements in the code

    Generate triplets (name, level, fromlist) where
    name is the imported module and level, fromlist are
    the corresponding args to __import__.
    IMPORT_NAMEconstsopargsopargfrom_oplevel_op_find_store_namesFind names of variables which are written in the code

    Generate sequence of strings
    STORE_NAMESTORE_GLOBALSTORE_OPSThe bytecode operations of a piece of code

    Instantiate this with a function, method, other compiled object, string of
    code, or a code object (as returned by compile()).

    Iterating over this yields the bytecode operations as Instruction instances.
    current_offsetcodeobj_line_offset_linestarts_original_object{}({!r})from_traceback Construct a Bytecode from the given traceback Return formatted information about the code object.Return a formatted view of the bytecode operations.# fill opname and opmap# Extract functions from methods.# Extract compiled code objects from...# ...a function, or#...a generator object, or#...an asynchronous generator object, or#...a coroutine.# Perform the disassembly.# Class or module# Code object# Raw bytecode# Source code# The inspect module interrogates this dictionary to build its# list of CO_* constants. It is also used by pretty_flags to# turn the co_flags field into a human readable list.# Sentinel to represent values that cannot be calculated# Handle source code.# By now, if we don't have a code object, we can't disassemble x.# Column: Source code line number# Column: Current instruction indicator# Column: Jump target marker# Column: Instruction offset from start of code sequence# Column: Opcode name# Column: Opcode argument# Column: Opcode argument details#  Set argval to the dereferenced value of the argument when#  available, and argrepr to the string representation of argval.#    _disassemble_bytes needs the string repr of the#    raw name index for LOAD_GLOBAL, LOAD_CONST, etc.# We still need to advance the co_positions iterator:# Only show the fancy argrepr for a CACHE instruction when it's# the first entry for a particular cache value:# Omit the line number column entirely if we have no line number info# Each CACHE takes 2 bytes# XXX For backwards compatibility# Rely on C `int` being 32 bits for oparg# Value for c int when it overflows# Skip inline CACHE entries:# The oparg is stored as a signed integer# If the value exceeds its upper limit, it will overflow and wrap# to a negative integerb'Disassembler of Python byte code into mnemonics.'u'Disassembler of Python byte code into mnemonics.'b'code_info'u'code_info'b'dis'u'dis'b'disassemble'u'disassemble'b'distb'u'distb'b'disco'u'disco'b'findlinestarts'u'findlinestarts'b'findlabels'u'findlabels'b'show_code'u'show_code'b'get_instructions'u'get_instructions'b'Instruction'u'Instruction'b'Bytecode'u'Bytecode'b'FORMAT_VALUE'u'FORMAT_VALUE'b'MAKE_FUNCTION'u'MAKE_FUNCTION'b'defaults'b'kwdefaults'u'kwdefaults'b'closure'u'closure'b'LOAD_CONST'u'LOAD_CONST'b'RETURN_CONST'u'RETURN_CONST'b'LOAD_GLOBAL'u'LOAD_GLOBAL'b'BINARY_OP'u'BINARY_OP'b'JUMP_BACKWARD'u'JUMP_BACKWARD'b'FOR_ITER'u'FOR_ITER'b'SEND'u'SEND'b'LOAD_ATTR'u'LOAD_ATTR'b'LOAD_SUPER_ATTR'u'LOAD_SUPER_ATTR'b'CALL_INTRINSIC_1'u'CALL_INTRINSIC_1'b'CALL_INTRINSIC_2'u'CALL_INTRINSIC_2'b'CACHE'u'CACHE'b'Attempts to compile the given source, first as an expression and
       then as a statement if the first approach fails.

       Utility function to accept strings in functions that otherwise
       expect code objects
    'u'Attempts to compile the given source, first as an expression and
       then as a statement if the first approach fails.

       Utility function to accept strings in functions that otherwise
       expect code objects
    'b'Disassemble classes, methods, functions, and other compiled objects.

    With no argument, disassemble the last traceback.

    Compiled objects currently include generator objects, async generator
    objects, and coroutine objects, all of which store their code object
    in a special attribute.
    'u'Disassemble classes, methods, functions, and other compiled objects.

    With no argument, disassemble the last traceback.

    Compiled objects currently include generator objects, async generator
    objects, and coroutine objects, all of which store their code object
    in a special attribute.
    'b'__func__'u'__func__'b'__code__'u'__code__'b'ag_code'u'ag_code'b'Disassembly of %s:'u'Disassembly of %s:'b'Sorry:'u'Sorry:'b'co_code'u'co_code'b'don't know how to disassemble %s objects'u'don't know how to disassemble %s objects'b'Disassemble a traceback (default: last traceback).'u'Disassemble a traceback (default: last traceback).'b'last_exc'u'last_exc'b'no last traceback to disassemble'u'no last traceback to disassemble'b'OPTIMIZED'u'OPTIMIZED'b'NEWLOCALS'u'NEWLOCALS'b'VARARGS'u'VARARGS'b'VARKEYWORDS'u'VARKEYWORDS'b'NESTED'u'NESTED'b'GENERATOR'u'GENERATOR'b'NOFREE'u'NOFREE'b'COROUTINE'u'COROUTINE'b'ITERABLE_COROUTINE'u'ITERABLE_COROUTINE'b'ASYNC_GENERATOR'u'ASYNC_GENERATOR'b'Return pretty representation of code flags.'u'Return pretty representation of code flags.'b'Helper to handle methods, compiled or raw code objects, and strings.'u'Helper to handle methods, compiled or raw code objects, and strings.'b'<disassembly>'u'<disassembly>'b'Formatted details of methods, functions, or code.'u'Formatted details of methods, functions, or code.'b'Name:              %s'u'Name:              %s'b'Filename:          %s'u'Filename:          %s'b'Argument count:    %s'u'Argument count:    %s'b'Positional-only arguments: %s'u'Positional-only arguments: %s'b'Kw-only arguments: %s'u'Kw-only arguments: %s'b'Number of locals:  %s'u'Number of locals:  %s'b'Stack size:        %s'u'Stack size:        %s'b'Flags:             %s'u'Flags:             %s'b'Constants:'u'Constants:'b'%4d: %r'u'%4d: %r'b'Names:'u'Names:'b'%4d: %s'u'%4d: %s'b'Variable names:'u'Variable names:'b'Free variables:'u'Free variables:'b'Cell variables:'u'Cell variables:'b'Print details of methods, functions, or code to *file*.

    If *file* is not provided, the output is printed on stdout.
    'u'Print details of methods, functions, or code to *file*.

    If *file* is not provided, the output is printed on stdout.
    'b'Positions'u'Positions'b'_Instruction'u'_Instruction'b'opname'u'opname'b'opcode'u'opcode'b'arg'b'argval'u'argval'b'argrepr'u'argrepr'b'offset'u'offset'b'starts_line'u'starts_line'b'is_jump_target'u'is_jump_target'b'positions'u'positions'b'Human readable name for operation'u'Human readable name for operation'b'Numeric code for operation'u'Numeric code for operation'b'Numeric argument to operation (if any), otherwise None'u'Numeric argument to operation (if any), otherwise None'b'Resolved arg value (if known), otherwise same as arg'u'Resolved arg value (if known), otherwise same as arg'b'Human readable description of operation argument'u'Human readable description of operation argument'b'Start index of operation within bytecode sequence'u'Start index of operation within bytecode sequence'b'Line started by this opcode (if any), otherwise None'u'Line started by this opcode (if any), otherwise None'b'True if other code jumps to here, otherwise False'u'True if other code jumps to here, otherwise False'b'dis.Positions object holding the span of source code covered by this instruction'u'dis.Positions object holding the span of source code covered by this instruction'b'_ExceptionTableEntry'u'_ExceptionTableEntry'b'start end target depth lasti'u'start end target depth lasti'b'Details for a bytecode operation

       Defined fields:
         opname - human readable name for operation
         opcode - numeric code for operation
         arg - numeric argument to operation (if any), otherwise None
         argval - resolved arg value (if known), otherwise same as arg
         argrepr - human readable description of operation argument
         offset - start index of operation within bytecode sequence
         starts_line - line started by this opcode (if any), otherwise None
         is_jump_target - True if other code jumps to here, otherwise False
         positions - Optional dis.Positions object holding the span of source code
                     covered by this instruction
    'u'Details for a bytecode operation

       Defined fields:
         opname - human readable name for operation
         opcode - numeric code for operation
         arg - numeric argument to operation (if any), otherwise None
         argval - resolved arg value (if known), otherwise same as arg
         argrepr - human readable description of operation argument
         offset - start index of operation within bytecode sequence
         starts_line - line started by this opcode (if any), otherwise None
         is_jump_target - True if other code jumps to here, otherwise False
         positions - Optional dis.Positions object holding the span of source code
                     covered by this instruction
    'b'Format instruction details for inclusion in disassembly output

        *lineno_width* sets the width of the line number field (0 omits it)
        *mark_as_current* inserts a '-->' marker arrow as part of the line
        *offset_width* sets the width of the instruction offset field
        'u'Format instruction details for inclusion in disassembly output

        *lineno_width* sets the width of the line number field (0 omits it)
        *mark_as_current* inserts a '-->' marker arrow as part of the line
        *offset_width* sets the width of the instruction offset field
        'b'%%%dd'u'%%%dd'b'-->'u'-->'b'   'u'   'b'Iterator for the opcodes in methods, functions or code

    Generates a series of Instruction named tuples giving the details of
    each operations in the supplied code.

    If *first_line* is not None, it indicates the line number that should
    be reported for the first source line in the disassembled code.
    Otherwise, the source line information (if any) is taken directly from
    the disassembled code object.
    'u'Iterator for the opcodes in methods, functions or code

    Generates a series of Instruction named tuples giving the details of
    each operations in the supplied code.

    If *first_line* is not None, it indicates the line number that should
    be reported for the first source line in the disassembled code.
    Otherwise, the source line information (if any) is taken directly from
    the disassembled code object.
    'b'Helper to get the value of the const in a hasconst op.

       Returns the dereferenced constant if this is possible.
       Otherwise (if it is a LOAD_CONST and co_consts is not
       provided) returns the dis.UNKNOWN sentinel.
    'u'Helper to get the value of the const in a hasconst op.

       Returns the dereferenced constant if this is possible.
       Otherwise (if it is a LOAD_CONST and co_consts is not
       provided) returns the dis.UNKNOWN sentinel.
    'b'Helper to get optional details about const references

       Returns the dereferenced constant and its repr if the value
       can be calculated.
       Otherwise returns the sentinel value dis.UNKNOWN for the value
       and an empty string for its repr.
    'u'Helper to get optional details about const references

       Returns the dereferenced constant and its repr if the value
       can be calculated.
       Otherwise returns the sentinel value dis.UNKNOWN for the value
       and an empty string for its repr.
    'b'Helper to get optional details about named references

       Returns the dereferenced name as both value and repr if the name
       list is defined.
       Otherwise returns the sentinel value dis.UNKNOWN for the value
       and an empty string for its repr.
    'u'Helper to get optional details about named references

       Returns the dereferenced name as both value and repr if the name
       list is defined.
       Otherwise returns the sentinel value dis.UNKNOWN for the value
       and an empty string for its repr.
    'b'Iterate over the instructions in a bytecode string.

    Generates a sequence of Instruction namedtuples giving the details of each
    opcode.  Additional information about the code's runtime environment
    (e.g. variable names, co_consts) can be specified using optional
    arguments.

    'u'Iterate over the instructions in a bytecode string.

    Generates a sequence of Instruction namedtuples giving the details of each
    opcode.  Additional information about the code's runtime environment
    (e.g. variable names, co_consts) can be specified using optional
    arguments.

    'b'NULL + 'u'NULL + 'b'NULL|self + 'u'NULL|self + 'b'to 'u'to 'b'with format'u'with format'b'Disassemble a code object.'u'Disassemble a code object.'b'Disassembly of %r:'u'Disassembly of %r:'b'ExceptionTable:'u'ExceptionTable:'b' lasti'u' lasti'b' to 'u' to 'b'Compile the source string, then disassemble the code object.'u'Compile the source string, then disassemble the code object.'b'<dis>'u'<dis>'b'Detect all offsets in a byte code which are jump targets.

    Return the list of offsets.

    'u'Detect all offsets in a byte code which are jump targets.

    Return the list of offsets.

    'b'Find the offsets in a byte code which are start of lines in the source.

    Generate pairs (offset, lineno)
    'u'Find the offsets in a byte code which are start of lines in the source.

    Generate pairs (offset, lineno)
    'b'Find import statements in the code

    Generate triplets (name, level, fromlist) where
    name is the imported module and level, fromlist are
    the corresponding args to __import__.
    'u'Find import statements in the code

    Generate triplets (name, level, fromlist) where
    name is the imported module and level, fromlist are
    the corresponding args to __import__.
    'b'IMPORT_NAME'u'IMPORT_NAME'b'Find names of variables which are written in the code

    Generate sequence of strings
    'u'Find names of variables which are written in the code

    Generate sequence of strings
    'b'STORE_NAME'u'STORE_NAME'b'STORE_GLOBAL'u'STORE_GLOBAL'b'The bytecode operations of a piece of code

    Instantiate this with a function, method, other compiled object, string of
    code, or a code object (as returned by compile()).

    Iterating over this yields the bytecode operations as Instruction instances.
    'u'The bytecode operations of a piece of code

    Instantiate this with a function, method, other compiled object, string of
    code, or a code object (as returned by compile()).

    Iterating over this yields the bytecode operations as Instruction instances.
    'b'{}({!r})'u'{}({!r})'b' Construct a Bytecode from the given traceback 'u' Construct a Bytecode from the given traceback 'b'Return formatted information about the code object.'u'Return formatted information about the code object.'b'Return a formatted view of the bytecode operations.'u'Return a formatted view of the bytecode operations.'u'Lib.dis'Module doctest -- a framework for running examples in docstrings.

In simplest use, end each module M to be tested with:

def _test():
    import doctest
    doctest.testmod()

if __name__ == "__main__":
    _test()

Then running the module as a script will cause the examples in the
docstrings to get executed and verified:

python M.py

This won't display anything unless an example fails, in which case the
failing example(s) and the cause(s) of the failure(s) are printed to stdout
(why not stderr? because stderr is a lame hack <0.2 wink>), and the final
line of output is "Test failed.".

Run it with the -v switch instead:

python M.py -v

and a detailed report of all examples tried is printed to stdout, along
with assorted summaries at the end.

You can force verbose mode by passing "verbose=True" to testmod, or prohibit
it by passing "verbose=False".  In either of those cases, sys.argv is not
examined by testmod.

There are a variety of other ways to run doctests, including integration
with the unittest framework, and support for running non-Python text
files containing doctests.  There are also many ways to override parts
of doctest's default behaviors.  See the Library Reference Manual for
details.
reStructuredText en__docformat__register_optionflagDONT_ACCEPT_TRUE_FOR_1DONT_ACCEPT_BLANKLINENORMALIZE_WHITESPACEELLIPSISSKIPIGNORE_EXCEPTION_DETAILCOMPARISON_FLAGSREPORT_UDIFFREPORT_CDIFFREPORT_NDIFFREPORT_ONLY_FIRST_FAILUREREPORTING_FLAGSFAIL_FASTExampleDocTestDocTestParserDocTestFinderDocTestRunnerOutputCheckerDocTestFailureUnexpectedExceptionDebugRunnertestfilerun_docstring_examplesDocTestSuiteDocFileSuiteset_unittest_reportflagsscript_from_examplestestsourcedebug_srcpdbunittestTestResultsfailed attemptedOPTIONFLAGS_BY_NAME<BLANKLINE>BLANKLINE_MARKERELLIPSIS_MARKER_extract_future_flagsglobs
    Return the compiler-flags associated with the future features that
    have been imported into the given namespace (globs).
    _normalize_module
    Return the module specified by `module`.  In particular:
      - If `module` is a module, then return module.
      - If `module` is a string, then import and return the
        module with that name.
      - If `module` is None, then return the calling module.
        The calling module is assumed to be the module of
        the stack frame at the given depth in the call stack.
    ismoduleExpected a module, string, or None_newline_convert_load_testfilemodule_relative_module_relative_pathfile_contents
    Add the given number of space characters to the beginning of
    every non-blank line in `s`, and return the result.
    (?m)^(?!$)_exception_traceback
    Return a string containing a traceback message for the given
    exc_info tuple (as returned by sys.exc_info()).
    excout_SpoofOut_ellipsis_matchwantgot
    Essentially the only subtle case:
    >>> _ellipsis_match('aa...aa', 'aaa')
    False
    startposendpos_comment_lineReturn a commented form of the given line_strip_exception_details_OutputRedirectingPdbPdb
    A specialized version of the python debugger that redirects stdout
    to a given stream when interacting with the user.  Stdout is *not*
    redirected when traced code is executed.
    __out__debugger_usednosigintsave_stdouttest_pathExpected a module: %rModule-relative files may not have absolute pathsbasedirdirectoryfullpathCan't resolve paths relative to the module %r (it has no __file__)"Can't resolve paths relative to the module ""%r (it has no __file__)"
    A single doctest example, consisting of source code and expected
    output.  `Example` defines the following attributes:

      - source: A single Python statement, always ending with a newline.
        The constructor adds a newline if needed.

      - want: The expected output from running the source code (either
        from stdout, or a traceback in case of exception).  `want` ends
        with a newline unless it's empty, in which case it's an empty
        string.  The constructor adds a newline if needed.

      - exc_msg: The exception message generated by the example, if
        the example is expected to generate an exception; or `None` if
        it is not expected to generate an exception.  This exception
        message is compared against the return value of
        `traceback.format_exception_only()`.  `exc_msg` ends with a
        newline unless it's `None`.  The constructor adds a newline
        if needed.

      - lineno: The line number within the DocTest string containing
        this Example where the Example begins.  This line number is
        zero-based, with respect to the beginning of the DocTest.

      - indent: The example's indentation in the DocTest string.
        I.e., the number of space characters that precede the
        example's first prompt.

      - options: A dictionary mapping from option flags to True or
        False, which is used to override default options for this
        example.  Any option flags not contained in this dictionary
        are left at their default value (as specified by the
        DocTestRunner's optionflags).  By default, no options are set.
    exc_msg
    A collection of doctest examples that should be run in a single
    namespace.  Each `DocTest` defines the following attributes:

      - examples: the list of examples.

      - globs: The namespace (aka globals) that the examples should
        be run in.

      - name: A name identifying the DocTest (typically, the name of
        the object whose docstring this DocTest was extracted from).

      - filename: The name of the file that this DocTest was extracted
        from, or `None` if the filename is unknown.

      - lineno: The line number within filename where this DocTest
        begins, or `None` if the line number is unavailable.  This
        line number is zero-based, with respect to the beginning of
        the file.

      - docstring: The string that the examples were extracted from,
        or `None` if the string is unavailable.
    examples
        Create a new DocTest containing the given examples.  The
        DocTest's globals are initialized with a copy of `globs`.
        DocTest no longer accepts str; use DocTestParser insteadno examples1 example%d examples<%s %s from %s:%s (%s)>self_lnoother_lno
    A class used to parse strings containing doctest examples.
    
        # Source consists of a PS1 line followed by zero or more PS2 lines.
        (?P<source>
            (?:^(?P<indent> [ ]*) >>>    .*)    # PS1 line
            (?:\n           [ ]*  \.\.\. .*)*)  # PS2 lines
        \n?
        # Want consists of any non-blank lines that do not start with PS1.
        (?P<want> (?:(?![ ]*$)    # Not a blank line
                     (?![ ]*>>>)  # Not a line starting with PS1
                     .+$\n?       # But any other line
                  )*)
        r'''_EXAMPLE_RE
        # Grab the traceback header.  Different versions of Python have
        # said different things on the first traceback line.
        ^(?P<hdr> Traceback\ \(
            (?: most\ recent\ call\ last
            |   innermost\ last
            ) \) :
        )
        \s* $                # toss trailing whitespace on the header.
        (?P<stack> .*?)      # don't blink: absorb stuff until...
        ^ (?P<msg> \w+ .*)   #     a line *starts* with alphanum.
        _EXCEPTION_RE^[ ]*(#.*)?$_IS_BLANK_OR_COMMENT
        Divide the given string into examples and intervening text,
        and return them as a list of alternating Examples and strings.
        Line numbers for the Examples are 0-based.  The optional
        argument `name` is a name identifying this string, and is only
        used for error messages.
        _min_indentmin_indentcharno_parse_exampleget_doctest
        Extract all doctest examples from the given string, and
        collect them into a `DocTest` object.

        `globs`, `name`, `filename`, and `lineno` are attributes for
        the new `DocTest` object.  See the documentation for `DocTest`
        for more information.
        get_examples
        Extract all doctest examples from the given string, and return
        them as a list of `Example` objects.  Line numbers are
        0-based, because it's most common in doctests that nothing
        interesting appears on the same line as opening triple-quote,
        and so the first interesting line is called "line 1" then.

        The optional argument `name` is a name identifying this
        string, and is only used for error messages.
        
        Given a regular expression match from `_EXAMPLE_RE` (`m`),
        return a pair `(source, want)`, where `source` is the matched
        example's source code (with prompts and indentation stripped);
        and `want` is the example's expected output (with indentation
        stripped).

        `name` is the string's name, and `lineno` is the line number
        where the example starts; both are used for error messages.
        source_lines_check_prompt_blank_check_prefixslwant_lines *$wl_find_options#\s*doctest:\s*([^\n\'"]*)$_OPTION_DIRECTIVE_RE
        Return a dictionary containing option overrides extracted from
        option directives in the given source string.

        `name` is the string's name, and `lineno` is the line number
        where the example starts; both are used for error messages.
        line %r of the doctest for %s has an invalid option: %r'line %r of the doctest for %s ''has an invalid option: %r'line %r of the doctest for %s has an option directive on a line with no example: %r'line %r of the doctest for %s has an option ''directive on a line with no example: %r'^([ ]*)(?=\S)_INDENT_REReturn the minimum indentation of any non-blank line in `s`indents
        Given the lines of a source string (including prompts and
        leading indentation), check to make sure that every prompt is
        followed by a space character.  If any line is not followed by
        a space character, then raise ValueError.
        line %r of the docstring for %s lacks blank after %s: %r'line %r of the docstring for %s ''lacks blank after %s: %r'
        Check that every line in the given list starts with the given
        prefix; if any line does not, then raise a ValueError.
        line %r of the docstring for %s has inconsistent leading whitespace: %r'line %r of the docstring for %s has ''inconsistent leading whitespace: %r'
    A class used to extract the DocTests that are relevant to a given
    object, from its docstring and the docstrings of its contained
    objects.  Doctests can currently be extracted from the following
    object types: modules, functions, classes, methods, staticmethods,
    classmethods, and properties.
    recurseexclude_empty
        Create a new doctest finder.

        The optional argument `parser` specifies a class or
        function that should be used to create new DocTest objects (or
        objects that implement the same interface as DocTest).  The
        signature for this factory function should match the signature
        of the DocTest constructor.

        If the optional argument `recurse` is false, then `find` will
        only examine the given object, and not any contained objects.

        If the optional argument `exclude_empty` is false, then `find`
        will include tests for objects with empty docstrings.
        _verbose_recurse_exclude_emptyextraglobs
        Return a list of the DocTests that are defined by the given
        object's docstring, or by any of its contained objects'
        docstrings.

        The optional parameter `module` is the module that contains
        the given object.  If the module is not specified or is None, then
        the test finder will attempt to automatically determine the
        correct module.  The object's module is used:

            - As a default namespace, if `globs` is not specified.
            - To prevent the DocTestFinder from extracting DocTests
              from objects that are imported from other modules.
            - To find the name of the file containing the object.
            - To help find the line number of the object within its
              file.

        Contained objects whose module does not match `module` are ignored.

        If `module` is False, no attempt to find the module will be made.
        This is obscure, of use mostly in tests:  if `module` is False, or
        is None but cannot be found automatically, then all objects are
        considered to belong to the (non-existent) module, so all contained
        objects will (recursively) be searched for doctests.

        The globals for each DocTest is formed by combining `globs`
        and `extraglobs` (bindings in `extraglobs` override bindings
        in `globs`).  A new copy of the globals dictionary is created
        for each DocTest.  If `globs` is not specified, then it
        defaults to the module's `__dict__`, if specified, or {}
        otherwise.  If `extraglobs` is not specified, then it defaults
        to {}.

        DocTestFinder.find: name must be given when obj.__name__ doesn't exist: %r"DocTestFinder.find: name must be given ""when obj.__name__ doesn't exist: %r"getmodulegetsourcefilegetfile<]>getlinestests_find_from_module
        Return true if the given object is defined in the given
        module.
        isfunctionismethoddescriptorismethodwrapperobj_modisclassobject must be a class or function_is_routine
        Safely unwrap objects and determine if they are functions.
        maybe_routineunwrapisroutine
        Find tests for the given object and any contained objects, and
        add them to `tests`.
        Finding tests in %s_get_testvalname__test__DocTestFinder.find: __test__ keys must be strings: %r"DocTestFinder.find: __test__ keys ""must be strings: %r"DocTestFinder.find: __test__ values must be strings, functions, methods, classes, or modules: %r"DocTestFinder.find: __test__ values ""must be strings, functions, methods, ""classes, or modules: %r"%s.__test__.%s
        Return a DocTest for the given object, if it defines a docstring;
        otherwise, return None.
        _find_lineno
        Return a line number of the given object's docstring.

        Returns `None` if the given object does not have a docstring.
        ^\s*class\s*%s\bismethodistracebackisframeiscode(^|.*:)\s*\w*("|\')
    A class used to run DocTest test cases, and accumulate statistics.
    The `run` method is used to process a single DocTest case.  It
    returns a tuple `(f, t)`, where `t` is the number of test cases
    tried, and `f` is the number of test cases that failed.

        >>> tests = DocTestFinder().find(_TestClass)
        >>> runner = DocTestRunner(verbose=False)
        >>> tests.sort(key = lambda test: test.name)
        >>> for test in tests:
        ...     print(test.name, '->', runner.run(test))
        _TestClass -> TestResults(failed=0, attempted=2)
        _TestClass.__init__ -> TestResults(failed=0, attempted=2)
        _TestClass.get -> TestResults(failed=0, attempted=2)
        _TestClass.square -> TestResults(failed=0, attempted=1)

    The `summarize` method prints a summary of all the test cases that
    have been run by the runner, and returns an aggregated `(f, t)`
    tuple:

        >>> runner.summarize(verbose=1)
        4 items passed all tests:
           2 tests in _TestClass
           2 tests in _TestClass.__init__
           2 tests in _TestClass.get
           1 tests in _TestClass.square
        7 tests in 4 items.
        7 passed and 0 failed.
        Test passed.
        TestResults(failed=0, attempted=7)

    The aggregated number of tried examples and failed examples is
    also available via the `tries` and `failures` attributes:

        >>> runner.tries
        7
        >>> runner.failures
        0

    The comparison between expected outputs and actual outputs is done
    by an `OutputChecker`.  This comparison may be customized with a
    number of option flags; see the documentation for `testmod` for
    more information.  If the option flags are insufficient, then the
    comparison may also be customized by passing a subclass of
    `OutputChecker` to the constructor.

    The test runner's display output can be controlled in two ways.
    First, an output function (`out) can be passed to
    `TestRunner.run`; this function will be called with strings that
    should be displayed.  It defaults to `sys.stdout.write`.  If
    capturing the output is not sufficient, then the display output
    can be also customized by subclassing DocTestRunner, and
    overriding the methods `report_start`, `report_success`,
    `report_unexpected_exception`, and `report_failure`.
    DIVIDERcheckeroptionflags
        Create a new test runner.

        Optional keyword arg `checker` is the `OutputChecker` that
        should be used to compare the expected outputs and actual
        outputs of doctest examples.

        Optional keyword arg 'verbose' prints lots of stuff if true,
        only failures if false; by default, it's true iff '-v' is in
        sys.argv.

        Optional argument `optionflags` can be used to control how the
        test runner compares expected output to actual output, and how
        it displays failures.  See the documentation for `testmod` for
        more information.
        _checker-voriginal_optionflagstriesfailures_name2ft_fakeoutreport_startexample
        Report that the test runner is about to process the given
        example.  (Only displays a message if verbose=True)
        Trying:
Expecting:
Expecting nothing
report_success
        Report that the given example ran successfully.  (Only
        displays a message if verbose=True)
        ok
report_failure
        Report that the given example failed.
        _failure_headeroutput_differencereport_unexpected_exception
        Report that the given example raised an unexpected exception.
        Exception raised:
File "%s", line %s, in %sLine %s, in %sFailed example:__runcompileflags
        Run the examples in `test`.  Write the outcome of each example
        with one of the `DocTestRunner.report_*` methods, using the
        writer function `out`.  `compileflags` is the set of compiler
        flags that should be used to execute examples.  Return a tuple
        `(f, t)`, where `t` is the number of examples tried, and `f`
        is the number of examples that failed.  The examples are run
        in the namespace `test.globs`.
        BOOMcheckexamplenumoptionflag<doctest %s[%d]>debuggerformatted_exexception_line_prefixesexc_msg_indexunknown outcome__record_outcome
        Record the fact that the given DocTest (`test`) generated `f`
        failures out of `t` tried examples.
        f2<doctest (?P<name>.+)\[(?P<examplenum>\d+)\]>$r'<doctest 'r'(?P<name>.+)'r'\[(?P<examplenum>\d+)\]>$'__LINECACHE_FILENAME_RE__patched_linecache_getlinessave_linecache_getlinesclear_globs
        Run the examples in `test`, and display the results using the
        writer function `out`.

        The examples are run in the namespace `test.globs`.  If
        `clear_globs` is true (the default), then this namespace will
        be cleared after the test runs, to help with garbage
        collection.  If you would like to examine the namespace after
        the test completes, then use `clear_globs=False`.

        `compileflags` gives the set of flags that should be used by
        the Python compiler when running the examples.  If not
        specified, then it will default to the set of future-import
        flags that apply to `globs`.

        The output of each example is checked using
        `DocTestRunner.check_output`, and the results are formatted by
        the `DocTestRunner.report_*` methods.
        save_tracesave_set_tracesave_displayhooksummarize
        Print a summary of all the test cases that have been run by
        this DocTestRunner, and return a tuple `(f, t)`, where `f` is
        the total number of failed examples, and `t` is the total
        number of tried examples.

        The optional `verbose` argument controls how detailed the
        summary is.  If the verbosity is not specified, then the
        DocTestRunner's verbosity is used.
        notestspassedfailedtotalttotalfitems had no tests:items passed all tests: %3d tests in %sitems had failures: %3d of %3d in %stests initems.passed andfailed.***Test Failed***failures.Test passed.merge
    A class used to check the whether the actual output from a doctest
    example matches the expected output.  `OutputChecker` defines two
    methods: `check_output`, which compares a given pair of outputs,
    and returns true if they match; and `output_difference`, which
    returns a string describing the differences between two outputs.
    _toAscii
        Convert string to hex-escaped ASCII string.
        
        Return True iff the actual output from an example (`got`)
        matches the expected output (`want`).  These strings are
        always considered to match if they are identical; but
        depending on what option flags the test runner is using,
        several non-exact match types are also possible.  See the
        documentation for `TestRunner` for more information about
        option flags.
        True
1
False
0
(?m)^%s\s*?$(?m)^[^\S\n]+$_do_a_fancy_diff
        Return a string describing the differences between the
        expected output for a given example (`example`) and the actual
        output (`got`).  `optionflags` is the set of option flags used
        to compare `want` and `got`.
        (?m)^[ ]*(?=
)got_linesunified diff with -expected +actualcontext diff with expected followed by actualenginendiff with -expected +actualBad diff optionDifferences (%s):
Expected:
%sGot:
%sExpected:
%sGot nothing
Expected nothing
Got:
%sExpected nothing
Got nothing
A DocTest example has failed in debugging mode.

    The exception instance has variables:

    - test: the DocTest object being run

    - example: the Example object that failed

    - got: the actual output
    A DocTest example has encountered an unexpected exception

    The exception instance has variables:

    - test: the DocTest object being run

    - example: the Example object that failed

    - exc_info: the exception info
    Run doc tests but raise an exception as soon as there is a failure.

       If an unexpected exception occurs, an UnexpectedException is raised.
       It contains the test, the example, and the original exception:

         >>> runner = DebugRunner(verbose=False)
         >>> test = DocTestParser().get_doctest('>>> raise KeyError\n42',
         ...                                    {}, 'foo', 'foo.py', 0)
         >>> try:
         ...     runner.run(test)
         ... except UnexpectedException as f:
         ...     failure = f

         >>> failure.test is test
         True

         >>> failure.example.want
         '42\n'

         >>> exc_info = failure.exc_info
         >>> raise exc_info[1] # Already has the traceback
         Traceback (most recent call last):
         ...
         KeyError

       We wrap the original exception to give the calling application
       access to the test and example information.

       If the output doesn't match, then a DocTestFailure is raised:

         >>> test = DocTestParser().get_doctest('''
         ...      >>> x = 1
         ...      >>> x
         ...      2
         ...      ''', {}, 'foo', 'foo.py', 0)

         >>> try:
         ...    runner.run(test)
         ... except DocTestFailure as f:
         ...    failure = f

       DocTestFailure objects provide access to the test:

         >>> failure.test is test
         True

       As well as to the example:

         >>> failure.example.want
         '2\n'

       and the actual output:

         >>> failure.got
         '1\n'

       If a failure or error occurs, the globals are left intact:

         >>> del test.globs['__builtins__']
         >>> test.globs
         {'x': 1}

         >>> test = DocTestParser().get_doctest('''
         ...      >>> x = 2
         ...      >>> raise KeyError
         ...      ''', {}, 'foo', 'foo.py', 0)

         >>> runner.run(test)
         Traceback (most recent call last):
         ...
         doctest.UnexpectedException: <DocTest foo from foo.py:0 (2 examples)>

         >>> del test.globs['__builtins__']
         >>> test.globs
         {'x': 2}

       But the globals are cleared if there is no error:

         >>> test = DocTestParser().get_doctest('''
         ...      >>> x = 2
         ...      ''', {}, 'foo', 'foo.py', 0)

         >>> runner.run(test)
         TestResults(failed=0, attempted=1)

         >>> test.globs
         {}

       masterreportraise_on_errorm=None, name=None, globs=None, verbose=None, report=True,
       optionflags=0, extraglobs=None, raise_on_error=False,
       exclude_empty=False

    Test examples in docstrings in functions and classes reachable
    from module m (or the current module if m is not supplied), starting
    with m.__doc__.

    Also test examples reachable from dict m.__test__ if it exists and is
    not None.  m.__test__ maps names to functions, classes and strings;
    function and class docstrings are tested even if the name is private;
    strings are tested directly, as if they were docstrings.

    Return (#failures, #tests).

    See help(doctest) for an overview.

    Optional keyword arg "name" gives the name of the module; by default
    use m.__name__.

    Optional keyword arg "globs" gives a dict to be used as the globals
    when executing examples; by default, use m.__dict__.  A copy of this
    dict is actually used for each docstring, so that each docstring's
    examples start with a clean slate.

    Optional keyword arg "extraglobs" gives a dictionary that should be
    merged into the globals that are used to execute examples.  By
    default, no extra globals are used.  This is new in 2.4.

    Optional keyword arg "verbose" prints lots of stuff if true, prints
    only failures if false; by default, it's true iff "-v" is in sys.argv.

    Optional keyword arg "report" prints a summary at the end when true,
    else prints nothing at the end.  In verbose mode, the summary is
    detailed, else very brief (in fact, empty if all tests passed).

    Optional keyword arg "optionflags" or's together module constants,
    and defaults to 0.  This is new in 2.3.  Possible values (see the
    docs for details):

        DONT_ACCEPT_TRUE_FOR_1
        DONT_ACCEPT_BLANKLINE
        NORMALIZE_WHITESPACE
        ELLIPSIS
        SKIP
        IGNORE_EXCEPTION_DETAIL
        REPORT_UDIFF
        REPORT_CDIFF
        REPORT_NDIFF
        REPORT_ONLY_FIRST_FAILURE

    Optional keyword arg "raise_on_error" raises an exception on the
    first unexpected exception or failure. This allows failures to be
    post-mortem debugged.

    Advanced tomfoolery:  testmod runs methods of a local instance of
    class doctest.Tester, then merges the results into (or creates)
    global Tester instance doctest.master.  Methods of doctest.master
    can be called directly too, if you want to do something unusual.
    Passing report=0 to testmod is especially useful then, to delay
    displaying a summary.  Invoke doctest.master.summarize(verbose)
    when you're done fiddling.
    testmod: module required; %r
    Test examples in the given file.  Return (#failures, #tests).

    Optional keyword arg "module_relative" specifies how filenames
    should be interpreted:

      - If "module_relative" is True (the default), then "filename"
         specifies a module-relative path.  By default, this path is
         relative to the calling module's directory; but if the
         "package" argument is specified, then it is relative to that
         package.  To ensure os-independence, "filename" should use
         "/" characters to separate path segments, and should not
         be an absolute path (i.e., it may not begin with "/").

      - If "module_relative" is False, then "filename" specifies an
        os-specific path.  The path may be absolute or relative (to
        the current working directory).

    Optional keyword arg "name" gives the name of the test; by default
    use the file's basename.

    Optional keyword argument "package" is a Python package or the
    name of a Python package whose directory should be used as the
    base directory for a module relative filename.  If no package is
    specified, then the calling module's directory is used as the base
    directory for module relative filenames.  It is an error to
    specify "package" if "module_relative" is False.

    Optional keyword arg "globs" gives a dict to be used as the globals
    when executing examples; by default, use {}.  A copy of this dict
    is actually used for each docstring, so that each docstring's
    examples start with a clean slate.

    Optional keyword arg "extraglobs" gives a dictionary that should be
    merged into the globals that are used to execute examples.  By
    default, no extra globals are used.

    Optional keyword arg "verbose" prints lots of stuff if true, prints
    only failures if false; by default, it's true iff "-v" is in sys.argv.

    Optional keyword arg "report" prints a summary at the end when true,
    else prints nothing at the end.  In verbose mode, the summary is
    detailed, else very brief (in fact, empty if all tests passed).

    Optional keyword arg "optionflags" or's together module constants,
    and defaults to 0.  Possible values (see the docs for details):

        DONT_ACCEPT_TRUE_FOR_1
        DONT_ACCEPT_BLANKLINE
        NORMALIZE_WHITESPACE
        ELLIPSIS
        SKIP
        IGNORE_EXCEPTION_DETAIL
        REPORT_UDIFF
        REPORT_CDIFF
        REPORT_NDIFF
        REPORT_ONLY_FIRST_FAILURE

    Optional keyword arg "raise_on_error" raises an exception on the
    first unexpected exception or failure. This allows failures to be
    post-mortem debugged.

    Optional keyword arg "parser" specifies a DocTestParser (or
    subclass) that should be used to extract tests from the files.

    Optional keyword arg "encoding" specifies an encoding that should
    be used to convert the file to unicode.

    Advanced tomfoolery:  testmod runs methods of a local instance of
    class doctest.Tester, then merges the results into (or creates)
    global Tester instance doctest.master.  Methods of doctest.master
    can be called directly too, if you want to do something unusual.
    Passing report=0 to testmod is especially useful then, to delay
    displaying a summary.  Invoke doctest.master.summarize(verbose)
    when you're done fiddling.
    Package may only be specified for module-relative paths."Package may only be specified for module-""relative paths."
    Test examples in the given object's docstring (`f`), using `globs`
    as globals.  Optional argument `name` is used in failure messages.
    If the optional argument `verbose` is true, then generate output
    even if there are no failures.

    `compileflags` gives the set of flags that should be used by the
    Python compiler when running the examples.  If not specified, then
    it will default to the set of future-import flags that apply to
    `globs`.

    Optional keyword arg `optionflags` specifies options for the
    testing and output.  See the documentation for `testmod` for more
    information.
    _unittest_reportflagsSets the unittest option flags.

    The old flag is returned so that a runner could restore the old
    value if it wished to:

      >>> import doctest
      >>> old = doctest._unittest_reportflags
      >>> doctest.set_unittest_reportflags(REPORT_NDIFF |
      ...                          REPORT_ONLY_FIRST_FAILURE) == old
      True

      >>> doctest._unittest_reportflags == (REPORT_NDIFF |
      ...                                   REPORT_ONLY_FIRST_FAILURE)
      True

    Only reporting flags can be set:

      >>> doctest.set_unittest_reportflags(ELLIPSIS)
      Traceback (most recent call last):
      ...
      ValueError: ('Only reporting flags allowed', 8)

      >>> doctest.set_unittest_reportflags(old) == (REPORT_NDIFF |
      ...                                   REPORT_ONLY_FIRST_FAILURE)
      True
    Only reporting flags allowedDocTestCase_dt_optionflags_dt_checker_dt_test_dt_setUp_dt_tearDown_dt_globsformat_failureunknown line numberlnameFailed doctest test for %s
  File "%s", line %s, in %s

%s'Failed doctest test for %s\n''  File "%s", line %s, in %s\n\n%s'Run the test case without results and without catching exceptions

           The unit test framework includes a debug method on test cases
           and test suites to support post-mortem debugging.  The test code
           is run in such a way that errors are not caught.  This way a
           caller can catch the errors and initiate post-mortem debugging.

           The DocTestCase provides a debug method that raises
           UnexpectedException errors if there is an unexpected
           exception:

             >>> test = DocTestParser().get_doctest('>>> raise KeyError\n42',
             ...                {}, 'foo', 'foo.py', 0)
             >>> case = DocTestCase(test)
             >>> try:
             ...     case.debug()
             ... except UnexpectedException as f:
             ...     failure = f

           The UnexpectedException contains the test, the example, and
           the original exception:

             >>> failure.test is test
             True

             >>> failure.example.want
             '42\n'

             >>> exc_info = failure.exc_info
             >>> raise exc_info[1] # Already has the traceback
             Traceback (most recent call last):
             ...
             KeyError

           If the output doesn't match, then a DocTestFailure is raised:

             >>> test = DocTestParser().get_doctest('''
             ...      >>> x = 1
             ...      >>> x
             ...      2
             ...      ''', {}, 'foo', 'foo.py', 0)
             >>> case = DocTestCase(test)

             >>> try:
             ...    case.debug()
             ... except DocTestFailure as f:
             ...    failure = f

           DocTestFailure objects provide access to the test:

             >>> failure.test is test
             True

           As well as to the example:

             >>> failure.example.want
             '2\n'

           and the actual output:

             >>> failure.got
             '1\n'

           Doctest: SkipDocTestCaseDocTestSuite will not work with -O2 and abovetest_skipSkipping tests from %s_DocTestSuite_removeTestAtIndextest_finder
    Convert doctest tests for a module to a unittest test suite.

    This converts each documentation string in a module that
    contains doctest tests to a unittest test case.  If any of the
    tests in a doc string fail, then the test case fails.  An exception
    is raised showing the name of the file containing the test and a
    (sometimes approximate) line number.

    The `module` argument provides the module to be tested.  The argument
    can be either a module or a module name.

    If no argument is given, the calling module is used.

    A number of options may be provided as keyword arguments:

    setUp
      A set-up function.  This is called before running the
      tests in each file. The setUp function will be passed a DocTest
      object.  The setUp function can access the test globals as the
      globs attribute of the test passed.

    tearDown
      A tear-down function.  This is called after running the
      tests in each file.  The tearDown function will be passed a DocTest
      object.  The tearDown function can access the test globals as the
      globs attribute of the test passed.

    globs
      A dictionary containing initial global variables for the tests.

    optionflags
       A set of doctest option flags expressed as an integer.
    addTestDocFileCaseFailed doctest test for %s
  File "%s", line 0

%sDocFileTestA unittest suite for one or more doctest files.

    The path to each doctest file is given as a string; the
    interpretation of that string depends on the keyword argument
    "module_relative".

    A number of options may be provided as keyword arguments:

    module_relative
      If "module_relative" is True, then the given file paths are
      interpreted as os-independent module-relative paths.  By
      default, these paths are relative to the calling module's
      directory; but if the "package" argument is specified, then
      they are relative to that package.  To ensure os-independence,
      "filename" should use "/" characters to separate path
      segments, and may not be an absolute path (i.e., it may not
      begin with "/").

      If "module_relative" is False, then the given file paths are
      interpreted as os-specific paths.  These paths may be absolute
      or relative (to the current working directory).

    package
      A Python package or the name of a Python package whose directory
      should be used as the base directory for module relative paths.
      If "package" is not specified, then the calling module's
      directory is used as the base directory for module relative
      filenames.  It is an error to specify "package" if
      "module_relative" is False.

    setUp
      A set-up function.  This is called before running the
      tests in each file. The setUp function will be passed a DocTest
      object.  The setUp function can access the test globals as the
      globs attribute of the test passed.

    tearDown
      A tear-down function.  This is called after running the
      tests in each file.  The tearDown function will be passed a DocTest
      object.  The tearDown function can access the test globals as the
      globs attribute of the test passed.

    globs
      A dictionary containing initial global variables for the tests.

    optionflags
      A set of doctest option flags expressed as an integer.

    parser
      A DocTestParser (or subclass) that should be used to extract
      tests from the files.

    encoding
      An encoding that will be used to convert the files to unicode.
    Extract script from text with examples.

       Converts text with examples to a Python script.  Example input is
       converted to regular code.  Example output and all other words
       are converted to comments:

       >>> text = '''
       ...       Here are examples of simple math.
       ...
       ...           Python has super accurate integer addition
       ...
       ...           >>> 2 + 2
       ...           5
       ...
       ...           And very friendly error messages:
       ...
       ...           >>> 1/0
       ...           To Infinity
       ...           And
       ...           Beyond
       ...
       ...           You can use logic if you want:
       ...
       ...           >>> if 0:
       ...           ...    blah
       ...           ...    blah
       ...           ...
       ...
       ...           Ho hum
       ...           '''

       >>> print(script_from_examples(text))
       # Here are examples of simple math.
       #
       #     Python has super accurate integer addition
       #
       2 + 2
       # Expected:
       ## 5
       #
       #     And very friendly error messages:
       #
       1/0
       # Expected:
       ## To Infinity
       ## And
       ## Beyond
       #
       #     You can use logic if you want:
       #
       if 0:
          blah
          blah
       #
       #     Ho hum
       <BLANKLINE>
       piece# Expected:## Extract the test sources from a doctest docstring as a script.

    Provide the module (or dotted name of the module) containing the
    test to be debugged and the name (within the module) of the object
    with the doc string with tests to be debugged.
    not found in teststestsrcpmDebug a single doctest docstring, in argument `src`'debug_scriptDebug a test script.  `src` is the script, as a string.interactionexec(%r)Debug a single doctest docstring.

    Provide the module (or dotted name of the module) containing the
    test to be debugged and the name (within the module) of the object
    with the docstring with tests to be debugged.
    _TestClass
    A pointless class, for sanity-checking of docstring testing.

    Methods:
        square()
        get()

    >>> _TestClass(13).get() + _TestClass(-12).get()
    1
    >>> hex(_TestClass(13).square().get())
    '0xa9'
    val -> _TestClass object with associated value val.

        >>> t = _TestClass(123)
        >>> print(t.get())
        123
        squaresquare() -> square TestClass's associated value

        >>> _TestClass(13).square().get()
        169
        get() -> return TestClass's associated value.

        >>> x = _TestClass(-42)
        >>> print(x.get())
        -42
        
                      Example of a string object, searched as-is.
                      >>> x = 1; y = 2
                      >>> x + y, x * y
                      (3, 2)
                      
                                    In 2.2, boolean expressions displayed
                                    0 or 1.  By default, we still accept
                                    them.  This can be disabled by passing
                                    DONT_ACCEPT_TRUE_FOR_1 to the new
                                    optionflags argument.
                                    >>> 4 == 4
                                    1
                                    >>> 4 == 4
                                    True
                                    >>> 4 > 4
                                    0
                                    >>> 4 > 4
                                    False
                                    bool-int equivalence
                Blank lines can be marked with <BLANKLINE>:
                    >>> print('foo\n\nbar\n')
                    foo
                    <BLANKLINE>
                    bar
                    <BLANKLINE>
            blank lines
                If the ellipsis flag is used, then '...' can be used to
                elide substrings in the desired output:
                    >>> print(list(range(1000))) #doctest: +ELLIPSIS
                    [0, 1, 2, ..., 999]
            
                If the whitespace normalization flag is used, then
                differences in whitespace are ignored.
                    >>> print(list(range(30))) #doctest: +NORMALIZE_WHITESPACE
                    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,
                     15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,
                     27, 28, 29]
            whitespace normalizationdoctest runner--verboseprint very verbose output for all tests-o--optionspecify a doctest option flag to apply to the test run; may be specified more than once to apply multiple options'specify a doctest option flag to apply'' to the test run; may be specified more'' than once to apply multiple options'-f--fail-faststop running tests after first failure (this is a shorthand for -o FAIL_FAST, and is in addition to any other -o options)'stop running tests after first failure (this'' is a shorthand for -o FAIL_FAST, and is'' in addition to any other -o options)'file containing the tests to runtestfilesfail_fast# Module doctest.# Released to the public domain 16-Jan-2001, by Tim Peters (tim@python.org).# Major enhancements and refactoring by:#     Jim Fulton#     Edward Loper# Provided as-is; use at your own risk; no warranty; no promises; enjoy!# 0, Option Flags# 1. Utility Functions# 2. Example & DocTest# 3. Doctest Parser# 4. Doctest Finder# 5. Doctest Runner# 6. Test Functions# 7. Unittest Support# 8. Debugging Support# There are 4 basic classes:#  - Example: a <source, want> pair, plus an intra-docstring line number.#  - DocTest: a collection of examples, parsed from a docstring, plus#    info about where the docstring came from (name, filename, lineno).#  - DocTestFinder: extracts DocTests from a given object's docstring and#    its contained objects' docstrings.#  - DocTestRunner: runs DocTest cases, and accumulates statistics.# So the basic picture is:#                             list of:# +------+                   +---------+                   +-------+# |object| --DocTestFinder-> | DocTest | --DocTestRunner-> |results|#                            | Example |#                            |   ...   |#                            +---------+# Option constants.# Create a new flag unless `name` is already known.# Special string markers for use in `want` strings:######################################################################## Table of Contents#  1. Utility Functions#  2. Example & DocTest -- store test cases#  3. DocTest Parser -- extracts examples from strings#  4. DocTest Finder -- extracts test cases from objects#  5. DocTest Runner -- runs test cases#  6. Test Functions -- convenient wrappers for testing#  7. Unittest Support#  8. Debugging Support#  9. Example Usage## 1. Utility Functions# The IO module provides a handy decoder for universal newline conversion# get_data() opens files as 'rb', so one must do the equivalent# conversion as universal newlines would do.# This regexp matches the start of non-blank lines:# Get a traceback message.# Override some StringIO methods.# If anything at all was written, make sure there's a trailing# newline.  There's no way for the expected output to indicate# that a trailing newline is missing.# Worst-case linear-time ellipsis matching.# Find "the real" strings.# Deal with exact matches possibly needed at one or both ends.# starts with exact match# ends with exact match# Exact end matches required more characters than we have, as in# _ellipsis_match('aa...aa', 'aaa')# For the rest, we only need to find the leftmost non-overlapping# match for each piece.  If there's no overall match that way alone,# there's no overall match period.# w may be '' at times, if there are consecutive ellipses, or# due to an ellipsis at the start or end of `want`.  That's OK.# Search for an empty string succeeds, and doesn't change startpos.# Support for IGNORE_EXCEPTION_DETAIL.# Get rid of everything except the exception name; in particular, drop# the possibly dotted module path (if any) and the exception message (if# any).  We assume that a colon is never part of a dotted name, or of an# exception name.# E.g., given#    "foo.bar.MyError: la di da"# return "MyError"# Or for "abc.def" or "abc.def:\n" return "def".# The exception name must appear on the first line.# retain up to the first colon (if any)# retain just the exception name# do not play signal games in the pdb# still use input() to get user input# Calling set_continue unconditionally would break unit test# coverage reporting, as Bdb.set_continue calls sys.settrace(None).# Redirect stdout to the given stream.# Call Pdb's trace dispatch method.# [XX] Normalize with respect to os.path.pardir?# Normalize the path. On Windows, replace "/" with "\".# Find the base directory for the path.# A normal module/package# An interactive session.# A module w/o __file__ (this includes builtins)# Combine the base directory and the test path.## 2. Example & DocTest## - An "example" is a <source, want> pair, where "source" is a##   fragment of source code, and "want" is the expected output for##   "source."  The Example class also includes information about##   where the example was extracted from.## - A "doctest" is a collection of examples, typically extracted from##   a string (such as an object's docstring).  The DocTest class also##   includes information about where the string was extracted from.# Normalize inputs.# Store properties.# This lets us sort tests by name:## 3. DocTestParser# This regular expression is used to find doctest examples in a# string.  It defines three groups: `source` is the source code# (including leading indentation and prompts); `indent` is the# indentation of the first (PS1) line of the source code; and# `want` is the expected output (including leading indentation).# A regular expression for handling `want` strings that contain# expected exceptions.  It divides `want` into three pieces:#    - the traceback header line (`hdr`)#    - the traceback stack (`stack`)#    - the exception message (`msg`), as generated by#      traceback.format_exception_only()# `msg` may have multiple lines.  We assume/require that the# exception message is the first non-indented line starting with a word# character following the traceback header line.# A callable returning a true value iff its argument is a blank line# or contains a single comment.# If all lines begin with the same indentation, then strip it.# Find all doctest examples in the string:# Add the pre-example text to `output`.# Update lineno (lines before this example)# Extract info from the regexp match.# Create an Example, and add it to the list.# Update lineno (lines inside this example)# Update charno.# Add any remaining post-example text to `output`.# Get the example's indentation level.# Divide source into lines; check that they're properly# indented; and then strip their indentation & prompts.# Divide want into lines; check that it's properly indented; and# then strip the indentation.  Spaces before the last newline should# be preserved, so plain rstrip() isn't good enough.# forget final newline & spaces after it# If `want` contains a traceback message, then extract it.# Extract options from the source.# This regular expression looks for option directives in the# source code of an example.  Option directives are comments# starting with "doctest:".  Warning: this may give false# positives for string-literals that contain the string# "#doctest:".  Eliminating these false positives would require# actually parsing the string; but we limit them by ignoring any# line containing "#doctest:" that is *followed* by a quote mark.# (note: with the current regexp, this will match at most once:)# This regular expression finds the indentation of every non-blank# line in a string.## 4. DocTest Finder# If name was not specified, then extract it from the object.# Find the module that contains the given object (if obj is# a module, then module=obj.).  Note: this may fail, in which# case module will be None.# Read the module's source code.  This is used by# DocTestFinder._find_lineno to find the line number for a# given object's docstring.# Check to see if it's one of our special internal "files"# (see __patched_linecache_getlines).# Supply the module globals in case the module was# originally loaded via a PEP 302 loader and# file is not a valid filesystem path# No access to a loader, so assume it's a normal# filesystem path# Initialize globals, and merge in extraglobs.# provide a default module name# Recursively explore `obj`, extracting DocTests.# Sort the tests by alpha order of names, for consistency in# verbose-mode output.  This was a feature of doctest in Pythons# <= 2.3 that got lost by accident in 2.4.  It was repaired in# 2.4.4 and 2.5.# [XX] no easy way to tell otherwise# [XX] no way not be sure.# If we've already processed this object, then ignore it.# Find a test for this object, and add it to the list of tests.# Look for tests in a module's contained objects.# Recurse to functions & classes.# Look for tests in a module's __test__ dictionary.# Look for tests in a class's contained objects.# Special handling for staticmethod/classmethod.# Recurse to methods, properties, and nested classes.# Extract the object's docstring.  If it doesn't have one,# then return None (no test for this object).# Find the docstring's location in the file.# Don't bother if the docstring is empty.# Return a DocTest for this object.# __file__ can be None for namespace packages.# Find the line number for modules.# Find the line number for classes.# Note: this could be fooled if a class is defined multiple# times in a single file.# Find the line number for functions & methods.# We don't use `docstring` var here, because `obj` can be changed.# Functions implemented in C don't necessarily# have a __code__ attribute.# If there's no code, there's no lineno# Find the line number where the docstring starts.  Assume# that it's the first line that begins with a quote mark.# Note: this could be fooled by a multiline function# signature, where a continuation line begins with a quote# mark.# We couldn't find the line number.## 5. DocTest Runner# This divider string is used to separate failure messages, and to# separate sections of the summary.# Keep track of the examples we've run.# Create a fake output target for capturing doctest output.#/////////////////////////////////////////////////////////////////# Reporting methods# DocTest Running# Keep track of the number of failures and tries.# Save the option flags (since option directives can be used# to modify them).# `outcome` state# Process each example.# If REPORT_ONLY_FIRST_FAILURE is set, then suppress# reporting after the first failure.# Merge in the example's options.# If 'SKIP' is set, then skip this example.# Record that we started this example.# Use a special filename for compile(), so we can retrieve# the source code during interactive debugging (see# __patched_linecache_getlines).# Run the example in the given context (globs), and record# any exception that gets raised.  (But don't intercept# keyboard interrupts.)# Don't blink!  This is where the user's code gets run.# ==== Example Finished ====# the actual output# guilty until proved innocent or insane# If the example executed without raising any exceptions,# verify its output.# The example raised an exception:  check if it was expected.# SyntaxError / IndentationError is special:# we don't care about the carets / suggestions / etc# We only care about the error message and notes.# They start with `SyntaxError:` (or any other class name)# If `example.exc_msg` is None, then we weren't expecting# an exception.# We expected an exception:  see whether it matches.# Another chance if they didn't care about the detail.# Report the outcome.# Restore the option flags (in case they were modified)# Record and return the number of failures and tries.# Use backslashreplace error handling on write# Patch pdb.set_trace to restore sys.stdout during interactive# debugging (so it's not still redirected to self._fakeout).# Note that the interactive output will go to *our*# save_stdout, even if that's not the real sys.stdout; this# allows us to write test cases for the set_trace behavior.# Patch linecache.getlines, so we can see the example's source# when we're inside the debugger.# Make sure sys.displayhook just prints the value to stdout# Summarization# Backward compatibility cruft to maintain doctest.master.# Don't print here by default, since doing#     so breaks some of the buildbots#print("*** DocTestRunner.merge: '" + name + "' in both" \#    " testers; summing outcomes.")# If `want` contains hex-escaped character such as "\u1234",# then `want` is a string of six characters(e.g. [\,u,1,2,3,4]).# On the other hand, `got` could be another sequence of# characters such as [\u1234], so `want` and `got` should# be folded to hex-escaped ASCII string to compare.# Handle the common case first, for efficiency:# if they're string-identical, always return true.# The values True and False replaced 1 and 0 as the return# value for boolean comparisons in Python 2.3.# <BLANKLINE> can be used as a special sequence to signify a# blank line, unless the DONT_ACCEPT_BLANKLINE flag is used.# Replace <BLANKLINE> in want with a blank line.# If a line in got contains only spaces, then remove the# spaces.# This flag causes doctest to ignore any differences in the# contents of whitespace strings.  Note that this can be used# in conjunction with the ELLIPSIS flag.# The ELLIPSIS flag says to let the sequence "..." in `want`# match any substring in `got`.# We didn't find any match; return false.# Should we do a fancy diff?# Not unless they asked for a fancy diff.# If expected output uses ellipsis, a meaningful fancy diff is# too hard ... or maybe not.  In two real-life failures Tim saw,# a diff was a major help anyway, so this is commented out.# [todo] _ellipsis_match() knows which pieces do and don't match,# and could be the basis for a kick-ass diff in this case.##if optionflags & ELLIPSIS and ELLIPSIS_MARKER in want:##    return False# ndiff does intraline difference marking, so can be useful even# for 1-line differences.# The other diff types need at least a few lines to be helpful.# If <BLANKLINE>s are being used, then replace blank lines# with <BLANKLINE> in the actual output string.# Check if we should use diff.# Split want & got into lines.# Use difflib to find their differences.# strip the diff header# If we're not using diff, then simply list the expected# output followed by the actual output.## 6. Test Functions# These should be backwards compatible.# For backward compatibility, a global instance of a DocTestRunner# class, updated by testmod.# If no module was given, then use __main__.# DWA - m will still be None if this wasn't invoked from the command# line, in which case the following TypeError is about as good an error# as we should expect# Check that we were actually given a module.# If no name was given, then use the module's name.# Find, parse, and run all tests in the given module.# Relativize the path# If no name was given, then use the file's name.# Assemble the globals.# Read the file, convert it to a test, and run it.## 7. Unittest Support# restore the original globs# The option flags don't include any reporting flags,# so add the default reporting flags# Skip doctests when running with -O2# Relativize the path.# Find the file and read it.# Convert it to a test, and wrap it in a DocFileCase.# We do this here so that _normalize_module is called at the right# level.  If it were called in DocFileTest, then this function# would be the caller and we might guess the package incorrectly.## 8. Debugging Support# Add the example's source code (strip trailing NL)# Add the expected output:# Add non-example text.# Trim junk on both ends.# Combine the output, and return it.# Add a courtesy newline to prevent exec from choking (see bug #1172785)## 9. Example Usage# Verbose used to be handled by the "inspect argv" magic in DocTestRunner,# but since we are using argparse we are passing it manually now.# It is a module -- insert its dir into sys.path and try to# import it. If it is part of a package, that possibly# won't work because of package imports.b'Module doctest -- a framework for running examples in docstrings.

In simplest use, end each module M to be tested with:

def _test():
    import doctest
    doctest.testmod()

if __name__ == "__main__":
    _test()

Then running the module as a script will cause the examples in the
docstrings to get executed and verified:

python M.py

This won't display anything unless an example fails, in which case the
failing example(s) and the cause(s) of the failure(s) are printed to stdout
(why not stderr? because stderr is a lame hack <0.2 wink>), and the final
line of output is "Test failed.".

Run it with the -v switch instead:

python M.py -v

and a detailed report of all examples tried is printed to stdout, along
with assorted summaries at the end.

You can force verbose mode by passing "verbose=True" to testmod, or prohibit
it by passing "verbose=False".  In either of those cases, sys.argv is not
examined by testmod.

There are a variety of other ways to run doctests, including integration
with the unittest framework, and support for running non-Python text
files containing doctests.  There are also many ways to override parts
of doctest's default behaviors.  See the Library Reference Manual for
details.
'u'Module doctest -- a framework for running examples in docstrings.

In simplest use, end each module M to be tested with:

def _test():
    import doctest
    doctest.testmod()

if __name__ == "__main__":
    _test()

Then running the module as a script will cause the examples in the
docstrings to get executed and verified:

python M.py

This won't display anything unless an example fails, in which case the
failing example(s) and the cause(s) of the failure(s) are printed to stdout
(why not stderr? because stderr is a lame hack <0.2 wink>), and the final
line of output is "Test failed.".

Run it with the -v switch instead:

python M.py -v

and a detailed report of all examples tried is printed to stdout, along
with assorted summaries at the end.

You can force verbose mode by passing "verbose=True" to testmod, or prohibit
it by passing "verbose=False".  In either of those cases, sys.argv is not
examined by testmod.

There are a variety of other ways to run doctests, including integration
with the unittest framework, and support for running non-Python text
files containing doctests.  There are also many ways to override parts
of doctest's default behaviors.  See the Library Reference Manual for
details.
'b'reStructuredText en'u'reStructuredText en'b'register_optionflag'u'register_optionflag'b'DONT_ACCEPT_TRUE_FOR_1'u'DONT_ACCEPT_TRUE_FOR_1'b'DONT_ACCEPT_BLANKLINE'u'DONT_ACCEPT_BLANKLINE'b'NORMALIZE_WHITESPACE'u'NORMALIZE_WHITESPACE'b'ELLIPSIS'u'ELLIPSIS'b'SKIP'u'SKIP'b'IGNORE_EXCEPTION_DETAIL'u'IGNORE_EXCEPTION_DETAIL'b'COMPARISON_FLAGS'u'COMPARISON_FLAGS'b'REPORT_UDIFF'u'REPORT_UDIFF'b'REPORT_CDIFF'u'REPORT_CDIFF'b'REPORT_NDIFF'u'REPORT_NDIFF'b'REPORT_ONLY_FIRST_FAILURE'u'REPORT_ONLY_FIRST_FAILURE'b'REPORTING_FLAGS'u'REPORTING_FLAGS'b'FAIL_FAST'u'FAIL_FAST'b'Example'u'Example'b'DocTest'u'DocTest'b'DocTestParser'u'DocTestParser'b'DocTestFinder'u'DocTestFinder'b'DocTestRunner'u'DocTestRunner'b'OutputChecker'u'OutputChecker'b'DocTestFailure'u'DocTestFailure'b'UnexpectedException'u'UnexpectedException'b'DebugRunner'u'DebugRunner'b'testmod'u'testmod'b'testfile'u'testfile'b'run_docstring_examples'u'run_docstring_examples'b'DocTestSuite'u'DocTestSuite'b'DocFileSuite'u'DocFileSuite'b'set_unittest_reportflags'u'set_unittest_reportflags'b'script_from_examples'u'script_from_examples'b'testsource'u'testsource'b'debug_src'u'debug_src'b'TestResults'u'TestResults'b'failed attempted'u'failed attempted'b'<BLANKLINE>'u'<BLANKLINE>'b'
    Return the compiler-flags associated with the future features that
    have been imported into the given namespace (globs).
    'u'
    Return the compiler-flags associated with the future features that
    have been imported into the given namespace (globs).
    'b'
    Return the module specified by `module`.  In particular:
      - If `module` is a module, then return module.
      - If `module` is a string, then import and return the
        module with that name.
      - If `module` is None, then return the calling module.
        The calling module is assumed to be the module of
        the stack frame at the given depth in the call stack.
    'u'
    Return the module specified by `module`.  In particular:
      - If `module` is a module, then return module.
      - If `module` is a string, then import and return the
        module with that name.
      - If `module` is None, then return the calling module.
        The calling module is assumed to be the module of
        the stack frame at the given depth in the call stack.
    'b'Expected a module, string, or None'u'Expected a module, string, or None'b'get_data'u'get_data'b'
    Add the given number of space characters to the beginning of
    every non-blank line in `s`, and return the result.
    'u'
    Add the given number of space characters to the beginning of
    every non-blank line in `s`, and return the result.
    'b'(?m)^(?!$)'u'(?m)^(?!$)'b'
    Return a string containing a traceback message for the given
    exc_info tuple (as returned by sys.exc_info()).
    'u'
    Return a string containing a traceback message for the given
    exc_info tuple (as returned by sys.exc_info()).
    'b'
    Essentially the only subtle case:
    >>> _ellipsis_match('aa...aa', 'aaa')
    False
    'u'
    Essentially the only subtle case:
    >>> _ellipsis_match('aa...aa', 'aaa')
    False
    'b'Return a commented form of the given line'u'Return a commented form of the given line'b'
    A specialized version of the python debugger that redirects stdout
    to a given stream when interacting with the user.  Stdout is *not*
    redirected when traced code is executed.
    'u'
    A specialized version of the python debugger that redirects stdout
    to a given stream when interacting with the user.  Stdout is *not*
    redirected when traced code is executed.
    'b'Expected a module: %r'u'Expected a module: %r'b'Module-relative files may not have absolute paths'u'Module-relative files may not have absolute paths'b'Can't resolve paths relative to the module %r (it has no __file__)'u'Can't resolve paths relative to the module %r (it has no __file__)'b'
    A single doctest example, consisting of source code and expected
    output.  `Example` defines the following attributes:

      - source: A single Python statement, always ending with a newline.
        The constructor adds a newline if needed.

      - want: The expected output from running the source code (either
        from stdout, or a traceback in case of exception).  `want` ends
        with a newline unless it's empty, in which case it's an empty
        string.  The constructor adds a newline if needed.

      - exc_msg: The exception message generated by the example, if
        the example is expected to generate an exception; or `None` if
        it is not expected to generate an exception.  This exception
        message is compared against the return value of
        `traceback.format_exception_only()`.  `exc_msg` ends with a
        newline unless it's `None`.  The constructor adds a newline
        if needed.

      - lineno: The line number within the DocTest string containing
        this Example where the Example begins.  This line number is
        zero-based, with respect to the beginning of the DocTest.

      - indent: The example's indentation in the DocTest string.
        I.e., the number of space characters that precede the
        example's first prompt.

      - options: A dictionary mapping from option flags to True or
        False, which is used to override default options for this
        example.  Any option flags not contained in this dictionary
        are left at their default value (as specified by the
        DocTestRunner's optionflags).  By default, no options are set.
    'u'
    A single doctest example, consisting of source code and expected
    output.  `Example` defines the following attributes:

      - source: A single Python statement, always ending with a newline.
        The constructor adds a newline if needed.

      - want: The expected output from running the source code (either
        from stdout, or a traceback in case of exception).  `want` ends
        with a newline unless it's empty, in which case it's an empty
        string.  The constructor adds a newline if needed.

      - exc_msg: The exception message generated by the example, if
        the example is expected to generate an exception; or `None` if
        it is not expected to generate an exception.  This exception
        message is compared against the return value of
        `traceback.format_exception_only()`.  `exc_msg` ends with a
        newline unless it's `None`.  The constructor adds a newline
        if needed.

      - lineno: The line number within the DocTest string containing
        this Example where the Example begins.  This line number is
        zero-based, with respect to the beginning of the DocTest.

      - indent: The example's indentation in the DocTest string.
        I.e., the number of space characters that precede the
        example's first prompt.

      - options: A dictionary mapping from option flags to True or
        False, which is used to override default options for this
        example.  Any option flags not contained in this dictionary
        are left at their default value (as specified by the
        DocTestRunner's optionflags).  By default, no options are set.
    'b'
    A collection of doctest examples that should be run in a single
    namespace.  Each `DocTest` defines the following attributes:

      - examples: the list of examples.

      - globs: The namespace (aka globals) that the examples should
        be run in.

      - name: A name identifying the DocTest (typically, the name of
        the object whose docstring this DocTest was extracted from).

      - filename: The name of the file that this DocTest was extracted
        from, or `None` if the filename is unknown.

      - lineno: The line number within filename where this DocTest
        begins, or `None` if the line number is unavailable.  This
        line number is zero-based, with respect to the beginning of
        the file.

      - docstring: The string that the examples were extracted from,
        or `None` if the string is unavailable.
    'u'
    A collection of doctest examples that should be run in a single
    namespace.  Each `DocTest` defines the following attributes:

      - examples: the list of examples.

      - globs: The namespace (aka globals) that the examples should
        be run in.

      - name: A name identifying the DocTest (typically, the name of
        the object whose docstring this DocTest was extracted from).

      - filename: The name of the file that this DocTest was extracted
        from, or `None` if the filename is unknown.

      - lineno: The line number within filename where this DocTest
        begins, or `None` if the line number is unavailable.  This
        line number is zero-based, with respect to the beginning of
        the file.

      - docstring: The string that the examples were extracted from,
        or `None` if the string is unavailable.
    'b'
        Create a new DocTest containing the given examples.  The
        DocTest's globals are initialized with a copy of `globs`.
        'u'
        Create a new DocTest containing the given examples.  The
        DocTest's globals are initialized with a copy of `globs`.
        'b'DocTest no longer accepts str; use DocTestParser instead'u'DocTest no longer accepts str; use DocTestParser instead'b'no examples'u'no examples'b'1 example'u'1 example'b'%d examples'u'%d examples'b'<%s %s from %s:%s (%s)>'u'<%s %s from %s:%s (%s)>'b'
    A class used to parse strings containing doctest examples.
    'u'
    A class used to parse strings containing doctest examples.
    'b'
        # Source consists of a PS1 line followed by zero or more PS2 lines.
        (?P<source>
            (?:^(?P<indent> [ ]*) >>>    .*)    # PS1 line
            (?:\n           [ ]*  \.\.\. .*)*)  # PS2 lines
        \n?
        # Want consists of any non-blank lines that do not start with PS1.
        (?P<want> (?:(?![ ]*$)    # Not a blank line
                     (?![ ]*>>>)  # Not a line starting with PS1
                     .+$\n?       # But any other line
                  )*)
        'u'
        # Source consists of a PS1 line followed by zero or more PS2 lines.
        (?P<source>
            (?:^(?P<indent> [ ]*) >>>    .*)    # PS1 line
            (?:\n           [ ]*  \.\.\. .*)*)  # PS2 lines
        \n?
        # Want consists of any non-blank lines that do not start with PS1.
        (?P<want> (?:(?![ ]*$)    # Not a blank line
                     (?![ ]*>>>)  # Not a line starting with PS1
                     .+$\n?       # But any other line
                  )*)
        'b'
        # Grab the traceback header.  Different versions of Python have
        # said different things on the first traceback line.
        ^(?P<hdr> Traceback\ \(
            (?: most\ recent\ call\ last
            |   innermost\ last
            ) \) :
        )
        \s* $                # toss trailing whitespace on the header.
        (?P<stack> .*?)      # don't blink: absorb stuff until...
        ^ (?P<msg> \w+ .*)   #     a line *starts* with alphanum.
        'u'
        # Grab the traceback header.  Different versions of Python have
        # said different things on the first traceback line.
        ^(?P<hdr> Traceback\ \(
            (?: most\ recent\ call\ last
            |   innermost\ last
            ) \) :
        )
        \s* $                # toss trailing whitespace on the header.
        (?P<stack> .*?)      # don't blink: absorb stuff until...
        ^ (?P<msg> \w+ .*)   #     a line *starts* with alphanum.
        'b'^[ ]*(#.*)?$'u'^[ ]*(#.*)?$'b'
        Divide the given string into examples and intervening text,
        and return them as a list of alternating Examples and strings.
        Line numbers for the Examples are 0-based.  The optional
        argument `name` is a name identifying this string, and is only
        used for error messages.
        'u'
        Divide the given string into examples and intervening text,
        and return them as a list of alternating Examples and strings.
        Line numbers for the Examples are 0-based.  The optional
        argument `name` is a name identifying this string, and is only
        used for error messages.
        'b'indent'u'indent'b'
        Extract all doctest examples from the given string, and
        collect them into a `DocTest` object.

        `globs`, `name`, `filename`, and `lineno` are attributes for
        the new `DocTest` object.  See the documentation for `DocTest`
        for more information.
        'u'
        Extract all doctest examples from the given string, and
        collect them into a `DocTest` object.

        `globs`, `name`, `filename`, and `lineno` are attributes for
        the new `DocTest` object.  See the documentation for `DocTest`
        for more information.
        'b'
        Extract all doctest examples from the given string, and return
        them as a list of `Example` objects.  Line numbers are
        0-based, because it's most common in doctests that nothing
        interesting appears on the same line as opening triple-quote,
        and so the first interesting line is called "line 1" then.

        The optional argument `name` is a name identifying this
        string, and is only used for error messages.
        'u'
        Extract all doctest examples from the given string, and return
        them as a list of `Example` objects.  Line numbers are
        0-based, because it's most common in doctests that nothing
        interesting appears on the same line as opening triple-quote,
        and so the first interesting line is called "line 1" then.

        The optional argument `name` is a name identifying this
        string, and is only used for error messages.
        'b'
        Given a regular expression match from `_EXAMPLE_RE` (`m`),
        return a pair `(source, want)`, where `source` is the matched
        example's source code (with prompts and indentation stripped);
        and `want` is the example's expected output (with indentation
        stripped).

        `name` is the string's name, and `lineno` is the line number
        where the example starts; both are used for error messages.
        'u'
        Given a regular expression match from `_EXAMPLE_RE` (`m`),
        return a pair `(source, want)`, where `source` is the matched
        example's source code (with prompts and indentation stripped);
        and `want` is the example's expected output (with indentation
        stripped).

        `name` is the string's name, and `lineno` is the line number
        where the example starts; both are used for error messages.
        'b'source'u'source'b'want'u'want'b' *$'u' *$'b'#\s*doctest:\s*([^\n\'"]*)$'u'#\s*doctest:\s*([^\n\'"]*)$'b'
        Return a dictionary containing option overrides extracted from
        option directives in the given source string.

        `name` is the string's name, and `lineno` is the line number
        where the example starts; both are used for error messages.
        'u'
        Return a dictionary containing option overrides extracted from
        option directives in the given source string.

        `name` is the string's name, and `lineno` is the line number
        where the example starts; both are used for error messages.
        'b'line %r of the doctest for %s has an invalid option: %r'u'line %r of the doctest for %s has an invalid option: %r'b'line %r of the doctest for %s has an option directive on a line with no example: %r'u'line %r of the doctest for %s has an option directive on a line with no example: %r'b'^([ ]*)(?=\S)'u'^([ ]*)(?=\S)'b'Return the minimum indentation of any non-blank line in `s`'u'Return the minimum indentation of any non-blank line in `s`'b'
        Given the lines of a source string (including prompts and
        leading indentation), check to make sure that every prompt is
        followed by a space character.  If any line is not followed by
        a space character, then raise ValueError.
        'u'
        Given the lines of a source string (including prompts and
        leading indentation), check to make sure that every prompt is
        followed by a space character.  If any line is not followed by
        a space character, then raise ValueError.
        'b'line %r of the docstring for %s lacks blank after %s: %r'u'line %r of the docstring for %s lacks blank after %s: %r'b'
        Check that every line in the given list starts with the given
        prefix; if any line does not, then raise a ValueError.
        'u'
        Check that every line in the given list starts with the given
        prefix; if any line does not, then raise a ValueError.
        'b'line %r of the docstring for %s has inconsistent leading whitespace: %r'u'line %r of the docstring for %s has inconsistent leading whitespace: %r'b'
    A class used to extract the DocTests that are relevant to a given
    object, from its docstring and the docstrings of its contained
    objects.  Doctests can currently be extracted from the following
    object types: modules, functions, classes, methods, staticmethods,
    classmethods, and properties.
    'u'
    A class used to extract the DocTests that are relevant to a given
    object, from its docstring and the docstrings of its contained
    objects.  Doctests can currently be extracted from the following
    object types: modules, functions, classes, methods, staticmethods,
    classmethods, and properties.
    'b'
        Create a new doctest finder.

        The optional argument `parser` specifies a class or
        function that should be used to create new DocTest objects (or
        objects that implement the same interface as DocTest).  The
        signature for this factory function should match the signature
        of the DocTest constructor.

        If the optional argument `recurse` is false, then `find` will
        only examine the given object, and not any contained objects.

        If the optional argument `exclude_empty` is false, then `find`
        will include tests for objects with empty docstrings.
        'u'
        Create a new doctest finder.

        The optional argument `parser` specifies a class or
        function that should be used to create new DocTest objects (or
        objects that implement the same interface as DocTest).  The
        signature for this factory function should match the signature
        of the DocTest constructor.

        If the optional argument `recurse` is false, then `find` will
        only examine the given object, and not any contained objects.

        If the optional argument `exclude_empty` is false, then `find`
        will include tests for objects with empty docstrings.
        'b'
        Return a list of the DocTests that are defined by the given
        object's docstring, or by any of its contained objects'
        docstrings.

        The optional parameter `module` is the module that contains
        the given object.  If the module is not specified or is None, then
        the test finder will attempt to automatically determine the
        correct module.  The object's module is used:

            - As a default namespace, if `globs` is not specified.
            - To prevent the DocTestFinder from extracting DocTests
              from objects that are imported from other modules.
            - To find the name of the file containing the object.
            - To help find the line number of the object within its
              file.

        Contained objects whose module does not match `module` are ignored.

        If `module` is False, no attempt to find the module will be made.
        This is obscure, of use mostly in tests:  if `module` is False, or
        is None but cannot be found automatically, then all objects are
        considered to belong to the (non-existent) module, so all contained
        objects will (recursively) be searched for doctests.

        The globals for each DocTest is formed by combining `globs`
        and `extraglobs` (bindings in `extraglobs` override bindings
        in `globs`).  A new copy of the globals dictionary is created
        for each DocTest.  If `globs` is not specified, then it
        defaults to the module's `__dict__`, if specified, or {}
        otherwise.  If `extraglobs` is not specified, then it defaults
        to {}.

        'u'
        Return a list of the DocTests that are defined by the given
        object's docstring, or by any of its contained objects'
        docstrings.

        The optional parameter `module` is the module that contains
        the given object.  If the module is not specified or is None, then
        the test finder will attempt to automatically determine the
        correct module.  The object's module is used:

            - As a default namespace, if `globs` is not specified.
            - To prevent the DocTestFinder from extracting DocTests
              from objects that are imported from other modules.
            - To find the name of the file containing the object.
            - To help find the line number of the object within its
              file.

        Contained objects whose module does not match `module` are ignored.

        If `module` is False, no attempt to find the module will be made.
        This is obscure, of use mostly in tests:  if `module` is False, or
        is None but cannot be found automatically, then all objects are
        considered to belong to the (non-existent) module, so all contained
        objects will (recursively) be searched for doctests.

        The globals for each DocTest is formed by combining `globs`
        and `extraglobs` (bindings in `extraglobs` override bindings
        in `globs`).  A new copy of the globals dictionary is created
        for each DocTest.  If `globs` is not specified, then it
        defaults to the module's `__dict__`, if specified, or {}
        otherwise.  If `extraglobs` is not specified, then it defaults
        to {}.

        'b'DocTestFinder.find: name must be given when obj.__name__ doesn't exist: %r'u'DocTestFinder.find: name must be given when obj.__name__ doesn't exist: %r'b'<]>'u'<]>'b'
        Return true if the given object is defined in the given
        module.
        'u'
        Return true if the given object is defined in the given
        module.
        'b'__objclass__'u'__objclass__'b'object must be a class or function'u'object must be a class or function'b'
        Safely unwrap objects and determine if they are functions.
        'u'
        Safely unwrap objects and determine if they are functions.
        'b'
        Find tests for the given object and any contained objects, and
        add them to `tests`.
        'u'
        Find tests for the given object and any contained objects, and
        add them to `tests`.
        'b'Finding tests in %s'u'Finding tests in %s'b'__test__'u'__test__'b'DocTestFinder.find: __test__ keys must be strings: %r'u'DocTestFinder.find: __test__ keys must be strings: %r'b'DocTestFinder.find: __test__ values must be strings, functions, methods, classes, or modules: %r'u'DocTestFinder.find: __test__ values must be strings, functions, methods, classes, or modules: %r'b'%s.__test__.%s'u'%s.__test__.%s'b'
        Return a DocTest for the given object, if it defines a docstring;
        otherwise, return None.
        'u'
        Return a DocTest for the given object, if it defines a docstring;
        otherwise, return None.
        'b'
        Return a line number of the given object's docstring.

        Returns `None` if the given object does not have a docstring.
        'u'
        Return a line number of the given object's docstring.

        Returns `None` if the given object does not have a docstring.
        'b'^\s*class\s*%s\b'u'^\s*class\s*%s\b'b'(^|.*:)\s*\w*("|\')'u'(^|.*:)\s*\w*("|\')'b'
    A class used to run DocTest test cases, and accumulate statistics.
    The `run` method is used to process a single DocTest case.  It
    returns a tuple `(f, t)`, where `t` is the number of test cases
    tried, and `f` is the number of test cases that failed.

        >>> tests = DocTestFinder().find(_TestClass)
        >>> runner = DocTestRunner(verbose=False)
        >>> tests.sort(key = lambda test: test.name)
        >>> for test in tests:
        ...     print(test.name, '->', runner.run(test))
        _TestClass -> TestResults(failed=0, attempted=2)
        _TestClass.__init__ -> TestResults(failed=0, attempted=2)
        _TestClass.get -> TestResults(failed=0, attempted=2)
        _TestClass.square -> TestResults(failed=0, attempted=1)

    The `summarize` method prints a summary of all the test cases that
    have been run by the runner, and returns an aggregated `(f, t)`
    tuple:

        >>> runner.summarize(verbose=1)
        4 items passed all tests:
           2 tests in _TestClass
           2 tests in _TestClass.__init__
           2 tests in _TestClass.get
           1 tests in _TestClass.square
        7 tests in 4 items.
        7 passed and 0 failed.
        Test passed.
        TestResults(failed=0, attempted=7)

    The aggregated number of tried examples and failed examples is
    also available via the `tries` and `failures` attributes:

        >>> runner.tries
        7
        >>> runner.failures
        0

    The comparison between expected outputs and actual outputs is done
    by an `OutputChecker`.  This comparison may be customized with a
    number of option flags; see the documentation for `testmod` for
    more information.  If the option flags are insufficient, then the
    comparison may also be customized by passing a subclass of
    `OutputChecker` to the constructor.

    The test runner's display output can be controlled in two ways.
    First, an output function (`out) can be passed to
    `TestRunner.run`; this function will be called with strings that
    should be displayed.  It defaults to `sys.stdout.write`.  If
    capturing the output is not sufficient, then the display output
    can be also customized by subclassing DocTestRunner, and
    overriding the methods `report_start`, `report_success`,
    `report_unexpected_exception`, and `report_failure`.
    'u'
    A class used to run DocTest test cases, and accumulate statistics.
    The `run` method is used to process a single DocTest case.  It
    returns a tuple `(f, t)`, where `t` is the number of test cases
    tried, and `f` is the number of test cases that failed.

        >>> tests = DocTestFinder().find(_TestClass)
        >>> runner = DocTestRunner(verbose=False)
        >>> tests.sort(key = lambda test: test.name)
        >>> for test in tests:
        ...     print(test.name, '->', runner.run(test))
        _TestClass -> TestResults(failed=0, attempted=2)
        _TestClass.__init__ -> TestResults(failed=0, attempted=2)
        _TestClass.get -> TestResults(failed=0, attempted=2)
        _TestClass.square -> TestResults(failed=0, attempted=1)

    The `summarize` method prints a summary of all the test cases that
    have been run by the runner, and returns an aggregated `(f, t)`
    tuple:

        >>> runner.summarize(verbose=1)
        4 items passed all tests:
           2 tests in _TestClass
           2 tests in _TestClass.__init__
           2 tests in _TestClass.get
           1 tests in _TestClass.square
        7 tests in 4 items.
        7 passed and 0 failed.
        Test passed.
        TestResults(failed=0, attempted=7)

    The aggregated number of tried examples and failed examples is
    also available via the `tries` and `failures` attributes:

        >>> runner.tries
        7
        >>> runner.failures
        0

    The comparison between expected outputs and actual outputs is done
    by an `OutputChecker`.  This comparison may be customized with a
    number of option flags; see the documentation for `testmod` for
    more information.  If the option flags are insufficient, then the
    comparison may also be customized by passing a subclass of
    `OutputChecker` to the constructor.

    The test runner's display output can be controlled in two ways.
    First, an output function (`out) can be passed to
    `TestRunner.run`; this function will be called with strings that
    should be displayed.  It defaults to `sys.stdout.write`.  If
    capturing the output is not sufficient, then the display output
    can be also customized by subclassing DocTestRunner, and
    overriding the methods `report_start`, `report_success`,
    `report_unexpected_exception`, and `report_failure`.
    'b'
        Create a new test runner.

        Optional keyword arg `checker` is the `OutputChecker` that
        should be used to compare the expected outputs and actual
        outputs of doctest examples.

        Optional keyword arg 'verbose' prints lots of stuff if true,
        only failures if false; by default, it's true iff '-v' is in
        sys.argv.

        Optional argument `optionflags` can be used to control how the
        test runner compares expected output to actual output, and how
        it displays failures.  See the documentation for `testmod` for
        more information.
        'u'
        Create a new test runner.

        Optional keyword arg `checker` is the `OutputChecker` that
        should be used to compare the expected outputs and actual
        outputs of doctest examples.

        Optional keyword arg 'verbose' prints lots of stuff if true,
        only failures if false; by default, it's true iff '-v' is in
        sys.argv.

        Optional argument `optionflags` can be used to control how the
        test runner compares expected output to actual output, and how
        it displays failures.  See the documentation for `testmod` for
        more information.
        'b'-v'u'-v'b'
        Report that the test runner is about to process the given
        example.  (Only displays a message if verbose=True)
        'u'
        Report that the test runner is about to process the given
        example.  (Only displays a message if verbose=True)
        'b'Trying:
'u'Trying:
'b'Expecting:
'u'Expecting:
'b'Expecting nothing
'u'Expecting nothing
'b'
        Report that the given example ran successfully.  (Only
        displays a message if verbose=True)
        'u'
        Report that the given example ran successfully.  (Only
        displays a message if verbose=True)
        'b'ok
'u'ok
'b'
        Report that the given example failed.
        'u'
        Report that the given example failed.
        'b'
        Report that the given example raised an unexpected exception.
        'u'
        Report that the given example raised an unexpected exception.
        'b'Exception raised:
'u'Exception raised:
'b'File "%s", line %s, in %s'u'File "%s", line %s, in %s'b'Line %s, in %s'u'Line %s, in %s'b'Failed example:'u'Failed example:'b'
        Run the examples in `test`.  Write the outcome of each example
        with one of the `DocTestRunner.report_*` methods, using the
        writer function `out`.  `compileflags` is the set of compiler
        flags that should be used to execute examples.  Return a tuple
        `(f, t)`, where `t` is the number of examples tried, and `f`
        is the number of examples that failed.  The examples are run
        in the namespace `test.globs`.
        'u'
        Run the examples in `test`.  Write the outcome of each example
        with one of the `DocTestRunner.report_*` methods, using the
        writer function `out`.  `compileflags` is the set of compiler
        flags that should be used to execute examples.  Return a tuple
        `(f, t)`, where `t` is the number of examples tried, and `f`
        is the number of examples that failed.  The examples are run
        in the namespace `test.globs`.
        'b'<doctest %s[%d]>'u'<doctest %s[%d]>'b'unknown outcome'u'unknown outcome'b'
        Record the fact that the given DocTest (`test`) generated `f`
        failures out of `t` tried examples.
        'u'
        Record the fact that the given DocTest (`test`) generated `f`
        failures out of `t` tried examples.
        'b'<doctest (?P<name>.+)\[(?P<examplenum>\d+)\]>$'u'<doctest (?P<name>.+)\[(?P<examplenum>\d+)\]>$'b'examplenum'u'examplenum'b'
        Run the examples in `test`, and display the results using the
        writer function `out`.

        The examples are run in the namespace `test.globs`.  If
        `clear_globs` is true (the default), then this namespace will
        be cleared after the test runs, to help with garbage
        collection.  If you would like to examine the namespace after
        the test completes, then use `clear_globs=False`.

        `compileflags` gives the set of flags that should be used by
        the Python compiler when running the examples.  If not
        specified, then it will default to the set of future-import
        flags that apply to `globs`.

        The output of each example is checked using
        `DocTestRunner.check_output`, and the results are formatted by
        the `DocTestRunner.report_*` methods.
        'u'
        Run the examples in `test`, and display the results using the
        writer function `out`.

        The examples are run in the namespace `test.globs`.  If
        `clear_globs` is true (the default), then this namespace will
        be cleared after the test runs, to help with garbage
        collection.  If you would like to examine the namespace after
        the test completes, then use `clear_globs=False`.

        `compileflags` gives the set of flags that should be used by
        the Python compiler when running the examples.  If not
        specified, then it will default to the set of future-import
        flags that apply to `globs`.

        The output of each example is checked using
        `DocTestRunner.check_output`, and the results are formatted by
        the `DocTestRunner.report_*` methods.
        'b'
        Print a summary of all the test cases that have been run by
        this DocTestRunner, and return a tuple `(f, t)`, where `f` is
        the total number of failed examples, and `t` is the total
        number of tried examples.

        The optional `verbose` argument controls how detailed the
        summary is.  If the verbosity is not specified, then the
        DocTestRunner's verbosity is used.
        'u'
        Print a summary of all the test cases that have been run by
        this DocTestRunner, and return a tuple `(f, t)`, where `f` is
        the total number of failed examples, and `t` is the total
        number of tried examples.

        The optional `verbose` argument controls how detailed the
        summary is.  If the verbosity is not specified, then the
        DocTestRunner's verbosity is used.
        'b'items had no tests:'u'items had no tests:'b'items passed all tests:'u'items passed all tests:'b' %3d tests in %s'u' %3d tests in %s'b'items had failures:'u'items had failures:'b' %3d of %3d in %s'u' %3d of %3d in %s'b'tests in'u'tests in'b'items.'u'items.'b'passed and'u'passed and'b'failed.'u'failed.'b'***Test Failed***'u'***Test Failed***'b'failures.'u'failures.'b'Test passed.'u'Test passed.'b'
    A class used to check the whether the actual output from a doctest
    example matches the expected output.  `OutputChecker` defines two
    methods: `check_output`, which compares a given pair of outputs,
    and returns true if they match; and `output_difference`, which
    returns a string describing the differences between two outputs.
    'u'
    A class used to check the whether the actual output from a doctest
    example matches the expected output.  `OutputChecker` defines two
    methods: `check_output`, which compares a given pair of outputs,
    and returns true if they match; and `output_difference`, which
    returns a string describing the differences between two outputs.
    'b'
        Convert string to hex-escaped ASCII string.
        'u'
        Convert string to hex-escaped ASCII string.
        'b'
        Return True iff the actual output from an example (`got`)
        matches the expected output (`want`).  These strings are
        always considered to match if they are identical; but
        depending on what option flags the test runner is using,
        several non-exact match types are also possible.  See the
        documentation for `TestRunner` for more information about
        option flags.
        'u'
        Return True iff the actual output from an example (`got`)
        matches the expected output (`want`).  These strings are
        always considered to match if they are identical; but
        depending on what option flags the test runner is using,
        several non-exact match types are also possible.  See the
        documentation for `TestRunner` for more information about
        option flags.
        'b'True
'u'True
'b'1
'u'1
'b'False
'u'False
'b'0
'u'0
'b'(?m)^%s\s*?$'u'(?m)^%s\s*?$'b'(?m)^[^\S\n]+$'u'(?m)^[^\S\n]+$'b'
        Return a string describing the differences between the
        expected output for a given example (`example`) and the actual
        output (`got`).  `optionflags` is the set of option flags used
        to compare `want` and `got`.
        'u'
        Return a string describing the differences between the
        expected output for a given example (`example`) and the actual
        output (`got`).  `optionflags` is the set of option flags used
        to compare `want` and `got`.
        'b'(?m)^[ ]*(?=
)'u'(?m)^[ ]*(?=
)'b'unified diff with -expected +actual'u'unified diff with -expected +actual'b'context diff with expected followed by actual'u'context diff with expected followed by actual'b'ndiff with -expected +actual'u'ndiff with -expected +actual'b'Bad diff option'u'Bad diff option'b'Differences (%s):
'u'Differences (%s):
'b'Expected:
%sGot:
%s'u'Expected:
%sGot:
%s'b'Expected:
%sGot nothing
'u'Expected:
%sGot nothing
'b'Expected nothing
Got:
%s'u'Expected nothing
Got:
%s'b'Expected nothing
Got nothing
'u'Expected nothing
Got nothing
'b'A DocTest example has failed in debugging mode.

    The exception instance has variables:

    - test: the DocTest object being run

    - example: the Example object that failed

    - got: the actual output
    'u'A DocTest example has failed in debugging mode.

    The exception instance has variables:

    - test: the DocTest object being run

    - example: the Example object that failed

    - got: the actual output
    'b'A DocTest example has encountered an unexpected exception

    The exception instance has variables:

    - test: the DocTest object being run

    - example: the Example object that failed

    - exc_info: the exception info
    'u'A DocTest example has encountered an unexpected exception

    The exception instance has variables:

    - test: the DocTest object being run

    - example: the Example object that failed

    - exc_info: the exception info
    'b'Run doc tests but raise an exception as soon as there is a failure.

       If an unexpected exception occurs, an UnexpectedException is raised.
       It contains the test, the example, and the original exception:

         >>> runner = DebugRunner(verbose=False)
         >>> test = DocTestParser().get_doctest('>>> raise KeyError\n42',
         ...                                    {}, 'foo', 'foo.py', 0)
         >>> try:
         ...     runner.run(test)
         ... except UnexpectedException as f:
         ...     failure = f

         >>> failure.test is test
         True

         >>> failure.example.want
         '42\n'

         >>> exc_info = failure.exc_info
         >>> raise exc_info[1] # Already has the traceback
         Traceback (most recent call last):
         ...
         KeyError

       We wrap the original exception to give the calling application
       access to the test and example information.

       If the output doesn't match, then a DocTestFailure is raised:

         >>> test = DocTestParser().get_doctest('''
         ...      >>> x = 1
         ...      >>> x
         ...      2
         ...      ''', {}, 'foo', 'foo.py', 0)

         >>> try:
         ...    runner.run(test)
         ... except DocTestFailure as f:
         ...    failure = f

       DocTestFailure objects provide access to the test:

         >>> failure.test is test
         True

       As well as to the example:

         >>> failure.example.want
         '2\n'

       and the actual output:

         >>> failure.got
         '1\n'

       If a failure or error occurs, the globals are left intact:

         >>> del test.globs['__builtins__']
         >>> test.globs
         {'x': 1}

         >>> test = DocTestParser().get_doctest('''
         ...      >>> x = 2
         ...      >>> raise KeyError
         ...      ''', {}, 'foo', 'foo.py', 0)

         >>> runner.run(test)
         Traceback (most recent call last):
         ...
         doctest.UnexpectedException: <DocTest foo from foo.py:0 (2 examples)>

         >>> del test.globs['__builtins__']
         >>> test.globs
         {'x': 2}

       But the globals are cleared if there is no error:

         >>> test = DocTestParser().get_doctest('''
         ...      >>> x = 2
         ...      ''', {}, 'foo', 'foo.py', 0)

         >>> runner.run(test)
         TestResults(failed=0, attempted=1)

         >>> test.globs
         {}

       'u'Run doc tests but raise an exception as soon as there is a failure.

       If an unexpected exception occurs, an UnexpectedException is raised.
       It contains the test, the example, and the original exception:

         >>> runner = DebugRunner(verbose=False)
         >>> test = DocTestParser().get_doctest('>>> raise KeyError\n42',
         ...                                    {}, 'foo', 'foo.py', 0)
         >>> try:
         ...     runner.run(test)
         ... except UnexpectedException as f:
         ...     failure = f

         >>> failure.test is test
         True

         >>> failure.example.want
         '42\n'

         >>> exc_info = failure.exc_info
         >>> raise exc_info[1] # Already has the traceback
         Traceback (most recent call last):
         ...
         KeyError

       We wrap the original exception to give the calling application
       access to the test and example information.

       If the output doesn't match, then a DocTestFailure is raised:

         >>> test = DocTestParser().get_doctest('''
         ...      >>> x = 1
         ...      >>> x
         ...      2
         ...      ''', {}, 'foo', 'foo.py', 0)

         >>> try:
         ...    runner.run(test)
         ... except DocTestFailure as f:
         ...    failure = f

       DocTestFailure objects provide access to the test:

         >>> failure.test is test
         True

       As well as to the example:

         >>> failure.example.want
         '2\n'

       and the actual output:

         >>> failure.got
         '1\n'

       If a failure or error occurs, the globals are left intact:

         >>> del test.globs['__builtins__']
         >>> test.globs
         {'x': 1}

         >>> test = DocTestParser().get_doctest('''
         ...      >>> x = 2
         ...      >>> raise KeyError
         ...      ''', {}, 'foo', 'foo.py', 0)

         >>> runner.run(test)
         Traceback (most recent call last):
         ...
         doctest.UnexpectedException: <DocTest foo from foo.py:0 (2 examples)>

         >>> del test.globs['__builtins__']
         >>> test.globs
         {'x': 2}

       But the globals are cleared if there is no error:

         >>> test = DocTestParser().get_doctest('''
         ...      >>> x = 2
         ...      ''', {}, 'foo', 'foo.py', 0)

         >>> runner.run(test)
         TestResults(failed=0, attempted=1)

         >>> test.globs
         {}

       'b'm=None, name=None, globs=None, verbose=None, report=True,
       optionflags=0, extraglobs=None, raise_on_error=False,
       exclude_empty=False

    Test examples in docstrings in functions and classes reachable
    from module m (or the current module if m is not supplied), starting
    with m.__doc__.

    Also test examples reachable from dict m.__test__ if it exists and is
    not None.  m.__test__ maps names to functions, classes and strings;
    function and class docstrings are tested even if the name is private;
    strings are tested directly, as if they were docstrings.

    Return (#failures, #tests).

    See help(doctest) for an overview.

    Optional keyword arg "name" gives the name of the module; by default
    use m.__name__.

    Optional keyword arg "globs" gives a dict to be used as the globals
    when executing examples; by default, use m.__dict__.  A copy of this
    dict is actually used for each docstring, so that each docstring's
    examples start with a clean slate.

    Optional keyword arg "extraglobs" gives a dictionary that should be
    merged into the globals that are used to execute examples.  By
    default, no extra globals are used.  This is new in 2.4.

    Optional keyword arg "verbose" prints lots of stuff if true, prints
    only failures if false; by default, it's true iff "-v" is in sys.argv.

    Optional keyword arg "report" prints a summary at the end when true,
    else prints nothing at the end.  In verbose mode, the summary is
    detailed, else very brief (in fact, empty if all tests passed).

    Optional keyword arg "optionflags" or's together module constants,
    and defaults to 0.  This is new in 2.3.  Possible values (see the
    docs for details):

        DONT_ACCEPT_TRUE_FOR_1
        DONT_ACCEPT_BLANKLINE
        NORMALIZE_WHITESPACE
        ELLIPSIS
        SKIP
        IGNORE_EXCEPTION_DETAIL
        REPORT_UDIFF
        REPORT_CDIFF
        REPORT_NDIFF
        REPORT_ONLY_FIRST_FAILURE

    Optional keyword arg "raise_on_error" raises an exception on the
    first unexpected exception or failure. This allows failures to be
    post-mortem debugged.

    Advanced tomfoolery:  testmod runs methods of a local instance of
    class doctest.Tester, then merges the results into (or creates)
    global Tester instance doctest.master.  Methods of doctest.master
    can be called directly too, if you want to do something unusual.
    Passing report=0 to testmod is especially useful then, to delay
    displaying a summary.  Invoke doctest.master.summarize(verbose)
    when you're done fiddling.
    'u'm=None, name=None, globs=None, verbose=None, report=True,
       optionflags=0, extraglobs=None, raise_on_error=False,
       exclude_empty=False

    Test examples in docstrings in functions and classes reachable
    from module m (or the current module if m is not supplied), starting
    with m.__doc__.

    Also test examples reachable from dict m.__test__ if it exists and is
    not None.  m.__test__ maps names to functions, classes and strings;
    function and class docstrings are tested even if the name is private;
    strings are tested directly, as if they were docstrings.

    Return (#failures, #tests).

    See help(doctest) for an overview.

    Optional keyword arg "name" gives the name of the module; by default
    use m.__name__.

    Optional keyword arg "globs" gives a dict to be used as the globals
    when executing examples; by default, use m.__dict__.  A copy of this
    dict is actually used for each docstring, so that each docstring's
    examples start with a clean slate.

    Optional keyword arg "extraglobs" gives a dictionary that should be
    merged into the globals that are used to execute examples.  By
    default, no extra globals are used.  This is new in 2.4.

    Optional keyword arg "verbose" prints lots of stuff if true, prints
    only failures if false; by default, it's true iff "-v" is in sys.argv.

    Optional keyword arg "report" prints a summary at the end when true,
    else prints nothing at the end.  In verbose mode, the summary is
    detailed, else very brief (in fact, empty if all tests passed).

    Optional keyword arg "optionflags" or's together module constants,
    and defaults to 0.  This is new in 2.3.  Possible values (see the
    docs for details):

        DONT_ACCEPT_TRUE_FOR_1
        DONT_ACCEPT_BLANKLINE
        NORMALIZE_WHITESPACE
        ELLIPSIS
        SKIP
        IGNORE_EXCEPTION_DETAIL
        REPORT_UDIFF
        REPORT_CDIFF
        REPORT_NDIFF
        REPORT_ONLY_FIRST_FAILURE

    Optional keyword arg "raise_on_error" raises an exception on the
    first unexpected exception or failure. This allows failures to be
    post-mortem debugged.

    Advanced tomfoolery:  testmod runs methods of a local instance of
    class doctest.Tester, then merges the results into (or creates)
    global Tester instance doctest.master.  Methods of doctest.master
    can be called directly too, if you want to do something unusual.
    Passing report=0 to testmod is especially useful then, to delay
    displaying a summary.  Invoke doctest.master.summarize(verbose)
    when you're done fiddling.
    'b'testmod: module required; %r'u'testmod: module required; %r'b'
    Test examples in the given file.  Return (#failures, #tests).

    Optional keyword arg "module_relative" specifies how filenames
    should be interpreted:

      - If "module_relative" is True (the default), then "filename"
         specifies a module-relative path.  By default, this path is
         relative to the calling module's directory; but if the
         "package" argument is specified, then it is relative to that
         package.  To ensure os-independence, "filename" should use
         "/" characters to separate path segments, and should not
         be an absolute path (i.e., it may not begin with "/").

      - If "module_relative" is False, then "filename" specifies an
        os-specific path.  The path may be absolute or relative (to
        the current working directory).

    Optional keyword arg "name" gives the name of the test; by default
    use the file's basename.

    Optional keyword argument "package" is a Python package or the
    name of a Python package whose directory should be used as the
    base directory for a module relative filename.  If no package is
    specified, then the calling module's directory is used as the base
    directory for module relative filenames.  It is an error to
    specify "package" if "module_relative" is False.

    Optional keyword arg "globs" gives a dict to be used as the globals
    when executing examples; by default, use {}.  A copy of this dict
    is actually used for each docstring, so that each docstring's
    examples start with a clean slate.

    Optional keyword arg "extraglobs" gives a dictionary that should be
    merged into the globals that are used to execute examples.  By
    default, no extra globals are used.

    Optional keyword arg "verbose" prints lots of stuff if true, prints
    only failures if false; by default, it's true iff "-v" is in sys.argv.

    Optional keyword arg "report" prints a summary at the end when true,
    else prints nothing at the end.  In verbose mode, the summary is
    detailed, else very brief (in fact, empty if all tests passed).

    Optional keyword arg "optionflags" or's together module constants,
    and defaults to 0.  Possible values (see the docs for details):

        DONT_ACCEPT_TRUE_FOR_1
        DONT_ACCEPT_BLANKLINE
        NORMALIZE_WHITESPACE
        ELLIPSIS
        SKIP
        IGNORE_EXCEPTION_DETAIL
        REPORT_UDIFF
        REPORT_CDIFF
        REPORT_NDIFF
        REPORT_ONLY_FIRST_FAILURE

    Optional keyword arg "raise_on_error" raises an exception on the
    first unexpected exception or failure. This allows failures to be
    post-mortem debugged.

    Optional keyword arg "parser" specifies a DocTestParser (or
    subclass) that should be used to extract tests from the files.

    Optional keyword arg "encoding" specifies an encoding that should
    be used to convert the file to unicode.

    Advanced tomfoolery:  testmod runs methods of a local instance of
    class doctest.Tester, then merges the results into (or creates)
    global Tester instance doctest.master.  Methods of doctest.master
    can be called directly too, if you want to do something unusual.
    Passing report=0 to testmod is especially useful then, to delay
    displaying a summary.  Invoke doctest.master.summarize(verbose)
    when you're done fiddling.
    'u'
    Test examples in the given file.  Return (#failures, #tests).

    Optional keyword arg "module_relative" specifies how filenames
    should be interpreted:

      - If "module_relative" is True (the default), then "filename"
         specifies a module-relative path.  By default, this path is
         relative to the calling module's directory; but if the
         "package" argument is specified, then it is relative to that
         package.  To ensure os-independence, "filename" should use
         "/" characters to separate path segments, and should not
         be an absolute path (i.e., it may not begin with "/").

      - If "module_relative" is False, then "filename" specifies an
        os-specific path.  The path may be absolute or relative (to
        the current working directory).

    Optional keyword arg "name" gives the name of the test; by default
    use the file's basename.

    Optional keyword argument "package" is a Python package or the
    name of a Python package whose directory should be used as the
    base directory for a module relative filename.  If no package is
    specified, then the calling module's directory is used as the base
    directory for module relative filenames.  It is an error to
    specify "package" if "module_relative" is False.

    Optional keyword arg "globs" gives a dict to be used as the globals
    when executing examples; by default, use {}.  A copy of this dict
    is actually used for each docstring, so that each docstring's
    examples start with a clean slate.

    Optional keyword arg "extraglobs" gives a dictionary that should be
    merged into the globals that are used to execute examples.  By
    default, no extra globals are used.

    Optional keyword arg "verbose" prints lots of stuff if true, prints
    only failures if false; by default, it's true iff "-v" is in sys.argv.

    Optional keyword arg "report" prints a summary at the end when true,
    else prints nothing at the end.  In verbose mode, the summary is
    detailed, else very brief (in fact, empty if all tests passed).

    Optional keyword arg "optionflags" or's together module constants,
    and defaults to 0.  Possible values (see the docs for details):

        DONT_ACCEPT_TRUE_FOR_1
        DONT_ACCEPT_BLANKLINE
        NORMALIZE_WHITESPACE
        ELLIPSIS
        SKIP
        IGNORE_EXCEPTION_DETAIL
        REPORT_UDIFF
        REPORT_CDIFF
        REPORT_NDIFF
        REPORT_ONLY_FIRST_FAILURE

    Optional keyword arg "raise_on_error" raises an exception on the
    first unexpected exception or failure. This allows failures to be
    post-mortem debugged.

    Optional keyword arg "parser" specifies a DocTestParser (or
    subclass) that should be used to extract tests from the files.

    Optional keyword arg "encoding" specifies an encoding that should
    be used to convert the file to unicode.

    Advanced tomfoolery:  testmod runs methods of a local instance of
    class doctest.Tester, then merges the results into (or creates)
    global Tester instance doctest.master.  Methods of doctest.master
    can be called directly too, if you want to do something unusual.
    Passing report=0 to testmod is especially useful then, to delay
    displaying a summary.  Invoke doctest.master.summarize(verbose)
    when you're done fiddling.
    'b'Package may only be specified for module-relative paths.'u'Package may only be specified for module-relative paths.'b'
    Test examples in the given object's docstring (`f`), using `globs`
    as globals.  Optional argument `name` is used in failure messages.
    If the optional argument `verbose` is true, then generate output
    even if there are no failures.

    `compileflags` gives the set of flags that should be used by the
    Python compiler when running the examples.  If not specified, then
    it will default to the set of future-import flags that apply to
    `globs`.

    Optional keyword arg `optionflags` specifies options for the
    testing and output.  See the documentation for `testmod` for more
    information.
    'u'
    Test examples in the given object's docstring (`f`), using `globs`
    as globals.  Optional argument `name` is used in failure messages.
    If the optional argument `verbose` is true, then generate output
    even if there are no failures.

    `compileflags` gives the set of flags that should be used by the
    Python compiler when running the examples.  If not specified, then
    it will default to the set of future-import flags that apply to
    `globs`.

    Optional keyword arg `optionflags` specifies options for the
    testing and output.  See the documentation for `testmod` for more
    information.
    'b'Sets the unittest option flags.

    The old flag is returned so that a runner could restore the old
    value if it wished to:

      >>> import doctest
      >>> old = doctest._unittest_reportflags
      >>> doctest.set_unittest_reportflags(REPORT_NDIFF |
      ...                          REPORT_ONLY_FIRST_FAILURE) == old
      True

      >>> doctest._unittest_reportflags == (REPORT_NDIFF |
      ...                                   REPORT_ONLY_FIRST_FAILURE)
      True

    Only reporting flags can be set:

      >>> doctest.set_unittest_reportflags(ELLIPSIS)
      Traceback (most recent call last):
      ...
      ValueError: ('Only reporting flags allowed', 8)

      >>> doctest.set_unittest_reportflags(old) == (REPORT_NDIFF |
      ...                                   REPORT_ONLY_FIRST_FAILURE)
      True
    'u'Sets the unittest option flags.

    The old flag is returned so that a runner could restore the old
    value if it wished to:

      >>> import doctest
      >>> old = doctest._unittest_reportflags
      >>> doctest.set_unittest_reportflags(REPORT_NDIFF |
      ...                          REPORT_ONLY_FIRST_FAILURE) == old
      True

      >>> doctest._unittest_reportflags == (REPORT_NDIFF |
      ...                                   REPORT_ONLY_FIRST_FAILURE)
      True

    Only reporting flags can be set:

      >>> doctest.set_unittest_reportflags(ELLIPSIS)
      Traceback (most recent call last):
      ...
      ValueError: ('Only reporting flags allowed', 8)

      >>> doctest.set_unittest_reportflags(old) == (REPORT_NDIFF |
      ...                                   REPORT_ONLY_FIRST_FAILURE)
      True
    'b'Only reporting flags allowed'u'Only reporting flags allowed'b'unknown line number'u'unknown line number'b'Failed doctest test for %s
  File "%s", line %s, in %s

%s'u'Failed doctest test for %s
  File "%s", line %s, in %s

%s'b'Run the test case without results and without catching exceptions

           The unit test framework includes a debug method on test cases
           and test suites to support post-mortem debugging.  The test code
           is run in such a way that errors are not caught.  This way a
           caller can catch the errors and initiate post-mortem debugging.

           The DocTestCase provides a debug method that raises
           UnexpectedException errors if there is an unexpected
           exception:

             >>> test = DocTestParser().get_doctest('>>> raise KeyError\n42',
             ...                {}, 'foo', 'foo.py', 0)
             >>> case = DocTestCase(test)
             >>> try:
             ...     case.debug()
             ... except UnexpectedException as f:
             ...     failure = f

           The UnexpectedException contains the test, the example, and
           the original exception:

             >>> failure.test is test
             True

             >>> failure.example.want
             '42\n'

             >>> exc_info = failure.exc_info
             >>> raise exc_info[1] # Already has the traceback
             Traceback (most recent call last):
             ...
             KeyError

           If the output doesn't match, then a DocTestFailure is raised:

             >>> test = DocTestParser().get_doctest('''
             ...      >>> x = 1
             ...      >>> x
             ...      2
             ...      ''', {}, 'foo', 'foo.py', 0)
             >>> case = DocTestCase(test)

             >>> try:
             ...    case.debug()
             ... except DocTestFailure as f:
             ...    failure = f

           DocTestFailure objects provide access to the test:

             >>> failure.test is test
             True

           As well as to the example:

             >>> failure.example.want
             '2\n'

           and the actual output:

             >>> failure.got
             '1\n'

           'u'Run the test case without results and without catching exceptions

           The unit test framework includes a debug method on test cases
           and test suites to support post-mortem debugging.  The test code
           is run in such a way that errors are not caught.  This way a
           caller can catch the errors and initiate post-mortem debugging.

           The DocTestCase provides a debug method that raises
           UnexpectedException errors if there is an unexpected
           exception:

             >>> test = DocTestParser().get_doctest('>>> raise KeyError\n42',
             ...                {}, 'foo', 'foo.py', 0)
             >>> case = DocTestCase(test)
             >>> try:
             ...     case.debug()
             ... except UnexpectedException as f:
             ...     failure = f

           The UnexpectedException contains the test, the example, and
           the original exception:

             >>> failure.test is test
             True

             >>> failure.example.want
             '42\n'

             >>> exc_info = failure.exc_info
             >>> raise exc_info[1] # Already has the traceback
             Traceback (most recent call last):
             ...
             KeyError

           If the output doesn't match, then a DocTestFailure is raised:

             >>> test = DocTestParser().get_doctest('''
             ...      >>> x = 1
             ...      >>> x
             ...      2
             ...      ''', {}, 'foo', 'foo.py', 0)
             >>> case = DocTestCase(test)

             >>> try:
             ...    case.debug()
             ... except DocTestFailure as f:
             ...    failure = f

           DocTestFailure objects provide access to the test:

             >>> failure.test is test
             True

           As well as to the example:

             >>> failure.example.want
             '2\n'

           and the actual output:

             >>> failure.got
             '1\n'

           'b'Doctest: 'u'Doctest: 'b'DocTestSuite will not work with -O2 and above'u'DocTestSuite will not work with -O2 and above'b'Skipping tests from %s'u'Skipping tests from %s'b'
    Convert doctest tests for a module to a unittest test suite.

    This converts each documentation string in a module that
    contains doctest tests to a unittest test case.  If any of the
    tests in a doc string fail, then the test case fails.  An exception
    is raised showing the name of the file containing the test and a
    (sometimes approximate) line number.

    The `module` argument provides the module to be tested.  The argument
    can be either a module or a module name.

    If no argument is given, the calling module is used.

    A number of options may be provided as keyword arguments:

    setUp
      A set-up function.  This is called before running the
      tests in each file. The setUp function will be passed a DocTest
      object.  The setUp function can access the test globals as the
      globs attribute of the test passed.

    tearDown
      A tear-down function.  This is called after running the
      tests in each file.  The tearDown function will be passed a DocTest
      object.  The tearDown function can access the test globals as the
      globs attribute of the test passed.

    globs
      A dictionary containing initial global variables for the tests.

    optionflags
       A set of doctest option flags expressed as an integer.
    'u'
    Convert doctest tests for a module to a unittest test suite.

    This converts each documentation string in a module that
    contains doctest tests to a unittest test case.  If any of the
    tests in a doc string fail, then the test case fails.  An exception
    is raised showing the name of the file containing the test and a
    (sometimes approximate) line number.

    The `module` argument provides the module to be tested.  The argument
    can be either a module or a module name.

    If no argument is given, the calling module is used.

    A number of options may be provided as keyword arguments:

    setUp
      A set-up function.  This is called before running the
      tests in each file. The setUp function will be passed a DocTest
      object.  The setUp function can access the test globals as the
      globs attribute of the test passed.

    tearDown
      A tear-down function.  This is called after running the
      tests in each file.  The tearDown function will be passed a DocTest
      object.  The tearDown function can access the test globals as the
      globs attribute of the test passed.

    globs
      A dictionary containing initial global variables for the tests.

    optionflags
       A set of doctest option flags expressed as an integer.
    'b'Failed doctest test for %s
  File "%s", line 0

%s'u'Failed doctest test for %s
  File "%s", line 0

%s'b'A unittest suite for one or more doctest files.

    The path to each doctest file is given as a string; the
    interpretation of that string depends on the keyword argument
    "module_relative".

    A number of options may be provided as keyword arguments:

    module_relative
      If "module_relative" is True, then the given file paths are
      interpreted as os-independent module-relative paths.  By
      default, these paths are relative to the calling module's
      directory; but if the "package" argument is specified, then
      they are relative to that package.  To ensure os-independence,
      "filename" should use "/" characters to separate path
      segments, and may not be an absolute path (i.e., it may not
      begin with "/").

      If "module_relative" is False, then the given file paths are
      interpreted as os-specific paths.  These paths may be absolute
      or relative (to the current working directory).

    package
      A Python package or the name of a Python package whose directory
      should be used as the base directory for module relative paths.
      If "package" is not specified, then the calling module's
      directory is used as the base directory for module relative
      filenames.  It is an error to specify "package" if
      "module_relative" is False.

    setUp
      A set-up function.  This is called before running the
      tests in each file. The setUp function will be passed a DocTest
      object.  The setUp function can access the test globals as the
      globs attribute of the test passed.

    tearDown
      A tear-down function.  This is called after running the
      tests in each file.  The tearDown function will be passed a DocTest
      object.  The tearDown function can access the test globals as the
      globs attribute of the test passed.

    globs
      A dictionary containing initial global variables for the tests.

    optionflags
      A set of doctest option flags expressed as an integer.

    parser
      A DocTestParser (or subclass) that should be used to extract
      tests from the files.

    encoding
      An encoding that will be used to convert the files to unicode.
    'u'A unittest suite for one or more doctest files.

    The path to each doctest file is given as a string; the
    interpretation of that string depends on the keyword argument
    "module_relative".

    A number of options may be provided as keyword arguments:

    module_relative
      If "module_relative" is True, then the given file paths are
      interpreted as os-independent module-relative paths.  By
      default, these paths are relative to the calling module's
      directory; but if the "package" argument is specified, then
      they are relative to that package.  To ensure os-independence,
      "filename" should use "/" characters to separate path
      segments, and may not be an absolute path (i.e., it may not
      begin with "/").

      If "module_relative" is False, then the given file paths are
      interpreted as os-specific paths.  These paths may be absolute
      or relative (to the current working directory).

    package
      A Python package or the name of a Python package whose directory
      should be used as the base directory for module relative paths.
      If "package" is not specified, then the calling module's
      directory is used as the base directory for module relative
      filenames.  It is an error to specify "package" if
      "module_relative" is False.

    setUp
      A set-up function.  This is called before running the
      tests in each file. The setUp function will be passed a DocTest
      object.  The setUp function can access the test globals as the
      globs attribute of the test passed.

    tearDown
      A tear-down function.  This is called after running the
      tests in each file.  The tearDown function will be passed a DocTest
      object.  The tearDown function can access the test globals as the
      globs attribute of the test passed.

    globs
      A dictionary containing initial global variables for the tests.

    optionflags
      A set of doctest option flags expressed as an integer.

    parser
      A DocTestParser (or subclass) that should be used to extract
      tests from the files.

    encoding
      An encoding that will be used to convert the files to unicode.
    'b'module_relative'u'module_relative'b'package'u'package'b'Extract script from text with examples.

       Converts text with examples to a Python script.  Example input is
       converted to regular code.  Example output and all other words
       are converted to comments:

       >>> text = '''
       ...       Here are examples of simple math.
       ...
       ...           Python has super accurate integer addition
       ...
       ...           >>> 2 + 2
       ...           5
       ...
       ...           And very friendly error messages:
       ...
       ...           >>> 1/0
       ...           To Infinity
       ...           And
       ...           Beyond
       ...
       ...           You can use logic if you want:
       ...
       ...           >>> if 0:
       ...           ...    blah
       ...           ...    blah
       ...           ...
       ...
       ...           Ho hum
       ...           '''

       >>> print(script_from_examples(text))
       # Here are examples of simple math.
       #
       #     Python has super accurate integer addition
       #
       2 + 2
       # Expected:
       ## 5
       #
       #     And very friendly error messages:
       #
       1/0
       # Expected:
       ## To Infinity
       ## And
       ## Beyond
       #
       #     You can use logic if you want:
       #
       if 0:
          blah
          blah
       #
       #     Ho hum
       <BLANKLINE>
       'u'Extract script from text with examples.

       Converts text with examples to a Python script.  Example input is
       converted to regular code.  Example output and all other words
       are converted to comments:

       >>> text = '''
       ...       Here are examples of simple math.
       ...
       ...           Python has super accurate integer addition
       ...
       ...           >>> 2 + 2
       ...           5
       ...
       ...           And very friendly error messages:
       ...
       ...           >>> 1/0
       ...           To Infinity
       ...           And
       ...           Beyond
       ...
       ...           You can use logic if you want:
       ...
       ...           >>> if 0:
       ...           ...    blah
       ...           ...    blah
       ...           ...
       ...
       ...           Ho hum
       ...           '''

       >>> print(script_from_examples(text))
       # Here are examples of simple math.
       #
       #     Python has super accurate integer addition
       #
       2 + 2
       # Expected:
       ## 5
       #
       #     And very friendly error messages:
       #
       1/0
       # Expected:
       ## To Infinity
       ## And
       ## Beyond
       #
       #     You can use logic if you want:
       #
       if 0:
          blah
          blah
       #
       #     Ho hum
       <BLANKLINE>
       'b'# Expected:'u'# Expected:'b'## 'u'## 'b'Extract the test sources from a doctest docstring as a script.

    Provide the module (or dotted name of the module) containing the
    test to be debugged and the name (within the module) of the object
    with the doc string with tests to be debugged.
    'u'Extract the test sources from a doctest docstring as a script.

    Provide the module (or dotted name of the module) containing the
    test to be debugged and the name (within the module) of the object
    with the doc string with tests to be debugged.
    'b'not found in tests'u'not found in tests'b'Debug a single doctest docstring, in argument `src`''u'Debug a single doctest docstring, in argument `src`''b'Debug a test script.  `src` is the script, as a string.'u'Debug a test script.  `src` is the script, as a string.'b'exec(%r)'u'exec(%r)'b'Debug a single doctest docstring.

    Provide the module (or dotted name of the module) containing the
    test to be debugged and the name (within the module) of the object
    with the docstring with tests to be debugged.
    'u'Debug a single doctest docstring.

    Provide the module (or dotted name of the module) containing the
    test to be debugged and the name (within the module) of the object
    with the docstring with tests to be debugged.
    'b'
    A pointless class, for sanity-checking of docstring testing.

    Methods:
        square()
        get()

    >>> _TestClass(13).get() + _TestClass(-12).get()
    1
    >>> hex(_TestClass(13).square().get())
    '0xa9'
    'u'
    A pointless class, for sanity-checking of docstring testing.

    Methods:
        square()
        get()

    >>> _TestClass(13).get() + _TestClass(-12).get()
    1
    >>> hex(_TestClass(13).square().get())
    '0xa9'
    'b'val -> _TestClass object with associated value val.

        >>> t = _TestClass(123)
        >>> print(t.get())
        123
        'u'val -> _TestClass object with associated value val.

        >>> t = _TestClass(123)
        >>> print(t.get())
        123
        'b'square() -> square TestClass's associated value

        >>> _TestClass(13).square().get()
        169
        'u'square() -> square TestClass's associated value

        >>> _TestClass(13).square().get()
        169
        'b'get() -> return TestClass's associated value.

        >>> x = _TestClass(-42)
        >>> print(x.get())
        -42
        'u'get() -> return TestClass's associated value.

        >>> x = _TestClass(-42)
        >>> print(x.get())
        -42
        'b'_TestClass'u'_TestClass'b'
                      Example of a string object, searched as-is.
                      >>> x = 1; y = 2
                      >>> x + y, x * y
                      (3, 2)
                      'u'
                      Example of a string object, searched as-is.
                      >>> x = 1; y = 2
                      >>> x + y, x * y
                      (3, 2)
                      'b'
                                    In 2.2, boolean expressions displayed
                                    0 or 1.  By default, we still accept
                                    them.  This can be disabled by passing
                                    DONT_ACCEPT_TRUE_FOR_1 to the new
                                    optionflags argument.
                                    >>> 4 == 4
                                    1
                                    >>> 4 == 4
                                    True
                                    >>> 4 > 4
                                    0
                                    >>> 4 > 4
                                    False
                                    'u'
                                    In 2.2, boolean expressions displayed
                                    0 or 1.  By default, we still accept
                                    them.  This can be disabled by passing
                                    DONT_ACCEPT_TRUE_FOR_1 to the new
                                    optionflags argument.
                                    >>> 4 == 4
                                    1
                                    >>> 4 == 4
                                    True
                                    >>> 4 > 4
                                    0
                                    >>> 4 > 4
                                    False
                                    'b'bool-int equivalence'u'bool-int equivalence'b'
                Blank lines can be marked with <BLANKLINE>:
                    >>> print('foo\n\nbar\n')
                    foo
                    <BLANKLINE>
                    bar
                    <BLANKLINE>
            'u'
                Blank lines can be marked with <BLANKLINE>:
                    >>> print('foo\n\nbar\n')
                    foo
                    <BLANKLINE>
                    bar
                    <BLANKLINE>
            'b'blank lines'u'blank lines'b'
                If the ellipsis flag is used, then '...' can be used to
                elide substrings in the desired output:
                    >>> print(list(range(1000))) #doctest: +ELLIPSIS
                    [0, 1, 2, ..., 999]
            'u'
                If the ellipsis flag is used, then '...' can be used to
                elide substrings in the desired output:
                    >>> print(list(range(1000))) #doctest: +ELLIPSIS
                    [0, 1, 2, ..., 999]
            'b'ellipsis'u'ellipsis'b'
                If the whitespace normalization flag is used, then
                differences in whitespace are ignored.
                    >>> print(list(range(30))) #doctest: +NORMALIZE_WHITESPACE
                    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,
                     15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,
                     27, 28, 29]
            'u'
                If the whitespace normalization flag is used, then
                differences in whitespace are ignored.
                    >>> print(list(range(30))) #doctest: +NORMALIZE_WHITESPACE
                    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,
                     15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,
                     27, 28, 29]
            'b'whitespace normalization'u'whitespace normalization'b'doctest runner'u'doctest runner'b'--verbose'u'--verbose'b'print very verbose output for all tests'u'print very verbose output for all tests'b'-o'u'-o'b'--option'u'--option'b'specify a doctest option flag to apply to the test run; may be specified more than once to apply multiple options'u'specify a doctest option flag to apply to the test run; may be specified more than once to apply multiple options'b'-f'u'-f'b'--fail-fast'u'--fail-fast'b'stop running tests after first failure (this is a shorthand for -o FAIL_FAST, and is in addition to any other -o options)'u'stop running tests after first failure (this is a shorthand for -o FAIL_FAST, and is in addition to any other -o options)'b'file containing the tests to run'u'file containing the tests to run'u'Lib.doctest'u'doctest'Encodings and related functions.encode_base64encode_noopencode_quopri_bencodeencodestring_encodestring_qencodequotetabs=20Encode the message's payload in Base64.

    Also, add an appropriate Content-Transfer-Encoding header.
    get_payloadorigencdataset_payloadContent-Transfer-EncodingEncode the message's payload in quoted-printable.

    Also, add an appropriate Content-Transfer-Encoding header.
    Set the Content-Transfer-Encoding header to 7bit or 8bit.Do nothing.# Copyright (C) 2001-2006 Python Software Foundation# Must encode spaces, which quopri.encodestring() doesn't do# There's no payload.  For backwards compatibility we use 7bit# We play a trick to make this go fast.  If decoding from ASCII succeeds,# we know the data must be 7bit, otherwise treat it as 8bit.b'Encodings and related functions.'u'Encodings and related functions.'b'encode_7or8bit'u'encode_7or8bit'b'encode_base64'u'encode_base64'b'encode_noop'u'encode_noop'b'encode_quopri'u'encode_quopri'b'=20'b'Encode the message's payload in Base64.

    Also, add an appropriate Content-Transfer-Encoding header.
    'u'Encode the message's payload in Base64.

    Also, add an appropriate Content-Transfer-Encoding header.
    'b'Content-Transfer-Encoding'u'Content-Transfer-Encoding'b'Encode the message's payload in quoted-printable.

    Also, add an appropriate Content-Transfer-Encoding header.
    'u'Encode the message's payload in quoted-printable.

    Also, add an appropriate Content-Transfer-Encoding header.
    'b'Set the Content-Transfer-Encoding header to 7bit or 8bit.'u'Set the Content-Transfer-Encoding header to 7bit or 8bit.'b'Do nothing.'u'Do nothing.'u'Lib.email.encoders'u'email.encoders'HTML character entity references.name2codepointcodepoint2nameentitydefs1980x00c6AElig1930x00c1Aacute1940x00c2Acirc1920x00c0Agrave9130x0391Alpha1970x00c5Aring1950x00c3Atilde1960x00c4Auml9140x0392Beta0x00c7Ccedil9350x03a7Chi82250x2021Dagger9160x0394Delta0x00d0ETH0x00c9Eacute0x00caEcirc0x00c8Egrave9170x0395Epsilon9190x0397Eta0x00cbEuml9150x0393Gamma0x00cdIacute0x00ceIcirc0x00ccIgrave9210x0399Iota0x00cfIuml9220x039aKappa9230x039b9240x039cMu2090x00d1Ntilde9250x039dNu3380x0152OElig2110x00d3Oacute2120x00d4Ocirc2100x00d2Ograve9370x03a9Omega9270x039fOmicron2160x00d8Oslash2130x00d5Otilde2140x00d6Ouml9340x03a6Phi9280x03a0Pi82430x2033Prime0x03a8Psi9290x03a1Rho3520x0160Scaron9310x03a3Sigma2220x00deTHORN0x03a4Tau9200x0398Theta2180x00daUacute2190x00dbUcirc2170x00d9Ugrave9330x03a5Upsilon2200x00dcUuml9260x039eXi2210x00ddYacute3760x0178Yuml9180x0396Zeta2250x00e1aacute0x00e2acirc1800x00b4acute2300x00e6aelig2240x00e0agrave85010x2135alefsym9450x03b1380x0026amp87430x222787360x2220ang2290x00e5aring87760x2248asymp2270x00e3atilde2280x00e4auml82220x201ebdquo1660x00a6brvbar82260x2022bull87450x2229cap0x00e7ccedil1840x00b8cedil1620x00a2cent9670x03c7chi7100x02c6circ98270x2663clubs87730x2245cong1690x00a986290x21b5crarr87460x222acup1640x00a4curren86590x21d3dArr82240x2020dagger85950x2193darr1760x00b0deg9480x03b498300x2666diams2470x00f72330x00e9eacute0x00eaecirc0x00e8egrave87090x2205empty81950x2003emsp81940x2002ensp88010x2261equiv9510x03b7eta2400x00f0eth2350x00ebeuml83640x20aceuro87070x2203exist0x0192fnof87040x2200forall1890x00bdfrac121880x00bcfrac141900x00befrac3482600x2044frasl9470x03b3gamma88050x2265620x003e86600x21d4hArr85960x2194harr98290x2665hearts82300x2026hellip2370x00ediacute2380x00eeicirc1610x00a1iexcl2360x00ecigrave84650x2111image87340x221einfin87470x222biota1910x00bfiquest87120x2208isin2390x00efiumlkappa86560x21d0lArr9550x03bb90010x23291710x00ablaquo85920x2190larr89680x2308lceil82200x201cldquo88040x226489700x230alfloor87270x2217lowast96740x25caloz82060x200elrm82490x2039lsaquo82160x2018lsquo0x003c1750x00afmacr82120x2014mdash0x00b7middot87220x2212mu87110x2207nabla1600x00a0nbsp82110x2013ndash88000x226087150x220bni1720x00ac87130x2209notin88360x2284nsub2410x00f1ntilde9570x03bdnu2430x00f3oacute2440x00f4ocirc3390x0153oelig2420x00f2ograve82540x203eoline9690x03c9omega9590x03bfomicron88530x2295oplus87440x22281700x00aaordf1860x00baordm2480x00f8oslash2450x00f5otilde88550x2297otimes2460x00f6ouml1820x00b6para87060x220282400x2030permil88690x22a5perpphipipiv1770x00b1plusmn1630x00a3pound82420x2032prime87190x220fprod87330x221dprop9680x03c8psi340x002286580x21d2rArr87300x221aradic90020x232arang1870x00bbraquo85940x2192rarr89690x2309rceil82210x201drdquo84760x211c1740x00aereg89710x230brfloorrho82070x200frlm82500x203arsaquo82170x2019rsquo82180x201asbquo3530x0161scaron89010x22c5sdot1670x00a7sect1730x00adshysigmasigmaf87640x223csim98240x2660spades88340x228288380x2286sube87210x221188350x22831850x00b9sup11780x00b2sup21790x00b3sup388390x2287supe2230x00dfszlig9640x03c4tau87560x2234there4thetathetasym82010x2009thinsp2540x00fethorn7320x02dctilde2150x00d7times84820x2122trade86570x21d1uArr2500x00fauacute85930x2191uarr2510x00fbucirc2490x00f9ugrave1680x00a8uml9780x03d2upsih9650x03c5upsilon2520x00fcuuml84720x2118weierp9580x03bexi2530x00fdyacute1650x00a5yen0x00ffyuml0x03b6zeta82050x200dzwj82040x200czwnjAacute;aacute;Abreve;abreve;ac;acd;acE;Acirc;acirc;acute;Acy;acy;AElig;aelig;af;Afr;afr;Agrave;agrave;alefsym;aleph;Alpha;alpha;Amacr;amacr;amalg;AMPAMP;amp;And;and;andand;andd;andslope;andv;ang;ange;angle;angmsd;angmsdaa;angmsdab;angmsdac;angmsdad;angmsdae;angmsdaf;angmsdag;angmsdah;angrt;angrtvb;angrtvbd;angsph;angst;angzarr;Aogon;aogon;Aopf;aopf;ap;apacir;apE;ape;apid;apos;ApplyFunction;approx;approxeq;Aring;aring;Ascr;ascr;Assign;ast;asymp;asympeq;Atilde;atilde;Auml;auml;awconint;awint;backcong;backepsilon;backprime;backsim;backsimeq;Backslash;Barv;barvee;Barwed;barwed;barwedge;bbrk;bbrktbrk;bcong;Bcy;bcy;bdquo;becaus;Because;because;bemptyv;bepsi;bernou;Bernoullis;Beta;beta;beth;between;Bfr;bfr;bigcap;bigcirc;bigcup;bigodot;bigoplus;bigotimes;bigsqcup;bigstar;bigtriangledown;bigtriangleup;biguplus;bigvee;bigwedge;bkarow;blacklozenge;blacksquare;blacktriangle;blacktriangledown;blacktriangleleft;blacktriangleright;blank;blk12;blk14;blk34;block;=bne;bnequiv;bNot;bnot;Bopf;bopf;bot;bottom;bowtie;boxbox;boxDL;boxDl;boxdL;boxdl;boxDR;boxDr;boxdR;boxdr;boxH;boxh;boxHD;boxHd;boxhD;boxhd;boxHU;boxHu;boxhU;boxhu;boxminus;boxplus;boxtimes;boxUL;boxUl;boxuL;boxul;boxUR;boxUr;boxuR;boxur;boxV;boxv;boxVH;boxVh;boxvH;boxvh;boxVL;boxVl;boxvL;boxvl;boxVR;boxVr;boxvR;boxvr;bprime;Breve;breve;brvbar;Bscr;bscr;bsemi;bsim;bsime;bsol;bsolb;bsolhsub;bull;bullet;bump;bumpE;bumpe;Bumpeq;bumpeq;Cacute;cacute;Cap;cap;capand;capbrcup;capcap;capcup;capdot;CapitalDifferentialD;caps;caret;caron;Cayleys;ccaps;Ccaron;ccaron;Ccedil;ccedil;Ccirc;ccirc;Cconint;ccups;ccupssm;Cdot;cdot;cedil;Cedilla;cemptyv;cent;CenterDot;centerdot;Cfr;cfr;CHcy;chcy;check;checkmark;Chi;chi;cir;circ;circeq;circlearrowleft;circlearrowright;circledast;circledcirc;circleddash;CircleDot;circledR;circledS;CircleMinus;CirclePlus;CircleTimes;cirE;cire;cirfnint;cirmid;cirscir;ClockwiseContourIntegral;CloseCurlyDoubleQuote;CloseCurlyQuote;clubs;clubsuit;Colon;colon;Colone;colone;coloneq;comma;commat;comp;compfn;complement;complexes;cong;congdot;Congruent;Conint;conint;ContourIntegral;Copf;copf;coprod;Coproduct;COPYCOPY;copy;copysr;CounterClockwiseContourIntegral;crarr;Cross;cross;Cscr;cscr;csub;csube;csup;csupe;ctdot;cudarrl;cudarrr;cuepr;cuesc;cularr;cularrp;Cup;cup;cupbrcap;CupCap;cupcap;cupcup;cupdot;cupor;cups;curarr;curarrm;curlyeqprec;curlyeqsucc;curlyvee;curlywedge;curren;curvearrowleft;curvearrowright;cuvee;cuwed;cwconint;cwint;cylcty;Dagger;dagger;daleth;Darr;dArr;darr;dash;Dashv;dashv;dbkarow;dblac;Dcaron;dcaron;Dcy;dcy;DD;dd;ddagger;ddarr;DDotrahd;ddotseq;deg;Del;Delta;delta;demptyv;dfisht;Dfr;dfr;dHar;dharl;dharr;DiacriticalAcute;DiacriticalDot;DiacriticalDoubleAcute;`DiacriticalGrave;DiacriticalTilde;diam;Diamond;diamond;diamondsuit;diams;die;DifferentialD;digamma;disin;div;divide;divideontimes;divonx;DJcy;djcy;dlcorn;dlcrop;dollar;Dopf;dopf;Dot;dot;DotDot;doteq;doteqdot;DotEqual;dotminus;dotplus;dotsquare;doublebarwedge;DoubleContourIntegral;DoubleDot;DoubleDownArrow;DoubleLeftArrow;DoubleLeftRightArrow;DoubleLeftTee;DoubleLongLeftArrow;DoubleLongLeftRightArrow;DoubleLongRightArrow;DoubleRightArrow;DoubleRightTee;DoubleUpArrow;DoubleUpDownArrow;DoubleVerticalBar;DownArrow;Downarrow;downarrow;DownArrowBar;DownArrowUpArrow;DownBreve;downdownarrows;downharpoonleft;downharpoonright;DownLeftRightVector;DownLeftTeeVector;DownLeftVector;DownLeftVectorBar;DownRightTeeVector;DownRightVector;DownRightVectorBar;DownTee;DownTeeArrow;drbkarow;drcorn;drcrop;Dscr;dscr;DScy;dscy;dsol;Dstrok;dstrok;dtdot;dtri;dtrif;duarr;duhar;dwangle;DZcy;dzcy;dzigrarr;Eacute;eacute;easter;Ecaron;ecaron;ecir;Ecirc;ecirc;ecolon;Ecy;ecy;eDDot;Edot;eDot;edot;ee;efDot;Efr;efr;eg;Egrave;egrave;egs;egsdot;el;Element;elinters;ell;els;elsdot;Emacr;emacr;empty;emptyset;EmptySmallSquare;emptyv;EmptyVerySmallSquare;emsp13;emsp14;emsp;ENG;eng;ensp;Eogon;eogon;Eopf;eopf;epar;eparsl;eplus;epsi;Epsilon;epsilon;epsiv;eqcirc;eqcolon;eqsim;eqslantgtr;eqslantless;Equal;equals;EqualTilde;equest;Equilibrium;equiv;equivDD;eqvparsl;erarr;erDot;Escr;escr;esdot;Esim;esim;Eta;eta;ETH;eth;Euml;euml;euro;excl;exist;Exists;expectation;ExponentialE;exponentiale;fallingdotseq;Fcy;fcy;female;ffilig;fflig;ffllig;Ffr;ffr;filig;FilledSmallSquare;FilledVerySmallSquare;fjfjlig;flat;fllig;fltns;fnof;Fopf;fopf;ForAll;forall;fork;forkv;Fouriertrf;fpartint;frac12;frac13;frac14;frac15;frac16;frac18;frac23;frac25;frac34;frac35;frac38;frac45;frac56;frac58;frac78;frasl;frown;Fscr;fscr;gacute;Gamma;gamma;Gammad;gammad;gap;Gbreve;gbreve;Gcedil;Gcirc;gcirc;Gcy;gcy;Gdot;gdot;gE;ge;gEl;gel;geq;geqq;geqslant;ges;gescc;gesdot;gesdoto;gesdotol;gesl;gesles;Gfr;gfr;Gg;gg;ggg;gimel;GJcy;gjcy;gl;gla;glE;glj;gnap;gnapprox;gnE;gne;gneq;gneqq;gnsim;Gopf;gopf;grave;GreaterEqual;GreaterEqualLess;GreaterFullEqual;GreaterGreater;GreaterLess;GreaterSlantEqual;GreaterTilde;Gscr;gscr;gsim;gsime;gsiml;GTGT;Gt;gt;gtcc;gtcir;gtdot;gtlPar;gtquest;gtrapprox;gtrarr;gtrdot;gtreqless;gtreqqless;gtrless;gtrsim;gvertneqq;gvnE;Hacek;hairsp;half;hamilt;HARDcy;hardcy;hArr;harr;harrcir;harrw;Hat;hbar;Hcirc;hcirc;hearts;heartsuit;hellip;hercon;Hfr;hfr;HilbertSpace;hksearow;hkswarow;hoarr;homtht;hookleftarrow;hookrightarrow;Hopf;hopf;horbar;HorizontalLine;Hscr;hscr;hslash;Hstrok;hstrok;HumpDownHump;HumpEqual;hybull;hyphen;Iacute;iacute;ic;Icirc;icirc;Icy;icy;Idot;IEcy;iecy;iexcl;iff;Ifr;ifr;Igrave;igrave;ii;iiiint;iiint;iinfin;iiota;IJlig;ijlig;Im;Imacr;imacr;image;ImaginaryI;imagline;imagpart;imath;imof;imped;Implies;in;incare;infin;infintie;inodot;Int;int;intcal;integers;Integral;intercal;Intersection;intlarhk;intprod;InvisibleComma;InvisibleTimes;IOcy;iocy;Iogon;iogon;Iopf;iopf;Iota;iota;iprod;iquest;Iscr;iscr;isin;isindot;isinE;isins;isinsv;isinv;it;Itilde;itilde;Iukcy;iukcy;Iuml;iuml;Jcirc;jcirc;Jcy;jcy;Jfr;jfr;jmath;Jopf;jopf;Jscr;jscr;Jsercy;jsercy;Jukcy;jukcy;Kappa;kappa;kappav;Kcedil;kcedil;Kcy;kcy;Kfr;kfr;kgreen;KHcy;khcy;KJcy;kjcy;Kopf;kopf;Kscr;kscr;lAarr;Lacute;lacute;laemptyv;lagran;Lambda;lambda;Lang;lang;langd;langle;lap;Laplacetrf;laquo;Larr;lArr;larr;larrb;larrbfs;larrfs;larrhk;larrlp;larrpl;larrsim;larrtl;lat;lAtail;latail;late;lates;lBarr;lbarr;lbbrk;lbrace;lbrack;lbrke;lbrksld;lbrkslu;Lcaron;lcaron;Lcedil;lcedil;lceil;lcub;Lcy;lcy;ldca;ldquo;ldquor;ldrdhar;ldrushar;ldsh;lE;le;LeftAngleBracket;LeftArrow;Leftarrow;leftarrow;LeftArrowBar;LeftArrowRightArrow;leftarrowtail;LeftCeiling;LeftDoubleBracket;LeftDownTeeVector;LeftDownVector;LeftDownVectorBar;LeftFloor;leftharpoondown;leftharpoonup;leftleftarrows;LeftRightArrow;Leftrightarrow;leftrightarrow;leftrightarrows;leftrightharpoons;leftrightsquigarrow;LeftRightVector;LeftTee;LeftTeeArrow;LeftTeeVector;leftthreetimes;LeftTriangle;LeftTriangleBar;LeftTriangleEqual;LeftUpDownVector;LeftUpTeeVector;LeftUpVector;LeftUpVectorBar;LeftVector;LeftVectorBar;lEg;leg;leq;leqq;leqslant;les;lescc;lesdot;lesdoto;lesdotor;lesg;lesges;lessapprox;lessdot;lesseqgtr;lesseqqgtr;LessEqualGreater;LessFullEqual;LessGreater;lessgtr;LessLess;lesssim;LessSlantEqual;LessTilde;lfisht;lfloor;Lfr;lfr;lg;lgE;lHar;lhard;lharu;lharul;lhblk;LJcy;ljcy;Ll;ll;llarr;llcorner;Lleftarrow;llhard;lltri;Lmidot;lmidot;lmoust;lmoustache;lnap;lnapprox;lnE;lne;lneq;lneqq;lnsim;loang;loarr;lobrk;LongLeftArrow;Longleftarrow;longleftarrow;LongLeftRightArrow;Longleftrightarrow;longleftrightarrow;longmapsto;LongRightArrow;Longrightarrow;longrightarrow;looparrowleft;looparrowright;lopar;Lopf;lopf;loplus;lotimes;lowast;lowbar;LowerLeftArrow;LowerRightArrow;loz;lozenge;lozf;lpar;lparlt;lrarr;lrcorner;lrhar;lrhard;lrm;lrtri;lsaquo;Lscr;lscr;Lsh;lsh;lsim;lsime;lsimg;lsqb;lsquo;lsquor;Lstrok;lstrok;LTLT;Lt;lt;ltcc;ltcir;ltdot;lthree;ltimes;ltlarr;ltquest;ltri;ltrie;ltrif;ltrPar;lurdshar;luruhar;lvertneqq;lvnE;macr;male;malt;maltese;Map;map;mapsto;mapstodown;mapstoleft;mapstoup;marker;mcomma;Mcy;mcy;mdash;mDDot;measuredangle;MediumSpace;Mellintrf;Mfr;mfr;mho;micro;mid;midast;midcir;middot;minus;minusb;minusd;minusdu;MinusPlus;mlcp;mldr;mnplus;models;Mopf;mopf;mp;Mscr;mscr;mstpos;Mu;mu;multimap;mumap;nabla;Nacute;nacute;nang;nap;napE;napid;napos;napprox;natur;natural;naturals;nbsp;nbump;nbumpe;ncap;Ncaron;ncaron;Ncedil;ncedil;ncong;ncongdot;ncup;Ncy;ncy;ndash;ne;nearhk;neArr;nearr;nearrow;nedot;NegativeMediumSpace;NegativeThickSpace;NegativeThinSpace;NegativeVeryThinSpace;nequiv;nesear;nesim;NestedGreaterGreater;NestedLessLess;NewLine;nexist;nexists;Nfr;nfr;ngE;nge;ngeq;ngeqq;ngeqslant;nges;nGg;ngsim;nGt;ngt;ngtr;nGtv;nhArr;nharr;nhpar;ni;nis;nisd;niv;NJcy;njcy;nlArr;nlarr;nldr;nlE;nle;nLeftarrow;nleftarrow;nLeftrightarrow;nleftrightarrow;nleq;nleqq;nleqslant;nles;nless;nLl;nlsim;nLt;nlt;nltri;nltrie;nLtv;nmid;NoBreak;NonBreakingSpace;Nopf;nopf;Not;not;NotCongruent;NotCupCap;NotDoubleVerticalBar;NotElement;NotEqual;NotEqualTilde;NotExists;NotGreater;NotGreaterEqual;NotGreaterFullEqual;NotGreaterGreater;NotGreaterLess;NotGreaterSlantEqual;NotGreaterTilde;NotHumpDownHump;NotHumpEqual;notin;notindot;notinE;notinva;notinvb;notinvc;NotLeftTriangle;NotLeftTriangleBar;NotLeftTriangleEqual;NotLess;NotLessEqual;NotLessGreater;NotLessLess;NotLessSlantEqual;NotLessTilde;NotNestedGreaterGreater;NotNestedLessLess;notni;notniva;notnivb;notnivc;NotPrecedes;NotPrecedesEqual;NotPrecedesSlantEqual;NotReverseElement;NotRightTriangle;NotRightTriangleBar;NotRightTriangleEqual;NotSquareSubset;NotSquareSubsetEqual;NotSquareSuperset;NotSquareSupersetEqual;NotSubset;NotSubsetEqual;NotSucceeds;NotSucceedsEqual;NotSucceedsSlantEqual;NotSucceedsTilde;NotSuperset;NotSupersetEqual;NotTilde;NotTildeEqual;NotTildeFullEqual;NotTildeTilde;NotVerticalBar;npar;nparallel;nparsl;npart;npolint;npr;nprcue;npre;nprec;npreceq;nrArr;nrarr;nrarrc;nrarrw;nRightarrow;nrightarrow;nrtri;nrtrie;nsc;nsccue;nsce;Nscr;nscr;nshortmid;nshortparallel;nsim;nsime;nsimeq;nsmid;nspar;nsqsube;nsqsupe;nsub;nsubE;nsube;nsubset;nsubseteq;nsubseteqq;nsucc;nsucceq;nsup;nsupE;nsupe;nsupset;nsupseteq;nsupseteqq;ntgl;Ntilde;ntilde;ntlg;ntriangleleft;ntrianglelefteq;ntriangleright;ntrianglerighteq;Nu;nu;num;numero;numsp;nvap;nVDash;nVdash;nvDash;nvdash;nvge;>nvgt;nvHarr;nvinfin;nvlArr;nvle;<nvlt;nvltrie;nvrArr;nvrtrie;nvsim;nwarhk;nwArr;nwarr;nwarrow;nwnear;Oacute;oacute;oast;ocir;Ocirc;ocirc;Ocy;ocy;odash;Odblac;odblac;odiv;odot;odsold;OElig;oelig;ofcir;Ofr;ofr;ogon;Ograve;ograve;ogt;ohbar;ohm;oint;olarr;olcir;olcross;oline;olt;Omacr;omacr;Omega;omega;Omicron;omicron;omid;ominus;Oopf;oopf;opar;OpenCurlyDoubleQuote;OpenCurlyQuote;operp;oplus;Or;or;orarr;ord;order;orderof;ordf;ordm;origof;oror;orslope;orv;oS;Oscr;oscr;Oslash;oslash;osol;Otilde;otilde;Otimes;otimes;otimesas;Ouml;ouml;ovbar;OverBar;OverBrace;OverBracket;OverParenthesis;par;para;parallel;parsim;parsl;part;PartialD;Pcy;pcy;percnt;period;permil;perp;pertenk;Pfr;pfr;Phi;phi;phiv;phmmat;phone;Pi;pi;pitchfork;piv;planck;planckh;plankv;plus;plusacir;plusb;pluscir;plusdo;plusdu;pluse;PlusMinus;plusmn;plussim;plustwo;pm;Poincareplane;pointint;Popf;popf;pound;Pr;pr;prap;prcue;prE;pre;prec;precapprox;preccurlyeq;Precedes;PrecedesEqual;PrecedesSlantEqual;PrecedesTilde;preceq;precnapprox;precneqq;precnsim;precsim;Prime;prime;primes;prnap;prnE;prnsim;prod;Product;profalar;profline;profsurf;prop;Proportion;Proportional;propto;prsim;prurel;Pscr;pscr;Psi;psi;puncsp;Qfr;qfr;qint;Qopf;qopf;qprime;Qscr;qscr;quaternions;quatint;quest;questeq;QUOTQUOT;quot;rAarr;race;Racute;racute;radic;raemptyv;Rang;rang;rangd;range;rangle;raquo;Rarr;rArr;rarr;rarrap;rarrb;rarrbfs;rarrc;rarrfs;rarrhk;rarrlp;rarrpl;rarrsim;Rarrtl;rarrtl;rarrw;rAtail;ratail;ratio;rationals;RBarr;rBarr;rbarr;rbbrk;rbrace;rbrack;rbrke;rbrksld;rbrkslu;Rcaron;rcaron;Rcedil;rcedil;rceil;rcub;Rcy;rcy;rdca;rdldhar;rdquo;rdquor;rdsh;Re;real;realine;realpart;reals;rect;REGREG;reg;ReverseElement;ReverseEquilibrium;ReverseUpEquilibrium;rfisht;rfloor;Rfr;rfr;rHar;rhard;rharu;rharul;Rho;rho;rhov;RightAngleBracket;RightArrow;Rightarrow;rightarrow;RightArrowBar;RightArrowLeftArrow;rightarrowtail;RightCeiling;RightDoubleBracket;RightDownTeeVector;RightDownVector;RightDownVectorBar;RightFloor;rightharpoondown;rightharpoonup;rightleftarrows;rightleftharpoons;rightrightarrows;rightsquigarrow;RightTee;RightTeeArrow;RightTeeVector;rightthreetimes;RightTriangle;RightTriangleBar;RightTriangleEqual;RightUpDownVector;RightUpTeeVector;RightUpVector;RightUpVectorBar;RightVector;RightVectorBar;ring;risingdotseq;rlarr;rlhar;rlm;rmoust;rmoustache;rnmid;roang;roarr;robrk;ropar;Ropf;ropf;roplus;rotimes;RoundImplies;rpar;rpargt;rppolint;rrarr;Rrightarrow;rsaquo;Rscr;rscr;Rsh;rsh;rsqb;rsquo;rsquor;rthree;rtimes;rtri;rtrie;rtrif;rtriltri;RuleDelayed;ruluhar;rx;Sacute;sacute;sbquo;Sc;sc;scap;Scaron;scaron;sccue;scE;sce;Scedil;scedil;Scirc;scirc;scnap;scnE;scnsim;scpolint;scsim;Scy;scy;sdot;sdotb;sdote;searhk;seArr;searr;searrow;sect;semi;seswar;setminus;setmn;sext;Sfr;sfr;sfrown;sharp;SHCHcy;shchcy;SHcy;shcy;ShortDownArrow;ShortLeftArrow;shortmid;shortparallel;ShortRightArrow;ShortUpArrow;shy;Sigma;sigma;sigmaf;sigmav;sim;simdot;sime;simeq;simg;simgE;siml;simlE;simne;simplus;simrarr;slarr;SmallCircle;smallsetminus;smashp;smeparsl;smid;smile;smt;smte;smtes;SOFTcy;softcy;sol;solb;solbar;Sopf;sopf;spades;spadesuit;spar;sqcap;sqcaps;sqcup;sqcups;Sqrt;sqsub;sqsube;sqsubset;sqsubseteq;sqsup;sqsupe;sqsupset;sqsupseteq;squ;Square;square;SquareIntersection;SquareSubset;SquareSubsetEqual;SquareSuperset;SquareSupersetEqual;SquareUnion;squarf;squf;srarr;Sscr;sscr;ssetmn;ssmile;sstarf;Star;star;starf;straightepsilon;straightphi;strns;Sub;sub;subdot;subE;sube;subedot;submult;subnE;subne;subplus;subrarr;Subset;subset;subseteq;subseteqq;SubsetEqual;subsetneq;subsetneqq;subsim;subsub;subsup;succ;succapprox;succcurlyeq;Succeeds;SucceedsEqual;SucceedsSlantEqual;SucceedsTilde;succeq;succnapprox;succneqq;succnsim;succsim;SuchThat;Sum;sum;sung;sup1;sup2;sup3;Sup;sup;supdot;supdsub;supE;supe;supedot;Superset;SupersetEqual;suphsol;suphsub;suplarr;supmult;supnE;supne;supplus;Supset;supset;supseteq;supseteqq;supsetneq;supsetneqq;supsim;supsub;supsup;swarhk;swArr;swarr;swarrow;swnwar;szlig;Tab;target;Tau;tau;tbrk;Tcaron;tcaron;Tcedil;tcedil;Tcy;tcy;tdot;telrec;Tfr;tfr;there4;Therefore;therefore;Theta;theta;thetasym;thetav;thickapprox;thicksim;ThickSpace;thinsp;ThinSpace;thkap;thksim;THORN;thorn;Tilde;tilde;TildeEqual;TildeFullEqual;TildeTilde;times;timesb;timesbar;timesd;tint;toea;top;topbot;topcir;Topf;topf;topfork;tosa;tprime;TRADE;trade;triangle;triangledown;triangleleft;trianglelefteq;triangleq;triangleright;trianglerighteq;tridot;trie;triminus;TripleDot;triplus;trisb;tritime;trpezium;Tscr;tscr;TScy;tscy;TSHcy;tshcy;Tstrok;tstrok;twixt;twoheadleftarrow;twoheadrightarrow;Uacute;uacute;Uarr;uArr;uarr;Uarrocir;Ubrcy;ubrcy;Ubreve;ubreve;Ucirc;ucirc;Ucy;ucy;udarr;Udblac;udblac;udhar;ufisht;Ufr;ufr;Ugrave;ugrave;uHar;uharl;uharr;uhblk;ulcorn;ulcorner;ulcrop;ultri;Umacr;umacr;uml;UnderBar;UnderBrace;UnderBracket;UnderParenthesis;Union;UnionPlus;Uogon;uogon;Uopf;uopf;UpArrow;Uparrow;uparrow;UpArrowBar;UpArrowDownArrow;UpDownArrow;Updownarrow;updownarrow;UpEquilibrium;upharpoonleft;upharpoonright;uplus;UpperLeftArrow;UpperRightArrow;Upsi;upsi;upsih;Upsilon;upsilon;UpTee;UpTeeArrow;upuparrows;urcorn;urcorner;urcrop;Uring;uring;urtri;Uscr;uscr;utdot;Utilde;utilde;utri;utrif;uuarr;Uuml;uuml;uwangle;vangrt;varepsilon;varkappa;varnothing;varphi;varpi;varpropto;vArr;varr;varrho;varsigma;varsubsetneq;varsubsetneqq;varsupsetneq;varsupsetneqq;vartheta;vartriangleleft;vartriangleright;Vbar;vBar;vBarv;Vcy;vcy;VDash;Vdash;vDash;vdash;Vdashl;Vee;vee;veebar;veeeq;vellip;Verbar;verbar;Vert;vert;VerticalBar;VerticalLine;VerticalSeparator;VerticalTilde;VeryThinSpace;Vfr;vfr;vltri;vnsub;vnsup;Vopf;vopf;vprop;vrtri;Vscr;vscr;vsubnE;vsubne;vsupnE;vsupne;Vvdash;vzigzag;Wcirc;wcirc;wedbar;Wedge;wedge;wedgeq;weierp;Wfr;wfr;Wopf;wopf;wp;wr;wreath;Wscr;wscr;xcap;xcirc;xcup;xdtri;Xfr;xfr;xhArr;xharr;Xi;xi;xlArr;xlarr;xmap;xnis;xodot;Xopf;xopf;xoplus;xotime;xrArr;xrarr;Xscr;xscr;xsqcup;xuplus;xutri;xvee;xwedge;Yacute;yacute;YAcy;yacy;Ycirc;ycirc;Ycy;ycy;yen;Yfr;yfr;YIcy;yicy;Yopf;yopf;Yscr;yscr;YUcy;yucy;Yuml;yuml;Zacute;zacute;Zcaron;zcaron;Zcy;zcy;Zdot;zdot;zeetrf;ZeroWidthSpace;Zeta;zeta;Zfr;zfr;ZHcy;zhcy;zigrarr;Zopf;zopf;Zscr;zscr;zwj;zwnj;codepoint# maps HTML4 entity name to the Unicode code point# latin capital letter AE = latin capital ligature AE, U+00C6 ISOlat1# latin capital letter A with acute, U+00C1 ISOlat1# latin capital letter A with circumflex, U+00C2 ISOlat1# latin capital letter A with grave = latin capital letter A grave, U+00C0 ISOlat1# greek capital letter alpha, U+0391# latin capital letter A with ring above = latin capital letter A ring, U+00C5 ISOlat1# latin capital letter A with tilde, U+00C3 ISOlat1# latin capital letter A with diaeresis, U+00C4 ISOlat1# greek capital letter beta, U+0392# latin capital letter C with cedilla, U+00C7 ISOlat1# greek capital letter chi, U+03A7# double dagger, U+2021 ISOpub# greek capital letter delta, U+0394 ISOgrk3# latin capital letter ETH, U+00D0 ISOlat1# latin capital letter E with acute, U+00C9 ISOlat1# latin capital letter E with circumflex, U+00CA ISOlat1# latin capital letter E with grave, U+00C8 ISOlat1# greek capital letter epsilon, U+0395# greek capital letter eta, U+0397# latin capital letter E with diaeresis, U+00CB ISOlat1# greek capital letter gamma, U+0393 ISOgrk3# latin capital letter I with acute, U+00CD ISOlat1# latin capital letter I with circumflex, U+00CE ISOlat1# latin capital letter I with grave, U+00CC ISOlat1# greek capital letter iota, U+0399# latin capital letter I with diaeresis, U+00CF ISOlat1# greek capital letter kappa, U+039A# greek capital letter lambda, U+039B ISOgrk3# greek capital letter mu, U+039C# latin capital letter N with tilde, U+00D1 ISOlat1# greek capital letter nu, U+039D# latin capital ligature OE, U+0152 ISOlat2# latin capital letter O with acute, U+00D3 ISOlat1# latin capital letter O with circumflex, U+00D4 ISOlat1# latin capital letter O with grave, U+00D2 ISOlat1# greek capital letter omega, U+03A9 ISOgrk3# greek capital letter omicron, U+039F# latin capital letter O with stroke = latin capital letter O slash, U+00D8 ISOlat1# latin capital letter O with tilde, U+00D5 ISOlat1# latin capital letter O with diaeresis, U+00D6 ISOlat1# greek capital letter phi, U+03A6 ISOgrk3# greek capital letter pi, U+03A0 ISOgrk3# double prime = seconds = inches, U+2033 ISOtech# greek capital letter psi, U+03A8 ISOgrk3# greek capital letter rho, U+03A1# latin capital letter S with caron, U+0160 ISOlat2# greek capital letter sigma, U+03A3 ISOgrk3# latin capital letter THORN, U+00DE ISOlat1# greek capital letter tau, U+03A4# greek capital letter theta, U+0398 ISOgrk3# latin capital letter U with acute, U+00DA ISOlat1# latin capital letter U with circumflex, U+00DB ISOlat1# latin capital letter U with grave, U+00D9 ISOlat1# greek capital letter upsilon, U+03A5 ISOgrk3# latin capital letter U with diaeresis, U+00DC ISOlat1# greek capital letter xi, U+039E ISOgrk3# latin capital letter Y with acute, U+00DD ISOlat1# latin capital letter Y with diaeresis, U+0178 ISOlat2# greek capital letter zeta, U+0396# latin small letter a with acute, U+00E1 ISOlat1# latin small letter a with circumflex, U+00E2 ISOlat1# acute accent = spacing acute, U+00B4 ISOdia# latin small letter ae = latin small ligature ae, U+00E6 ISOlat1# latin small letter a with grave = latin small letter a grave, U+00E0 ISOlat1# alef symbol = first transfinite cardinal, U+2135 NEW# greek small letter alpha, U+03B1 ISOgrk3# ampersand, U+0026 ISOnum# logical and = wedge, U+2227 ISOtech# angle, U+2220 ISOamso# latin small letter a with ring above = latin small letter a ring, U+00E5 ISOlat1# almost equal to = asymptotic to, U+2248 ISOamsr# latin small letter a with tilde, U+00E3 ISOlat1# latin small letter a with diaeresis, U+00E4 ISOlat1# double low-9 quotation mark, U+201E NEW# greek small letter beta, U+03B2 ISOgrk3# broken bar = broken vertical bar, U+00A6 ISOnum# bullet = black small circle, U+2022 ISOpub# intersection = cap, U+2229 ISOtech# latin small letter c with cedilla, U+00E7 ISOlat1# cedilla = spacing cedilla, U+00B8 ISOdia# cent sign, U+00A2 ISOnum# greek small letter chi, U+03C7 ISOgrk3# modifier letter circumflex accent, U+02C6 ISOpub# black club suit = shamrock, U+2663 ISOpub# approximately equal to, U+2245 ISOtech# copyright sign, U+00A9 ISOnum# downwards arrow with corner leftwards = carriage return, U+21B5 NEW# union = cup, U+222A ISOtech# currency sign, U+00A4 ISOnum# downwards double arrow, U+21D3 ISOamsa# dagger, U+2020 ISOpub# downwards arrow, U+2193 ISOnum# degree sign, U+00B0 ISOnum# greek small letter delta, U+03B4 ISOgrk3# black diamond suit, U+2666 ISOpub# division sign, U+00F7 ISOnum# latin small letter e with acute, U+00E9 ISOlat1# latin small letter e with circumflex, U+00EA ISOlat1# latin small letter e with grave, U+00E8 ISOlat1# empty set = null set = diameter, U+2205 ISOamso# em space, U+2003 ISOpub# en space, U+2002 ISOpub# greek small letter epsilon, U+03B5 ISOgrk3# identical to, U+2261 ISOtech# greek small letter eta, U+03B7 ISOgrk3# latin small letter eth, U+00F0 ISOlat1# latin small letter e with diaeresis, U+00EB ISOlat1# euro sign, U+20AC NEW# there exists, U+2203 ISOtech# latin small f with hook = function = florin, U+0192 ISOtech# for all, U+2200 ISOtech# vulgar fraction one half = fraction one half, U+00BD ISOnum# vulgar fraction one quarter = fraction one quarter, U+00BC ISOnum# vulgar fraction three quarters = fraction three quarters, U+00BE ISOnum# fraction slash, U+2044 NEW# greek small letter gamma, U+03B3 ISOgrk3# greater-than or equal to, U+2265 ISOtech# greater-than sign, U+003E ISOnum# left right double arrow, U+21D4 ISOamsa# left right arrow, U+2194 ISOamsa# black heart suit = valentine, U+2665 ISOpub# horizontal ellipsis = three dot leader, U+2026 ISOpub# latin small letter i with acute, U+00ED ISOlat1# latin small letter i with circumflex, U+00EE ISOlat1# inverted exclamation mark, U+00A1 ISOnum# latin small letter i with grave, U+00EC ISOlat1# blackletter capital I = imaginary part, U+2111 ISOamso# infinity, U+221E ISOtech# integral, U+222B ISOtech# greek small letter iota, U+03B9 ISOgrk3# inverted question mark = turned question mark, U+00BF ISOnum# element of, U+2208 ISOtech# latin small letter i with diaeresis, U+00EF ISOlat1# greek small letter kappa, U+03BA ISOgrk3# leftwards double arrow, U+21D0 ISOtech# greek small letter lambda, U+03BB ISOgrk3# left-pointing angle bracket = bra, U+2329 ISOtech# left-pointing double angle quotation mark = left pointing guillemet, U+00AB ISOnum# leftwards arrow, U+2190 ISOnum# left ceiling = apl upstile, U+2308 ISOamsc# left double quotation mark, U+201C ISOnum# less-than or equal to, U+2264 ISOtech# left floor = apl downstile, U+230A ISOamsc# asterisk operator, U+2217 ISOtech# lozenge, U+25CA ISOpub# left-to-right mark, U+200E NEW RFC 2070# single left-pointing angle quotation mark, U+2039 ISO proposed# left single quotation mark, U+2018 ISOnum# less-than sign, U+003C ISOnum# macron = spacing macron = overline = APL overbar, U+00AF ISOdia# em dash, U+2014 ISOpub# micro sign, U+00B5 ISOnum# middle dot = Georgian comma = Greek middle dot, U+00B7 ISOnum# minus sign, U+2212 ISOtech# greek small letter mu, U+03BC ISOgrk3# nabla = backward difference, U+2207 ISOtech# no-break space = non-breaking space, U+00A0 ISOnum# en dash, U+2013 ISOpub# not equal to, U+2260 ISOtech# contains as member, U+220B ISOtech# not sign, U+00AC ISOnum# not an element of, U+2209 ISOtech# not a subset of, U+2284 ISOamsn# latin small letter n with tilde, U+00F1 ISOlat1# greek small letter nu, U+03BD ISOgrk3# latin small letter o with acute, U+00F3 ISOlat1# latin small letter o with circumflex, U+00F4 ISOlat1# latin small ligature oe, U+0153 ISOlat2# latin small letter o with grave, U+00F2 ISOlat1# overline = spacing overscore, U+203E NEW# greek small letter omega, U+03C9 ISOgrk3# greek small letter omicron, U+03BF NEW# circled plus = direct sum, U+2295 ISOamsb# logical or = vee, U+2228 ISOtech# feminine ordinal indicator, U+00AA ISOnum# masculine ordinal indicator, U+00BA ISOnum# latin small letter o with stroke, = latin small letter o slash, U+00F8 ISOlat1# latin small letter o with tilde, U+00F5 ISOlat1# circled times = vector product, U+2297 ISOamsb# latin small letter o with diaeresis, U+00F6 ISOlat1# pilcrow sign = paragraph sign, U+00B6 ISOnum# partial differential, U+2202 ISOtech# per mille sign, U+2030 ISOtech# up tack = orthogonal to = perpendicular, U+22A5 ISOtech# greek small letter phi, U+03C6 ISOgrk3# greek small letter pi, U+03C0 ISOgrk3# greek pi symbol, U+03D6 ISOgrk3# plus-minus sign = plus-or-minus sign, U+00B1 ISOnum# pound sign, U+00A3 ISOnum# prime = minutes = feet, U+2032 ISOtech# n-ary product = product sign, U+220F ISOamsb# proportional to, U+221D ISOtech# greek small letter psi, U+03C8 ISOgrk3# quotation mark = APL quote, U+0022 ISOnum# rightwards double arrow, U+21D2 ISOtech# square root = radical sign, U+221A ISOtech# right-pointing angle bracket = ket, U+232A ISOtech# right-pointing double angle quotation mark = right pointing guillemet, U+00BB ISOnum# rightwards arrow, U+2192 ISOnum# right ceiling, U+2309 ISOamsc# right double quotation mark, U+201D ISOnum# blackletter capital R = real part symbol, U+211C ISOamso# registered sign = registered trade mark sign, U+00AE ISOnum# right floor, U+230B ISOamsc# greek small letter rho, U+03C1 ISOgrk3# right-to-left mark, U+200F NEW RFC 2070# single right-pointing angle quotation mark, U+203A ISO proposed# right single quotation mark, U+2019 ISOnum# single low-9 quotation mark, U+201A NEW# latin small letter s with caron, U+0161 ISOlat2# dot operator, U+22C5 ISOamsb# section sign, U+00A7 ISOnum# soft hyphen = discretionary hyphen, U+00AD ISOnum# greek small letter sigma, U+03C3 ISOgrk3# greek small letter final sigma, U+03C2 ISOgrk3# tilde operator = varies with = similar to, U+223C ISOtech# black spade suit, U+2660 ISOpub# subset of, U+2282 ISOtech# subset of or equal to, U+2286 ISOtech# n-ary summation, U+2211 ISOamsb# superset of, U+2283 ISOtech# superscript one = superscript digit one, U+00B9 ISOnum# superscript two = superscript digit two = squared, U+00B2 ISOnum# superscript three = superscript digit three = cubed, U+00B3 ISOnum# superset of or equal to, U+2287 ISOtech# latin small letter sharp s = ess-zed, U+00DF ISOlat1# greek small letter tau, U+03C4 ISOgrk3# therefore, U+2234 ISOtech# greek small letter theta, U+03B8 ISOgrk3# greek small letter theta symbol, U+03D1 NEW# thin space, U+2009 ISOpub# latin small letter thorn with, U+00FE ISOlat1# small tilde, U+02DC ISOdia# multiplication sign, U+00D7 ISOnum# trade mark sign, U+2122 ISOnum# upwards double arrow, U+21D1 ISOamsa# latin small letter u with acute, U+00FA ISOlat1# upwards arrow, U+2191 ISOnum# latin small letter u with circumflex, U+00FB ISOlat1# latin small letter u with grave, U+00F9 ISOlat1# diaeresis = spacing diaeresis, U+00A8 ISOdia# greek upsilon with hook symbol, U+03D2 NEW# greek small letter upsilon, U+03C5 ISOgrk3# latin small letter u with diaeresis, U+00FC ISOlat1# script capital P = power set = Weierstrass p, U+2118 ISOamso# greek small letter xi, U+03BE ISOgrk3# latin small letter y with acute, U+00FD ISOlat1# yen sign = yuan sign, U+00A5 ISOnum# latin small letter y with diaeresis, U+00FF ISOlat1# greek small letter zeta, U+03B6 ISOgrk3# zero width joiner, U+200D NEW RFC 2070# zero width non-joiner, U+200C NEW RFC 2070# HTML5 named character references# Generated by Tools/build/parse_html5_entities.py# from https://html.spec.whatwg.org/entities.json and# https://html.spec.whatwg.org/multipage/named-characters.html.# Map HTML5 named character references to the equivalent Unicode character(s).# maps the Unicode code point to the HTML entity name# maps the HTML entity name to the character# (or a character reference if the character is outside the Latin-1 range)b'HTML character entity references.'u'HTML character entity references.'b'html5'u'html5'b'name2codepoint'u'name2codepoint'b'codepoint2name'u'codepoint2name'b'entitydefs'u'entitydefs'b'AElig'u'AElig'b'Aacute'u'Aacute'b'Acirc'u'Acirc'b'Agrave'u'Agrave'b'Alpha'u'Alpha'b'Aring'u'Aring'b'Atilde'u'Atilde'b'Auml'u'Auml'b'Beta'u'Beta'b'Ccedil'u'Ccedil'b'Chi'u'Chi'b'Dagger'u'Dagger'b'Delta'u'Delta'b'ETH'u'ETH'b'Eacute'u'Eacute'b'Ecirc'u'Ecirc'b'Egrave'u'Egrave'b'Epsilon'u'Epsilon'b'Eta'u'Eta'b'Euml'u'Euml'b'Gamma'u'Gamma'b'Iacute'u'Iacute'b'Icirc'u'Icirc'b'Igrave'u'Igrave'b'Iota'u'Iota'b'Iuml'u'Iuml'b'Kappa'u'Kappa'b'Lambda'u'Lambda'b'Mu'u'Mu'b'Ntilde'u'Ntilde'b'Nu'u'Nu'b'OElig'u'OElig'b'Oacute'u'Oacute'b'Ocirc'u'Ocirc'b'Ograve'u'Ograve'b'Omega'u'Omega'b'Omicron'u'Omicron'b'Oslash'u'Oslash'b'Otilde'u'Otilde'b'Ouml'u'Ouml'b'Phi'u'Phi'b'Pi'u'Pi'b'Prime'u'Prime'b'Psi'u'Psi'b'Rho'u'Rho'b'Scaron'u'Scaron'b'Sigma'u'Sigma'b'THORN'u'THORN'b'Tau'u'Tau'b'Theta'u'Theta'b'Uacute'u'Uacute'b'Ucirc'u'Ucirc'b'Ugrave'u'Ugrave'b'Upsilon'u'Upsilon'b'Uuml'u'Uuml'b'Xi'u'Xi'b'Yacute'u'Yacute'b'Yuml'u'Yuml'b'Zeta'u'Zeta'b'aacute'u'aacute'b'acirc'u'acirc'b'acute'u'acute'b'aelig'u'aelig'b'agrave'u'agrave'b'alefsym'u'alefsym'b'amp'u'amp'b'ang'u'ang'b'aring'u'aring'b'asymp'u'asymp'b'atilde'u'atilde'b'auml'u'auml'b'bdquo'u'bdquo'b'brvbar'u'brvbar'b'bull'u'bull'b'cap'u'cap'b'ccedil'u'ccedil'b'cedil'u'cedil'b'cent'u'cent'b'chi'u'chi'b'circ'u'circ'b'clubs'u'clubs'b'cong'u'cong'b'crarr'u'crarr'b'cup'u'cup'b'curren'u'curren'b'dArr'u'dArr'b'dagger'u'dagger'b'darr'u'darr'b'deg'u'deg'b'delta'u'delta'b'diams'u'diams'b'divide'u'divide'b'eacute'u'eacute'b'ecirc'u'ecirc'b'egrave'u'egrave'b'empty'u'empty'b'emsp'u'emsp'b'ensp'u'ensp'b'epsilon'b'equiv'u'equiv'b'eta'u'eta'b'eth'u'eth'b'euml'u'euml'b'euro'u'euro'b'exist'u'exist'b'fnof'u'fnof'b'forall'u'forall'b'frac12'u'frac12'b'frac14'u'frac14'b'frac34'u'frac34'b'frasl'u'frasl'b'gamma'u'gamma'b'ge'u'ge'b'gt'u'gt'b'hArr'u'hArr'b'harr'u'harr'b'hearts'u'hearts'b'hellip'u'hellip'b'iacute'u'iacute'b'icirc'u'icirc'b'iexcl'u'iexcl'b'igrave'u'igrave'b'image'u'image'b'infin'u'infin'b'iota'u'iota'b'iquest'u'iquest'b'isin'u'isin'b'iuml'u'iuml'b'kappa'u'kappa'b'lArr'u'lArr'b'lang'u'lang'b'laquo'u'laquo'b'larr'u'larr'b'lceil'u'lceil'b'ldquo'u'ldquo'b'le'u'le'b'lfloor'u'lfloor'b'lowast'u'lowast'b'loz'u'loz'b'lrm'u'lrm'b'lsaquo'u'lsaquo'b'lsquo'u'lsquo'b'lt'u'lt'b'macr'u'macr'b'mdash'u'mdash'b'micro'b'middot'u'middot'b'minus'u'minus'b'mu'u'mu'b'nabla'u'nabla'b'nbsp'u'nbsp'b'ndash'u'ndash'b'ne'u'ne'b'ni'u'ni'b'notin'u'notin'b'nsub'u'nsub'b'ntilde'u'ntilde'b'nu'u'nu'b'oacute'u'oacute'b'ocirc'u'ocirc'b'oelig'u'oelig'b'ograve'u'ograve'b'oline'u'oline'b'omega'u'omega'b'omicron'u'omicron'b'oplus'u'oplus'b'ordf'u'ordf'b'ordm'u'ordm'b'oslash'u'oslash'b'otilde'u'otilde'b'otimes'u'otimes'b'ouml'u'ouml'b'para'u'para'b'part'u'part'b'permil'u'permil'b'perp'u'perp'b'phi'u'phi'b'pi'u'pi'b'piv'u'piv'b'plusmn'u'plusmn'b'pound'u'pound'b'prime'u'prime'b'prod'u'prod'b'prop'u'prop'b'psi'u'psi'b'quot'u'quot'b'rArr'u'rArr'b'radic'u'radic'b'rang'u'rang'b'raquo'u'raquo'b'rarr'u'rarr'b'rceil'u'rceil'b'rdquo'u'rdquo'b'real'u'real'b'reg'u'reg'b'rfloor'u'rfloor'b'rho'u'rho'b'rlm'u'rlm'b'rsaquo'u'rsaquo'b'rsquo'u'rsquo'b'sbquo'u'sbquo'b'scaron'u'scaron'b'sdot'u'sdot'b'sect'u'sect'b'shy'u'shy'b'sigma'u'sigma'b'sigmaf'u'sigmaf'b'sim'u'sim'b'spades'u'spades'b'sube'u'sube'b'sum'u'sum'b'sup'u'sup'b'sup1'u'sup1'b'sup2'u'sup2'b'sup3'u'sup3'b'supe'u'supe'b'szlig'u'szlig'b'tau'u'tau'b'there4'u'there4'b'theta'u'theta'b'thetasym'u'thetasym'b'thinsp'u'thinsp'b'thorn'u'thorn'b'tilde'u'tilde'b'times'u'times'b'trade'u'trade'b'uArr'u'uArr'b'uacute'u'uacute'b'uarr'u'uarr'b'ucirc'u'ucirc'b'ugrave'u'ugrave'b'uml'u'uml'b'upsih'u'upsih'b'upsilon'u'upsilon'b'uuml'u'uuml'b'weierp'u'weierp'b'xi'u'xi'b'yacute'u'yacute'b'yen'u'yen'b'yuml'u'yuml'b'zeta'u'zeta'b'zwj'u'zwj'b'zwnj'u'zwnj'b''u''b''u''b'Aacute;'u'Aacute;'b'aacute;'u'aacute;'u''b'Abreve;'u'Abreve;'u''b'abreve;'u'abreve;'u''b'ac;'u'ac;'u''b'acd;'u'acd;'u''b'acE;'u'acE;'b''u''b''u''b'Acirc;'u'Acirc;'b'acirc;'u'acirc;'b''u''b'acute;'u'acute;'u''b'Acy;'u'Acy;'u''b'acy;'u'acy;'b''u''b''u''b'AElig;'u'AElig;'b'aelig;'u'aelig;'u''b'af;'u'af;'b'Afr;'u'Afr;'b'afr;'u'afr;'b''u''b''u''b'Agrave;'u'Agrave;'b'agrave;'u'agrave;'u''b'alefsym;'u'alefsym;'b'aleph;'u'aleph;'u''b'Alpha;'u'Alpha;'u''b'alpha;'u'alpha;'u''b'Amacr;'u'Amacr;'u''b'amacr;'u'amacr;'u''b'amalg;'u'amalg;'b'AMP'u'AMP'b'AMP;'u'AMP;'b'amp;'u'amp;'u''b'And;'u'And;'u''b'and;'u'and;'u''b'andand;'u'andand;'u''b'andd;'u'andd;'u''b'andslope;'u'andslope;'u''b'andv;'u'andv;'u''b'ang;'u'ang;'u''b'ange;'u'ange;'b'angle;'u'angle;'u''b'angmsd;'u'angmsd;'u''b'angmsdaa;'u'angmsdaa;'u''b'angmsdab;'u'angmsdab;'u''b'angmsdac;'u'angmsdac;'u''b'angmsdad;'u'angmsdad;'u''b'angmsdae;'u'angmsdae;'u''b'angmsdaf;'u'angmsdaf;'u''b'angmsdag;'u'angmsdag;'u''b'angmsdah;'u'angmsdah;'u''b'angrt;'u'angrt;'u''b'angrtvb;'u'angrtvb;'u''b'angrtvbd;'u'angrtvbd;'u''b'angsph;'u'angsph;'b''u''b'angst;'u'angst;'u''b'angzarr;'u'angzarr;'u''b'Aogon;'u'Aogon;'u''b'aogon;'u'aogon;'b'Aopf;'u'Aopf;'b'aopf;'u'aopf;'u''b'ap;'u'ap;'u''b'apacir;'u'apacir;'u''b'apE;'u'apE;'u''b'ape;'u'ape;'u''b'apid;'u'apid;'b'apos;'u'apos;'b'ApplyFunction;'u'ApplyFunction;'b'approx;'u'approx;'b'approxeq;'u'approxeq;'b''u''b'Aring;'u'Aring;'b'aring;'u'aring;'b'Ascr;'u'Ascr;'b'ascr;'u'ascr;'u''b'Assign;'u'Assign;'b'ast;'u'ast;'b'asymp;'u'asymp;'u''b'asympeq;'u'asympeq;'b''u''b''u''b'Atilde;'u'Atilde;'b'atilde;'u'atilde;'b''u''b''u''b'Auml;'u'Auml;'b'auml;'u'auml;'u''b'awconint;'u'awconint;'u''b'awint;'u'awint;'u''b'backcong;'u'backcong;'u''b'backepsilon;'u'backepsilon;'u''b'backprime;'u'backprime;'u''b'backsim;'u'backsim;'u''b'backsimeq;'u'backsimeq;'u''b'Backslash;'u'Backslash;'u''b'Barv;'u'Barv;'u''b'barvee;'u'barvee;'u''b'Barwed;'u'Barwed;'u''b'barwed;'u'barwed;'b'barwedge;'u'barwedge;'u''b'bbrk;'u'bbrk;'u''b'bbrktbrk;'u'bbrktbrk;'b'bcong;'u'bcong;'u''b'Bcy;'u'Bcy;'u''b'bcy;'u'bcy;'b'bdquo;'u'bdquo;'u''b'becaus;'u'becaus;'b'Because;'u'Because;'b'because;'u'because;'u''b'bemptyv;'u'bemptyv;'b'bepsi;'u'bepsi;'u''b'bernou;'u'bernou;'b'Bernoullis;'u'Bernoullis;'u''b'Beta;'u'Beta;'u''b'beta;'u'beta;'u''b'beth;'u'beth;'u''b'between;'u'between;'b'Bfr;'u'Bfr;'b'bfr;'u'bfr;'u''b'bigcap;'u'bigcap;'u''b'bigcirc;'u'bigcirc;'u''b'bigcup;'u'bigcup;'u''b'bigodot;'u'bigodot;'u''b'bigoplus;'u'bigoplus;'u''b'bigotimes;'u'bigotimes;'u''b'bigsqcup;'u'bigsqcup;'u''b'bigstar;'u'bigstar;'u''b'bigtriangledown;'u'bigtriangledown;'u''b'bigtriangleup;'u'bigtriangleup;'u''b'biguplus;'u'biguplus;'u''b'bigvee;'u'bigvee;'u''b'bigwedge;'u'bigwedge;'u''b'bkarow;'u'bkarow;'u''b'blacklozenge;'u'blacklozenge;'u''b'blacksquare;'u'blacksquare;'u''b'blacktriangle;'u'blacktriangle;'u''b'blacktriangledown;'u'blacktriangledown;'u''b'blacktriangleleft;'u'blacktriangleleft;'u''b'blacktriangleright;'u'blacktriangleright;'u''b'blank;'u'blank;'u''b'blk12;'u'blk12;'u''b'blk14;'u'blk14;'u''b'blk34;'u'blk34;'u''b'block;'u'block;'u'='b'bne;'u'bne;'u''b'bnequiv;'u'bnequiv;'u''b'bNot;'u'bNot;'u''b'bnot;'u'bnot;'b'Bopf;'u'Bopf;'b'bopf;'u'bopf;'u''b'bot;'u'bot;'b'bottom;'u'bottom;'u''b'bowtie;'u'bowtie;'u''b'boxbox;'u'boxbox;'u''b'boxDL;'u'boxDL;'u''b'boxDl;'u'boxDl;'u''b'boxdL;'u'boxdL;'u''b'boxdl;'u'boxdl;'u''b'boxDR;'u'boxDR;'u''b'boxDr;'u'boxDr;'u''b'boxdR;'u'boxdR;'u''b'boxdr;'u'boxdr;'u''b'boxH;'u'boxH;'u''b'boxh;'u'boxh;'u''b'boxHD;'u'boxHD;'u''b'boxHd;'u'boxHd;'u''b'boxhD;'u'boxhD;'u''b'boxhd;'u'boxhd;'u''b'boxHU;'u'boxHU;'u''b'boxHu;'u'boxHu;'u''b'boxhU;'u'boxhU;'u''b'boxhu;'u'boxhu;'u''b'boxminus;'u'boxminus;'u''b'boxplus;'u'boxplus;'u''b'boxtimes;'u'boxtimes;'u''b'boxUL;'u'boxUL;'u''b'boxUl;'u'boxUl;'u''b'boxuL;'u'boxuL;'u''b'boxul;'u'boxul;'u''b'boxUR;'u'boxUR;'u''b'boxUr;'u'boxUr;'u''b'boxuR;'u'boxuR;'u''b'boxur;'u'boxur;'u''b'boxV;'u'boxV;'u''b'boxv;'u'boxv;'u''b'boxVH;'u'boxVH;'u''b'boxVh;'u'boxVh;'u''b'boxvH;'u'boxvH;'u''b'boxvh;'u'boxvh;'u''b'boxVL;'u'boxVL;'u''b'boxVl;'u'boxVl;'u''b'boxvL;'u'boxvL;'u''b'boxvl;'u'boxvl;'u''b'boxVR;'u'boxVR;'u''b'boxVr;'u'boxVr;'u''b'boxvR;'u'boxvR;'u''b'boxvr;'u'boxvr;'b'bprime;'u'bprime;'u''b'Breve;'u'Breve;'b'breve;'u'breve;'b''u''b'brvbar;'u'brvbar;'b'Bscr;'u'Bscr;'b'bscr;'u'bscr;'u''b'bsemi;'u'bsemi;'b'bsim;'u'bsim;'b'bsime;'u'bsime;'b'bsol;'u'bsol;'u''b'bsolb;'u'bsolb;'u''b'bsolhsub;'u'bsolhsub;'b'bull;'u'bull;'b'bullet;'u'bullet;'u''b'bump;'u'bump;'u''b'bumpE;'u'bumpE;'u''b'bumpe;'u'bumpe;'b'Bumpeq;'u'Bumpeq;'b'bumpeq;'u'bumpeq;'u''b'Cacute;'u'Cacute;'u''b'cacute;'u'cacute;'u''b'Cap;'u'Cap;'u''b'cap;'u'cap;'u''b'capand;'u'capand;'u''b'capbrcup;'u'capbrcup;'u''b'capcap;'u'capcap;'u''b'capcup;'u'capcup;'u''b'capdot;'u'capdot;'u''b'CapitalDifferentialD;'u'CapitalDifferentialD;'u''b'caps;'u'caps;'u''b'caret;'u'caret;'u''b'caron;'u'caron;'u''b'Cayleys;'u'Cayleys;'u''b'ccaps;'u'ccaps;'u''b'Ccaron;'u'Ccaron;'u''b'ccaron;'u'ccaron;'b''u''b''u''b'Ccedil;'u'Ccedil;'b'ccedil;'u'ccedil;'u''b'Ccirc;'u'Ccirc;'u''b'ccirc;'u'ccirc;'u''b'Cconint;'u'Cconint;'u''b'ccups;'u'ccups;'u''b'ccupssm;'u'ccupssm;'u''b'Cdot;'u'Cdot;'u''b'cdot;'u'cdot;'b''u''b'cedil;'u'cedil;'b'Cedilla;'u'Cedilla;'u''b'cemptyv;'u'cemptyv;'b''u''b'cent;'u'cent;'b''u''b'CenterDot;'u'CenterDot;'b'centerdot;'u'centerdot;'b'Cfr;'u'Cfr;'b'cfr;'u'cfr;'u''b'CHcy;'u'CHcy;'u''b'chcy;'u'chcy;'u''b'check;'u'check;'b'checkmark;'u'checkmark;'u''b'Chi;'u'Chi;'u''b'chi;'u'chi;'u''b'cir;'u'cir;'b'circ;'u'circ;'u''b'circeq;'u'circeq;'u''b'circlearrowleft;'u'circlearrowleft;'u''b'circlearrowright;'u'circlearrowright;'u''b'circledast;'u'circledast;'u''b'circledcirc;'u'circledcirc;'u''b'circleddash;'u'circleddash;'u''b'CircleDot;'u'CircleDot;'b''u''b'circledR;'u'circledR;'u''b'circledS;'u'circledS;'u''b'CircleMinus;'u'CircleMinus;'u''b'CirclePlus;'u'CirclePlus;'u''b'CircleTimes;'u'CircleTimes;'u''b'cirE;'u'cirE;'b'cire;'u'cire;'u''b'cirfnint;'u'cirfnint;'u''b'cirmid;'u'cirmid;'u''b'cirscir;'u'cirscir;'u''b'ClockwiseContourIntegral;'u'ClockwiseContourIntegral;'b'CloseCurlyDoubleQuote;'u'CloseCurlyDoubleQuote;'b'CloseCurlyQuote;'u'CloseCurlyQuote;'u''b'clubs;'u'clubs;'b'clubsuit;'u'clubsuit;'u''b'Colon;'u'Colon;'b'colon;'u'colon;'u''b'Colone;'u'Colone;'b'colone;'u'colone;'b'coloneq;'u'coloneq;'b'comma;'u'comma;'b'commat;'u'commat;'u''b'comp;'u'comp;'u''b'compfn;'u'compfn;'b'complement;'u'complement;'u''b'complexes;'u'complexes;'u''b'cong;'u'cong;'u''b'congdot;'u'congdot;'u''b'Congruent;'u'Congruent;'u''b'Conint;'u'Conint;'u''b'conint;'u'conint;'b'ContourIntegral;'u'ContourIntegral;'b'Copf;'u'Copf;'b'copf;'u'copf;'u''b'coprod;'u'coprod;'b'Coproduct;'u'Coproduct;'b''u''b'COPY'u'COPY'b'COPY;'u'COPY;'b'copy;'u'copy;'u''b'copysr;'u'copysr;'b'CounterClockwiseContourIntegral;'u'CounterClockwiseContourIntegral;'u''b'crarr;'u'crarr;'u''b'Cross;'u'Cross;'u''b'cross;'u'cross;'b'Cscr;'u'Cscr;'b'cscr;'u'cscr;'u''b'csub;'u'csub;'u''b'csube;'u'csube;'u''b'csup;'u'csup;'u''b'csupe;'u'csupe;'u''b'ctdot;'u'ctdot;'u''b'cudarrl;'u'cudarrl;'u''b'cudarrr;'u'cudarrr;'u''b'cuepr;'u'cuepr;'u''b'cuesc;'u'cuesc;'u''b'cularr;'u'cularr;'u''b'cularrp;'u'cularrp;'u''b'Cup;'u'Cup;'u''b'cup;'u'cup;'u''b'cupbrcap;'u'cupbrcap;'b'CupCap;'u'CupCap;'u''b'cupcap;'u'cupcap;'u''b'cupcup;'u'cupcup;'u''b'cupdot;'u'cupdot;'u''b'cupor;'u'cupor;'u''b'cups;'u'cups;'u''b'curarr;'u'curarr;'u''b'curarrm;'u'curarrm;'b'curlyeqprec;'u'curlyeqprec;'b'curlyeqsucc;'u'curlyeqsucc;'u''b'curlyvee;'u'curlyvee;'u''b'curlywedge;'u'curlywedge;'b''u''b'curren;'u'curren;'b'curvearrowleft;'u'curvearrowleft;'b'curvearrowright;'u'curvearrowright;'b'cuvee;'u'cuvee;'b'cuwed;'u'cuwed;'b'cwconint;'u'cwconint;'u''b'cwint;'u'cwint;'u''b'cylcty;'u'cylcty;'b'Dagger;'u'Dagger;'b'dagger;'u'dagger;'u''b'daleth;'u'daleth;'u''b'Darr;'u'Darr;'u''b'dArr;'u'dArr;'u''b'darr;'u'darr;'u''b'dash;'u'dash;'u''b'Dashv;'u'Dashv;'u''b'dashv;'u'dashv;'u''b'dbkarow;'u'dbkarow;'u''b'dblac;'u'dblac;'u''b'Dcaron;'u'Dcaron;'u''b'dcaron;'u'dcaron;'u''b'Dcy;'u'Dcy;'u''b'dcy;'u'dcy;'b'DD;'u'DD;'u''b'dd;'u'dd;'b'ddagger;'u'ddagger;'u''b'ddarr;'u'ddarr;'u''b'DDotrahd;'u'DDotrahd;'u''b'ddotseq;'u'ddotseq;'b''u''b'deg;'u'deg;'u''b'Del;'u'Del;'u''b'Delta;'u'Delta;'u''b'delta;'u'delta;'u''b'demptyv;'u'demptyv;'u''b'dfisht;'u'dfisht;'b'Dfr;'u'Dfr;'b'dfr;'u'dfr;'u''b'dHar;'u'dHar;'u''b'dharl;'u'dharl;'u''b'dharr;'u'dharr;'b'DiacriticalAcute;'u'DiacriticalAcute;'u''b'DiacriticalDot;'u'DiacriticalDot;'b'DiacriticalDoubleAcute;'u'DiacriticalDoubleAcute;'b'`'u'`'b'DiacriticalGrave;'u'DiacriticalGrave;'b'DiacriticalTilde;'u'DiacriticalTilde;'u''b'diam;'u'diam;'b'Diamond;'u'Diamond;'b'diamond;'u'diamond;'u''b'diamondsuit;'u'diamondsuit;'b'diams;'u'diams;'b''u''b'die;'u'die;'b'DifferentialD;'u'DifferentialD;'u''b'digamma;'u'digamma;'u''b'disin;'u'disin;'b''u''b'div;'u'div;'b'divide;'u'divide;'u''b'divideontimes;'u'divideontimes;'b'divonx;'u'divonx;'u''b'DJcy;'u'DJcy;'u''b'djcy;'u'djcy;'u''b'dlcorn;'u'dlcorn;'u''b'dlcrop;'u'dlcrop;'b'dollar;'u'dollar;'b'Dopf;'u'Dopf;'b'dopf;'u'dopf;'b'Dot;'u'Dot;'b'dot;'u'dot;'u''b'DotDot;'u'DotDot;'u''b'doteq;'u'doteq;'u''b'doteqdot;'u'doteqdot;'b'DotEqual;'u'DotEqual;'u''b'dotminus;'u'dotminus;'u''b'dotplus;'u'dotplus;'u''b'dotsquare;'u'dotsquare;'b'doublebarwedge;'u'doublebarwedge;'b'DoubleContourIntegral;'u'DoubleContourIntegral;'b'DoubleDot;'u'DoubleDot;'b'DoubleDownArrow;'u'DoubleDownArrow;'u''b'DoubleLeftArrow;'u'DoubleLeftArrow;'u''b'DoubleLeftRightArrow;'u'DoubleLeftRightArrow;'b'DoubleLeftTee;'u'DoubleLeftTee;'u''b'DoubleLongLeftArrow;'u'DoubleLongLeftArrow;'u''b'DoubleLongLeftRightArrow;'u'DoubleLongLeftRightArrow;'u''b'DoubleLongRightArrow;'u'DoubleLongRightArrow;'u''b'DoubleRightArrow;'u'DoubleRightArrow;'u''b'DoubleRightTee;'u'DoubleRightTee;'u''b'DoubleUpArrow;'u'DoubleUpArrow;'u''b'DoubleUpDownArrow;'u'DoubleUpDownArrow;'u''b'DoubleVerticalBar;'u'DoubleVerticalBar;'b'DownArrow;'u'DownArrow;'b'Downarrow;'u'Downarrow;'b'downarrow;'u'downarrow;'u''b'DownArrowBar;'u'DownArrowBar;'u''b'DownArrowUpArrow;'u'DownArrowUpArrow;'u''b'DownBreve;'u'DownBreve;'b'downdownarrows;'u'downdownarrows;'b'downharpoonleft;'u'downharpoonleft;'b'downharpoonright;'u'downharpoonright;'u''b'DownLeftRightVector;'u'DownLeftRightVector;'u''b'DownLeftTeeVector;'u'DownLeftTeeVector;'u''b'DownLeftVector;'u'DownLeftVector;'u''b'DownLeftVectorBar;'u'DownLeftVectorBar;'u''b'DownRightTeeVector;'u'DownRightTeeVector;'u''b'DownRightVector;'u'DownRightVector;'u''b'DownRightVectorBar;'u'DownRightVectorBar;'u''b'DownTee;'u'DownTee;'u''b'DownTeeArrow;'u'DownTeeArrow;'u''b'drbkarow;'u'drbkarow;'u''b'drcorn;'u'drcorn;'u''b'drcrop;'u'drcrop;'b'Dscr;'u'Dscr;'b'dscr;'u'dscr;'u''b'DScy;'u'DScy;'u''b'dscy;'u'dscy;'u''b'dsol;'u'dsol;'u''b'Dstrok;'u'Dstrok;'u''b'dstrok;'u'dstrok;'u''b'dtdot;'u'dtdot;'u''b'dtri;'u'dtri;'b'dtrif;'u'dtrif;'b'duarr;'u'duarr;'u''b'duhar;'u'duhar;'u''b'dwangle;'u'dwangle;'u''b'DZcy;'u'DZcy;'u''b'dzcy;'u'dzcy;'u''b'dzigrarr;'u'dzigrarr;'b''u''b''u''b'Eacute;'u'Eacute;'b'eacute;'u'eacute;'u''b'easter;'u'easter;'u''b'Ecaron;'u'Ecaron;'u''b'ecaron;'u'ecaron;'u''b'ecir;'u'ecir;'b''u''b''u''b'Ecirc;'u'Ecirc;'b'ecirc;'u'ecirc;'u''b'ecolon;'u'ecolon;'u''b'Ecy;'u'Ecy;'u''b'ecy;'u'ecy;'b'eDDot;'u'eDDot;'u''b'Edot;'u'Edot;'b'eDot;'u'eDot;'u''b'edot;'u'edot;'u''b'ee;'u'ee;'u''b'efDot;'u'efDot;'b'Efr;'u'Efr;'b'efr;'u'efr;'u''b'eg;'u'eg;'b''u''b''u''b'Egrave;'u'Egrave;'b'egrave;'u'egrave;'u''b'egs;'u'egs;'u''b'egsdot;'u'egsdot;'u''b'el;'u'el;'u''b'Element;'u'Element;'u''b'elinters;'u'elinters;'u''b'ell;'u'ell;'u''b'els;'u'els;'u''b'elsdot;'u'elsdot;'u''b'Emacr;'u'Emacr;'u''b'emacr;'u'emacr;'u''b'empty;'u'empty;'b'emptyset;'u'emptyset;'u''b'EmptySmallSquare;'u'EmptySmallSquare;'b'emptyv;'u'emptyv;'u''b'EmptyVerySmallSquare;'u'EmptyVerySmallSquare;'u''b'emsp13;'u'emsp13;'u''b'emsp14;'u'emsp14;'u''b'emsp;'u'emsp;'u''b'ENG;'u'ENG;'u''b'eng;'u'eng;'u''b'ensp;'u'ensp;'u''b'Eogon;'u'Eogon;'u''b'eogon;'u'eogon;'b'Eopf;'u'Eopf;'b'eopf;'u'eopf;'u''b'epar;'u'epar;'u''b'eparsl;'u'eparsl;'u''b'eplus;'u'eplus;'u''b'epsi;'u'epsi;'u''b'Epsilon;'u'Epsilon;'b'epsilon;'u'epsilon;'u''b'epsiv;'u'epsiv;'b'eqcirc;'u'eqcirc;'b'eqcolon;'u'eqcolon;'u''b'eqsim;'u'eqsim;'b'eqslantgtr;'u'eqslantgtr;'b'eqslantless;'u'eqslantless;'u''b'Equal;'u'Equal;'b'equals;'u'equals;'b'EqualTilde;'u'EqualTilde;'u''b'equest;'u'equest;'u''b'Equilibrium;'u'Equilibrium;'b'equiv;'u'equiv;'u''b'equivDD;'u'equivDD;'u''b'eqvparsl;'u'eqvparsl;'u''b'erarr;'u'erarr;'u''b'erDot;'u'erDot;'u''b'Escr;'u'Escr;'u''b'escr;'u'escr;'b'esdot;'u'esdot;'u''b'Esim;'u'Esim;'b'esim;'u'esim;'u''b'Eta;'u'Eta;'u''b'eta;'u'eta;'b''u''b''u''b'ETH;'u'ETH;'b'eth;'u'eth;'b''u''b''u''b'Euml;'u'Euml;'b'euml;'u'euml;'b'euro;'u'euro;'b'excl;'u'excl;'u''b'exist;'u'exist;'b'Exists;'u'Exists;'b'expectation;'u'expectation;'b'ExponentialE;'u'ExponentialE;'b'exponentiale;'u'exponentiale;'b'fallingdotseq;'u'fallingdotseq;'u''b'Fcy;'u'Fcy;'u''b'fcy;'u'fcy;'u''b'female;'u'female;'u''b'ffilig;'u'ffilig;'u''b'fflig;'u'fflig;'u''b'ffllig;'u'ffllig;'b'Ffr;'u'Ffr;'b'ffr;'u'ffr;'u''b'filig;'u'filig;'u''b'FilledSmallSquare;'u'FilledSmallSquare;'b'FilledVerySmallSquare;'u'FilledVerySmallSquare;'b'fj'u'fj'b'fjlig;'u'fjlig;'u''b'flat;'u'flat;'u''b'fllig;'u'fllig;'u''b'fltns;'u'fltns;'b'fnof;'u'fnof;'b'Fopf;'u'Fopf;'b'fopf;'u'fopf;'u''b'ForAll;'u'ForAll;'b'forall;'u'forall;'u''b'fork;'u'fork;'u''b'forkv;'u'forkv;'u''b'Fouriertrf;'u'Fouriertrf;'u''b'fpartint;'u'fpartint;'b''u''b'frac12;'u'frac12;'u''b'frac13;'u'frac13;'b''u''b'frac14;'u'frac14;'u''b'frac15;'u'frac15;'u''b'frac16;'u'frac16;'u''b'frac18;'u'frac18;'u''b'frac23;'u'frac23;'u''b'frac25;'u'frac25;'b''u''b'frac34;'u'frac34;'u''b'frac35;'u'frac35;'u''b'frac38;'u'frac38;'u''b'frac45;'u'frac45;'u''b'frac56;'u'frac56;'u''b'frac58;'u'frac58;'u''b'frac78;'u'frac78;'u''b'frasl;'u'frasl;'u''b'frown;'u'frown;'b'Fscr;'u'Fscr;'b'fscr;'u'fscr;'u''b'gacute;'u'gacute;'u''b'Gamma;'u'Gamma;'u''b'gamma;'u'gamma;'u''b'Gammad;'u'Gammad;'b'gammad;'u'gammad;'u''b'gap;'u'gap;'u''b'Gbreve;'u'Gbreve;'u''b'gbreve;'u'gbreve;'u''b'Gcedil;'u'Gcedil;'u''b'Gcirc;'u'Gcirc;'u''b'gcirc;'u'gcirc;'u''b'Gcy;'u'Gcy;'u''b'gcy;'u'gcy;'u''b'Gdot;'u'Gdot;'u''b'gdot;'u'gdot;'u''b'gE;'u'gE;'u''b'ge;'u'ge;'u''b'gEl;'u'gEl;'u''b'gel;'u'gel;'b'geq;'u'geq;'b'geqq;'u'geqq;'u''b'geqslant;'u'geqslant;'b'ges;'u'ges;'u''b'gescc;'u'gescc;'u''b'gesdot;'u'gesdot;'u''b'gesdoto;'u'gesdoto;'u''b'gesdotol;'u'gesdotol;'u''b'gesl;'u'gesl;'u''b'gesles;'u'gesles;'b'Gfr;'u'Gfr;'b'gfr;'u'gfr;'u''b'Gg;'u'Gg;'u''b'gg;'u'gg;'b'ggg;'u'ggg;'u''b'gimel;'u'gimel;'u''b'GJcy;'u'GJcy;'u''b'gjcy;'u'gjcy;'u''b'gl;'u'gl;'u''b'gla;'u'gla;'u''b'glE;'u'glE;'u''b'glj;'u'glj;'u''b'gnap;'u'gnap;'b'gnapprox;'u'gnapprox;'u''b'gnE;'u'gnE;'u''b'gne;'u'gne;'b'gneq;'u'gneq;'b'gneqq;'u'gneqq;'u''b'gnsim;'u'gnsim;'b'Gopf;'u'Gopf;'b'gopf;'u'gopf;'b'grave;'u'grave;'b'GreaterEqual;'u'GreaterEqual;'b'GreaterEqualLess;'u'GreaterEqualLess;'b'GreaterFullEqual;'u'GreaterFullEqual;'u''b'GreaterGreater;'u'GreaterGreater;'b'GreaterLess;'u'GreaterLess;'b'GreaterSlantEqual;'u'GreaterSlantEqual;'u''b'GreaterTilde;'u'GreaterTilde;'b'Gscr;'u'Gscr;'u''b'gscr;'u'gscr;'b'gsim;'u'gsim;'u''b'gsime;'u'gsime;'u''b'gsiml;'u'gsiml;'b'GT'u'GT'b'GT;'u'GT;'b'Gt;'u'Gt;'b'gt;'u'gt;'u''b'gtcc;'u'gtcc;'u''b'gtcir;'u'gtcir;'u''b'gtdot;'u'gtdot;'u''b'gtlPar;'u'gtlPar;'u''b'gtquest;'u'gtquest;'b'gtrapprox;'u'gtrapprox;'u''b'gtrarr;'u'gtrarr;'b'gtrdot;'u'gtrdot;'b'gtreqless;'u'gtreqless;'b'gtreqqless;'u'gtreqqless;'b'gtrless;'u'gtrless;'b'gtrsim;'u'gtrsim;'u''b'gvertneqq;'u'gvertneqq;'b'gvnE;'u'gvnE;'b'Hacek;'u'Hacek;'u''b'hairsp;'u'hairsp;'b'half;'u'half;'u''b'hamilt;'u'hamilt;'u''b'HARDcy;'u'HARDcy;'u''b'hardcy;'u'hardcy;'b'hArr;'u'hArr;'u''b'harr;'u'harr;'u''b'harrcir;'u'harrcir;'u''b'harrw;'u'harrw;'b'Hat;'u'Hat;'u''b'hbar;'u'hbar;'u''b'Hcirc;'u'Hcirc;'u''b'hcirc;'u'hcirc;'u''b'hearts;'u'hearts;'b'heartsuit;'u'heartsuit;'b'hellip;'u'hellip;'u''b'hercon;'u'hercon;'u''b'Hfr;'u'Hfr;'b'hfr;'u'hfr;'b'HilbertSpace;'u'HilbertSpace;'u''b'hksearow;'u'hksearow;'u''b'hkswarow;'u'hkswarow;'u''b'hoarr;'u'hoarr;'u''b'homtht;'u'homtht;'u''b'hookleftarrow;'u'hookleftarrow;'u''b'hookrightarrow;'u'hookrightarrow;'u''b'Hopf;'u'Hopf;'b'hopf;'u'hopf;'u''b'horbar;'u'horbar;'b'HorizontalLine;'u'HorizontalLine;'b'Hscr;'u'Hscr;'b'hscr;'u'hscr;'b'hslash;'u'hslash;'u''b'Hstrok;'u'Hstrok;'u''b'hstrok;'u'hstrok;'b'HumpDownHump;'u'HumpDownHump;'b'HumpEqual;'u'HumpEqual;'u''b'hybull;'u'hybull;'b'hyphen;'u'hyphen;'b''u''b''u''b'Iacute;'u'Iacute;'b'iacute;'u'iacute;'u''b'ic;'u'ic;'b''u''b''u''b'Icirc;'u'Icirc;'b'icirc;'u'icirc;'u''b'Icy;'u'Icy;'u''b'icy;'u'icy;'u''b'Idot;'u'Idot;'u''b'IEcy;'u'IEcy;'u''b'iecy;'u'iecy;'b''u''b'iexcl;'u'iexcl;'b'iff;'u'iff;'u''b'Ifr;'u'Ifr;'b'ifr;'u'ifr;'b''u''b''u''b'Igrave;'u'Igrave;'b'igrave;'u'igrave;'u''b'ii;'u'ii;'u''b'iiiint;'u'iiiint;'u''b'iiint;'u'iiint;'u''b'iinfin;'u'iinfin;'u''b'iiota;'u'iiota;'u''b'IJlig;'u'IJlig;'u''b'ijlig;'u'ijlig;'b'Im;'u'Im;'u''b'Imacr;'u'Imacr;'u''b'imacr;'u'imacr;'b'image;'u'image;'b'ImaginaryI;'u'ImaginaryI;'u''b'imagline;'u'imagline;'b'imagpart;'u'imagpart;'u''b'imath;'u'imath;'u''b'imof;'u'imof;'u''b'imped;'u'imped;'b'Implies;'u'Implies;'b'in;'u'in;'u''b'incare;'u'incare;'u''b'infin;'u'infin;'u''b'infintie;'u'infintie;'b'inodot;'u'inodot;'u''b'Int;'u'Int;'u''b'int;'u'int;'u''b'intcal;'u'intcal;'u''b'integers;'u'integers;'b'Integral;'u'Integral;'b'intercal;'u'intercal;'b'Intersection;'u'Intersection;'u''b'intlarhk;'u'intlarhk;'u''b'intprod;'u'intprod;'b'InvisibleComma;'u'InvisibleComma;'u''b'InvisibleTimes;'u'InvisibleTimes;'u''b'IOcy;'u'IOcy;'u''b'iocy;'u'iocy;'u''b'Iogon;'u'Iogon;'u''b'iogon;'u'iogon;'b'Iopf;'u'Iopf;'b'iopf;'u'iopf;'u''b'Iota;'u'Iota;'u''b'iota;'u'iota;'b'iprod;'u'iprod;'b''u''b'iquest;'u'iquest;'b'Iscr;'u'Iscr;'b'iscr;'u'iscr;'b'isin;'u'isin;'u''b'isindot;'u'isindot;'u''b'isinE;'u'isinE;'u''b'isins;'u'isins;'u''b'isinsv;'u'isinsv;'b'isinv;'u'isinv;'b'it;'u'it;'u''b'Itilde;'u'Itilde;'u''b'itilde;'u'itilde;'u''b'Iukcy;'u'Iukcy;'u''b'iukcy;'u'iukcy;'b''u''b''u''b'Iuml;'u'Iuml;'b'iuml;'u'iuml;'u''b'Jcirc;'u'Jcirc;'u''b'jcirc;'u'jcirc;'u''b'Jcy;'u'Jcy;'u''b'jcy;'u'jcy;'b'Jfr;'u'Jfr;'b'jfr;'u'jfr;'u''b'jmath;'u'jmath;'b'Jopf;'u'Jopf;'b'jopf;'u'jopf;'b'Jscr;'u'Jscr;'b'jscr;'u'jscr;'u''b'Jsercy;'u'Jsercy;'u''b'jsercy;'u'jsercy;'u''b'Jukcy;'u'Jukcy;'u''b'jukcy;'u'jukcy;'u''b'Kappa;'u'Kappa;'u''b'kappa;'u'kappa;'u''b'kappav;'u'kappav;'u''b'Kcedil;'u'Kcedil;'u''b'kcedil;'u'kcedil;'u''b'Kcy;'u'Kcy;'u''b'kcy;'u'kcy;'b'Kfr;'u'Kfr;'b'kfr;'u'kfr;'u''b'kgreen;'u'kgreen;'u''b'KHcy;'u'KHcy;'u''b'khcy;'u'khcy;'u''b'KJcy;'u'KJcy;'u''b'kjcy;'u'kjcy;'b'Kopf;'u'Kopf;'b'kopf;'u'kopf;'b'Kscr;'u'Kscr;'b'kscr;'u'kscr;'u''b'lAarr;'u'lAarr;'u''b'Lacute;'u'Lacute;'u''b'lacute;'u'lacute;'u''b'laemptyv;'u'laemptyv;'u''b'lagran;'u'lagran;'u''b'Lambda;'u'Lambda;'u''b'lambda;'u'lambda;'u''b'Lang;'u'Lang;'u''b'lang;'u'lang;'u''b'langd;'u'langd;'b'langle;'u'langle;'u''b'lap;'u'lap;'b'Laplacetrf;'u'Laplacetrf;'b''u''b'laquo;'u'laquo;'u''b'Larr;'u'Larr;'b'lArr;'u'lArr;'u''b'larr;'u'larr;'u''b'larrb;'u'larrb;'u''b'larrbfs;'u'larrbfs;'u''b'larrfs;'u'larrfs;'b'larrhk;'u'larrhk;'u''b'larrlp;'u'larrlp;'u''b'larrpl;'u'larrpl;'u''b'larrsim;'u'larrsim;'u''b'larrtl;'u'larrtl;'u''b'lat;'u'lat;'u''b'lAtail;'u'lAtail;'u''b'latail;'u'latail;'u''b'late;'u'late;'u''b'lates;'u'lates;'u''b'lBarr;'u'lBarr;'u''b'lbarr;'u'lbarr;'u''b'lbbrk;'u'lbbrk;'b'lbrace;'u'lbrace;'b'lbrack;'u'lbrack;'u''b'lbrke;'u'lbrke;'u''b'lbrksld;'u'lbrksld;'u''b'lbrkslu;'u'lbrkslu;'u''b'Lcaron;'u'Lcaron;'u''b'lcaron;'u'lcaron;'u''b'Lcedil;'u'Lcedil;'u''b'lcedil;'u'lcedil;'u''b'lceil;'u'lceil;'b'lcub;'u'lcub;'u''b'Lcy;'u'Lcy;'u''b'lcy;'u'lcy;'u''b'ldca;'u'ldca;'b'ldquo;'u'ldquo;'b'ldquor;'u'ldquor;'u''b'ldrdhar;'u'ldrdhar;'u''b'ldrushar;'u'ldrushar;'u''b'ldsh;'u'ldsh;'u''b'lE;'u'lE;'u''b'le;'u'le;'b'LeftAngleBracket;'u'LeftAngleBracket;'b'LeftArrow;'u'LeftArrow;'b'Leftarrow;'u'Leftarrow;'b'leftarrow;'u'leftarrow;'b'LeftArrowBar;'u'LeftArrowBar;'u''b'LeftArrowRightArrow;'u'LeftArrowRightArrow;'b'leftarrowtail;'u'leftarrowtail;'b'LeftCeiling;'u'LeftCeiling;'u''b'LeftDoubleBracket;'u'LeftDoubleBracket;'u''b'LeftDownTeeVector;'u'LeftDownTeeVector;'b'LeftDownVector;'u'LeftDownVector;'u''b'LeftDownVectorBar;'u'LeftDownVectorBar;'u''b'LeftFloor;'u'LeftFloor;'b'leftharpoondown;'u'leftharpoondown;'u''b'leftharpoonup;'u'leftharpoonup;'u''b'leftleftarrows;'u'leftleftarrows;'b'LeftRightArrow;'u'LeftRightArrow;'b'Leftrightarrow;'u'Leftrightarrow;'b'leftrightarrow;'u'leftrightarrow;'b'leftrightarrows;'u'leftrightarrows;'u''b'leftrightharpoons;'u'leftrightharpoons;'b'leftrightsquigarrow;'u'leftrightsquigarrow;'u''b'LeftRightVector;'u'LeftRightVector;'b'LeftTee;'u'LeftTee;'u''b'LeftTeeArrow;'u'LeftTeeArrow;'u''b'LeftTeeVector;'u'LeftTeeVector;'u''b'leftthreetimes;'u'leftthreetimes;'u''b'LeftTriangle;'u'LeftTriangle;'u''b'LeftTriangleBar;'u'LeftTriangleBar;'u''b'LeftTriangleEqual;'u'LeftTriangleEqual;'u''b'LeftUpDownVector;'u'LeftUpDownVector;'u''b'LeftUpTeeVector;'u'LeftUpTeeVector;'u''b'LeftUpVector;'u'LeftUpVector;'u''b'LeftUpVectorBar;'u'LeftUpVectorBar;'b'LeftVector;'u'LeftVector;'u''b'LeftVectorBar;'u'LeftVectorBar;'u''b'lEg;'u'lEg;'u''b'leg;'u'leg;'b'leq;'u'leq;'b'leqq;'u'leqq;'u''b'leqslant;'u'leqslant;'b'les;'u'les;'u''b'lescc;'u'lescc;'u''b'lesdot;'u'lesdot;'u''b'lesdoto;'u'lesdoto;'u''b'lesdotor;'u'lesdotor;'u''b'lesg;'u'lesg;'u''b'lesges;'u'lesges;'b'lessapprox;'u'lessapprox;'u''b'lessdot;'u'lessdot;'b'lesseqgtr;'u'lesseqgtr;'b'lesseqqgtr;'u'lesseqqgtr;'b'LessEqualGreater;'u'LessEqualGreater;'b'LessFullEqual;'u'LessFullEqual;'u''b'LessGreater;'u'LessGreater;'b'lessgtr;'u'lessgtr;'u''b'LessLess;'u'LessLess;'u''b'lesssim;'u'lesssim;'b'LessSlantEqual;'u'LessSlantEqual;'b'LessTilde;'u'LessTilde;'u''b'lfisht;'u'lfisht;'b'lfloor;'u'lfloor;'b'Lfr;'u'Lfr;'b'lfr;'u'lfr;'b'lg;'u'lg;'u''b'lgE;'u'lgE;'u''b'lHar;'u'lHar;'b'lhard;'u'lhard;'b'lharu;'u'lharu;'u''b'lharul;'u'lharul;'u''b'lhblk;'u'lhblk;'u''b'LJcy;'u'LJcy;'u''b'ljcy;'u'ljcy;'u''b'Ll;'u'Ll;'u''b'll;'u'll;'b'llarr;'u'llarr;'b'llcorner;'u'llcorner;'b'Lleftarrow;'u'Lleftarrow;'u''b'llhard;'u'llhard;'u''b'lltri;'u'lltri;'u''b'Lmidot;'u'Lmidot;'u''b'lmidot;'u'lmidot;'u''b'lmoust;'u'lmoust;'b'lmoustache;'u'lmoustache;'u''b'lnap;'u'lnap;'b'lnapprox;'u'lnapprox;'u''b'lnE;'u'lnE;'u''b'lne;'u'lne;'b'lneq;'u'lneq;'b'lneqq;'u'lneqq;'u''b'lnsim;'u'lnsim;'u''b'loang;'u'loang;'u''b'loarr;'u'loarr;'b'lobrk;'u'lobrk;'u''b'LongLeftArrow;'u'LongLeftArrow;'b'Longleftarrow;'u'Longleftarrow;'b'longleftarrow;'u'longleftarrow;'u''b'LongLeftRightArrow;'u'LongLeftRightArrow;'b'Longleftrightarrow;'u'Longleftrightarrow;'b'longleftrightarrow;'u'longleftrightarrow;'u''b'longmapsto;'u'longmapsto;'u''b'LongRightArrow;'u'LongRightArrow;'b'Longrightarrow;'u'Longrightarrow;'b'longrightarrow;'u'longrightarrow;'b'looparrowleft;'u'looparrowleft;'u''b'looparrowright;'u'looparrowright;'u''b'lopar;'u'lopar;'b'Lopf;'u'Lopf;'b'lopf;'u'lopf;'u''b'loplus;'u'loplus;'u''b'lotimes;'u'lotimes;'u''b'lowast;'u'lowast;'b'lowbar;'u'lowbar;'u''b'LowerLeftArrow;'u'LowerLeftArrow;'u''b'LowerRightArrow;'u'LowerRightArrow;'u''b'loz;'u'loz;'b'lozenge;'u'lozenge;'b'lozf;'u'lozf;'b'lpar;'u'lpar;'u''b'lparlt;'u'lparlt;'b'lrarr;'u'lrarr;'b'lrcorner;'u'lrcorner;'b'lrhar;'u'lrhar;'u''b'lrhard;'u'lrhard;'u''b'lrm;'u'lrm;'u''b'lrtri;'u'lrtri;'b'lsaquo;'u'lsaquo;'b'Lscr;'u'Lscr;'b'lscr;'u'lscr;'u''b'Lsh;'u'Lsh;'b'lsh;'u'lsh;'b'lsim;'u'lsim;'u''b'lsime;'u'lsime;'u''b'lsimg;'u'lsimg;'b'lsqb;'u'lsqb;'b'lsquo;'u'lsquo;'b'lsquor;'u'lsquor;'u''b'Lstrok;'u'Lstrok;'u''b'lstrok;'u'lstrok;'b'LT'u'LT'b'LT;'u'LT;'b'Lt;'u'Lt;'b'lt;'u'lt;'u''b'ltcc;'u'ltcc;'u''b'ltcir;'u'ltcir;'b'ltdot;'u'ltdot;'b'lthree;'u'lthree;'u''b'ltimes;'u'ltimes;'u''b'ltlarr;'u'ltlarr;'u''b'ltquest;'u'ltquest;'u''b'ltri;'u'ltri;'b'ltrie;'u'ltrie;'b'ltrif;'u'ltrif;'u''b'ltrPar;'u'ltrPar;'u''b'lurdshar;'u'lurdshar;'u''b'luruhar;'u'luruhar;'u''b'lvertneqq;'u'lvertneqq;'b'lvnE;'u'lvnE;'b''u''b'macr;'u'macr;'u''b'male;'u'male;'u''b'malt;'u'malt;'b'maltese;'u'maltese;'u''b'Map;'u'Map;'u''b'map;'u'map;'b'mapsto;'u'mapsto;'b'mapstodown;'u'mapstodown;'b'mapstoleft;'u'mapstoleft;'u''b'mapstoup;'u'mapstoup;'u''b'marker;'u'marker;'u''b'mcomma;'u'mcomma;'u''b'Mcy;'u'Mcy;'u''b'mcy;'u'mcy;'b'mdash;'u'mdash;'u''b'mDDot;'u'mDDot;'b'measuredangle;'u'measuredangle;'u''b'MediumSpace;'u'MediumSpace;'u''b'Mellintrf;'u'Mellintrf;'b'Mfr;'u'Mfr;'b'mfr;'u'mfr;'u''b'mho;'u'mho;'b''u''b'micro;'u'micro;'u''b'mid;'u'mid;'b'midast;'u'midast;'u''b'midcir;'u'midcir;'b'middot;'u'middot;'u''b'minus;'u'minus;'b'minusb;'u'minusb;'b'minusd;'u'minusd;'u''b'minusdu;'u'minusdu;'u''b'MinusPlus;'u'MinusPlus;'u''b'mlcp;'u'mlcp;'b'mldr;'u'mldr;'b'mnplus;'u'mnplus;'u''b'models;'u'models;'b'Mopf;'u'Mopf;'b'mopf;'u'mopf;'b'mp;'u'mp;'b'Mscr;'u'Mscr;'b'mscr;'u'mscr;'b'mstpos;'u'mstpos;'u''b'Mu;'u'Mu;'u''b'mu;'u'mu;'u''b'multimap;'u'multimap;'b'mumap;'u'mumap;'b'nabla;'u'nabla;'u''b'Nacute;'u'Nacute;'u''b'nacute;'u'nacute;'u''b'nang;'u'nang;'u''b'nap;'u'nap;'u''b'napE;'u'napE;'u''b'napid;'u'napid;'u''b'napos;'u'napos;'b'napprox;'u'napprox;'u''b'natur;'u'natur;'b'natural;'u'natural;'u''b'naturals;'u'naturals;'b''u''b'nbsp;'u'nbsp;'u''b'nbump;'u'nbump;'u''b'nbumpe;'u'nbumpe;'u''b'ncap;'u'ncap;'u''b'Ncaron;'u'Ncaron;'u''b'ncaron;'u'ncaron;'u''b'Ncedil;'u'Ncedil;'u''b'ncedil;'u'ncedil;'u''b'ncong;'u'ncong;'u''b'ncongdot;'u'ncongdot;'u''b'ncup;'u'ncup;'u''b'Ncy;'u'Ncy;'u''b'ncy;'u'ncy;'b'ndash;'u'ndash;'u''b'ne;'u'ne;'u''b'nearhk;'u'nearhk;'u''b'neArr;'u'neArr;'u''b'nearr;'u'nearr;'b'nearrow;'u'nearrow;'u''b'nedot;'u'nedot;'u''b'NegativeMediumSpace;'u'NegativeMediumSpace;'b'NegativeThickSpace;'u'NegativeThickSpace;'b'NegativeThinSpace;'u'NegativeThinSpace;'b'NegativeVeryThinSpace;'u'NegativeVeryThinSpace;'u''b'nequiv;'u'nequiv;'u''b'nesear;'u'nesear;'u''b'nesim;'u'nesim;'b'NestedGreaterGreater;'u'NestedGreaterGreater;'b'NestedLessLess;'u'NestedLessLess;'b'NewLine;'u'NewLine;'u''b'nexist;'u'nexist;'b'nexists;'u'nexists;'b'Nfr;'u'Nfr;'b'nfr;'u'nfr;'u''b'ngE;'u'ngE;'u''b'nge;'u'nge;'b'ngeq;'u'ngeq;'b'ngeqq;'u'ngeqq;'u''b'ngeqslant;'u'ngeqslant;'b'nges;'u'nges;'u''b'nGg;'u'nGg;'u''b'ngsim;'u'ngsim;'u''b'nGt;'u'nGt;'u''b'ngt;'u'ngt;'b'ngtr;'u'ngtr;'u''b'nGtv;'u'nGtv;'u''b'nhArr;'u'nhArr;'u''b'nharr;'u'nharr;'u''b'nhpar;'u'nhpar;'u''b'ni;'u'ni;'u''b'nis;'u'nis;'u''b'nisd;'u'nisd;'b'niv;'u'niv;'u''b'NJcy;'u'NJcy;'u''b'njcy;'u'njcy;'u''b'nlArr;'u'nlArr;'u''b'nlarr;'u'nlarr;'u''b'nldr;'u'nldr;'u''b'nlE;'u'nlE;'u''b'nle;'u'nle;'b'nLeftarrow;'u'nLeftarrow;'b'nleftarrow;'u'nleftarrow;'b'nLeftrightarrow;'u'nLeftrightarrow;'b'nleftrightarrow;'u'nleftrightarrow;'b'nleq;'u'nleq;'b'nleqq;'u'nleqq;'u''b'nleqslant;'u'nleqslant;'b'nles;'u'nles;'u''b'nless;'u'nless;'u''b'nLl;'u'nLl;'u''b'nlsim;'u'nlsim;'u''b'nLt;'u'nLt;'b'nlt;'u'nlt;'u''b'nltri;'u'nltri;'u''b'nltrie;'u'nltrie;'u''b'nLtv;'u'nLtv;'u''b'nmid;'u'nmid;'u''b'NoBreak;'u'NoBreak;'b'NonBreakingSpace;'u'NonBreakingSpace;'b'Nopf;'u'Nopf;'b'nopf;'u'nopf;'b''u''u''b'Not;'u'Not;'b'not;'u'not;'b'NotCongruent;'u'NotCongruent;'u''b'NotCupCap;'u'NotCupCap;'u''b'NotDoubleVerticalBar;'u'NotDoubleVerticalBar;'u''b'NotElement;'u'NotElement;'b'NotEqual;'u'NotEqual;'b'NotEqualTilde;'u'NotEqualTilde;'b'NotExists;'u'NotExists;'b'NotGreater;'u'NotGreater;'b'NotGreaterEqual;'u'NotGreaterEqual;'b'NotGreaterFullEqual;'u'NotGreaterFullEqual;'b'NotGreaterGreater;'u'NotGreaterGreater;'u''b'NotGreaterLess;'u'NotGreaterLess;'b'NotGreaterSlantEqual;'u'NotGreaterSlantEqual;'b'NotGreaterTilde;'u'NotGreaterTilde;'b'NotHumpDownHump;'u'NotHumpDownHump;'b'NotHumpEqual;'u'NotHumpEqual;'b'notin;'u'notin;'u''b'notindot;'u'notindot;'u''b'notinE;'u'notinE;'b'notinva;'u'notinva;'u''b'notinvb;'u'notinvb;'u''b'notinvc;'u'notinvc;'b'NotLeftTriangle;'u'NotLeftTriangle;'u''b'NotLeftTriangleBar;'u'NotLeftTriangleBar;'b'NotLeftTriangleEqual;'u'NotLeftTriangleEqual;'b'NotLess;'u'NotLess;'b'NotLessEqual;'u'NotLessEqual;'u''b'NotLessGreater;'u'NotLessGreater;'b'NotLessLess;'u'NotLessLess;'b'NotLessSlantEqual;'u'NotLessSlantEqual;'b'NotLessTilde;'u'NotLessTilde;'u''b'NotNestedGreaterGreater;'u'NotNestedGreaterGreater;'u''b'NotNestedLessLess;'u'NotNestedLessLess;'u''b'notni;'u'notni;'b'notniva;'u'notniva;'u''b'notnivb;'u'notnivb;'u''b'notnivc;'u'notnivc;'u''b'NotPrecedes;'u'NotPrecedes;'u''b'NotPrecedesEqual;'u'NotPrecedesEqual;'u''b'NotPrecedesSlantEqual;'u'NotPrecedesSlantEqual;'b'NotReverseElement;'u'NotReverseElement;'u''b'NotRightTriangle;'u'NotRightTriangle;'u''b'NotRightTriangleBar;'u'NotRightTriangleBar;'u''b'NotRightTriangleEqual;'u'NotRightTriangleEqual;'u''b'NotSquareSubset;'u'NotSquareSubset;'u''b'NotSquareSubsetEqual;'u'NotSquareSubsetEqual;'u''b'NotSquareSuperset;'u'NotSquareSuperset;'u''b'NotSquareSupersetEqual;'u'NotSquareSupersetEqual;'u''b'NotSubset;'u'NotSubset;'u''b'NotSubsetEqual;'u'NotSubsetEqual;'u''b'NotSucceeds;'u'NotSucceeds;'u''b'NotSucceedsEqual;'u'NotSucceedsEqual;'u''b'NotSucceedsSlantEqual;'u'NotSucceedsSlantEqual;'u''b'NotSucceedsTilde;'u'NotSucceedsTilde;'u''b'NotSuperset;'u'NotSuperset;'u''b'NotSupersetEqual;'u'NotSupersetEqual;'u''b'NotTilde;'u'NotTilde;'u''b'NotTildeEqual;'u'NotTildeEqual;'b'NotTildeFullEqual;'u'NotTildeFullEqual;'b'NotTildeTilde;'u'NotTildeTilde;'b'NotVerticalBar;'u'NotVerticalBar;'b'npar;'u'npar;'b'nparallel;'u'nparallel;'u''b'nparsl;'u'nparsl;'u''b'npart;'u'npart;'u''b'npolint;'u'npolint;'b'npr;'u'npr;'b'nprcue;'u'nprcue;'b'npre;'u'npre;'b'nprec;'u'nprec;'b'npreceq;'u'npreceq;'u''b'nrArr;'u'nrArr;'u''b'nrarr;'u'nrarr;'u''b'nrarrc;'u'nrarrc;'u''b'nrarrw;'u'nrarrw;'b'nRightarrow;'u'nRightarrow;'b'nrightarrow;'u'nrightarrow;'b'nrtri;'u'nrtri;'b'nrtrie;'u'nrtrie;'b'nsc;'u'nsc;'b'nsccue;'u'nsccue;'b'nsce;'u'nsce;'b'Nscr;'u'Nscr;'b'nscr;'u'nscr;'b'nshortmid;'u'nshortmid;'b'nshortparallel;'u'nshortparallel;'b'nsim;'u'nsim;'b'nsime;'u'nsime;'b'nsimeq;'u'nsimeq;'b'nsmid;'u'nsmid;'b'nspar;'u'nspar;'b'nsqsube;'u'nsqsube;'b'nsqsupe;'u'nsqsupe;'u''b'nsub;'u'nsub;'u''b'nsubE;'u'nsubE;'b'nsube;'u'nsube;'b'nsubset;'u'nsubset;'b'nsubseteq;'u'nsubseteq;'b'nsubseteqq;'u'nsubseteqq;'b'nsucc;'u'nsucc;'b'nsucceq;'u'nsucceq;'u''b'nsup;'u'nsup;'u''b'nsupE;'u'nsupE;'b'nsupe;'u'nsupe;'b'nsupset;'u'nsupset;'b'nsupseteq;'u'nsupseteq;'b'nsupseteqq;'u'nsupseteqq;'b'ntgl;'u'ntgl;'b''u''b''u''b'Ntilde;'u'Ntilde;'b'ntilde;'u'ntilde;'b'ntlg;'u'ntlg;'b'ntriangleleft;'u'ntriangleleft;'b'ntrianglelefteq;'u'ntrianglelefteq;'b'ntriangleright;'u'ntriangleright;'b'ntrianglerighteq;'u'ntrianglerighteq;'u''b'Nu;'u'Nu;'u''b'nu;'u'nu;'b'num;'u'num;'u''b'numero;'u'numero;'u''b'numsp;'u'numsp;'u''b'nvap;'u'nvap;'u''b'nVDash;'u'nVDash;'u''b'nVdash;'u'nVdash;'u''b'nvDash;'u'nvDash;'u''b'nvdash;'u'nvdash;'u''b'nvge;'u'nvge;'u'>'b'nvgt;'u'nvgt;'u''b'nvHarr;'u'nvHarr;'u''b'nvinfin;'u'nvinfin;'u''b'nvlArr;'u'nvlArr;'u''b'nvle;'u'nvle;'u'<'b'nvlt;'u'nvlt;'u''b'nvltrie;'u'nvltrie;'u''b'nvrArr;'u'nvrArr;'u''b'nvrtrie;'u'nvrtrie;'u''b'nvsim;'u'nvsim;'u''b'nwarhk;'u'nwarhk;'u''b'nwArr;'u'nwArr;'u''b'nwarr;'u'nwarr;'b'nwarrow;'u'nwarrow;'u''b'nwnear;'u'nwnear;'b''u''b''u''b'Oacute;'u'Oacute;'b'oacute;'u'oacute;'b'oast;'u'oast;'b'ocir;'u'ocir;'b''u''b''u''b'Ocirc;'u'Ocirc;'b'ocirc;'u'ocirc;'u''b'Ocy;'u'Ocy;'u''b'ocy;'u'ocy;'b'odash;'u'odash;'u''b'Odblac;'u'Odblac;'u''b'odblac;'u'odblac;'u''b'odiv;'u'odiv;'b'odot;'u'odot;'u''b'odsold;'u'odsold;'b'OElig;'u'OElig;'b'oelig;'u'oelig;'u''b'ofcir;'u'ofcir;'b'Ofr;'u'Ofr;'b'ofr;'u'ofr;'u''b'ogon;'u'ogon;'b''u''b''u''b'Ograve;'u'Ograve;'b'ograve;'u'ograve;'u''b'ogt;'u'ogt;'u''b'ohbar;'u'ohbar;'u''b'ohm;'u'ohm;'b'oint;'u'oint;'b'olarr;'u'olarr;'u''b'olcir;'u'olcir;'u''b'olcross;'u'olcross;'u''b'oline;'u'oline;'u''b'olt;'u'olt;'u''b'Omacr;'u'Omacr;'u''b'omacr;'u'omacr;'b'Omega;'u'Omega;'u''b'omega;'u'omega;'u''b'Omicron;'u'Omicron;'u''b'omicron;'u'omicron;'u''b'omid;'u'omid;'b'ominus;'u'ominus;'b'Oopf;'u'Oopf;'b'oopf;'u'oopf;'u''b'opar;'u'opar;'b'OpenCurlyDoubleQuote;'u'OpenCurlyDoubleQuote;'b'OpenCurlyQuote;'u'OpenCurlyQuote;'u''b'operp;'u'operp;'b'oplus;'u'oplus;'u''b'Or;'u'Or;'u''b'or;'u'or;'b'orarr;'u'orarr;'u''b'ord;'u'ord;'u''b'order;'u'order;'b'orderof;'u'orderof;'b''u''b'ordf;'u'ordf;'b''u''b'ordm;'u'ordm;'u''b'origof;'u'origof;'u''b'oror;'u'oror;'u''b'orslope;'u'orslope;'u''b'orv;'u'orv;'b'oS;'u'oS;'b'Oscr;'u'Oscr;'b'oscr;'u'oscr;'b''u''b''u''b'Oslash;'u'Oslash;'b'oslash;'u'oslash;'u''b'osol;'u'osol;'b''u''b''u''b'Otilde;'u'Otilde;'b'otilde;'u'otilde;'u''b'Otimes;'u'Otimes;'b'otimes;'u'otimes;'u''b'otimesas;'u'otimesas;'b''u''b''u''b'Ouml;'u'Ouml;'b'ouml;'u'ouml;'u''b'ovbar;'u'ovbar;'b'OverBar;'u'OverBar;'u''b'OverBrace;'u'OverBrace;'u''b'OverBracket;'u'OverBracket;'u''b'OverParenthesis;'u'OverParenthesis;'b'par;'u'par;'b''u''b'para;'u'para;'b'parallel;'u'parallel;'u''b'parsim;'u'parsim;'u''b'parsl;'u'parsl;'u''b'part;'u'part;'b'PartialD;'u'PartialD;'u''b'Pcy;'u'Pcy;'u''b'pcy;'u'pcy;'b'percnt;'u'percnt;'b'period;'u'period;'b'permil;'u'permil;'b'perp;'u'perp;'u''b'pertenk;'u'pertenk;'b'Pfr;'u'Pfr;'b'pfr;'u'pfr;'u''b'Phi;'u'Phi;'u''b'phi;'u'phi;'u''b'phiv;'u'phiv;'b'phmmat;'u'phmmat;'u''b'phone;'u'phone;'u''b'Pi;'u'Pi;'u''b'pi;'u'pi;'b'pitchfork;'u'pitchfork;'u''b'piv;'u'piv;'b'planck;'u'planck;'u''b'planckh;'u'planckh;'b'plankv;'u'plankv;'b'plus;'u'plus;'u''b'plusacir;'u'plusacir;'b'plusb;'u'plusb;'u''b'pluscir;'u'pluscir;'b'plusdo;'u'plusdo;'u''b'plusdu;'u'plusdu;'u''b'pluse;'u'pluse;'b''u''b'PlusMinus;'u'PlusMinus;'b'plusmn;'u'plusmn;'u''b'plussim;'u'plussim;'u''b'plustwo;'u'plustwo;'b'pm;'u'pm;'b'Poincareplane;'u'Poincareplane;'u''b'pointint;'u'pointint;'u''b'Popf;'u'Popf;'b'popf;'u'popf;'b''u''b'pound;'u'pound;'u''b'Pr;'u'Pr;'u''b'pr;'u'pr;'u''b'prap;'u'prap;'u''b'prcue;'u'prcue;'u''b'prE;'u'prE;'u''b'pre;'u'pre;'b'prec;'u'prec;'b'precapprox;'u'precapprox;'b'preccurlyeq;'u'preccurlyeq;'b'Precedes;'u'Precedes;'b'PrecedesEqual;'u'PrecedesEqual;'b'PrecedesSlantEqual;'u'PrecedesSlantEqual;'u''b'PrecedesTilde;'u'PrecedesTilde;'b'preceq;'u'preceq;'u''b'precnapprox;'u'precnapprox;'u''b'precneqq;'u'precneqq;'u''b'precnsim;'u'precnsim;'b'precsim;'u'precsim;'u''b'Prime;'u'Prime;'u''b'prime;'u'prime;'b'primes;'u'primes;'b'prnap;'u'prnap;'b'prnE;'u'prnE;'b'prnsim;'u'prnsim;'u''b'prod;'u'prod;'b'Product;'u'Product;'u''b'profalar;'u'profalar;'u''b'profline;'u'profline;'u''b'profsurf;'u'profsurf;'u''b'prop;'u'prop;'b'Proportion;'u'Proportion;'b'Proportional;'u'Proportional;'b'propto;'u'propto;'b'prsim;'u'prsim;'u''b'prurel;'u'prurel;'b'Pscr;'u'Pscr;'b'pscr;'u'pscr;'u''b'Psi;'u'Psi;'u''b'psi;'u'psi;'u''b'puncsp;'u'puncsp;'b'Qfr;'u'Qfr;'b'qfr;'u'qfr;'b'qint;'u'qint;'u''b'Qopf;'u'Qopf;'b'qopf;'u'qopf;'u''b'qprime;'u'qprime;'b'Qscr;'u'Qscr;'b'qscr;'u'qscr;'b'quaternions;'u'quaternions;'u''b'quatint;'u'quatint;'b'quest;'u'quest;'b'questeq;'u'questeq;'b'QUOT'u'QUOT'b'QUOT;'u'QUOT;'b'quot;'u'quot;'u''b'rAarr;'u'rAarr;'u''b'race;'u'race;'u''b'Racute;'u'Racute;'u''b'racute;'u'racute;'u''b'radic;'u'radic;'u''b'raemptyv;'u'raemptyv;'u''b'Rang;'u'Rang;'u''b'rang;'u'rang;'u''b'rangd;'u'rangd;'u''b'range;'u'range;'b'rangle;'u'rangle;'b''u''b'raquo;'u'raquo;'u''b'Rarr;'u'Rarr;'b'rArr;'u'rArr;'u''b'rarr;'u'rarr;'u''b'rarrap;'u'rarrap;'u''b'rarrb;'u'rarrb;'u''b'rarrbfs;'u'rarrbfs;'u''b'rarrc;'u'rarrc;'u''b'rarrfs;'u'rarrfs;'b'rarrhk;'u'rarrhk;'b'rarrlp;'u'rarrlp;'u''b'rarrpl;'u'rarrpl;'u''b'rarrsim;'u'rarrsim;'u''b'Rarrtl;'u'Rarrtl;'u''b'rarrtl;'u'rarrtl;'u''b'rarrw;'u'rarrw;'u''b'rAtail;'u'rAtail;'u''b'ratail;'u'ratail;'u''b'ratio;'u'ratio;'b'rationals;'u'rationals;'b'RBarr;'u'RBarr;'b'rBarr;'u'rBarr;'b'rbarr;'u'rbarr;'u''b'rbbrk;'u'rbbrk;'b'rbrace;'u'rbrace;'b'rbrack;'u'rbrack;'u''b'rbrke;'u'rbrke;'u''b'rbrksld;'u'rbrksld;'u''b'rbrkslu;'u'rbrkslu;'u''b'Rcaron;'u'Rcaron;'u''b'rcaron;'u'rcaron;'u''b'Rcedil;'u'Rcedil;'u''b'rcedil;'u'rcedil;'u''b'rceil;'u'rceil;'b'rcub;'u'rcub;'u''b'Rcy;'u'Rcy;'u''b'rcy;'u'rcy;'u''b'rdca;'u'rdca;'u''b'rdldhar;'u'rdldhar;'b'rdquo;'u'rdquo;'b'rdquor;'u'rdquor;'u''b'rdsh;'u'rdsh;'u''b'Re;'u'Re;'b'real;'u'real;'u''b'realine;'u'realine;'b'realpart;'u'realpart;'u''b'reals;'u'reals;'u''b'rect;'u'rect;'b'REG'u'REG'b'REG;'u'REG;'b'reg;'u'reg;'b'ReverseElement;'u'ReverseElement;'b'ReverseEquilibrium;'u'ReverseEquilibrium;'b'ReverseUpEquilibrium;'u'ReverseUpEquilibrium;'u''b'rfisht;'u'rfisht;'u''b'rfloor;'u'rfloor;'b'Rfr;'u'Rfr;'b'rfr;'u'rfr;'u''b'rHar;'u'rHar;'b'rhard;'u'rhard;'u''b'rharu;'u'rharu;'u''b'rharul;'u'rharul;'u''b'Rho;'u'Rho;'u''b'rho;'u'rho;'u''b'rhov;'u'rhov;'b'RightAngleBracket;'u'RightAngleBracket;'b'RightArrow;'u'RightArrow;'b'Rightarrow;'u'Rightarrow;'b'rightarrow;'u'rightarrow;'b'RightArrowBar;'u'RightArrowBar;'u''b'RightArrowLeftArrow;'u'RightArrowLeftArrow;'b'rightarrowtail;'u'rightarrowtail;'b'RightCeiling;'u'RightCeiling;'u''b'RightDoubleBracket;'u'RightDoubleBracket;'u''b'RightDownTeeVector;'u'RightDownTeeVector;'b'RightDownVector;'u'RightDownVector;'u''b'RightDownVectorBar;'u'RightDownVectorBar;'b'RightFloor;'u'RightFloor;'b'rightharpoondown;'u'rightharpoondown;'b'rightharpoonup;'u'rightharpoonup;'b'rightleftarrows;'u'rightleftarrows;'b'rightleftharpoons;'u'rightleftharpoons;'u''b'rightrightarrows;'u'rightrightarrows;'b'rightsquigarrow;'u'rightsquigarrow;'u''b'RightTee;'u'RightTee;'b'RightTeeArrow;'u'RightTeeArrow;'u''b'RightTeeVector;'u'RightTeeVector;'u''b'rightthreetimes;'u'rightthreetimes;'u''b'RightTriangle;'u'RightTriangle;'u''b'RightTriangleBar;'u'RightTriangleBar;'u''b'RightTriangleEqual;'u'RightTriangleEqual;'u''b'RightUpDownVector;'u'RightUpDownVector;'u''b'RightUpTeeVector;'u'RightUpTeeVector;'u''b'RightUpVector;'u'RightUpVector;'u''b'RightUpVectorBar;'u'RightUpVectorBar;'b'RightVector;'u'RightVector;'u''b'RightVectorBar;'u'RightVectorBar;'u''b'ring;'u'ring;'b'risingdotseq;'u'risingdotseq;'b'rlarr;'u'rlarr;'b'rlhar;'u'rlhar;'u''b'rlm;'u'rlm;'u''b'rmoust;'u'rmoust;'b'rmoustache;'u'rmoustache;'u''b'rnmid;'u'rnmid;'u''b'roang;'u'roang;'u''b'roarr;'u'roarr;'b'robrk;'u'robrk;'u''b'ropar;'u'ropar;'b'Ropf;'u'Ropf;'b'ropf;'u'ropf;'u''b'roplus;'u'roplus;'u''b'rotimes;'u'rotimes;'u''b'RoundImplies;'u'RoundImplies;'b'rpar;'u'rpar;'u''b'rpargt;'u'rpargt;'u''b'rppolint;'u'rppolint;'b'rrarr;'u'rrarr;'b'Rrightarrow;'u'Rrightarrow;'b'rsaquo;'u'rsaquo;'b'Rscr;'u'Rscr;'b'rscr;'u'rscr;'u''b'Rsh;'u'Rsh;'b'rsh;'u'rsh;'b'rsqb;'u'rsqb;'b'rsquo;'u'rsquo;'b'rsquor;'u'rsquor;'b'rthree;'u'rthree;'u''b'rtimes;'u'rtimes;'u''b'rtri;'u'rtri;'b'rtrie;'u'rtrie;'b'rtrif;'u'rtrif;'u''b'rtriltri;'u'rtriltri;'u''b'RuleDelayed;'u'RuleDelayed;'u''b'ruluhar;'u'ruluhar;'u''b'rx;'u'rx;'u''b'Sacute;'u'Sacute;'u''b'sacute;'u'sacute;'b'sbquo;'u'sbquo;'u''b'Sc;'u'Sc;'u''b'sc;'u'sc;'u''b'scap;'u'scap;'b'Scaron;'u'Scaron;'b'scaron;'u'scaron;'u''b'sccue;'u'sccue;'u''b'scE;'u'scE;'u''b'sce;'u'sce;'u''b'Scedil;'u'Scedil;'u''b'scedil;'u'scedil;'u''b'Scirc;'u'Scirc;'u''b'scirc;'u'scirc;'u''b'scnap;'u'scnap;'u''b'scnE;'u'scnE;'u''b'scnsim;'u'scnsim;'u''b'scpolint;'u'scpolint;'u''b'scsim;'u'scsim;'u''b'Scy;'u'Scy;'u''b'scy;'u'scy;'u''b'sdot;'u'sdot;'b'sdotb;'u'sdotb;'u''b'sdote;'u'sdote;'b'searhk;'u'searhk;'u''b'seArr;'u'seArr;'b'searr;'u'searr;'b'searrow;'u'searrow;'b''u''b'sect;'u'sect;'b'semi;'u'semi;'u''b'seswar;'u'seswar;'b'setminus;'u'setminus;'b'setmn;'u'setmn;'u''b'sext;'u'sext;'b'Sfr;'u'Sfr;'b'sfr;'u'sfr;'b'sfrown;'u'sfrown;'u''b'sharp;'u'sharp;'u''b'SHCHcy;'u'SHCHcy;'u''b'shchcy;'u'shchcy;'u''b'SHcy;'u'SHcy;'u''b'shcy;'u'shcy;'b'ShortDownArrow;'u'ShortDownArrow;'b'ShortLeftArrow;'u'ShortLeftArrow;'b'shortmid;'u'shortmid;'b'shortparallel;'u'shortparallel;'b'ShortRightArrow;'u'ShortRightArrow;'u''b'ShortUpArrow;'u'ShortUpArrow;'b''u''b'shy;'u'shy;'u''b'Sigma;'u'Sigma;'u''b'sigma;'u'sigma;'u''b'sigmaf;'u'sigmaf;'b'sigmav;'u'sigmav;'u''b'sim;'u'sim;'u''b'simdot;'u'simdot;'u''b'sime;'u'sime;'b'simeq;'u'simeq;'u''b'simg;'u'simg;'u''b'simgE;'u'simgE;'u''b'siml;'u'siml;'u''b'simlE;'u'simlE;'u''b'simne;'u'simne;'u''b'simplus;'u'simplus;'u''b'simrarr;'u'simrarr;'b'slarr;'u'slarr;'b'SmallCircle;'u'SmallCircle;'b'smallsetminus;'u'smallsetminus;'u''b'smashp;'u'smashp;'u''b'smeparsl;'u'smeparsl;'b'smid;'u'smid;'u''b'smile;'u'smile;'u''b'smt;'u'smt;'u''b'smte;'u'smte;'u''b'smtes;'u'smtes;'u''b'SOFTcy;'u'SOFTcy;'u''b'softcy;'u'softcy;'b'sol;'u'sol;'u''b'solb;'u'solb;'u''b'solbar;'u'solbar;'b'Sopf;'u'Sopf;'b'sopf;'u'sopf;'u''b'spades;'u'spades;'b'spadesuit;'u'spadesuit;'b'spar;'u'spar;'u''b'sqcap;'u'sqcap;'u''b'sqcaps;'u'sqcaps;'u''b'sqcup;'u'sqcup;'u''b'sqcups;'u'sqcups;'b'Sqrt;'u'Sqrt;'u''b'sqsub;'u'sqsub;'u''b'sqsube;'u'sqsube;'b'sqsubset;'u'sqsubset;'b'sqsubseteq;'u'sqsubseteq;'u''b'sqsup;'u'sqsup;'u''b'sqsupe;'u'sqsupe;'b'sqsupset;'u'sqsupset;'b'sqsupseteq;'u'sqsupseteq;'u''b'squ;'u'squ;'b'Square;'u'Square;'b'square;'u'square;'b'SquareIntersection;'u'SquareIntersection;'b'SquareSubset;'u'SquareSubset;'b'SquareSubsetEqual;'u'SquareSubsetEqual;'b'SquareSuperset;'u'SquareSuperset;'b'SquareSupersetEqual;'u'SquareSupersetEqual;'b'SquareUnion;'u'SquareUnion;'b'squarf;'u'squarf;'b'squf;'u'squf;'b'srarr;'u'srarr;'b'Sscr;'u'Sscr;'b'sscr;'u'sscr;'b'ssetmn;'u'ssetmn;'b'ssmile;'u'ssmile;'u''b'sstarf;'u'sstarf;'b'Star;'u'Star;'u''b'star;'u'star;'b'starf;'u'starf;'b'straightepsilon;'u'straightepsilon;'b'straightphi;'u'straightphi;'b'strns;'u'strns;'u''b'Sub;'u'Sub;'u''b'sub;'u'sub;'u''b'subdot;'u'subdot;'u''b'subE;'u'subE;'u''b'sube;'u'sube;'u''b'subedot;'u'subedot;'u''b'submult;'u'submult;'u''b'subnE;'u'subnE;'u''b'subne;'u'subne;'u''b'subplus;'u'subplus;'u''b'subrarr;'u'subrarr;'b'Subset;'u'Subset;'b'subset;'u'subset;'b'subseteq;'u'subseteq;'b'subseteqq;'u'subseteqq;'b'SubsetEqual;'u'SubsetEqual;'b'subsetneq;'u'subsetneq;'b'subsetneqq;'u'subsetneqq;'u''b'subsim;'u'subsim;'u''b'subsub;'u'subsub;'u''b'subsup;'u'subsup;'b'succ;'u'succ;'b'succapprox;'u'succapprox;'b'succcurlyeq;'u'succcurlyeq;'b'Succeeds;'u'Succeeds;'b'SucceedsEqual;'u'SucceedsEqual;'b'SucceedsSlantEqual;'u'SucceedsSlantEqual;'b'SucceedsTilde;'u'SucceedsTilde;'b'succeq;'u'succeq;'b'succnapprox;'u'succnapprox;'b'succneqq;'u'succneqq;'b'succnsim;'u'succnsim;'b'succsim;'u'succsim;'b'SuchThat;'u'SuchThat;'u''b'Sum;'u'Sum;'b'sum;'u'sum;'u''b'sung;'u'sung;'b''u''b'sup1;'u'sup1;'b''u''b'sup2;'u'sup2;'b''u''b'sup3;'u'sup3;'u''b'Sup;'u'Sup;'u''b'sup;'u'sup;'u''b'supdot;'u'supdot;'u''b'supdsub;'u'supdsub;'u''b'supE;'u'supE;'u''b'supe;'u'supe;'u''b'supedot;'u'supedot;'b'Superset;'u'Superset;'b'SupersetEqual;'u'SupersetEqual;'u''b'suphsol;'u'suphsol;'u''b'suphsub;'u'suphsub;'u''b'suplarr;'u'suplarr;'u''b'supmult;'u'supmult;'u''b'supnE;'u'supnE;'u''b'supne;'u'supne;'u''b'supplus;'u'supplus;'b'Supset;'u'Supset;'b'supset;'u'supset;'b'supseteq;'u'supseteq;'b'supseteqq;'u'supseteqq;'b'supsetneq;'u'supsetneq;'b'supsetneqq;'u'supsetneqq;'u''b'supsim;'u'supsim;'u''b'supsub;'u'supsub;'u''b'supsup;'u'supsup;'b'swarhk;'u'swarhk;'u''b'swArr;'u'swArr;'b'swarr;'u'swarr;'b'swarrow;'u'swarrow;'u''b'swnwar;'u'swnwar;'b''u''b'szlig;'u'szlig;'b'Tab;'u'Tab;'u''b'target;'u'target;'u''b'Tau;'u'Tau;'u''b'tau;'u'tau;'b'tbrk;'u'tbrk;'u''b'Tcaron;'u'Tcaron;'u''b'tcaron;'u'tcaron;'u''b'Tcedil;'u'Tcedil;'u''b'tcedil;'u'tcedil;'u''b'Tcy;'u'Tcy;'u''b'tcy;'u'tcy;'u''b'tdot;'u'tdot;'u''b'telrec;'u'telrec;'b'Tfr;'u'Tfr;'b'tfr;'u'tfr;'u''b'there4;'u'there4;'b'Therefore;'u'Therefore;'b'therefore;'u'therefore;'u''b'Theta;'u'Theta;'u''b'theta;'u'theta;'u''b'thetasym;'u'thetasym;'b'thetav;'u'thetav;'b'thickapprox;'u'thickapprox;'b'thicksim;'u'thicksim;'u''b'ThickSpace;'u'ThickSpace;'u''b'thinsp;'u'thinsp;'b'ThinSpace;'u'ThinSpace;'b'thkap;'u'thkap;'b'thksim;'u'thksim;'b''u''b''u''b'THORN;'u'THORN;'b'thorn;'u'thorn;'b'Tilde;'u'Tilde;'b'tilde;'u'tilde;'b'TildeEqual;'u'TildeEqual;'b'TildeFullEqual;'u'TildeFullEqual;'b'TildeTilde;'u'TildeTilde;'b''u''b'times;'u'times;'b'timesb;'u'timesb;'u''b'timesbar;'u'timesbar;'u''b'timesd;'u'timesd;'b'tint;'u'tint;'b'toea;'u'toea;'b'top;'u'top;'u''b'topbot;'u'topbot;'u''b'topcir;'u'topcir;'b'Topf;'u'Topf;'b'topf;'u'topf;'u''b'topfork;'u'topfork;'b'tosa;'u'tosa;'u''b'tprime;'u'tprime;'b'TRADE;'u'TRADE;'b'trade;'u'trade;'u''b'triangle;'u'triangle;'b'triangledown;'u'triangledown;'b'triangleleft;'u'triangleleft;'b'trianglelefteq;'u'trianglelefteq;'u''b'triangleq;'u'triangleq;'b'triangleright;'u'triangleright;'b'trianglerighteq;'u'trianglerighteq;'u''b'tridot;'u'tridot;'b'trie;'u'trie;'u''b'triminus;'u'triminus;'b'TripleDot;'u'TripleDot;'u''b'triplus;'u'triplus;'u''b'trisb;'u'trisb;'u''b'tritime;'u'tritime;'u''b'trpezium;'u'trpezium;'b'Tscr;'u'Tscr;'b'tscr;'u'tscr;'u''b'TScy;'u'TScy;'u''b'tscy;'u'tscy;'u''b'TSHcy;'u'TSHcy;'u''b'tshcy;'u'tshcy;'u''b'Tstrok;'u'Tstrok;'u''b'tstrok;'u'tstrok;'b'twixt;'u'twixt;'b'twoheadleftarrow;'u'twoheadleftarrow;'b'twoheadrightarrow;'u'twoheadrightarrow;'b''u''b''u''b'Uacute;'u'Uacute;'b'uacute;'u'uacute;'u''b'Uarr;'u'Uarr;'b'uArr;'u'uArr;'b'uarr;'u'uarr;'u''b'Uarrocir;'u'Uarrocir;'u''b'Ubrcy;'u'Ubrcy;'u''b'ubrcy;'u'ubrcy;'u''b'Ubreve;'u'Ubreve;'u''b'ubreve;'u'ubreve;'b''u''b''u''b'Ucirc;'u'Ucirc;'b'ucirc;'u'ucirc;'u''b'Ucy;'u'Ucy;'u''b'ucy;'u'ucy;'u''b'udarr;'u'udarr;'u''b'Udblac;'u'Udblac;'u''b'udblac;'u'udblac;'u''b'udhar;'u'udhar;'u''b'ufisht;'u'ufisht;'b'Ufr;'u'Ufr;'b'ufr;'u'ufr;'b''u''b''u''b'Ugrave;'u'Ugrave;'b'ugrave;'u'ugrave;'u''b'uHar;'u'uHar;'b'uharl;'u'uharl;'b'uharr;'u'uharr;'u''b'uhblk;'u'uhblk;'u''b'ulcorn;'u'ulcorn;'b'ulcorner;'u'ulcorner;'u''b'ulcrop;'u'ulcrop;'u''b'ultri;'u'ultri;'u''b'Umacr;'u'Umacr;'u''b'umacr;'u'umacr;'b'uml;'u'uml;'b'UnderBar;'u'UnderBar;'u''b'UnderBrace;'u'UnderBrace;'b'UnderBracket;'u'UnderBracket;'u''b'UnderParenthesis;'u'UnderParenthesis;'b'Union;'u'Union;'u''b'UnionPlus;'u'UnionPlus;'u''b'Uogon;'u'Uogon;'u''b'uogon;'u'uogon;'b'Uopf;'u'Uopf;'b'uopf;'u'uopf;'b'UpArrow;'u'UpArrow;'b'Uparrow;'u'Uparrow;'b'uparrow;'u'uparrow;'u''b'UpArrowBar;'u'UpArrowBar;'b'UpArrowDownArrow;'u'UpArrowDownArrow;'u''b'UpDownArrow;'u'UpDownArrow;'b'Updownarrow;'u'Updownarrow;'b'updownarrow;'u'updownarrow;'b'UpEquilibrium;'u'UpEquilibrium;'b'upharpoonleft;'u'upharpoonleft;'b'upharpoonright;'u'upharpoonright;'b'uplus;'u'uplus;'b'UpperLeftArrow;'u'UpperLeftArrow;'b'UpperRightArrow;'u'UpperRightArrow;'u''b'Upsi;'u'Upsi;'u''b'upsi;'u'upsi;'b'upsih;'u'upsih;'u''b'Upsilon;'u'Upsilon;'b'upsilon;'u'upsilon;'b'UpTee;'u'UpTee;'b'UpTeeArrow;'u'UpTeeArrow;'u''b'upuparrows;'u'upuparrows;'u''b'urcorn;'u'urcorn;'b'urcorner;'u'urcorner;'u''b'urcrop;'u'urcrop;'u''b'Uring;'u'Uring;'u''b'uring;'u'uring;'u''b'urtri;'u'urtri;'b'Uscr;'u'Uscr;'b'uscr;'u'uscr;'u''b'utdot;'u'utdot;'u''b'Utilde;'u'Utilde;'u''b'utilde;'u'utilde;'b'utri;'u'utri;'b'utrif;'u'utrif;'b'uuarr;'u'uuarr;'b''u''b''u''b'Uuml;'u'Uuml;'b'uuml;'u'uuml;'u''b'uwangle;'u'uwangle;'u''b'vangrt;'u'vangrt;'b'varepsilon;'u'varepsilon;'b'varkappa;'u'varkappa;'b'varnothing;'u'varnothing;'b'varphi;'u'varphi;'b'varpi;'u'varpi;'b'varpropto;'u'varpropto;'b'vArr;'u'vArr;'b'varr;'u'varr;'b'varrho;'u'varrho;'b'varsigma;'u'varsigma;'u''b'varsubsetneq;'u'varsubsetneq;'u''b'varsubsetneqq;'u'varsubsetneqq;'u''b'varsupsetneq;'u'varsupsetneq;'u''b'varsupsetneqq;'u'varsupsetneqq;'b'vartheta;'u'vartheta;'b'vartriangleleft;'u'vartriangleleft;'b'vartriangleright;'u'vartriangleright;'u''b'Vbar;'u'Vbar;'u''b'vBar;'u'vBar;'u''b'vBarv;'u'vBarv;'u''b'Vcy;'u'Vcy;'u''b'vcy;'u'vcy;'u''b'VDash;'u'VDash;'u''b'Vdash;'u'Vdash;'b'vDash;'u'vDash;'b'vdash;'u'vdash;'u''b'Vdashl;'u'Vdashl;'b'Vee;'u'Vee;'b'vee;'u'vee;'u''b'veebar;'u'veebar;'u''b'veeeq;'u'veeeq;'u''b'vellip;'u'vellip;'u''b'Verbar;'u'Verbar;'b'verbar;'u'verbar;'b'Vert;'u'Vert;'b'vert;'u'vert;'b'VerticalBar;'u'VerticalBar;'b'VerticalLine;'u'VerticalLine;'u''b'VerticalSeparator;'u'VerticalSeparator;'u''b'VerticalTilde;'u'VerticalTilde;'b'VeryThinSpace;'u'VeryThinSpace;'b'Vfr;'u'Vfr;'b'vfr;'u'vfr;'b'vltri;'u'vltri;'b'vnsub;'u'vnsub;'b'vnsup;'u'vnsup;'b'Vopf;'u'Vopf;'b'vopf;'u'vopf;'b'vprop;'u'vprop;'b'vrtri;'u'vrtri;'b'Vscr;'u'Vscr;'b'vscr;'u'vscr;'b'vsubnE;'u'vsubnE;'b'vsubne;'u'vsubne;'b'vsupnE;'u'vsupnE;'b'vsupne;'u'vsupne;'u''b'Vvdash;'u'Vvdash;'u''b'vzigzag;'u'vzigzag;'u''b'Wcirc;'u'Wcirc;'u''b'wcirc;'u'wcirc;'u''b'wedbar;'u'wedbar;'b'Wedge;'u'Wedge;'b'wedge;'u'wedge;'u''b'wedgeq;'u'wedgeq;'u''b'weierp;'u'weierp;'b'Wfr;'u'Wfr;'b'wfr;'u'wfr;'b'Wopf;'u'Wopf;'b'wopf;'u'wopf;'b'wp;'u'wp;'b'wr;'u'wr;'b'wreath;'u'wreath;'b'Wscr;'u'Wscr;'b'wscr;'u'wscr;'b'xcap;'u'xcap;'b'xcirc;'u'xcirc;'b'xcup;'u'xcup;'b'xdtri;'u'xdtri;'b'Xfr;'u'Xfr;'b'xfr;'u'xfr;'b'xhArr;'u'xhArr;'b'xharr;'u'xharr;'u''b'Xi;'u'Xi;'u''b'xi;'u'xi;'b'xlArr;'u'xlArr;'b'xlarr;'u'xlarr;'b'xmap;'u'xmap;'u''b'xnis;'u'xnis;'b'xodot;'u'xodot;'b'Xopf;'u'Xopf;'b'xopf;'u'xopf;'b'xoplus;'u'xoplus;'b'xotime;'u'xotime;'b'xrArr;'u'xrArr;'b'xrarr;'u'xrarr;'b'Xscr;'u'Xscr;'b'xscr;'u'xscr;'b'xsqcup;'u'xsqcup;'b'xuplus;'u'xuplus;'b'xutri;'u'xutri;'b'xvee;'u'xvee;'b'xwedge;'u'xwedge;'b''u''b''u''b'Yacute;'u'Yacute;'b'yacute;'u'yacute;'u''b'YAcy;'u'YAcy;'u''b'yacy;'u'yacy;'u''b'Ycirc;'u'Ycirc;'u''b'ycirc;'u'ycirc;'u''b'Ycy;'u'Ycy;'u''b'ycy;'u'ycy;'b''u''b'yen;'u'yen;'b'Yfr;'u'Yfr;'b'yfr;'u'yfr;'u''b'YIcy;'u'YIcy;'u''b'yicy;'u'yicy;'b'Yopf;'u'Yopf;'b'yopf;'u'yopf;'b'Yscr;'u'Yscr;'b'yscr;'u'yscr;'u''b'YUcy;'u'YUcy;'u''b'yucy;'u'yucy;'b''u''b'Yuml;'u'Yuml;'b'yuml;'u'yuml;'u''b'Zacute;'u'Zacute;'u''b'zacute;'u'zacute;'b'Zcaron;'u'Zcaron;'b'zcaron;'u'zcaron;'u''b'Zcy;'u'Zcy;'u''b'zcy;'u'zcy;'u''b'Zdot;'u'Zdot;'u''b'zdot;'u'zdot;'u''b'zeetrf;'u'zeetrf;'b'ZeroWidthSpace;'u'ZeroWidthSpace;'u''b'Zeta;'u'Zeta;'u''b'zeta;'u'zeta;'b'Zfr;'u'Zfr;'b'zfr;'u'zfr;'u''b'ZHcy;'u'ZHcy;'u''b'zhcy;'u'zhcy;'u''b'zigrarr;'u'zigrarr;'b'Zopf;'u'Zopf;'b'zopf;'u'zopf;'b'Zscr;'u'Zscr;'b'zscr;'u'zscr;'u''b'zwj;'u'zwj;'u''b'zwnj;'u'zwnj;'u'Lib.html.entities'u'entities'bltnsDynamicClassAttribute_or_EnumTypeEnumMetaFlagReprEnumuniqueverifynonmemberFlagBoundarySTRICTCONFORMEJECTglobal_flag_reprglobal_enum_reprglobal_strEnumCheckCONTINUOUSNAMED_FLAGSUNIQUEpickle_by_global_namepickle_by_enum_name_stdlib_enums
    Protects item from becoming an Enum member during class creation.
    
    Forces item to become an Enum member during class creation.
    _is_descriptor
    Returns True if obj is a descriptor, False otherwise.
    _is_dunder
    Returns True if a __dunder__ name, False otherwise.
    _is_sunder
    Returns True if a _sunder_ name, False otherwise.
    _is_internal_classs_patterne_pattern_is_private_%s__pat_len_is_single_bit
    True if only one bit set in num (should be an int)
    _make_class_unpicklable
    Make the given obj un-picklable.

    obj should be either a dictionary, or an Enum
    _break_on_call_reduce%r cannot be pickled_iter_bits_lsboriginal%r is not a positive integershow_flag_valuesmax_bits
    Like built-in bin(), except negative values are represented in
    twos-compliment, and the leading bit always indicates sign
    (0=positive, 1=negative).

    >>> bin(10)
    '0b0 1010'
    >>> bin(~10)   # ~10 is -11
    '0b1 0101'
    ceiling
    Like textwrap.dedent.  Rewritten because we cannot import textwrap.
    blanks_not_given<not given>_auto_null
    Instances are replaced with an appropriate value in Enum class suites.
    auto(%r)
    This is a descriptor, used to define attributes that act differently
    when accessed through an enum member and through an enum class.
    Instance access is the same as property(), but access to an attribute
    through the enum class will instead look in the class' _member_map_ for
    a corresponding enum member.
    _attr_type_cls_typeownerclass%r has no attribute %rdesc_member_map_<enum %r> cannot set attribute %rclsname<enum %r> cannot delete attribute %r_proto_member
    intermediate step for enum members between class execution and final creation
    enum_classmember_name
        convert each quasi-member into an instance of the new enum class
        _member_type__use_args__new_member_enum_member_value_ not set in __new__, unable to create it_member_names__sort_order__flag_mask__singles_mask__all_bits__value2member_map_canonical_memberfound_descriptordescriptor_typeclass_typeredirect_get_set_del_unhashable_values__EnumDict
    Track enum member order and ensure member names are not reused.

    EnumType will use the names found in self._member_names as the
    enumeration member names.
    _member_names_last_values_ignore_auto_called
        Changes anything not dundered or not a descriptor.

        If an enum member name is used twice, an error is raised; duplicate
        values are not checked for.

        Single underscore (sunder) names are reserved.
        _cls_nameIn 3.13 classes created inside an enum will not become a member.  Use the `member` decorator to keep the current behavior."In 3.13 classes created inside an enum will not become a member.  ""Use the `member` decorator to keep the current behavior."_order__generate_next_value__missing__ignore__iter_member__iter_member_by_value__iter_member_by_def__sunder_ names, such as %r, are reserved for future Enum use_generate_next_value_ must be defined before members_gnv_generate_next_valuealready_ignore_ cannot specify already set names: %r__order__%r already defined as %rnon_auto_storeauto_valuedmore_members
    Metaclass for Enum
    metacls_check_for_existing_members_enum_dict_get_mixins_member_typefirst_enumclassdictmember_namesinvalid_namesinvalid enum member name(s) %s_find_new_save_newuse_args_find_data_repr__value_repr__boundary__inverted_ReprEnum subclasses must be mixed with a data type (i.e. int, str, float, etc.)'ReprEnum subclasses must be mixed with a data type (i.e.'' int, str, float, etc.)'enum_methodfound_methodobject_methoddata_type_method__new_member__member_listmember order does not match _order_:
  %r
  %r
        classes/types should always be True.
        
        Either returns an existing member, or creates a new enum class.

        This method is used both when an enum class is given a value to match
        to an enumeration member (i.e. Color(3)) and for the functional API
        (i.e. Color = Enum('Color', names='RED GREEN BLUE')).

        The value lookup branch is chosen if the enum is final.

        When used for the functional API:

        `value` will be the name of the new class.

        `names` should be either a string of white-space/comma delimited names
        (values will start at `start`), or an iterator/mapping of name, value pairs.

        `module` should be set to the module this class is being created in;
        if it is not set, an attempt to find that module will be made, but if
        it fails the class will not be picklable.

        `qualname` should be set to the actual location this class can be found
        at in its module; by default it is set to the global scope.  If this is
        not correct, unpickling will fail in some circumstances.

        `type`, if set, will be mixed in as the first base class.
         has no members; specify `names=()` if you meant to create a new, empty, enum_create_class_nameReturn True if `value` is in `cls`.

        `value` is in `cls` if:
        1) `value` is a member of `cls`, or
        2) `value` is the value of one of the `cls`'s members.
        %r cannot delete member %r.interesting
        Return the member matching `name`.
        
        Return members in definition order.
        
        Return the number of members (no aliases)
        
        Returns a mapping of member name->value.

        This mapping lists all enum members, including aliases. Note that this
        is a read-only view of the internal mapping.
        <flag %r><enum %r>
        Return members in reverse definition order.
        
        Block attempts to reassign Enum members.

        A simple assignment to the class namespace only changes one of the
        several possible ways to get an Enum member from the Enum class,
        resulting in an inconsistent Enumeration.
        member_mapcannot reassign member %r
        Convenience method to create a new Enum class.

        `names` can be:

        * A string containing member names, separated either with spaces or
          commas.  Values are incremented by 1 from `start`.
        * An iterable of member names.  Values are incremented by 1 from `start`.
        * An iterable of (member name, value) pairs.
        * A mapping of member name -> value pairs.
        original_nameslast_valuesmember_value_convert_as_global
        Create a new Enum subclass that replaces a collection of global constants
        tmp_clsetype<enum %r> cannot extend %r
        Returns the type for creating enum members, and the first inherited
        enum class.

        bases: the tuple of bases that was given to __new__
        new enumerations should be created as `EnumName([mixin_type, ...] [data_type,] enum_type)`"new enumerations should be created as ""`EnumName([mixin_type, ...] [data_type,] enum_type)`"_find_data_type__dataclass_reprdata_typesbase_chaincandidatetoo many data types for %r: %r
        Returns the __new__ to be used for creating the enum members.

        classdict: the class dictionary given to __new__
        member_type: the data type whose __new__ will be used by default
        first_enum: enumeration to check for an overriding __new__
        possible
    Create a collection of name/value pairs.

    Example enumeration:

    >>> class Color(Enum):
    ...     RED = 1
    ...     BLUE = 2
    ...     GREEN = 3

    Access them by:

    - attribute access:

      >>> Color.RED
      <Color.RED: 1>

    - value lookup:

      >>> Color(1)
      <Color.RED: 1>

    - name lookup:

      >>> Color['RED']
      <Color.RED: 1>

    Enumerations can be iterated over, and know how many members they have:

    >>> len(Color)
    3

    >>> list(Color)
    [<Color.RED: 1>, <Color.BLUE: 2>, <Color.GREEN: 3>]

    Methods can be added to enumerations, and members can have their own
    attributes -- see the documentation for details.
    __signature__(*values)(new_class_name, /, names, *, module=None, qualname=None, type=None, start=1, boundary=None)%r has no members defined%r is not a valid %sve_excerror in %s._missing_: returned %r instead of None or a valid member
        Generate the next value when not given.

        name: the name of the member
        start: the initial start value or None
        count: the number of existing members
        last_values: the list of values assigned
        In 3.13 the default `auto()`/`_generate_next_value_` will require all values to be sortable and support adding +1
and the value returned will be the largest value in the enum incremented by 1"In 3.13 the default `auto()`/`_generate_next_value_` will require all values to be sortable and support adding +1\n""and the value returned will be the largest value in the enum incremented by 1"v_repr<%s.%s: %s>
        Returns public methods and other interesting attributes.
        The name of the Enum member.The value of the Enum member.
    Only changes the repr(), leaving str() and format() to the mixed-in type.
    
    Enum where members are also (and must be) ints
    
    Enum where members are also (and must be) strings
    values must already be of type `str`too many arguments for str(): %r%r is not a stringencoding must be a string, not %rerrors must be a string, not %r
        Return the lower-cased version of the member name.
        _reduce_ex_by_global_name
    control how out of range values are handled
    "strict" -> error is raised             [default for Flag]
    "conform" -> extra bits are discarded
    "eject" -> lose flag status
    "keep" -> keep flag status and all bits [default for IntFlag]
    
    Support for flags
    
        Generate the next value when not given.

        name: the name of the member
        start: the initial start value or None
        count: the number of existing members
        last_values: the last value assigned or None
        _high_bithigh_bitinvalid flag value %r
        Extract all members from the value in definition (i.e. increasing value) order.
        
        Extract all members from the value in definition order.
        
        Create a composite member containing all canonical members present in `value`.

        If non-member values are present, result depends on `_boundary_` setting.
        flag_masksingles_maskall_bitsneg_value%r invalid value %r
    given %s
  allowed %s%r unknown flag boundary %r%s(%r) -->  unknown values %r [%s]pseudo_membercombined_value%r: no members with value %r|%s
        Returns True if self has at least the same flags set as other.
        unsupported operand type(s) for 'in': %r and %r
        Returns flags in definition order.
        <%s: %s>other_value' cannot be combined with other flags with |' cannot be combined with other flags with &' cannot be combined with other flags with ^' cannot be inverted
    Support for integer-based Flags
    
    returns index of highest bit, or -1 if value is zero or negative
    enumeration
    Class decorator for enumerations ensuring unique member values.
    duplicates%s -> %salias_detailsduplicate values found in %r: %sdcf
    use module.enum_name instead of class.enum_name

    the module is the last module in case of a multi-module name
    
    use module.flag_name instead of class.flag_name

    the module is the last module in case of a multi-module name
    
    use enum_name instead of class.enum_name
    update_str
    decorator that makes the repr() of an enum member reference its module
    instead of its class; also exports all members to the enum's module's
    global namespace
    
    Class decorator that converts a normal class into an :class:`Enum`.  No
    safety checks are done, and some advanced behavior (such as
    :func:`__init_subclass__`) is not available.  Enum creation can be faster
    using :func:`simple_enum`.

        >>> from enum import Enum, _simple_enum
        >>> @_simple_enum(Enum)
        ... class Color:
        ...     RED = auto()
        ...     GREEN = auto()
        ...     BLUE = auto()
        >>> Color
        <enum 'Color'>
    convert_classnew_membergnvvalue2member_mapAn enumeration.gnv_last_valuessingle_bitsmulti_bits
    various conditions to check an enumeration for
    no skipped integer valuesmulti-flag aliases may not contain unnamed flagsone name per value
    Check an enumeration for various constraints. (see EnumCheck)
    checksenum_typethe 'verify' decorator only works with Enum and Flagaliases found in %r: %slowhighverify: unknown type %rinvalid %s %r: missing values %smember_valuesmissing_namesmissing_valuemissedalias %s is missingaliases %s and %s are missingvalue 0x%xcombined values of 0x%xinvalid Flag %r: %s %s [use enum.show_flag_values(value) for details]_test_simple_enumchecked_enumsimple_enum
    A function that can be used to test an enum created with :func:`_simple_enum`
    against the version created by subclassing :class:`Enum`::

        >>> from enum import Enum, _simple_enum, _test_simple_enum
        >>> @_simple_enum(Enum)
        ... class Color:
        ...     RED = auto()
        ...     GREEN = auto()
        ...     BLUE = auto()
        >>> class CheckedColor(Enum):
        ...     RED = auto()
        ...     GREEN = auto()
        ...     BLUE = auto()
        >>> _test_simple_enum(CheckedColor, Color)

    If differences are found, a :exc:`TypeError` is raised.
    checked_dictchecked_keyssimple_dictsimple_keysmissing key: %rextra key:   %rchecked_valuesimple_valuecompressed_checked_valuecompressed_simple_value%r:
         %s
         %schecked -> %rsimple  -> %rfailed_membermissing member from simple enum: %rextra member in simple enum: %rchecked_member_dictchecked_member_keyssimple_member_dictsimple_member_keysmissing key %r not in the simple enum member %rextra key %r in simple enum member %rchecked member -> %rsimple member  -> %r%r member mismatch:
      %s
      __getnewargs_ex__checked_methodsimple_method%r:  %-30s %ssimple -> %renum mismatch:
   %s
   _old_convert_
    Create a new Enum subclass that replaces a collection of global constants
    # Dummy value for Enum and Flag as there are explicit checks for them# before they have been created.# This is also why there are checks in EnumType like `if Enum is not None`# do not use `re` as `re` imports `enum`# num must be a positive integer# use previous enum.property# look up previous attibute# use previous descriptor# look for a member by this name.# first step: remove ourself from enum_class# second step: create member based on enum_class# special case for tuple enums# wrap it one more time# If another member with the same value was already defined, the# new member becomes an alias to the existing one.# try to do a fast lookup to avoid the quadratic loop# this could still be an alias if the value is multi-bit and the# class is a flag class# no other instances found, record this member in _member_names_# if necessary, get redirect in place and then add it to _member_map_# earlier descriptor found; copy fget, fset, fdel to this one.# now add to _member_map_ (even aliases)# This may fail if value is not hashable. We can't add the value# to the map, and by-value lookups for this value will be# linear.# keep track of the value in a list so containment checks are quick# use a dict to keep insertion order# also do nothing, name will be a normal attribute# check if members already defined as auto()# descriptor overwriting an enum?# unwrap value here; it won't be processed by the below `else`# TODO: uncomment next three lines in 3.13# elif _is_internal_class(self._cls_name, value):#     # do nothing, name will be a normal attribute#     pass# enum overwriting a descriptor?# unwrap value here -- it will become a member# insist on an actual tuple, no subclasses, in keeping with only supporting# top-level auto() usage (not contained in any other data structure)# accepts iterable as multiple arguments?# then pass them in singlely# check that previous enum members do not exist# create the namespace dict# inherit previous flags and _generate_next_value_ function# an Enum class is final once enumeration items have been defined; it# cannot be mixed with other types (int, float, etc.) if it has an# inherited __new__ unless a new __new__ is defined (or the resulting# class will fail).# remove any keys listed in _ignore_# grab member names# check for illegal enum names (any others?)# adjust the sunders# convert to normal dict# data type of member and the controlling Enum class# convert future enum members into temporary _proto_members# house-keeping structures# now set the __repr__ for the value# Flag structures (will be removed if final class is not a Flag# since 3.12 the line "Error calling __set_name__ on '_proto_member' instance ..."# is tacked on to the error instead of raising a RuntimeError# recreate the exception to discard# update classdict with any changes made by __init_subclass__# double check that repr and friends are not the mixin's or various# things break (such as pickle)# however, if the method is defined in the Enum itself, don't replace# it# Also, special handling for ReprEnum# if member_type does not define __str__, object.__str__ will use# its __repr__ instead, so we'll also use its __repr__# check for mixin overrides before replacing# for Flag, add __or__, __and__, __xor__, and __invert__# replace any other __new__ with our own (as long as Enum is not None,# anyway) -- again, this is to support pickle# if the user defined their own __new__, save it before it gets# clobbered in case they subclass later# py3 support for definition order (helps keep py2/py3 code in sync)# _order_ checking is spread out into three/four steps# - if enum_class is a Flag:#   - remove any non-single-bit flags from _order_# - remove any aliases from _order_# - check that _order_ and _member_names_ match# step 1: ensure we have a list# remove Flag structures if final class is not a Flag# set correct __iter__# _order_ step 2: remove any items from _order_ that are not single-bit# _order_ step 3: remove aliases from _order_# _order_ step 4: verify that _order_ and _member_names_ match# simple value lookup if members exist# otherwise, functional API: we're creating a new Enum type# no body? no data-type? possibly wrong usage# nicer error message when someone tries to delete an attribute# (see issue19025).# return whatever mixed-in data type has# special processing needed for names?# Here, names is either an iterable of (name, value) or a mapping.# Fall back on _getframe if _getframemodulename is missing# convert all constants from source (or module) that pass filter() to# a new Enum called name, and export the enum and its members back to# module;# also, replace the __reduce_ex__ method so unpickling works in# previous Python versions# _value2member_map_ is populated in the same order every time# for a consistent reverse mapping of number to name when there# are multiple names for the same number.# sort by value# unless some values aren't comparable, in which case sort by name# ensure final parent class is an Enum derivative, find any concrete# data type, and check that Enum has no members# if we hit an Enum, use it's _value_repr_# this is our data repr# double-check if a dataclass with a default __repr__# a datatype has a __new__ method, or a __dataclass_fields__ attribute# now find the correct __new__, checking to see of one was defined# by the user; also check earlier enum classes in case a __new__ was# saved as __new_member__# should __new__ be saved as __new_member__ later?# check all possibles for __new_member__ before falling back to# __new__# if a non-object.__new__ is used then whatever value/tuple was# assigned to the enum member name will be passed to __new__ and to the# new enum member's __init__# all enum instances are actually created during class construction# without calling this method; this method is called by the metaclass'# __call__ (i.e. Color(3) ), and by pickle# For lookups like Color(Color.RED)# by-value search for a matching enum member# see if it's in the reverse mapping (for hashable values)# Not found, no need to do long O(n) search# not there, now do long search -- O(n) behavior# still not found -- verify that members exist, in-case somebody got here mistakenly# (such as via super when trying to override __new__)# still not found -- try _missing_ hook# ensure all variables that could hold an exception are destroyed# no difference between old and new methods# trigger old method (with warning)# that's an enum.property# in case it was added by `dir(self)`# enum.property is used to provide access to the `name` and# `value` attributes of enum members while keeping some measure of# protection from modification, while still allowing for an enumeration# to have members named `name` and `value`.  This works because each# instance of enum.property saves its companion member, which it returns# on class lookup; on instance lookup it either executes a provided function# or raises an AttributeError.# it must be a string# check that encoding argument is a string# check that errors argument is a string# should not be used with Flag-type enums# check boundaries# - value must be in range (e.g. -16 <-> +15, i.e. ~15 <-> 15)# - value must not include any skipped flags (e.g. if bit 2 is not#   defined, then 0d10 is invalid)# get members and unknown# normal Flag?# construct a singleton enum pseudo-member# use setdefault in case another thread already created a composite# with this value# note: zero is a special case -- always add it# Flag / IntFlag# an alias to an existing member# create the member# not a multi-bit alias, record in _member_names_ and _flag_mask_# Enum / IntEnum / StrEnum# check for duplicate names# check for powers of two# check for powers of one# limit max length to protect against DOS attacks# examine each alias and check for unnamed flags# not an alias# negative numbers are not checked# keys known to be different, or very long# members are checked below# remove all spaces/tabs# keys known to be different or absent# cannot compare functions, and it exists in both, so we're good# method is inherited -- check it out# if the method existed in only one of the enums, it will have been caught# in the first checks aboveb'EnumType'u'EnumType'b'EnumMeta'u'EnumMeta'b'Enum'u'Enum'b'IntEnum'u'IntEnum'b'StrEnum'u'StrEnum'b'Flag'u'Flag'b'IntFlag'u'IntFlag'b'ReprEnum'u'ReprEnum'b'unique'u'unique'b'property'u'property'b'verify'u'verify'b'member'u'member'b'nonmember'u'nonmember'b'FlagBoundary'u'FlagBoundary'b'STRICT'u'STRICT'b'CONFORM'u'CONFORM'b'EJECT'u'EJECT'b'KEEP'u'KEEP'b'global_flag_repr'u'global_flag_repr'b'global_enum_repr'u'global_enum_repr'b'global_str'u'global_str'b'global_enum'u'global_enum'b'EnumCheck'u'EnumCheck'b'CONTINUOUS'u'CONTINUOUS'b'NAMED_FLAGS'u'NAMED_FLAGS'b'UNIQUE'u'UNIQUE'b'pickle_by_global_name'u'pickle_by_global_name'b'pickle_by_enum_name'u'pickle_by_enum_name'b'
    Protects item from becoming an Enum member during class creation.
    'u'
    Protects item from becoming an Enum member during class creation.
    'b'
    Forces item to become an Enum member during class creation.
    'u'
    Forces item to become an Enum member during class creation.
    'b'
    Returns True if obj is a descriptor, False otherwise.
    'u'
    Returns True if obj is a descriptor, False otherwise.
    'b'__get__'u'__get__'b'__set__'u'__set__'b'__delete__'u'__delete__'b'
    Returns True if a __dunder__ name, False otherwise.
    'u'
    Returns True if a __dunder__ name, False otherwise.
    'b'
    Returns True if a _sunder_ name, False otherwise.
    'u'
    Returns True if a _sunder_ name, False otherwise.
    'b'_%s__'u'_%s__'b'
    True if only one bit set in num (should be an int)
    'u'
    True if only one bit set in num (should be an int)
    'b'
    Make the given obj un-picklable.

    obj should be either a dictionary, or an Enum
    'u'
    Make the given obj un-picklable.

    obj should be either a dictionary, or an Enum
    'b'%r cannot be pickled'u'%r cannot be pickled'b'%r is not a positive integer'u'%r is not a positive integer'b'
    Like built-in bin(), except negative values are represented in
    twos-compliment, and the leading bit always indicates sign
    (0=positive, 1=negative).

    >>> bin(10)
    '0b0 1010'
    >>> bin(~10)   # ~10 is -11
    '0b1 0101'
    'u'
    Like built-in bin(), except negative values are represented in
    twos-compliment, and the leading bit always indicates sign
    (0=positive, 1=negative).

    >>> bin(10)
    '0b0 1010'
    >>> bin(~10)   # ~10 is -11
    '0b1 0101'
    'b'
    Like textwrap.dedent.  Rewritten because we cannot import textwrap.
    'u'
    Like textwrap.dedent.  Rewritten because we cannot import textwrap.
    'b'<not given>'u'<not given>'b'_auto_null'u'_auto_null'b'
    Instances are replaced with an appropriate value in Enum class suites.
    'u'
    Instances are replaced with an appropriate value in Enum class suites.
    'b'auto(%r)'u'auto(%r)'b'
    This is a descriptor, used to define attributes that act differently
    when accessed through an enum member and through an enum class.
    Instance access is the same as property(), but access to an attribute
    through the enum class will instead look in the class' _member_map_ for
    a corresponding enum member.
    'u'
    This is a descriptor, used to define attributes that act differently
    when accessed through an enum member and through an enum class.
    Instance access is the same as property(), but access to an attribute
    through the enum class will instead look in the class' _member_map_ for
    a corresponding enum member.
    'b'%r has no attribute %r'u'%r has no attribute %r'b'attr'b'desc'u'desc'b'<enum %r> cannot set attribute %r'u'<enum %r> cannot set attribute %r'b'<enum %r> cannot delete attribute %r'u'<enum %r> cannot delete attribute %r'b'
    intermediate step for enum members between class execution and final creation
    'u'
    intermediate step for enum members between class execution and final creation
    'b'
        convert each quasi-member into an instance of the new enum class
        'u'
        convert each quasi-member into an instance of the new enum class
        'b'_value_'u'_value_'b'_value_ not set in __new__, unable to create it'u'_value_ not set in __new__, unable to create it'b'enum'u'enum'b'fget'u'fget'b'fset'u'fset'b'fdel'u'fdel'b'
    Track enum member order and ensure member names are not reused.

    EnumType will use the names found in self._member_names as the
    enumeration member names.
    'u'
    Track enum member order and ensure member names are not reused.

    EnumType will use the names found in self._member_names as the
    enumeration member names.
    'b'
        Changes anything not dundered or not a descriptor.

        If an enum member name is used twice, an error is raised; duplicate
        values are not checked for.

        Single underscore (sunder) names are reserved.
        'u'
        Changes anything not dundered or not a descriptor.

        If an enum member name is used twice, an error is raised; duplicate
        values are not checked for.

        Single underscore (sunder) names are reserved.
        'b'In 3.13 classes created inside an enum will not become a member.  Use the `member` decorator to keep the current behavior.'u'In 3.13 classes created inside an enum will not become a member.  Use the `member` decorator to keep the current behavior.'b'_order_'u'_order_'b'_generate_next_value_'u'_generate_next_value_'b'_numeric_repr_'u'_numeric_repr_'b'_missing_'u'_missing_'b'_ignore_'u'_ignore_'b'_iter_member_'u'_iter_member_'b'_iter_member_by_value_'u'_iter_member_by_value_'b'_iter_member_by_def_'u'_iter_member_by_def_'b'_sunder_ names, such as %r, are reserved for future Enum use'u'_sunder_ names, such as %r, are reserved for future Enum use'b'_generate_next_value_ must be defined before members'u'_generate_next_value_ must be defined before members'b'_generate_next_value'u'_generate_next_value'b'_ignore_ cannot specify already set names: %r'u'_ignore_ cannot specify already set names: %r'b'__order__'u'__order__'b'%r already defined as %r'u'%r already defined as %r'b'
    Metaclass for Enum
    'u'
    Metaclass for Enum
    'b'mro'u'mro'b'invalid enum member name(s) %s'u'invalid enum member name(s) %s'b'_new_member_'u'_new_member_'b'_use_args_'u'_use_args_'b'_member_names_'u'_member_names_'b'_member_map_'u'_member_map_'b'_value2member_map_'u'_value2member_map_'b'_unhashable_values_'u'_unhashable_values_'b'_member_type_'u'_member_type_'b'_value_repr_'u'_value_repr_'b'_boundary_'u'_boundary_'b'_flag_mask_'u'_flag_mask_'b'_singles_mask_'u'_singles_mask_'b'_all_bits_'u'_all_bits_'b'_inverted_'u'_inverted_'b'ReprEnum subclasses must be mixed with a data type (i.e. int, str, float, etc.)'u'ReprEnum subclasses must be mixed with a data type (i.e. int, str, float, etc.)'b'__format__'u'__format__'b'__str__'u'__str__'b'__or__'u'__or__'b'__and__'u'__and__'b'__xor__'u'__xor__'b'__ror__'u'__ror__'b'__rand__'u'__rand__'b'__rxor__'u'__rxor__'b'__invert__'u'__invert__'b'member order does not match _order_:
  %r
  %r'u'member order does not match _order_:
  %r
  %r'b'
        classes/types should always be True.
        'u'
        classes/types should always be True.
        'b'
        Either returns an existing member, or creates a new enum class.

        This method is used both when an enum class is given a value to match
        to an enumeration member (i.e. Color(3)) and for the functional API
        (i.e. Color = Enum('Color', names='RED GREEN BLUE')).

        The value lookup branch is chosen if the enum is final.

        When used for the functional API:

        `value` will be the name of the new class.

        `names` should be either a string of white-space/comma delimited names
        (values will start at `start`), or an iterator/mapping of name, value pairs.

        `module` should be set to the module this class is being created in;
        if it is not set, an attempt to find that module will be made, but if
        it fails the class will not be picklable.

        `qualname` should be set to the actual location this class can be found
        at in its module; by default it is set to the global scope.  If this is
        not correct, unpickling will fail in some circumstances.

        `type`, if set, will be mixed in as the first base class.
        'u'
        Either returns an existing member, or creates a new enum class.

        This method is used both when an enum class is given a value to match
        to an enumeration member (i.e. Color(3)) and for the functional API
        (i.e. Color = Enum('Color', names='RED GREEN BLUE')).

        The value lookup branch is chosen if the enum is final.

        When used for the functional API:

        `value` will be the name of the new class.

        `names` should be either a string of white-space/comma delimited names
        (values will start at `start`), or an iterator/mapping of name, value pairs.

        `module` should be set to the module this class is being created in;
        if it is not set, an attempt to find that module will be made, but if
        it fails the class will not be picklable.

        `qualname` should be set to the actual location this class can be found
        at in its module; by default it is set to the global scope.  If this is
        not correct, unpickling will fail in some circumstances.

        `type`, if set, will be mixed in as the first base class.
        'b' has no members; specify `names=()` if you meant to create a new, empty, enum'u' has no members; specify `names=()` if you meant to create a new, empty, enum'b'Return True if `value` is in `cls`.

        `value` is in `cls` if:
        1) `value` is a member of `cls`, or
        2) `value` is the value of one of the `cls`'s members.
        'u'Return True if `value` is in `cls`.

        `value` is in `cls` if:
        1) `value` is a member of `cls`, or
        2) `value` is the value of one of the `cls`'s members.
        'b'%r cannot delete member %r.'u'%r cannot delete member %r.'b'__class__'u'__class__'b'__getitem__'u'__getitem__'b'__members__'u'__members__'b'__init_subclass__'u'__init_subclass__'b'
        Return the member matching `name`.
        'u'
        Return the member matching `name`.
        'b'
        Return members in definition order.
        'u'
        Return members in definition order.
        'b'
        Return the number of members (no aliases)
        'u'
        Return the number of members (no aliases)
        'b'
        Returns a mapping of member name->value.

        This mapping lists all enum members, including aliases. Note that this
        is a read-only view of the internal mapping.
        'u'
        Returns a mapping of member name->value.

        This mapping lists all enum members, including aliases. Note that this
        is a read-only view of the internal mapping.
        'b'<flag %r>'u'<flag %r>'b'<enum %r>'u'<enum %r>'b'
        Return members in reverse definition order.
        'u'
        Return members in reverse definition order.
        'b'
        Block attempts to reassign Enum members.

        A simple assignment to the class namespace only changes one of the
        several possible ways to get an Enum member from the Enum class,
        resulting in an inconsistent Enumeration.
        'u'
        Block attempts to reassign Enum members.

        A simple assignment to the class namespace only changes one of the
        several possible ways to get an Enum member from the Enum class,
        resulting in an inconsistent Enumeration.
        'b'cannot reassign member %r'u'cannot reassign member %r'b'
        Convenience method to create a new Enum class.

        `names` can be:

        * A string containing member names, separated either with spaces or
          commas.  Values are incremented by 1 from `start`.
        * An iterable of member names.  Values are incremented by 1 from `start`.
        * An iterable of (member name, value) pairs.
        * A mapping of member name -> value pairs.
        'u'
        Convenience method to create a new Enum class.

        `names` can be:

        * A string containing member names, separated either with spaces or
          commas.  Values are incremented by 1 from `start`.
        * An iterable of member names.  Values are incremented by 1 from `start`.
        * An iterable of (member name, value) pairs.
        * A mapping of member name -> value pairs.
        'b'
        Create a new Enum subclass that replaces a collection of global constants
        'u'
        Create a new Enum subclass that replaces a collection of global constants
        'b'<enum %r> cannot extend %r'u'<enum %r> cannot extend %r'b'
        Returns the type for creating enum members, and the first inherited
        enum class.

        bases: the tuple of bases that was given to __new__
        'u'
        Returns the type for creating enum members, and the first inherited
        enum class.

        bases: the tuple of bases that was given to __new__
        'b'new enumerations should be created as `EnumName([mixin_type, ...] [data_type,] enum_type)`'u'new enumerations should be created as `EnumName([mixin_type, ...] [data_type,] enum_type)`'b'too many data types for %r: %r'u'too many data types for %r: %r'b'
        Returns the __new__ to be used for creating the enum members.

        classdict: the class dictionary given to __new__
        member_type: the data type whose __new__ will be used by default
        first_enum: enumeration to check for an overriding __new__
        'u'
        Returns the __new__ to be used for creating the enum members.

        classdict: the class dictionary given to __new__
        member_type: the data type whose __new__ will be used by default
        first_enum: enumeration to check for an overriding __new__
        'b'__new_member__'u'__new_member__'b'
    Create a collection of name/value pairs.

    Example enumeration:

    >>> class Color(Enum):
    ...     RED = 1
    ...     BLUE = 2
    ...     GREEN = 3

    Access them by:

    - attribute access:

      >>> Color.RED
      <Color.RED: 1>

    - value lookup:

      >>> Color(1)
      <Color.RED: 1>

    - name lookup:

      >>> Color['RED']
      <Color.RED: 1>

    Enumerations can be iterated over, and know how many members they have:

    >>> len(Color)
    3

    >>> list(Color)
    [<Color.RED: 1>, <Color.BLUE: 2>, <Color.GREEN: 3>]

    Methods can be added to enumerations, and members can have their own
    attributes -- see the documentation for details.
    'u'
    Create a collection of name/value pairs.

    Example enumeration:

    >>> class Color(Enum):
    ...     RED = 1
    ...     BLUE = 2
    ...     GREEN = 3

    Access them by:

    - attribute access:

      >>> Color.RED
      <Color.RED: 1>

    - value lookup:

      >>> Color(1)
      <Color.RED: 1>

    - name lookup:

      >>> Color['RED']
      <Color.RED: 1>

    Enumerations can be iterated over, and know how many members they have:

    >>> len(Color)
    3

    >>> list(Color)
    [<Color.RED: 1>, <Color.BLUE: 2>, <Color.GREEN: 3>]

    Methods can be added to enumerations, and members can have their own
    attributes -- see the documentation for details.
    'b'(*values)'u'(*values)'b'(new_class_name, /, names, *, module=None, qualname=None, type=None, start=1, boundary=None)'u'(new_class_name, /, names, *, module=None, qualname=None, type=None, start=1, boundary=None)'b'%r has no members defined'u'%r has no members defined'b'%r is not a valid %s'u'%r is not a valid %s'b'error in %s._missing_: returned %r instead of None or a valid member'u'error in %s._missing_: returned %r instead of None or a valid member'b'
        Generate the next value when not given.

        name: the name of the member
        start: the initial start value or None
        count: the number of existing members
        last_values: the list of values assigned
        'u'
        Generate the next value when not given.

        name: the name of the member
        start: the initial start value or None
        count: the number of existing members
        last_values: the list of values assigned
        'b'In 3.13 the default `auto()`/`_generate_next_value_` will require all values to be sortable and support adding +1
and the value returned will be the largest value in the enum incremented by 1'u'In 3.13 the default `auto()`/`_generate_next_value_` will require all values to be sortable and support adding +1
and the value returned will be the largest value in the enum incremented by 1'b'<%s.%s: %s>'u'<%s.%s: %s>'b'
        Returns public methods and other interesting attributes.
        'u'
        Returns public methods and other interesting attributes.
        'b'The name of the Enum member.'u'The name of the Enum member.'b'The value of the Enum member.'u'The value of the Enum member.'b'
    Only changes the repr(), leaving str() and format() to the mixed-in type.
    'u'
    Only changes the repr(), leaving str() and format() to the mixed-in type.
    'b'
    Enum where members are also (and must be) ints
    'u'
    Enum where members are also (and must be) ints
    'b'
    Enum where members are also (and must be) strings
    'u'
    Enum where members are also (and must be) strings
    'b'values must already be of type `str`'u'values must already be of type `str`'b'too many arguments for str(): %r'u'too many arguments for str(): %r'b'%r is not a string'u'%r is not a string'b'encoding must be a string, not %r'u'encoding must be a string, not %r'b'errors must be a string, not %r'u'errors must be a string, not %r'b'
        Return the lower-cased version of the member name.
        'u'
        Return the lower-cased version of the member name.
        'b'
    control how out of range values are handled
    "strict" -> error is raised             [default for Flag]
    "conform" -> extra bits are discarded
    "eject" -> lose flag status
    "keep" -> keep flag status and all bits [default for IntFlag]
    'u'
    control how out of range values are handled
    "strict" -> error is raised             [default for Flag]
    "conform" -> extra bits are discarded
    "eject" -> lose flag status
    "keep" -> keep flag status and all bits [default for IntFlag]
    'b'
    Support for flags
    'u'
    Support for flags
    'b'
        Generate the next value when not given.

        name: the name of the member
        start: the initial start value or None
        count: the number of existing members
        last_values: the last value assigned or None
        'u'
        Generate the next value when not given.

        name: the name of the member
        start: the initial start value or None
        count: the number of existing members
        last_values: the last value assigned or None
        'b'invalid flag value %r'u'invalid flag value %r'b'
        Extract all members from the value in definition (i.e. increasing value) order.
        'u'
        Extract all members from the value in definition (i.e. increasing value) order.
        'b'
        Extract all members from the value in definition order.
        'u'
        Extract all members from the value in definition order.
        'b'
        Create a composite member containing all canonical members present in `value`.

        If non-member values are present, result depends on `_boundary_` setting.
        'u'
        Create a composite member containing all canonical members present in `value`.

        If non-member values are present, result depends on `_boundary_` setting.
        'b'%r invalid value %r
    given %s
  allowed %s'u'%r invalid value %r
    given %s
  allowed %s'b'%r unknown flag boundary %r'u'%r unknown flag boundary %r'b'%s(%r) -->  unknown values %r [%s]'u'%s(%r) -->  unknown values %r [%s]'b'%r: no members with value %r'u'%r: no members with value %r'b'|%s'u'|%s'b'
        Returns True if self has at least the same flags set as other.
        'u'
        Returns True if self has at least the same flags set as other.
        'b'unsupported operand type(s) for 'in': %r and %r'u'unsupported operand type(s) for 'in': %r and %r'b'
        Returns flags in definition order.
        'u'
        Returns flags in definition order.
        'b'<%s: %s>'u'<%s: %s>'b'' cannot be combined with other flags with |'u'' cannot be combined with other flags with |'b'' cannot be combined with other flags with &'u'' cannot be combined with other flags with &'b'' cannot be combined with other flags with ^'u'' cannot be combined with other flags with ^'b'' cannot be inverted'u'' cannot be inverted'b'
    Support for integer-based Flags
    'u'
    Support for integer-based Flags
    'b'
    returns index of highest bit, or -1 if value is zero or negative
    'u'
    returns index of highest bit, or -1 if value is zero or negative
    'b'
    Class decorator for enumerations ensuring unique member values.
    'u'
    Class decorator for enumerations ensuring unique member values.
    'b'%s -> %s'u'%s -> %s'b'duplicate values found in %r: %s'u'duplicate values found in %r: %s'b'
    use module.enum_name instead of class.enum_name

    the module is the last module in case of a multi-module name
    'u'
    use module.enum_name instead of class.enum_name

    the module is the last module in case of a multi-module name
    'b'
    use module.flag_name instead of class.flag_name

    the module is the last module in case of a multi-module name
    'u'
    use module.flag_name instead of class.flag_name

    the module is the last module in case of a multi-module name
    'b'
    use enum_name instead of class.enum_name
    'u'
    use enum_name instead of class.enum_name
    'b'
    decorator that makes the repr() of an enum member reference its module
    instead of its class; also exports all members to the enum's module's
    global namespace
    'u'
    decorator that makes the repr() of an enum member reference its module
    instead of its class; also exports all members to the enum's module's
    global namespace
    'b'
    Class decorator that converts a normal class into an :class:`Enum`.  No
    safety checks are done, and some advanced behavior (such as
    :func:`__init_subclass__`) is not available.  Enum creation can be faster
    using :func:`simple_enum`.

        >>> from enum import Enum, _simple_enum
        >>> @_simple_enum(Enum)
        ... class Color:
        ...     RED = auto()
        ...     GREEN = auto()
        ...     BLUE = auto()
        >>> Color
        <enum 'Color'>
    'u'
    Class decorator that converts a normal class into an :class:`Enum`.  No
    safety checks are done, and some advanced behavior (such as
    :func:`__init_subclass__`) is not available.  Enum creation can be faster
    using :func:`simple_enum`.

        >>> from enum import Enum, _simple_enum
        >>> @_simple_enum(Enum)
        ... class Color:
        ...     RED = auto()
        ...     GREEN = auto()
        ...     BLUE = auto()
        >>> Color
        <enum 'Color'>
    'b'An enumeration.'u'An enumeration.'b'
    various conditions to check an enumeration for
    'u'
    various conditions to check an enumeration for
    'b'no skipped integer values'u'no skipped integer values'b'multi-flag aliases may not contain unnamed flags'u'multi-flag aliases may not contain unnamed flags'b'one name per value'u'one name per value'b'
    Check an enumeration for various constraints. (see EnumCheck)
    'u'
    Check an enumeration for various constraints. (see EnumCheck)
    'b'flag'u'flag'b'the 'verify' decorator only works with Enum and Flag'u'the 'verify' decorator only works with Enum and Flag'b'aliases found in %r: %s'u'aliases found in %r: %s'b'verify: unknown type %r'u'verify: unknown type %r'b'invalid %s %r: missing values %s'u'invalid %s %r: missing values %s'b'alias %s is missing'u'alias %s is missing'b'aliases %s and %s are missing'u'aliases %s and %s are missing'b'value 0x%x'u'value 0x%x'b'combined values of 0x%x'u'combined values of 0x%x'b'invalid Flag %r: %s %s [use enum.show_flag_values(value) for details]'u'invalid Flag %r: %s %s [use enum.show_flag_values(value) for details]'b'
    A function that can be used to test an enum created with :func:`_simple_enum`
    against the version created by subclassing :class:`Enum`::

        >>> from enum import Enum, _simple_enum, _test_simple_enum
        >>> @_simple_enum(Enum)
        ... class Color:
        ...     RED = auto()
        ...     GREEN = auto()
        ...     BLUE = auto()
        >>> class CheckedColor(Enum):
        ...     RED = auto()
        ...     GREEN = auto()
        ...     BLUE = auto()
        >>> _test_simple_enum(CheckedColor, Color)

    If differences are found, a :exc:`TypeError` is raised.
    'u'
    A function that can be used to test an enum created with :func:`_simple_enum`
    against the version created by subclassing :class:`Enum`::

        >>> from enum import Enum, _simple_enum, _test_simple_enum
        >>> @_simple_enum(Enum)
        ... class Color:
        ...     RED = auto()
        ...     GREEN = auto()
        ...     BLUE = auto()
        >>> class CheckedColor(Enum):
        ...     RED = auto()
        ...     GREEN = auto()
        ...     BLUE = auto()
        >>> _test_simple_enum(CheckedColor, Color)

    If differences are found, a :exc:`TypeError` is raised.
    'b'missing key: %r'u'missing key: %r'b'extra key:   %r'u'extra key:   %r'b'%r:
         %s
         %s'u'%r:
         %s
         %s'b'checked -> %r'u'checked -> %r'b'simple  -> %r'u'simple  -> %r'b'missing member from simple enum: %r'u'missing member from simple enum: %r'b'extra member in simple enum: %r'u'extra member in simple enum: %r'b'missing key %r not in the simple enum member %r'u'missing key %r not in the simple enum member %r'b'extra key %r in simple enum member %r'u'extra key %r in simple enum member %r'b'checked member -> %r'u'checked member -> %r'b'simple member  -> %r'u'simple member  -> %r'b'%r member mismatch:
      %s'u'%r member mismatch:
      %s'b'
      'u'
      'b'__getnewargs_ex__'u'__getnewargs_ex__'b'%r:  %-30s %s'u'%r:  %-30s %s'b'simple -> %r'u'simple -> %r'b'enum mismatch:
   %s'u'enum mismatch:
   %s'b'
   'u'
   'b'
    Create a new Enum subclass that replaces a collection of global constants
    'u'
    Create a new Enum subclass that replaces a collection of global constants
    'u'Lib.enum'E2BIGEACCES10048EADDRINUSE1004910047EAFNOSUPPORTEAGAIN10037EALREADYEBADF104EBADMSGEBUSYECANCELEDECHILD1005310061ECONNREFUSED1005436EDEADLKEDEADLOCK10039EDESTADDRREQEDOM10069EDQUOTEEXISTEFAULTEFBIG10064EHOSTDOWN10065EHOSTUNREACH111EIDRM42EILSEQ10036EINPROGRESSEINTREINVALEIO10056EISCONNEISDIR10062ELOOPEMFILEEMLINK10040EMSGSIZEENAMETOOLONG10050ENETDOWN10052ENETRESET10051ENETUNREACHENFILE10055ENOBUFS120ENODATAENODEVENOENTENOEXEC39ENOLCKENOLINKENOMEM122ENOMSG10042ENOSPC124ENOSR125ENOSTRENOSYS10057ENOTCONNENOTDIR41ENOTEMPTYENOTRECOVERABLE10038ENOTSOCKENOTSUPENOTTYENXIO10045EOPNOTSUPPEOVERFLOWEOWNERDEADEPERM10046EPFNOSUPPORTEPROTO10043EPROTONOSUPPORT10041EPROTOTYPEERANGE10071EREMOTEEROFS10058ESHUTDOWN10044ESOCKTNOSUPPORTESPIPEESRCH10070ESTALEETIME10060ETIMEDOUT10059ETOOMANYREFSETXTBSY10068EUSERS10035EWOULDBLOCKEXDEVWSABASEERR10013WSAEACCESWSAEADDRINUSEWSAEADDRNOTAVAILWSAEAFNOSUPPORTWSAEALREADY10009WSAEBADFWSAECONNABORTEDWSAECONNREFUSEDWSAECONNRESETWSAEDESTADDRREQ10101WSAEDISCONWSAEDQUOT10014WSAEFAULTWSAEHOSTDOWNWSAEHOSTUNREACHWSAEINPROGRESS10004WSAEINTR10022WSAEINVALWSAEISCONNWSAELOOP10024WSAEMFILEWSAEMSGSIZE10063WSAENAMETOOLONGWSAENETDOWNWSAENETRESETWSAENETUNREACHWSAENOBUFSWSAENOPROTOOPTWSAENOTCONN10066WSAENOTEMPTYWSAENOTSOCKWSAEOPNOTSUPPWSAEPFNOSUPPORT10067WSAEPROCLIMWSAEPROTONOSUPPORTWSAEPROTOTYPEWSAEREMOTEWSAESHUTDOWNWSAESOCKTNOSUPPORTWSAESTALEWSAETIMEDOUTWSAETOOMANYREFSWSAEUSERSWSAEWOULDBLOCK10093WSANOTINITIALISED10091WSASYSNOTREADY10092WSAVERNOTSUPPORTEDu'This module makes available standard errno system symbols.

The value of each symbol is the corresponding integer value,
e.g., on most systems, errno.ENOENT equals the integer 2.

The dictionary errno.errorcode maps numeric codes to symbol names,
e.g., errno.errorcode[2] could be the string 'ENOENT'.

Symbols that are not relevant to the underlying system are not defined.

To map error codes to error messages, use the function os.strerror(),
e.g. os.strerror(2) could return 'No such file or directory'.'errorcodeemail package exception classes.MessageErrorBase class for errors in the email package.MessageParseErrorBase class for message parsing errors.HeaderParseErrorError while parsing headers.BoundaryErrorCouldn't find terminating boundary.MultipartConversionErrorConversion to a multipart is prohibited.An illegal charset was given.MessageDefectBase class for a message defect.NoBoundaryInMultipartDefectA message claimed to be a multipart but had no boundary parameter.StartBoundaryNotFoundDefectThe claimed start boundary was never found.CloseBoundaryNotFoundDefectA start boundary was found, but not the corresponding close boundary.FirstHeaderLineIsContinuationDefectA message had a continuation line as its first header line.MisplacedEnvelopeHeaderDefectA 'Unix-from' header was found in the middle of a header block.MissingHeaderBodySeparatorDefectFound line with no leading whitespace and no colon before blank line.MalformedHeaderDefectMultipartInvariantViolationDefectA message claimed to be a multipart but no subparts were found.InvalidMultipartContentTransferEncodingDefectAn invalid content transfer encoding was set on the multipart itself.Header contained bytes that could not be decodedbase64 encoded sequence had an incorrect lengthbase64 encoded sequence had characters not in base64 alphabetbase64 encoded sequence had invalid length (1 mod 4)HeaderDefectBase class for a header defect.InvalidHeaderDefectHeader is not valid, message gives details.HeaderMissingRequiredValueA header that must have a value had noneNonPrintableDefectASCII characters outside the ascii-printable range foundnon_printablesthe following ASCII non-printables found in header: {}"the following ASCII non-printables found in header: ""{}"ObsoleteHeaderDefectHeader uses syntax declared obsolete by RFC 5322NonASCIILocalPartDefectlocal_part contains non-ASCII charactersInvalidDateDefectHeader has unparsable or invalid date# These are parsing defects which the parser was able to work around.# XXX: backward compatibility, just in case (it was never emitted).# These errors are specific to header parsing.# This defect only occurs during unicode parsing, not when# parsing messages decoded from binary.b'email package exception classes.'u'email package exception classes.'b'Base class for errors in the email package.'u'Base class for errors in the email package.'b'Base class for message parsing errors.'u'Base class for message parsing errors.'b'Error while parsing headers.'u'Error while parsing headers.'b'Couldn't find terminating boundary.'u'Couldn't find terminating boundary.'b'Conversion to a multipart is prohibited.'u'Conversion to a multipart is prohibited.'b'An illegal charset was given.'u'An illegal charset was given.'b'Base class for a message defect.'u'Base class for a message defect.'b'A message claimed to be a multipart but had no boundary parameter.'u'A message claimed to be a multipart but had no boundary parameter.'b'The claimed start boundary was never found.'u'The claimed start boundary was never found.'b'A start boundary was found, but not the corresponding close boundary.'u'A start boundary was found, but not the corresponding close boundary.'b'A message had a continuation line as its first header line.'u'A message had a continuation line as its first header line.'b'A 'Unix-from' header was found in the middle of a header block.'u'A 'Unix-from' header was found in the middle of a header block.'b'Found line with no leading whitespace and no colon before blank line.'u'Found line with no leading whitespace and no colon before blank line.'b'A message claimed to be a multipart but no subparts were found.'u'A message claimed to be a multipart but no subparts were found.'b'An invalid content transfer encoding was set on the multipart itself.'u'An invalid content transfer encoding was set on the multipart itself.'b'Header contained bytes that could not be decoded'u'Header contained bytes that could not be decoded'b'base64 encoded sequence had an incorrect length'u'base64 encoded sequence had an incorrect length'b'base64 encoded sequence had characters not in base64 alphabet'u'base64 encoded sequence had characters not in base64 alphabet'b'base64 encoded sequence had invalid length (1 mod 4)'u'base64 encoded sequence had invalid length (1 mod 4)'b'Base class for a header defect.'u'Base class for a header defect.'b'Header is not valid, message gives details.'u'Header is not valid, message gives details.'b'A header that must have a value had none'u'A header that must have a value had none'b'ASCII characters outside the ascii-printable range found'u'ASCII characters outside the ascii-printable range found'b'the following ASCII non-printables found in header: {}'u'the following ASCII non-printables found in header: {}'b'Header uses syntax declared obsolete by RFC 5322'u'Header uses syntax declared obsolete by RFC 5322'b'local_part contains non-ASCII characters'u'local_part contains non-ASCII characters'b'Header has unparsable or invalid date'u'Header has unparsable or invalid date'u'Lib.email.errors'u'email.errors'Event loop and event loop policy.AbstractEventLoopPolicyget_event_loop_policyset_event_loop_policyget_event_loopset_event_loopnew_event_loopget_child_watcherset_child_watcherget_running_loopObject returned by callback registration methods._args_reprextract_stack_repr_infoException in callback Object returned by timed callback registration methods.when=Return a scheduled callback time.

        The time is an absolute timestamp, using the same time
        reference as loop.time().
        Abstract server returned by create_server().Stop serving.  This leaves existing connections open.Get the event loop the Server object is attached to.Return True if the server is accepting connections.Start accepting connections.

        This method is idempotent, so it can be called when
        the server is already being serving.
        Start accepting connections until the coroutine is cancelled.

        The server is closed when the coroutine is cancelled.
        Coroutine to wait until service is closed.Abstract event loop.Run the event loop until stop() is called.Run the event loop until a Future is done.

        Return the Future's result, or raise its exception.
        Stop the event loop as soon as reasonable.

        Exactly how soon that is may depend on the implementation, but
        no more I/O callbacks should be scheduled.
        Return whether the event loop is currently running.Close the loop.

        The loop should not be running.

        This is idempotent and irreversible.

        No other methods should be called after this one.
        Schedule the shutdown of the default executor.A coroutine which creates a TCP server bound to host and port.

        The return value is a Server object which can be used to stop
        the service.

        If host is an empty string or None all interfaces are assumed
        and a list of multiple sockets will be returned (most likely
        one for IPv4 and another one for IPv6). The host parameter can also be
        a sequence (e.g. list) of hosts to bind to.

        family can be set to either AF_INET or AF_INET6 to force the
        socket to use IPv4 or IPv6. If not set it will be determined
        from host (defaults to AF_UNSPEC).

        flags is a bitmask for getaddrinfo().

        sock can optionally be specified in order to use a preexisting
        socket object.

        backlog is the maximum number of queued connections passed to
        listen() (defaults to 100).

        ssl can be set to an SSLContext to enable SSL over the
        accepted connections.

        reuse_address tells the kernel to reuse a local socket in
        TIME_WAIT state, without waiting for its natural timeout to
        expire. If not specified will automatically be set to True on
        UNIX.

        reuse_port tells the kernel to allow this endpoint to be bound to
        the same port as other existing endpoints are bound to, so long as
        they all set this flag when being created. This option is not
        supported on Windows.

        ssl_handshake_timeout is the time in seconds that an SSL server
        will wait for completion of the SSL handshake before aborting the
        connection. Default is 60s.

        ssl_shutdown_timeout is the time in seconds that an SSL server
        will wait for completion of the SSL shutdown procedure
        before aborting the connection. Default is 30s.

        start_serving set to True (default) causes the created server
        to start accepting connections immediately.  When set to False,
        the user should await Server.start_serving() or Server.serve_forever()
        to make the server to start accepting connections.
        Send a file through a transport.

        Return an amount of sent bytes.
        Upgrade a transport to TLS.

        Return a new transport that *protocol* should start using
        immediately.
        create_unix_connectioncreate_unix_serverA coroutine which creates a UNIX Domain Socket server.

        The return value is a Server object, which can be used to stop
        the service.

        path is a str, representing a file system path to bind the
        server socket to.

        sock can optionally be specified in order to use a preexisting
        socket object.

        backlog is the maximum number of queued connections passed to
        listen() (defaults to 100).

        ssl can be set to an SSLContext to enable SSL over the
        accepted connections.

        ssl_handshake_timeout is the time in seconds that an SSL server
        will wait for the SSL handshake to complete (defaults to 60s).

        ssl_shutdown_timeout is the time in seconds that an SSL server
        will wait for the SSL shutdown to finish (defaults to 30s).

        start_serving set to True (default) causes the created server
        to start accepting connections immediately.  When set to False,
        the user should await Server.start_serving() or Server.serve_forever()
        to make the server to start accepting connections.
        Handle an accepted connection.

        This is used by servers that accept connections outside of
        asyncio, but use asyncio to handle connections.

        This method is a coroutine.  When completed, the coroutine
        returns a (transport, protocol) pair.
        A coroutine which creates a datagram endpoint.

        This method will try to establish the endpoint in the background.
        When successful, the coroutine returns a (transport, protocol) pair.

        protocol_factory must be a callable returning a protocol instance.

        socket family AF_INET, socket.AF_INET6 or socket.AF_UNIX depending on
        host (or family if specified), socket type SOCK_DGRAM.

        reuse_address tells the kernel to reuse a local socket in
        TIME_WAIT state, without waiting for its natural timeout to
        expire. If not specified it will automatically be set to True on
        UNIX.

        reuse_port tells the kernel to allow this endpoint to be bound to
        the same port as other existing endpoints are bound to, so long as
        they all set this flag when being created. This option is not
        supported on Windows and some UNIX's. If the
        :py:data:`~socket.SO_REUSEPORT` constant is not defined then this
        capability is unsupported.

        allow_broadcast tells the kernel to allow this endpoint to send
        messages to the broadcast address.

        sock can optionally be specified in order to use a preexisting
        socket object.
        Register read pipe in event loop. Set the pipe to non-blocking mode.

        protocol_factory should instantiate object with Protocol interface.
        pipe is a file-like object.
        Return pair (transport, protocol), where transport supports the
        ReadTransport interface.Register write pipe in event loop.

        protocol_factory should instantiate object with BaseProtocol interface.
        Pipe is file-like object already switched to nonblocking.
        Return pair (transport, protocol), where transport support
        WriteTransport interface.add_readerremove_readeradd_writerremove_writersock_recvsock_recv_intosock_recvfromsock_recvfrom_intosock_sendtosock_acceptadd_signal_handlerremove_signal_handlerAbstract policy for accessing the event loop.Get the event loop for the current context.

        Returns an event loop object implementing the AbstractEventLoop interface,
        or raises an exception in case no event loop has been set for the
        current context and the current policy does not specify to create one.

        It should never return None.Set the event loop for the current context to loop.Create and return a new event loop object according to this
        policy's rules. If there's need to set this loop as the event loop for
        the current context, set_event_loop must be called explicitly.Get the watcher for child processes.watcherSet the watcher for child processes.BaseDefaultEventLoopPolicyDefault policy implementation for accessing the event loop.

    In this policy, each thread has its own event loop.  However, we
    only automatically create an event loop by default for the main
    thread; other threads by default have no event loop.

    Other policies may have different rules (e.g. a single global
    event loop, or automatically creating an event loop per thread, or
    using some other notion of context to which an event loop is
    associated).
    _loop_factory_Local_set_calledGet the event loop for the current context.

        Returns an instance of EventLoop or raises an exception.
        main_threadasyncio.There is no current event loopThere is no current event loop in thread %r.Set the event loop.loop must be an instance of AbstractEventLoop or None, not 'Create a new event loop.

        You must call set_event_loop() to make this the current event
        loop.
        _event_loop_policy_RunningLooploop_pid_running_loopReturn the running event loop.  Raise a RuntimeError if there is none.

    This function is thread-specific.
    no running event loopReturn the running event loop or None.

    This is a low-level function intended to be used by event loops.
    This function is thread-specific.
    running_loopSet the running event loop.

    This is a low-level function intended to be used by event loops.
    This function is thread-specific.
    _init_event_loop_policyDefaultEventLoopPolicyGet the current event loop policy.policySet the current event loop policy.

    If policy is None, the default policy is restored.policy must be an instance of AbstractEventLoopPolicy or None, not 'Return an asyncio event loop.

    When called from a coroutine or a callback (e.g. scheduled with call_soon
    or similar API), this function will always return the running event loop.

    If there is no running event loop set, the function will return
    the result of `get_event_loop_policy().get_event_loop()` call.
    current_loopEquivalent to calling get_event_loop_policy().set_event_loop(loop).Equivalent to calling get_event_loop_policy().new_event_loop().Equivalent to calling get_event_loop_policy().get_child_watcher().Equivalent to calling
    get_event_loop_policy().set_child_watcher(watcher)._py__get_running_loop_py__set_running_loop_py_get_running_loop_py_get_event_loop_asyncio_c__get_running_loop_c__set_running_loop_c_get_running_loop_c_get_event_loopon_fork# Keep a representation in debug mode to keep callback and# parameters. For example, to log the warning# "Executing <Handle...> took 2.5 second"# Running and stopping the event loop.# Methods scheduling callbacks.  All these return Handles.# Method scheduling a coroutine object: create a task.# Methods for interacting with threads.# Network I/O methods returning Futures.# Pipes and subprocesses.# The reason to accept file-like object instead of just file descriptor# is: we need to own pipe and close it at transport finishing# Can got complicated errors if pass f.fileno(),# close fd in pipe transport then close f and vice versa.# Ready-based callback registration methods.# The add_*() methods return None.# The remove_*() methods return True if something was removed,# False if there was nothing to delete.# Completion based I/O methods returning Futures.# Signal handling.# Task factory.# Error handlers.# Debug flag management.# Child processes handling (Unix only).# Move up the call stack so that the warning is attached# to the line outside asyncio itself.# Event loop policy.  The policy itself is always global, even if the# policy's rules say that there is an event loop per thread (or other# notion of context).  The default policy is installed by the first# call to get_event_loop_policy().# Lock for protecting the on-the-fly creation of the event loop policy.# A TLS for the running event loop, used by _get_running_loop.# NOTE: this function is implemented in C (see _asynciomodule.c)# pragma: no branch# Alias pure-Python implementations for testing purposes.# get_event_loop() is one of the most frequently called# functions in asyncio.  Pure Python implementation is# about 4 times slower than C-accelerated.# Alias C implementations for testing purposes.# Reset the loop and wakeupfd in the forked child process.b'Event loop and event loop policy.'u'Event loop and event loop policy.'b'AbstractEventLoopPolicy'u'AbstractEventLoopPolicy'b'AbstractEventLoop'u'AbstractEventLoop'b'AbstractServer'u'AbstractServer'b'Handle'u'Handle'b'TimerHandle'u'TimerHandle'b'get_event_loop_policy'u'get_event_loop_policy'b'set_event_loop_policy'u'set_event_loop_policy'b'get_event_loop'u'get_event_loop'b'set_event_loop'u'set_event_loop'b'new_event_loop'u'new_event_loop'b'get_child_watcher'u'get_child_watcher'b'set_child_watcher'u'set_child_watcher'b'_set_running_loop'u'_set_running_loop'b'get_running_loop'u'get_running_loop'b'_get_running_loop'u'_get_running_loop'b'Object returned by callback registration methods.'u'Object returned by callback registration methods.'b'_callback'u'_callback'b'_args'u'_args'b'_cancelled'u'_cancelled'b'_loop'u'_loop'b'_source_traceback'u'_source_traceback'b'_repr'u'_repr'b'_context'u'_context'b'Exception in callback 'u'Exception in callback 'b'Object returned by timed callback registration methods.'u'Object returned by timed callback registration methods.'b'_scheduled'u'_scheduled'b'_when'u'_when'b'when='u'when='b'Return a scheduled callback time.

        The time is an absolute timestamp, using the same time
        reference as loop.time().
        'u'Return a scheduled callback time.

        The time is an absolute timestamp, using the same time
        reference as loop.time().
        'b'Abstract server returned by create_server().'u'Abstract server returned by create_server().'b'Stop serving.  This leaves existing connections open.'u'Stop serving.  This leaves existing connections open.'b'Get the event loop the Server object is attached to.'u'Get the event loop the Server object is attached to.'b'Return True if the server is accepting connections.'u'Return True if the server is accepting connections.'b'Start accepting connections.

        This method is idempotent, so it can be called when
        the server is already being serving.
        'u'Start accepting connections.

        This method is idempotent, so it can be called when
        the server is already being serving.
        'b'Start accepting connections until the coroutine is cancelled.

        The server is closed when the coroutine is cancelled.
        'u'Start accepting connections until the coroutine is cancelled.

        The server is closed when the coroutine is cancelled.
        'b'Coroutine to wait until service is closed.'u'Coroutine to wait until service is closed.'b'Abstract event loop.'u'Abstract event loop.'b'Run the event loop until stop() is called.'u'Run the event loop until stop() is called.'b'Run the event loop until a Future is done.

        Return the Future's result, or raise its exception.
        'u'Run the event loop until a Future is done.

        Return the Future's result, or raise its exception.
        'b'Stop the event loop as soon as reasonable.

        Exactly how soon that is may depend on the implementation, but
        no more I/O callbacks should be scheduled.
        'u'Stop the event loop as soon as reasonable.

        Exactly how soon that is may depend on the implementation, but
        no more I/O callbacks should be scheduled.
        'b'Return whether the event loop is currently running.'u'Return whether the event loop is currently running.'b'Close the loop.

        The loop should not be running.

        This is idempotent and irreversible.

        No other methods should be called after this one.
        'u'Close the loop.

        The loop should not be running.

        This is idempotent and irreversible.

        No other methods should be called after this one.
        'b'Schedule the shutdown of the default executor.'u'Schedule the shutdown of the default executor.'b'A coroutine which creates a TCP server bound to host and port.

        The return value is a Server object which can be used to stop
        the service.

        If host is an empty string or None all interfaces are assumed
        and a list of multiple sockets will be returned (most likely
        one for IPv4 and another one for IPv6). The host parameter can also be
        a sequence (e.g. list) of hosts to bind to.

        family can be set to either AF_INET or AF_INET6 to force the
        socket to use IPv4 or IPv6. If not set it will be determined
        from host (defaults to AF_UNSPEC).

        flags is a bitmask for getaddrinfo().

        sock can optionally be specified in order to use a preexisting
        socket object.

        backlog is the maximum number of queued connections passed to
        listen() (defaults to 100).

        ssl can be set to an SSLContext to enable SSL over the
        accepted connections.

        reuse_address tells the kernel to reuse a local socket in
        TIME_WAIT state, without waiting for its natural timeout to
        expire. If not specified will automatically be set to True on
        UNIX.

        reuse_port tells the kernel to allow this endpoint to be bound to
        the same port as other existing endpoints are bound to, so long as
        they all set this flag when being created. This option is not
        supported on Windows.

        ssl_handshake_timeout is the time in seconds that an SSL server
        will wait for completion of the SSL handshake before aborting the
        connection. Default is 60s.

        ssl_shutdown_timeout is the time in seconds that an SSL server
        will wait for completion of the SSL shutdown procedure
        before aborting the connection. Default is 30s.

        start_serving set to True (default) causes the created server
        to start accepting connections immediately.  When set to False,
        the user should await Server.start_serving() or Server.serve_forever()
        to make the server to start accepting connections.
        'u'A coroutine which creates a TCP server bound to host and port.

        The return value is a Server object which can be used to stop
        the service.

        If host is an empty string or None all interfaces are assumed
        and a list of multiple sockets will be returned (most likely
        one for IPv4 and another one for IPv6). The host parameter can also be
        a sequence (e.g. list) of hosts to bind to.

        family can be set to either AF_INET or AF_INET6 to force the
        socket to use IPv4 or IPv6. If not set it will be determined
        from host (defaults to AF_UNSPEC).

        flags is a bitmask for getaddrinfo().

        sock can optionally be specified in order to use a preexisting
        socket object.

        backlog is the maximum number of queued connections passed to
        listen() (defaults to 100).

        ssl can be set to an SSLContext to enable SSL over the
        accepted connections.

        reuse_address tells the kernel to reuse a local socket in
        TIME_WAIT state, without waiting for its natural timeout to
        expire. If not specified will automatically be set to True on
        UNIX.

        reuse_port tells the kernel to allow this endpoint to be bound to
        the same port as other existing endpoints are bound to, so long as
        they all set this flag when being created. This option is not
        supported on Windows.

        ssl_handshake_timeout is the time in seconds that an SSL server
        will wait for completion of the SSL handshake before aborting the
        connection. Default is 60s.

        ssl_shutdown_timeout is the time in seconds that an SSL server
        will wait for completion of the SSL shutdown procedure
        before aborting the connection. Default is 30s.

        start_serving set to True (default) causes the created server
        to start accepting connections immediately.  When set to False,
        the user should await Server.start_serving() or Server.serve_forever()
        to make the server to start accepting connections.
        'b'Send a file through a transport.

        Return an amount of sent bytes.
        'u'Send a file through a transport.

        Return an amount of sent bytes.
        'b'Upgrade a transport to TLS.

        Return a new transport that *protocol* should start using
        immediately.
        'u'Upgrade a transport to TLS.

        Return a new transport that *protocol* should start using
        immediately.
        'b'A coroutine which creates a UNIX Domain Socket server.

        The return value is a Server object, which can be used to stop
        the service.

        path is a str, representing a file system path to bind the
        server socket to.

        sock can optionally be specified in order to use a preexisting
        socket object.

        backlog is the maximum number of queued connections passed to
        listen() (defaults to 100).

        ssl can be set to an SSLContext to enable SSL over the
        accepted connections.

        ssl_handshake_timeout is the time in seconds that an SSL server
        will wait for the SSL handshake to complete (defaults to 60s).

        ssl_shutdown_timeout is the time in seconds that an SSL server
        will wait for the SSL shutdown to finish (defaults to 30s).

        start_serving set to True (default) causes the created server
        to start accepting connections immediately.  When set to False,
        the user should await Server.start_serving() or Server.serve_forever()
        to make the server to start accepting connections.
        'u'A coroutine which creates a UNIX Domain Socket server.

        The return value is a Server object, which can be used to stop
        the service.

        path is a str, representing a file system path to bind the
        server socket to.

        sock can optionally be specified in order to use a preexisting
        socket object.

        backlog is the maximum number of queued connections passed to
        listen() (defaults to 100).

        ssl can be set to an SSLContext to enable SSL over the
        accepted connections.

        ssl_handshake_timeout is the time in seconds that an SSL server
        will wait for the SSL handshake to complete (defaults to 60s).

        ssl_shutdown_timeout is the time in seconds that an SSL server
        will wait for the SSL shutdown to finish (defaults to 30s).

        start_serving set to True (default) causes the created server
        to start accepting connections immediately.  When set to False,
        the user should await Server.start_serving() or Server.serve_forever()
        to make the server to start accepting connections.
        'b'Handle an accepted connection.

        This is used by servers that accept connections outside of
        asyncio, but use asyncio to handle connections.

        This method is a coroutine.  When completed, the coroutine
        returns a (transport, protocol) pair.
        'u'Handle an accepted connection.

        This is used by servers that accept connections outside of
        asyncio, but use asyncio to handle connections.

        This method is a coroutine.  When completed, the coroutine
        returns a (transport, protocol) pair.
        'b'A coroutine which creates a datagram endpoint.

        This method will try to establish the endpoint in the background.
        When successful, the coroutine returns a (transport, protocol) pair.

        protocol_factory must be a callable returning a protocol instance.

        socket family AF_INET, socket.AF_INET6 or socket.AF_UNIX depending on
        host (or family if specified), socket type SOCK_DGRAM.

        reuse_address tells the kernel to reuse a local socket in
        TIME_WAIT state, without waiting for its natural timeout to
        expire. If not specified it will automatically be set to True on
        UNIX.

        reuse_port tells the kernel to allow this endpoint to be bound to
        the same port as other existing endpoints are bound to, so long as
        they all set this flag when being created. This option is not
        supported on Windows and some UNIX's. If the
        :py:data:`~socket.SO_REUSEPORT` constant is not defined then this
        capability is unsupported.

        allow_broadcast tells the kernel to allow this endpoint to send
        messages to the broadcast address.

        sock can optionally be specified in order to use a preexisting
        socket object.
        'u'A coroutine which creates a datagram endpoint.

        This method will try to establish the endpoint in the background.
        When successful, the coroutine returns a (transport, protocol) pair.

        protocol_factory must be a callable returning a protocol instance.

        socket family AF_INET, socket.AF_INET6 or socket.AF_UNIX depending on
        host (or family if specified), socket type SOCK_DGRAM.

        reuse_address tells the kernel to reuse a local socket in
        TIME_WAIT state, without waiting for its natural timeout to
        expire. If not specified it will automatically be set to True on
        UNIX.

        reuse_port tells the kernel to allow this endpoint to be bound to
        the same port as other existing endpoints are bound to, so long as
        they all set this flag when being created. This option is not
        supported on Windows and some UNIX's. If the
        :py:data:`~socket.SO_REUSEPORT` constant is not defined then this
        capability is unsupported.

        allow_broadcast tells the kernel to allow this endpoint to send
        messages to the broadcast address.

        sock can optionally be specified in order to use a preexisting
        socket object.
        'b'Register read pipe in event loop. Set the pipe to non-blocking mode.

        protocol_factory should instantiate object with Protocol interface.
        pipe is a file-like object.
        Return pair (transport, protocol), where transport supports the
        ReadTransport interface.'u'Register read pipe in event loop. Set the pipe to non-blocking mode.

        protocol_factory should instantiate object with Protocol interface.
        pipe is a file-like object.
        Return pair (transport, protocol), where transport supports the
        ReadTransport interface.'b'Register write pipe in event loop.

        protocol_factory should instantiate object with BaseProtocol interface.
        Pipe is file-like object already switched to nonblocking.
        Return pair (transport, protocol), where transport support
        WriteTransport interface.'u'Register write pipe in event loop.

        protocol_factory should instantiate object with BaseProtocol interface.
        Pipe is file-like object already switched to nonblocking.
        Return pair (transport, protocol), where transport support
        WriteTransport interface.'b'Abstract policy for accessing the event loop.'u'Abstract policy for accessing the event loop.'b'Get the event loop for the current context.

        Returns an event loop object implementing the AbstractEventLoop interface,
        or raises an exception in case no event loop has been set for the
        current context and the current policy does not specify to create one.

        It should never return None.'u'Get the event loop for the current context.

        Returns an event loop object implementing the AbstractEventLoop interface,
        or raises an exception in case no event loop has been set for the
        current context and the current policy does not specify to create one.

        It should never return None.'b'Set the event loop for the current context to loop.'u'Set the event loop for the current context to loop.'b'Create and return a new event loop object according to this
        policy's rules. If there's need to set this loop as the event loop for
        the current context, set_event_loop must be called explicitly.'u'Create and return a new event loop object according to this
        policy's rules. If there's need to set this loop as the event loop for
        the current context, set_event_loop must be called explicitly.'b'Get the watcher for child processes.'u'Get the watcher for child processes.'b'Set the watcher for child processes.'u'Set the watcher for child processes.'b'Default policy implementation for accessing the event loop.

    In this policy, each thread has its own event loop.  However, we
    only automatically create an event loop by default for the main
    thread; other threads by default have no event loop.

    Other policies may have different rules (e.g. a single global
    event loop, or automatically creating an event loop per thread, or
    using some other notion of context to which an event loop is
    associated).
    'u'Default policy implementation for accessing the event loop.

    In this policy, each thread has its own event loop.  However, we
    only automatically create an event loop by default for the main
    thread; other threads by default have no event loop.

    Other policies may have different rules (e.g. a single global
    event loop, or automatically creating an event loop per thread, or
    using some other notion of context to which an event loop is
    associated).
    'b'Get the event loop for the current context.

        Returns an instance of EventLoop or raises an exception.
        'u'Get the event loop for the current context.

        Returns an instance of EventLoop or raises an exception.
        'b'asyncio.'u'asyncio.'b'There is no current event loop'u'There is no current event loop'b'There is no current event loop in thread %r.'u'There is no current event loop in thread %r.'b'Set the event loop.'u'Set the event loop.'b'loop must be an instance of AbstractEventLoop or None, not ''u'loop must be an instance of AbstractEventLoop or None, not ''b'Create a new event loop.

        You must call set_event_loop() to make this the current event
        loop.
        'u'Create a new event loop.

        You must call set_event_loop() to make this the current event
        loop.
        'b'Return the running event loop.  Raise a RuntimeError if there is none.

    This function is thread-specific.
    'u'Return the running event loop.  Raise a RuntimeError if there is none.

    This function is thread-specific.
    'b'no running event loop'u'no running event loop'b'Return the running event loop or None.

    This is a low-level function intended to be used by event loops.
    This function is thread-specific.
    'u'Return the running event loop or None.

    This is a low-level function intended to be used by event loops.
    This function is thread-specific.
    'b'Set the running event loop.

    This is a low-level function intended to be used by event loops.
    This function is thread-specific.
    'u'Set the running event loop.

    This is a low-level function intended to be used by event loops.
    This function is thread-specific.
    'b'Get the current event loop policy.'u'Get the current event loop policy.'b'Set the current event loop policy.

    If policy is None, the default policy is restored.'u'Set the current event loop policy.

    If policy is None, the default policy is restored.'b'policy must be an instance of AbstractEventLoopPolicy or None, not ''u'policy must be an instance of AbstractEventLoopPolicy or None, not ''b'Return an asyncio event loop.

    When called from a coroutine or a callback (e.g. scheduled with call_soon
    or similar API), this function will always return the running event loop.

    If there is no running event loop set, the function will return
    the result of `get_event_loop_policy().get_event_loop()` call.
    'u'Return an asyncio event loop.

    When called from a coroutine or a callback (e.g. scheduled with call_soon
    or similar API), this function will always return the running event loop.

    If there is no running event loop set, the function will return
    the result of `get_event_loop_policy().get_event_loop()` call.
    'b'Equivalent to calling get_event_loop_policy().set_event_loop(loop).'u'Equivalent to calling get_event_loop_policy().set_event_loop(loop).'b'Equivalent to calling get_event_loop_policy().new_event_loop().'u'Equivalent to calling get_event_loop_policy().new_event_loop().'b'Equivalent to calling get_event_loop_policy().get_child_watcher().'u'Equivalent to calling get_event_loop_policy().get_child_watcher().'b'Equivalent to calling
    get_event_loop_policy().set_child_watcher(watcher).'u'Equivalent to calling
    get_event_loop_policy().set_child_watcher(watcher).'u'Lib.asyncio.events'u'asyncio.events'u'events'asyncio exceptions.BrokenBarrierErrorIncompleteReadErrorLimitOverrunErrorThe Future or Task was cancelled.Sendfile syscall is not available.

    Raised if OS does not support sendfile syscall for given socket or
    file type.
    
    Incomplete read error. Attributes:

    - partial: read bytes string before the end of stream was reached
    - expected: total number of expected bytes (or None if unknown)
    undefinedr_expected bytes read on a total of ' bytes read on a total of ' expected bytesReached the buffer limit while looking for a separator.

    Attributes:
    - consumed: total number of to be consumed bytes.
    Barrier is broken by barrier.abort() call.b'asyncio exceptions.'u'asyncio exceptions.'b'BrokenBarrierError'u'BrokenBarrierError'b'InvalidStateError'u'InvalidStateError'b'IncompleteReadError'u'IncompleteReadError'b'LimitOverrunError'u'LimitOverrunError'b'SendfileNotAvailableError'u'SendfileNotAvailableError'b'The Future or Task was cancelled.'u'The Future or Task was cancelled.'b'Sendfile syscall is not available.

    Raised if OS does not support sendfile syscall for given socket or
    file type.
    'u'Sendfile syscall is not available.

    Raised if OS does not support sendfile syscall for given socket or
    file type.
    'b'
    Incomplete read error. Attributes:

    - partial: read bytes string before the end of stream was reached
    - expected: total number of expected bytes (or None if unknown)
    'u'
    Incomplete read error. Attributes:

    - partial: read bytes string before the end of stream was reached
    - expected: total number of expected bytes (or None if unknown)
    'b'undefined'u'undefined'b' bytes read on a total of 'u' bytes read on a total of 'b' expected bytes'u' expected bytes'b'Reached the buffer limit while looking for a separator.

    Attributes:
    - consumed: total number of to be consumed bytes.
    'u'Reached the buffer limit while looking for a separator.

    Attributes:
    - consumed: total number of to be consumed bytes.
    'b'Barrier is broken by barrier.abort() call.'u'Barrier is broken by barrier.abort() call.'u'Lib.asyncio.exceptions'u'asyncio.exceptions'Interface to the Expat non-validating XML parser.pyexpatxml.parsers.expat.modelxml.parsers.expat.errors# provide pyexpat submodules as xml.parsers.expat submodulesb'Interface to the Expat non-validating XML parser.'u'Interface to the Expat non-validating XML parser.'b'xml.parsers.expat.model'u'xml.parsers.expat.model'b'xml.parsers.expat.errors'u'xml.parsers.expat.errors'u'Lib.xml.parsers.expat'u'xml.parsers.expat'u'parsers.expat'u'expat'FeedParser - An email feed parser.

The feed parser implements an interface for incrementally parsing an email
message, line by line.  This has advantages for certain applications, such as
those reading email messages off a socket.

FeedParser.feed() is the primary interface for pushing new data into the
parser.  It returns when there's nothing more it can do with the available
data.  When you have no more data to push into the parser, call .close().
This completes the parsing and returns the root message object.

The other advantage of this parser is that it will never raise a parsing
exception.  Instead, when it finds something unexpected, it adds a 'defect' to
the current message.  Defects are just instances that live on the message
object's .defects attribute.
FeedParserBytesFeedParseremail._policybase\r\n|\r|\nNLCRE(\r\n|\r|\n)NLCRE_bol(\r\n|\r|\n)\ZNLCRE_eolNLCRE_crack^(From |[\041-\071\073-\176]*:|[\t ])headerRENeedMoreDataBufferedSubFileA file-ish object that can have new data loaded into it.

    You can also push and pop line-matching predicates onto a stack.  When the
    current predicate matches the current line, a false EOF response
    (i.e. empty string) is returned instead.  This lets the parser adhere to a
    simple abstraction -- it parses until EOF closes the current message.
    _partial_lines_eofstackpush_eof_matcherpredpop_eof_matcherpushlinesateofunreadlinePush some new data into this object.A feed-style parser of email._factory_factory is called with no arguments to create a new message obj

        The policy keyword specifies a policy object that controls a number of
        aspects of the parser's operation.  The default policy maintains
        backward compatibility.

        _old_style_factory_input_msgstack_parsegen_cur_last_headersonly_set_headersonlyPush more data into the parser._call_parseParse all remaining data and return the root message object._pop_messageget_content_maintypemultipartis_multipart_new_messageget_content_typemultipart/digestset_default_typemessage/rfc822attach_parse_headersmessage/delivery-statusget_boundarycontent-transfer-encodingbinaryseparator(?P<sep>)(?P<end>--)?(?P<ws>[ \t]*)(?P<linesep>\r\n|\r|\n)?$boundaryrecapturing_preamblepreambleclose_boundary_seenmoeolmoepilogue_payloadbolmolastheaderlastvalueset_rawFrom set_unixfromMissing header name._parse_headers fed line with no : and no leading WSLike FeedParser, but feed accepts bytes.# Copyright (C) 2004-2006 Python Software Foundation# Authors: Baxter, Wouters and Warsaw# RFC 2822 $3.6.8 Optional fields.  ftext is %d33-57 / %d59-126, Any character# except controls, SP, and ":".# Text stream of the last partial line pushed into this object.# See issue 22233 for why this is a text stream and not a list.# A deque of full, pushed lines# The stack of false-EOF checking predicates.# A flag indicating whether the file has been closed or not.# Don't forget any trailing partial line.# Pop the line off the stack and see if it matches the current# false-EOF predicate.# RFC 2046, section 5.1.2 requires us to recognize outer level# boundaries at any level of inner nesting.  Do this, but be sure it's# in the order of most to least nested.# We're at the false EOF.  But push the last line back first.# Let the consumer push a line back into the buffer.# No new complete lines, wait for more.# Crack into lines, preserving the linesep characters.# If the last element of the list does not end in a newline, then treat# it as a partial line.  We only check for '\n' here because a line# ending with '\r' might be a line that was split in the middle of a# '\r\n' sequence (see bugs 1555570 and 1721862).# Assume this is an old-style factory# Non-public interface for supporting Parser's headersonly flag# Look for final set of defects# Create a new message and start by parsing headers.# Collect the headers, searching for a line that doesn't match the RFC# 2822 header or continuation pattern (including an empty line).# If we saw the RFC defined header/body separator# (i.e. newline), just throw it away. Otherwise the line is# part of the body so push it back.# Done with the headers, so parse them and figure out what we're# supposed to see in the body of the message.# Headers-only parsing is a backwards compatibility hack, which was# necessary in the older parser, which could raise errors.  All# remaining lines in the input are thrown into the message body.# message/delivery-status contains blocks of headers separated by# a blank line.  We'll represent each header block as a separate# nested message object, but the processing is a bit different# than standard message/* types because there is no body for the# nested messages.  A blank line separates the subparts.# We need to pop the EOF matcher in order to tell if we're at# the end of the current file, not the end of the last block# of message headers.# The input stream must be sitting at the newline or at the# EOF.  We want to see if we're at the end of this subpart, so# first consume the blank line, then test the next line to see# if we're at this subpart's EOF.# Not at EOF so this is a line we're going to need.# The message claims to be a message/* type, then what follows is# another RFC 2822 message.# The message /claims/ to be a multipart but it has not# defined a boundary.  That's a problem which we'll handle by# reading everything until the EOF and marking the message as# defective.# Make sure a valid content type was specified per RFC 2045:6.4.# Create a line match predicate which matches the inter-part# boundary as well as the end-of-multipart boundary.  Don't push# this onto the input stream until we've scanned past the# preamble.# If we're looking at the end boundary, we're done with# this multipart.  If there was a newline at the end of# the closing boundary, then we need to initialize the# epilogue with the empty string (see below).# We saw an inter-part boundary.  Were we in the preamble?# According to RFC 2046, the last newline belongs# to the boundary.# We saw a boundary separating two parts.  Consume any# multiple boundary lines that may be following.  Our# interpretation of RFC 2046 BNF grammar does not produce# body parts within such double boundaries.# Recurse to parse this subpart; the input stream points# at the subpart's first line.# Because of RFC 2046, the newline preceding the boundary# separator actually belongs to the boundary, not the# previous subpart's payload (or epilogue if the previous# part is a multipart).# Set the multipart up for newline cleansing, which will# happen if we're in a nested multipart.# I think we must be in the preamble# We've seen either the EOF or the end boundary.  If we're still# capturing the preamble, we never saw the start boundary.  Note# that as a defect and store the captured text as the payload.# If we're not processing the preamble, then we might have seen# EOF without seeing that end boundary...that is also a defect.# Everything from here to the EOF is epilogue.  If the end boundary# ended in a newline, we'll need to make sure the epilogue isn't# Any CRLF at the front of the epilogue is not technically part of# the epilogue.  Also, watch out for an empty string epilogue,# which means a single newline.# Otherwise, it's some non-multipart type, so the entire rest of the# file contents becomes the payload.# Passed a list of lines that make up the headers for the current msg# Check for continuation# The first line of the headers was a continuation.  This# is illegal, so let's note the defect, store the illegal# line, and ignore it for purposes of headers.# Check for envelope header, i.e. unix-from# Strip off the trailing newline# Something looking like a unix-from at the end - it's# probably the first line of the body, so push back the# line and stop.# Weirdly placed unix-from line.  Note this as a defect# and ignore it.# Split the line on the colon separating field name from value.# There will always be a colon, because if there wasn't the part of# the parser that calls us would have started parsing the body.# If the colon is on the start of the line the header is clearly# malformed, but we might be able to salvage the rest of the# message. Track the error but keep going.# Done with all the lines, so handle the last header.b'FeedParser - An email feed parser.

The feed parser implements an interface for incrementally parsing an email
message, line by line.  This has advantages for certain applications, such as
those reading email messages off a socket.

FeedParser.feed() is the primary interface for pushing new data into the
parser.  It returns when there's nothing more it can do with the available
data.  When you have no more data to push into the parser, call .close().
This completes the parsing and returns the root message object.

The other advantage of this parser is that it will never raise a parsing
exception.  Instead, when it finds something unexpected, it adds a 'defect' to
the current message.  Defects are just instances that live on the message
object's .defects attribute.
'u'FeedParser - An email feed parser.

The feed parser implements an interface for incrementally parsing an email
message, line by line.  This has advantages for certain applications, such as
those reading email messages off a socket.

FeedParser.feed() is the primary interface for pushing new data into the
parser.  It returns when there's nothing more it can do with the available
data.  When you have no more data to push into the parser, call .close().
This completes the parsing and returns the root message object.

The other advantage of this parser is that it will never raise a parsing
exception.  Instead, when it finds something unexpected, it adds a 'defect' to
the current message.  Defects are just instances that live on the message
object's .defects attribute.
'b'FeedParser'u'FeedParser'b'BytesFeedParser'u'BytesFeedParser'b'\r\n|\r|\n'u'\r\n|\r|\n'b'(\r\n|\r|\n)'u'(\r\n|\r|\n)'b'(\r\n|\r|\n)\Z'u'(\r\n|\r|\n)\Z'b'^(From |[\041-\071\073-\176]*:|[\t ])'u'^(From |[\041-\071\073-\176]*:|[\t ])'b'A file-ish object that can have new data loaded into it.

    You can also push and pop line-matching predicates onto a stack.  When the
    current predicate matches the current line, a false EOF response
    (i.e. empty string) is returned instead.  This lets the parser adhere to a
    simple abstraction -- it parses until EOF closes the current message.
    'u'A file-ish object that can have new data loaded into it.

    You can also push and pop line-matching predicates onto a stack.  When the
    current predicate matches the current line, a false EOF response
    (i.e. empty string) is returned instead.  This lets the parser adhere to a
    simple abstraction -- it parses until EOF closes the current message.
    'b'Push some new data into this object.'u'Push some new data into this object.'b'A feed-style parser of email.'u'A feed-style parser of email.'b'_factory is called with no arguments to create a new message obj

        The policy keyword specifies a policy object that controls a number of
        aspects of the parser's operation.  The default policy maintains
        backward compatibility.

        'u'_factory is called with no arguments to create a new message obj

        The policy keyword specifies a policy object that controls a number of
        aspects of the parser's operation.  The default policy maintains
        backward compatibility.

        'b'Push more data into the parser.'u'Push more data into the parser.'b'Parse all remaining data and return the root message object.'u'Parse all remaining data and return the root message object.'b'multipart'u'multipart'b'multipart/digest'u'multipart/digest'b'message/rfc822'u'message/rfc822'b'message/delivery-status'u'message/delivery-status'b'content-transfer-encoding'u'content-transfer-encoding'b'binary'u'binary'b'(?P<sep>'u'(?P<sep>'b')(?P<end>--)?(?P<ws>[ \t]*)(?P<linesep>\r\n|\r|\n)?$'u')(?P<end>--)?(?P<ws>[ \t]*)(?P<linesep>\r\n|\r|\n)?$'b'end'u'end'b'linesep'u'linesep'b'From 'u'From 'b'Missing header name.'u'Missing header name.'b'_parse_headers fed line with no : and no leading WS'u'_parse_headers fed line with no : and no leading WS'b'Like FeedParser, but feed accepts bytes.'u'Like FeedParser, but feed accepts bytes.'u'Lib.email.feedparser'u'email.feedparser'Filename matching with shell patterns.

fnmatch(FILENAME, PATTERN) matches according to the local convention.
fnmatchcase(FILENAME, PATTERN) always takes case in account.

The functions operate by translating the pattern into a regular
expression.  They cache the compiled regular expressions for speed.

The function translate(PATTERN) returns a regular expression
corresponding to PATTERN.  (It does not compile it.)
fnmatchcaseTest whether FILENAME matches PATTERN.

    Patterns are Unix shell style:

    *       matches everything
    ?       matches any single character
    [seq]   matches any character in seq
    [!seq]  matches any char not in seq

    An initial period in FILENAME is not special.
    Both FILENAME and PATTERN are first case-normalized
    if the operating system requires it.
    If you don't want this, use fnmatchcase(FILENAME, PATTERN).
    typed_compile_patternISO-8859-1pat_strres_strConstruct a list from those elements of the iterable NAMES that match PAT.Test whether FILENAME matches PATTERN, including case.

    This is a version of fnmatch() which doesn't case-normalize
    its arguments.
    Translate a shell PATTERN to a regular expression.

    There is no way to quote meta-characters.
    STAR\[\-([&~|])\\\1(?!)inp.*fixed(?>.*?(?s:fr')\Z# normcase on posix is NOP. Optimize it away from the loop.# compress consecutive `*` into one# Remove empty ranges -- invalid in RE.# Escape backslashes and hyphens for set difference (--).# Hyphens that create ranges shouldn't be escaped.# Escape set operations (&&, ~~ and ||).# Empty range: never match.# Negated empty range: match any character.# Deal with STARs.# Fixed pieces at the start?# Now deal with STAR fixed STAR fixed ...# For an interior `STAR fixed` pairing, we want to do a minimal# .*? match followed by `fixed`, with no possibility of backtracking.# Atomic groups ("(?>...)") allow us to spell that directly.# Note: people rely on the undocumented ability to join multiple# translate() results together via "|" to build large regexps matching# "one of many" shell patterns.b'Filename matching with shell patterns.

fnmatch(FILENAME, PATTERN) matches according to the local convention.
fnmatchcase(FILENAME, PATTERN) always takes case in account.

The functions operate by translating the pattern into a regular
expression.  They cache the compiled regular expressions for speed.

The function translate(PATTERN) returns a regular expression
corresponding to PATTERN.  (It does not compile it.)
'u'Filename matching with shell patterns.

fnmatch(FILENAME, PATTERN) matches according to the local convention.
fnmatchcase(FILENAME, PATTERN) always takes case in account.

The functions operate by translating the pattern into a regular
expression.  They cache the compiled regular expressions for speed.

The function translate(PATTERN) returns a regular expression
corresponding to PATTERN.  (It does not compile it.)
'b'fnmatch'u'fnmatch'b'fnmatchcase'u'fnmatchcase'b'translate'u'translate'b'Test whether FILENAME matches PATTERN.

    Patterns are Unix shell style:

    *       matches everything
    ?       matches any single character
    [seq]   matches any character in seq
    [!seq]  matches any char not in seq

    An initial period in FILENAME is not special.
    Both FILENAME and PATTERN are first case-normalized
    if the operating system requires it.
    If you don't want this, use fnmatchcase(FILENAME, PATTERN).
    'u'Test whether FILENAME matches PATTERN.

    Patterns are Unix shell style:

    *       matches everything
    ?       matches any single character
    [seq]   matches any character in seq
    [!seq]  matches any char not in seq

    An initial period in FILENAME is not special.
    Both FILENAME and PATTERN are first case-normalized
    if the operating system requires it.
    If you don't want this, use fnmatchcase(FILENAME, PATTERN).
    'b'ISO-8859-1'u'ISO-8859-1'b'Construct a list from those elements of the iterable NAMES that match PAT.'u'Construct a list from those elements of the iterable NAMES that match PAT.'b'Test whether FILENAME matches PATTERN, including case.

    This is a version of fnmatch() which doesn't case-normalize
    its arguments.
    'u'Test whether FILENAME matches PATTERN, including case.

    This is a version of fnmatch() which doesn't case-normalize
    its arguments.
    'b'Translate a shell PATTERN to a regular expression.

    There is no way to quote meta-characters.
    'u'Translate a shell PATTERN to a regular expression.

    There is no way to quote meta-characters.
    'b'\['u'\['b'\-'u'\-'b'([&~|])'u'([&~|])'b'\\\1'u'\\\1'b'(?!)'u'(?!)'b'.*'u'.*'b'(?>.*?'u'(?>.*?'b'(?s:'u'(?s:'b')\Z'u')\Z'u'Lib.fnmatch'resource_trackerensure_runningget_inherited_fdsconnect_to_new_processMAXFDS_TO_SENDSIGNED_STRUCTForkServer_forkserver_address_forkserver_alive_fd_forkserver_pid_inherited_fds_preload_modules_stop_stop_unlockedwaitpidmodules_namesSet list of module names to try to load in forkserver process.module_names must be a list of stringsReturn list of fds inherited from parent process.

        This returns None if the current process was not started by fork
        server.
        fdsRequest forkserver to create a child process.

        Returns a pair of fds (status_r, data_w).  The calling process can read
        the child process's pid and (eventually) its returncode from status_r.
        The calling process should write to data_w the pickled preparation and
        process data.
        too many fdsparent_rchild_wchild_rparent_wgetfdallfdssendfdsMake sure that a fork server is running.

        This can be called from any process.  Note that usually a child
        process will just reuse the forkserver started by its parent, so
        ensure_running() will do nothing.
        WNOHANGfrom multiprocessing.forkserver import main; main(%d, %d, %r, **%r)main_pathsys_pathdesired_keysget_preparation_datachmodalive_ralive_wfds_to_passget_executableexe_args_from_interpreter_flagsspawnv_passfdslistener_fdpreloadRun forkserver._inheritingimport_main_path_close_stdinsig_rsig_wset_blockingsigchld_handler_unusedSIGCHLDold_handlerspid_to_fdDefaultSelector_forkserverrfdsNot at EOF?stswaitstatus_to_exitcodewrite_signedforkserver: waitpid returned unexpected pid %d'forkserver: waitpid returned ''unexpected pid %d'recvfdsToo many ({0:n}) fds to sendunused_fds_serve_one_resource_tracker_fdparent_sentinel_mainread_signedunexpected EOFshould not get here# large enough for pid_t# Forkserver class# Method used by unit tests to stop the server# close the "alive" file descriptor asks the server to stop# forkserver was launched before, is it still running?# still alive# dead, launch it again# all client processes own the write end of the "alive" pipe;# when they all terminate the read end becomes ready.# Dummy signal handler, doesn't do anything# unblocking SIGCHLD allows the wakeup fd to notify our event loop# protect the process from ^C# calling os.write() in the Python signal handler is racy# map child pids to client fds# EOF because no more client processes left# Got SIGCHLD# exhaust# Scan for child processes# Send exit code to client process# client vanished# This shouldn't happen really# Incoming fork request# Receive fds from client# Child# Send pid to client process# close unnecessary stuff and reset signal handlers# Run process object received over pipe# Read and write signed numbersb'ensure_running'u'ensure_running'b'get_inherited_fds'u'get_inherited_fds'b'connect_to_new_process'u'connect_to_new_process'b'set_forkserver_preload'u'set_forkserver_preload'b'Set list of module names to try to load in forkserver process.'u'Set list of module names to try to load in forkserver process.'b'module_names must be a list of strings'u'module_names must be a list of strings'b'Return list of fds inherited from parent process.

        This returns None if the current process was not started by fork
        server.
        'u'Return list of fds inherited from parent process.

        This returns None if the current process was not started by fork
        server.
        'b'Request forkserver to create a child process.

        Returns a pair of fds (status_r, data_w).  The calling process can read
        the child process's pid and (eventually) its returncode from status_r.
        The calling process should write to data_w the pickled preparation and
        process data.
        'u'Request forkserver to create a child process.

        Returns a pair of fds (status_r, data_w).  The calling process can read
        the child process's pid and (eventually) its returncode from status_r.
        The calling process should write to data_w the pickled preparation and
        process data.
        'b'too many fds'u'too many fds'b'Make sure that a fork server is running.

        This can be called from any process.  Note that usually a child
        process will just reuse the forkserver started by its parent, so
        ensure_running() will do nothing.
        'u'Make sure that a fork server is running.

        This can be called from any process.  Note that usually a child
        process will just reuse the forkserver started by its parent, so
        ensure_running() will do nothing.
        'b'from multiprocessing.forkserver import main; 'u'from multiprocessing.forkserver import main; 'b'main(%d, %d, %r, **%r)'u'main(%d, %d, %r, **%r)'b'main_path'u'main_path'b'sys_path'u'sys_path'b'Run forkserver.'u'Run forkserver.'b'Not at EOF?'u'Not at EOF?'b'forkserver: waitpid returned unexpected pid %d'u'forkserver: waitpid returned unexpected pid %d'b'Too many ({0:n}) fds to send'u'Too many ({0:n}) fds to send'b'unexpected EOF'u'unexpected EOF'b'should not get here'u'should not get here'u'Lib.multiprocessing.forkserver'u'multiprocessing.forkserver'_get_function_sourcepartialmethod_format_callbackfunc_repr at _format_args_and_kwargsFormat function arguments and keyword arguments.

    Special case for a single parameter: ('hello',) is formatted as ('hello').
    Replacement for traceback.extract_stack() that only does the
    necessary work for asyncio debug mode.
    StackSummarywalk_stacklookup_lines# use reprlib to limit the length of the output# Limit the amount of work to a reasonable amount, as extract_stack()# can be called for each coroutine and future in debug mode.b' at 'u' at 'b'Format function arguments and keyword arguments.

    Special case for a single parameter: ('hello',) is formatted as ('hello').
    'u'Format function arguments and keyword arguments.

    Special case for a single parameter: ('hello',) is formatted as ('hello').
    'b'Replacement for traceback.extract_stack() that only does the
    necessary work for asyncio debug mode.
    'u'Replacement for traceback.extract_stack() that only does the
    necessary work for asyncio debug mode.
    'u'Lib.asyncio.format_helpers'u'asyncio.format_helpers'u'format_helpers'Fraction, infinite-precision, rational numbers.Fraction_hash_algorithmdinv
    \A\s*                                  # optional whitespace at the start,
    (?P<sign>[-+]?)                        # an optional sign, then
    (?=\d|\.\d)                            # lookahead for digit or .digit
    (?P<num>\d*|\d+(_\d+)*)                # numerator (possibly empty)
    (?:                                    # followed by
       (?:\s*/\s*(?P<denom>\d+(_\d+)*))?   # an optional denominator
    |                                      # or
       (?:\.(?P<decimal>\d*|\d+(_\d+)*))?  # an optional fractional part
       (?:E(?P<exp>[-+]?\d+(_\d+)*))?      # and optional exponent
    )
    \s*\Z                                  # and optional whitespace to finish
_RATIONAL_FORMAT_round_to_exponentno_neg_zeroRound a rational number to the nearest multiple of a given power of 10.

    Rounds the rational number n/d to the nearest integer multiple of
    10**exponent, rounding to the nearest even integer multiple in the case of
    a tie. Returns a pair (sign: bool, significand: int) representing the
    rounded value (-1)**sign * significand * 10**exponent.

    If no_neg_zero is true, then the returned sign will always be False when
    the significand is zero. Otherwise, the sign reflects the sign of the
    input.

    d must be positive, but n and d need not be relatively prime.
    _round_to_figuresfiguresRound a rational number to a given number of significant figures.

    Rounds the rational number n/d to the given number of significant figures
    using the round-ties-to-even rule, and returns a triple
    (sign: bool, significand: int, exponent: int) representing the rounded
    value (-1)**sign * significand * 10**exponent.

    In the special case where n = 0, returns a significand of zero and
    an exponent of 1 - figures, for compatibility with formatting.
    Otherwise, the returned significand satisfies
    10**(figures - 1) <= significand < 10**figures.

    d must be positive, but n and d need not be relatively prime.
    figures must be positive.
    str_dsignificand
    (?:
        (?P<fill>.)?
        (?P<align>[<>=^])
    )?
    (?P<sign>[-+ ]?)
    (?P<no_neg_zero>z)?
    (?P<alt>\#)?
    # A '0' that's *not* followed by another digit is parsed as a minimum width
    # rather than a zeropad flag.
    (?P<zeropad>0(?=[0-9]))?
    (?P<minimumwidth>0|[1-9][0-9]*)?
    (?P<thousands_sep>[,_])?
    (?:\.(?P<precision>0|[1-9][0-9]*))?
    (?P<presentation_type>[eEfFgG%])
_FLOAT_FORMAT_SPECIFICATION_MATCHERThis class implements rational numbers.

    In the two-argument form of the constructor, Fraction(8, 6) will
    produce a rational number equivalent to 4/3. Both arguments must
    be Rational. The numerator defaults to 0 and the denominator
    defaults to 1 so that Fraction(3) == 3 and Fraction() == 0.

    Fractions can also be constructed from:

      - numeric strings similar to those accepted by the
        float constructor (for example, '-2.3' or '1e10')

      - strings of the form '123/456'

      - float and Decimal instances

      - other Rational instances (including integers)

    _numerator_denominatorConstructs a Rational.

        Takes a string like '3/2' or '1.5', another Rational instance, a
        numerator/denominator pair, or a float.

        Examples
        --------

        >>> Fraction(10, -8)
        Fraction(-5, 4)
        >>> Fraction(Fraction(1, 7), 5)
        Fraction(1, 35)
        >>> Fraction(Fraction(1, 7), Fraction(2, 3))
        Fraction(3, 14)
        >>> Fraction('314')
        Fraction(314, 1)
        >>> Fraction('-35/4')
        Fraction(-35, 4)
        >>> Fraction('3.1415') # conversion from numeric string
        Fraction(6283, 2000)
        >>> Fraction('-47e-2') # string may include a decimal exponent
        Fraction(-47, 100)
        >>> Fraction(1.47)  # direct construction from float (exact conversion)
        Fraction(6620291452234629, 4503599627370496)
        >>> Fraction(2.25)
        Fraction(9, 4)
        >>> Fraction(Decimal('1.47'))
        Fraction(147, 100)

        Invalid literal for Fraction: %rdenomscaleargument should be a string or a Rational instance"argument should be a string ""or a Rational instance"both arguments should be Rational instances"both arguments should be ""Rational instances"Fraction(%s, 0)gcdConverts a finite float to a rational number, exactly.

        Beware that Fraction.from_float(0.3) != Fraction(3, 10).

        Integral%s.from_float() only takes floats, not %r (%s)_from_coprime_intsfrom_decimalConverts a finite Decimal instance to a rational number, exactly.%s.from_decimal() only takes Decimals, not %r (%s)Convert a pair of ints to a rational number, for internal use.

        The ratio of integers should be in lowest terms and the denominator
        should be positive.
        Return True if the Fraction is an integer.Return a pair of integers, whose ratio is equal to the original Fraction.

        The ratio is in lowest terms and has a positive denominator.
        limit_denominatormax_denominatorClosest Fraction to self with denominator at most max_denominator.

        >>> Fraction('3.141592653589793').limit_denominator(10)
        Fraction(22, 7)
        >>> Fraction('3.141592653589793').limit_denominator(100)
        Fraction(311, 99)
        >>> Fraction(4321, 8765).limit_denominator(10000)
        Fraction(4321, 8765)

        max_denominator should be at least 1p0q0p1q1q2repr(self)%s(%s, %s)str(self)Format this fraction according to the given format specification.Invalid format specifier  for object of type "for object of type "; can't use explicit alignment when zero-padding"; ""can't use explicit alignment when zero-padding"pos_signalternate_formpresentation_typetrim_zerostrim_pointEFGexponent_indicatornegativescientificpoint_posleadingfrac_parttrailingmin_leadingfirst_pos_operator_fallbacksmonomorphic_operatorfallback_operatorGenerates forward and reverse operators given a purely-rational
        operator and a function from the operator module.

        Use this like:
        __op__, __rop__ = _operator_fallbacks(just_rational_op, operator.op)

        In general, we want to implement the arithmetic operations so
        that mixed-mode operations either call an implementation whose
        author knew about the types of both arguments, or convert both
        to the nearest built in type and do the operation there. In
        Fraction, that means that we define __add__ and __radd__ as:

            def __add__(self, other):
                # Both types have numerators/denominator attributes,
                # so do the operation directly
                if isinstance(other, (int, Fraction)):
                    return Fraction(self.numerator * other.denominator +
                                    other.numerator * self.denominator,
                                    self.denominator * other.denominator)
                # float and complex don't have those operations, but we
                # know about those types, so special case them.
                elif isinstance(other, float):
                    return float(self) + other
                elif isinstance(other, complex):
                    return complex(self) + other
                # Let the other type take over.
                return NotImplemented

            def __radd__(self, other):
                # radd handles more types than add because there's
                # nothing left to fall back to.
                if isinstance(other, numbers.Rational):
                    return Fraction(self.numerator * other.denominator +
                                    other.numerator * self.denominator,
                                    self.denominator * other.denominator)
                elif isinstance(other, Real):
                    return float(other) + float(self)
                elif isinstance(other, Complex):
                    return complex(other) + complex(self)
                return NotImplemented


        There are 5 different cases for a mixed-type addition on
        Fraction. I'll refer to all of the above code that doesn't
        refer to Fraction, float, or complex as "boilerplate". 'r'
        will be an instance of Fraction, which is a subtype of
        Rational (r : Fraction <: Rational), and b : B <:
        Complex. The first three involve 'r + b':

            1. If B <: Fraction, int, float, or complex, we handle
               that specially, and all is well.
            2. If Fraction falls back to the boilerplate code, and it
               were to return a value from __add__, we'd miss the
               possibility that B defines a more intelligent __radd__,
               so the boilerplate should return NotImplemented from
               __add__. In particular, we don't handle Rational
               here, even though we could get an exact answer, in case
               the other type wants to do something special.
            3. If B <: Fraction, Python tries B.__radd__ before
               Fraction.__add__. This is ok, because it was
               implemented with knowledge of Fraction, so it can
               handle those instances before delegating to Real or
               Complex.

        The next two situations describe 'b + r'. We assume that b
        didn't know about Fraction in its implementation, and that it
        uses similar boilerplate code:

            4. If B <: Rational, then __radd_ converts both to the
               builtin rational type (hey look, that's us) and
               proceeds.
            5. Otherwise, __radd__ tries to find the nearest common
               base ABC, and fall back to its builtin type. Since this
               class doesn't subclass a concrete type, there's no
               implementation to fall back to, so we need to try as
               hard as possible to return an actual value, or the user
               will get a TypeError.

        forwardReal__r_adda + bnadanbdbg2_suba - b_mula * bg1_diva / b_floordiva // b_divmod(a // b, a % b)divn_mod_moda % ba ** b

        If b is not an integer, the result will be a float or complex
        since roots are generally irrational. If b is an integer, the
        result will be rational.

        a ** b+a: Coerces a subclass instance to Fractionabs(a)int(a)math.trunc(a)math.floor(a)math.ceil(a)ndigitsround(self, ndigits)

        Rounds half toward even.
        floorhash(self)a == b_richcmpHelper for comparison operators, for internal use only.

        Implement comparison between a Rational instance `self`, and
        either another Rational instance or a float `other`.  If
        `other` is not a Rational instance or a float, return
        NotImplemented. `op` should be one of the six standard
        comparison operators.

        a < ba > ba <= ba >= ba != 0# Originally contributed by Sjoerd Mullender.# Significantly modified by Jeffrey Yasskin <jyasskin at gmail.com>.# on the reduction of x modulo the prime _PyHASH_MODULUS.# Value to be used for rationals that reduce to infinity modulo# _PyHASH_MODULUS.# To make sure that the hash of a Fraction agrees with the hash# of a numerically equal integer, float or Decimal instance, we# follow the rules for numeric hashes outlined in the# documentation.  (See library docs, 'Built-in Types').# ValueError means there is no modular inverse.# The general algorithm now specifies that the absolute value of# the hash is#    (|N| * dinv) % P# where N is self._numerator and P is _PyHASH_MODULUS.  That's# optimized here in two ways:  first, for a non-negative int i,# hash(i) == i % P, but the int hash implementation doesn't need# to divide, and is faster than doing % P explicitly.  So we do#    hash(|N| * dinv)# instead.  Second, N is unbounded, so its product with dinv may# be arbitrarily expensive to compute.  The final answer is the# same if we use the bounded |N| % P instead, which can again# be done with an int hash() call.  If 0 <= i < P, hash(i) == i,# so this nested hash() call wastes a bit of time making a# redundant copy when |N| < P, but can save an arbitrarily large# amount of computation for large |N|.# Helpers for formatting# The divmod quotient is correct for round-ties-towards-positive-infinity;# In the case of a tie, we zero out the least significant bit of q.# Special case for n == 0.# Find integer m satisfying 10**(m - 1) <= abs(n)/d <= 10**m. (If abs(n)/d# is a power of 10, either of the two possible values for m is fine.)# Round to a multiple of 10**(m - figures). The significand we get# satisfies 10**(figures - 1) <= significand <= 10**figures.# Adjust in the case where significand == 10**figures, to ensure that# 10**(figures - 1) <= significand < 10**figures.# Pattern for matching float-style format specifications;# supports 'e', 'E', 'f', 'F', 'g', 'G' and '%' presentation types.# Exact conversion# Handle construction from strings.# *very* normal case# Algorithm notes: For any real number x, define a *best upper# approximation* to x to be a rational number p/q such that:#   (1) p/q >= x, and#   (2) if p/q > r/s >= x then s > q, for any rational r/s.# Define *best lower approximation* similarly.  Then it can be# proved that a rational number is a best upper or lower# approximation to x if, and only if, it is a convergent or# semiconvergent of the (unique shortest) continued fraction# associated to x.# To find a best rational approximation with denominator <= M,# we find the best upper and lower approximations with# denominator <= M and take whichever of these is closer to x.# In the event of a tie, the bound with smaller denominator is# chosen.  If both denominators are equal (which can happen# only when max_denominator == 1 and self is midway between# two integers) the lower bound---i.e., the floor of self, is# taken.# Determine which of the candidates (p0+k*p1)/(q0+k*q1) and p1/q1 is# closer to self. The distance between them is 1/(q1*(q0+k*q1)), while# the distance from p1/q1 to self is d/(q1*self._denominator). So we# need to compare 2*(q0+k*q1) with self._denominator/d.# Backwards compatiblility with existing formatting.# Validate and parse the format specifier.# Avoid the temptation to guess.# Round to get the digits we need, figure out where to place the point,# and decide whether to use scientific notation. 'point_pos' is the# relative to the _end_ of the digit string: that is, it's the number# of digits that should follow the point.# presentation_type in "eEgG"# Get the suffix - the part following the digits, if any.# String of output digits, padded sufficiently with zeros on the left# so that we'll have at least one digit before the decimal point.# Before padding, the output has the form f"{sign}{leading}{trailing}",# where `leading` includes thousands separators if necessary and# `trailing` includes the decimal separator where appropriate.# Do zero padding if required.# When adding thousands separators, they'll be added to the# zero-padded portion too, so we need to compensate.# Insert thousands separators if required.# We now have a sign and a body. Pad with fill character if necessary# and return.# align == "="# Includes ints.# Rational arithmetic algorithms: Knuth, TAOCP, Volume 2, 4.5.1.# Assume input fractions a and b are normalized.# 1) Consider addition/subtraction.# Let g = gcd(da, db). Then#              na   nb    na*db  nb*da#     a  b == --  -- == ------------- ==#              da   db        da*db#              na*(db//g)  nb*(da//g)    t#           == ----------------------- == -#                      (da*db)//g         d# Now, if g > 1, we're working with smaller integers.# Note, that t, (da//g) and (db//g) are pairwise coprime.# Indeed, (da//g) and (db//g) share no common factors (they were# removed) and da is coprime with na (since input fractions are# normalized), hence (da//g) and na are coprime.  By symmetry,# (db//g) and nb are coprime too.  Then,#     gcd(t, da//g) == gcd(na*(db//g), da//g) == 1#     gcd(t, db//g) == gcd(nb*(da//g), db//g) == 1# Above allows us optimize reduction of the result to lowest# terms.  Indeed,#     g2 = gcd(t, d) == gcd(t, (da//g)*(db//g)*g) == gcd(t, g)#                       t//g2                   t//g2#     a  b == ----------------------- == ----------------#              (da//g)*(db//g)*(g//g2)    (da//g)*(db//g2)# is a normalized fraction.  This is useful because the unnormalized# denominator d could be much larger than g.# We should special-case g == 1 (and g2 == 1), since 60.8% of# randomly-chosen integers are coprime:# https://en.wikipedia.org/wiki/Coprime_integers#Probability_of_coprimality# Note, that g2 == 1 always for fractions, obtained from floats: here# g is a power of 2 and the unnormalized numerator t is an odd integer.# 2) Consider multiplication# Let g1 = gcd(na, db) and g2 = gcd(nb, da), then#            na*nb    na*nb    (na//g1)*(nb//g2)#     a*b == ----- == ----- == -----------------#            da*db    db*da    (db//g1)*(da//g2)# Note, that after divisions we're multiplying smaller integers.# Also, the resulting fraction is normalized, because each of# two factors in the numerator is coprime to each of the two factors# in the denominator.# Indeed, pick (na//g1).  It's coprime with (da//g2), because input# fractions are normalized.  It's also coprime with (db//g1), because# common factors are removed by g1 == gcd(na, db).# As for addition/subtraction, we should special-case g1 == 1# and g2 == 1 for same reason.  That happens also for multiplying# rationals, obtained from floats.# Same as _mul(), with inversed b.# A fractional power will generally produce an# irrational number.# If a is an int, keep it that way if possible.# The negations cleverly convince floordiv to return the ceiling.# Deal with the half case:# See _operator_fallbacks.forward to check that the results of# these operations will always be Fraction and therefore have# round().# comparisons with an infinity or nan should behave in# the same way for any finite a, so treat a as zero.# Since a doesn't know how to compare with b, let's give b# a chance to compare itself with a.# convert other to a Rational instance where reasonable.# bpo-39274: Use bool() because (a._numerator != 0) can return an# object which is not a bool.# support for pickling, copy, and deepcopyb'Fraction, infinite-precision, rational numbers.'u'Fraction, infinite-precision, rational numbers.'b'Fraction'u'Fraction'b'
    \A\s*                                  # optional whitespace at the start,
    (?P<sign>[-+]?)                        # an optional sign, then
    (?=\d|\.\d)                            # lookahead for digit or .digit
    (?P<num>\d*|\d+(_\d+)*)                # numerator (possibly empty)
    (?:                                    # followed by
       (?:\s*/\s*(?P<denom>\d+(_\d+)*))?   # an optional denominator
    |                                      # or
       (?:\.(?P<decimal>\d*|\d+(_\d+)*))?  # an optional fractional part
       (?:E(?P<exp>[-+]?\d+(_\d+)*))?      # and optional exponent
    )
    \s*\Z                                  # and optional whitespace to finish
'u'
    \A\s*                                  # optional whitespace at the start,
    (?P<sign>[-+]?)                        # an optional sign, then
    (?=\d|\.\d)                            # lookahead for digit or .digit
    (?P<num>\d*|\d+(_\d+)*)                # numerator (possibly empty)
    (?:                                    # followed by
       (?:\s*/\s*(?P<denom>\d+(_\d+)*))?   # an optional denominator
    |                                      # or
       (?:\.(?P<decimal>\d*|\d+(_\d+)*))?  # an optional fractional part
       (?:E(?P<exp>[-+]?\d+(_\d+)*))?      # and optional exponent
    )
    \s*\Z                                  # and optional whitespace to finish
'b'Round a rational number to the nearest multiple of a given power of 10.

    Rounds the rational number n/d to the nearest integer multiple of
    10**exponent, rounding to the nearest even integer multiple in the case of
    a tie. Returns a pair (sign: bool, significand: int) representing the
    rounded value (-1)**sign * significand * 10**exponent.

    If no_neg_zero is true, then the returned sign will always be False when
    the significand is zero. Otherwise, the sign reflects the sign of the
    input.

    d must be positive, but n and d need not be relatively prime.
    'u'Round a rational number to the nearest multiple of a given power of 10.

    Rounds the rational number n/d to the nearest integer multiple of
    10**exponent, rounding to the nearest even integer multiple in the case of
    a tie. Returns a pair (sign: bool, significand: int) representing the
    rounded value (-1)**sign * significand * 10**exponent.

    If no_neg_zero is true, then the returned sign will always be False when
    the significand is zero. Otherwise, the sign reflects the sign of the
    input.

    d must be positive, but n and d need not be relatively prime.
    'b'Round a rational number to a given number of significant figures.

    Rounds the rational number n/d to the given number of significant figures
    using the round-ties-to-even rule, and returns a triple
    (sign: bool, significand: int, exponent: int) representing the rounded
    value (-1)**sign * significand * 10**exponent.

    In the special case where n = 0, returns a significand of zero and
    an exponent of 1 - figures, for compatibility with formatting.
    Otherwise, the returned significand satisfies
    10**(figures - 1) <= significand < 10**figures.

    d must be positive, but n and d need not be relatively prime.
    figures must be positive.
    'u'Round a rational number to a given number of significant figures.

    Rounds the rational number n/d to the given number of significant figures
    using the round-ties-to-even rule, and returns a triple
    (sign: bool, significand: int, exponent: int) representing the rounded
    value (-1)**sign * significand * 10**exponent.

    In the special case where n = 0, returns a significand of zero and
    an exponent of 1 - figures, for compatibility with formatting.
    Otherwise, the returned significand satisfies
    10**(figures - 1) <= significand < 10**figures.

    d must be positive, but n and d need not be relatively prime.
    figures must be positive.
    'b'
    (?:
        (?P<fill>.)?
        (?P<align>[<>=^])
    )?
    (?P<sign>[-+ ]?)
    (?P<no_neg_zero>z)?
    (?P<alt>\#)?
    # A '0' that's *not* followed by another digit is parsed as a minimum width
    # rather than a zeropad flag.
    (?P<zeropad>0(?=[0-9]))?
    (?P<minimumwidth>0|[1-9][0-9]*)?
    (?P<thousands_sep>[,_])?
    (?:\.(?P<precision>0|[1-9][0-9]*))?
    (?P<presentation_type>[eEfFgG%])
'u'
    (?:
        (?P<fill>.)?
        (?P<align>[<>=^])
    )?
    (?P<sign>[-+ ]?)
    (?P<no_neg_zero>z)?
    (?P<alt>\#)?
    # A '0' that's *not* followed by another digit is parsed as a minimum width
    # rather than a zeropad flag.
    (?P<zeropad>0(?=[0-9]))?
    (?P<minimumwidth>0|[1-9][0-9]*)?
    (?P<thousands_sep>[,_])?
    (?:\.(?P<precision>0|[1-9][0-9]*))?
    (?P<presentation_type>[eEfFgG%])
'b'This class implements rational numbers.

    In the two-argument form of the constructor, Fraction(8, 6) will
    produce a rational number equivalent to 4/3. Both arguments must
    be Rational. The numerator defaults to 0 and the denominator
    defaults to 1 so that Fraction(3) == 3 and Fraction() == 0.

    Fractions can also be constructed from:

      - numeric strings similar to those accepted by the
        float constructor (for example, '-2.3' or '1e10')

      - strings of the form '123/456'

      - float and Decimal instances

      - other Rational instances (including integers)

    'u'This class implements rational numbers.

    In the two-argument form of the constructor, Fraction(8, 6) will
    produce a rational number equivalent to 4/3. Both arguments must
    be Rational. The numerator defaults to 0 and the denominator
    defaults to 1 so that Fraction(3) == 3 and Fraction() == 0.

    Fractions can also be constructed from:

      - numeric strings similar to those accepted by the
        float constructor (for example, '-2.3' or '1e10')

      - strings of the form '123/456'

      - float and Decimal instances

      - other Rational instances (including integers)

    'b'_numerator'u'_numerator'b'_denominator'u'_denominator'b'Constructs a Rational.

        Takes a string like '3/2' or '1.5', another Rational instance, a
        numerator/denominator pair, or a float.

        Examples
        --------

        >>> Fraction(10, -8)
        Fraction(-5, 4)
        >>> Fraction(Fraction(1, 7), 5)
        Fraction(1, 35)
        >>> Fraction(Fraction(1, 7), Fraction(2, 3))
        Fraction(3, 14)
        >>> Fraction('314')
        Fraction(314, 1)
        >>> Fraction('-35/4')
        Fraction(-35, 4)
        >>> Fraction('3.1415') # conversion from numeric string
        Fraction(6283, 2000)
        >>> Fraction('-47e-2') # string may include a decimal exponent
        Fraction(-47, 100)
        >>> Fraction(1.47)  # direct construction from float (exact conversion)
        Fraction(6620291452234629, 4503599627370496)
        >>> Fraction(2.25)
        Fraction(9, 4)
        >>> Fraction(Decimal('1.47'))
        Fraction(147, 100)

        'u'Constructs a Rational.

        Takes a string like '3/2' or '1.5', another Rational instance, a
        numerator/denominator pair, or a float.

        Examples
        --------

        >>> Fraction(10, -8)
        Fraction(-5, 4)
        >>> Fraction(Fraction(1, 7), 5)
        Fraction(1, 35)
        >>> Fraction(Fraction(1, 7), Fraction(2, 3))
        Fraction(3, 14)
        >>> Fraction('314')
        Fraction(314, 1)
        >>> Fraction('-35/4')
        Fraction(-35, 4)
        >>> Fraction('3.1415') # conversion from numeric string
        Fraction(6283, 2000)
        >>> Fraction('-47e-2') # string may include a decimal exponent
        Fraction(-47, 100)
        >>> Fraction(1.47)  # direct construction from float (exact conversion)
        Fraction(6620291452234629, 4503599627370496)
        >>> Fraction(2.25)
        Fraction(9, 4)
        >>> Fraction(Decimal('1.47'))
        Fraction(147, 100)

        'b'Invalid literal for Fraction: %r'u'Invalid literal for Fraction: %r'b'num'u'num'b'denom'u'denom'b'argument should be a string or a Rational instance'u'argument should be a string or a Rational instance'b'both arguments should be Rational instances'u'both arguments should be Rational instances'b'Fraction(%s, 0)'u'Fraction(%s, 0)'b'Converts a finite float to a rational number, exactly.

        Beware that Fraction.from_float(0.3) != Fraction(3, 10).

        'u'Converts a finite float to a rational number, exactly.

        Beware that Fraction.from_float(0.3) != Fraction(3, 10).

        'b'%s.from_float() only takes floats, not %r (%s)'u'%s.from_float() only takes floats, not %r (%s)'b'Converts a finite Decimal instance to a rational number, exactly.'u'Converts a finite Decimal instance to a rational number, exactly.'b'%s.from_decimal() only takes Decimals, not %r (%s)'u'%s.from_decimal() only takes Decimals, not %r (%s)'b'Convert a pair of ints to a rational number, for internal use.

        The ratio of integers should be in lowest terms and the denominator
        should be positive.
        'u'Convert a pair of ints to a rational number, for internal use.

        The ratio of integers should be in lowest terms and the denominator
        should be positive.
        'b'Return True if the Fraction is an integer.'u'Return True if the Fraction is an integer.'b'Return a pair of integers, whose ratio is equal to the original Fraction.

        The ratio is in lowest terms and has a positive denominator.
        'u'Return a pair of integers, whose ratio is equal to the original Fraction.

        The ratio is in lowest terms and has a positive denominator.
        'b'Closest Fraction to self with denominator at most max_denominator.

        >>> Fraction('3.141592653589793').limit_denominator(10)
        Fraction(22, 7)
        >>> Fraction('3.141592653589793').limit_denominator(100)
        Fraction(311, 99)
        >>> Fraction(4321, 8765).limit_denominator(10000)
        Fraction(4321, 8765)

        'u'Closest Fraction to self with denominator at most max_denominator.

        >>> Fraction('3.141592653589793').limit_denominator(10)
        Fraction(22, 7)
        >>> Fraction('3.141592653589793').limit_denominator(100)
        Fraction(311, 99)
        >>> Fraction(4321, 8765).limit_denominator(10000)
        Fraction(4321, 8765)

        'b'max_denominator should be at least 1'u'max_denominator should be at least 1'b'repr(self)'u'repr(self)'b'%s(%s, %s)'u'%s(%s, %s)'b'str(self)'u'str(self)'b'Format this fraction according to the given format specification.'u'Format this fraction according to the given format specification.'b'Invalid format specifier 'u'Invalid format specifier 'b' for object of type 'u' for object of type 'b'; can't use explicit alignment when zero-padding'u'; can't use explicit alignment when zero-padding'b'no_neg_zero'u'no_neg_zero'b'presentation_type'u'presentation_type'b'EFG'u'EFG'b'Generates forward and reverse operators given a purely-rational
        operator and a function from the operator module.

        Use this like:
        __op__, __rop__ = _operator_fallbacks(just_rational_op, operator.op)

        In general, we want to implement the arithmetic operations so
        that mixed-mode operations either call an implementation whose
        author knew about the types of both arguments, or convert both
        to the nearest built in type and do the operation there. In
        Fraction, that means that we define __add__ and __radd__ as:

            def __add__(self, other):
                # Both types have numerators/denominator attributes,
                # so do the operation directly
                if isinstance(other, (int, Fraction)):
                    return Fraction(self.numerator * other.denominator +
                                    other.numerator * self.denominator,
                                    self.denominator * other.denominator)
                # float and complex don't have those operations, but we
                # know about those types, so special case them.
                elif isinstance(other, float):
                    return float(self) + other
                elif isinstance(other, complex):
                    return complex(self) + other
                # Let the other type take over.
                return NotImplemented

            def __radd__(self, other):
                # radd handles more types than add because there's
                # nothing left to fall back to.
                if isinstance(other, numbers.Rational):
                    return Fraction(self.numerator * other.denominator +
                                    other.numerator * self.denominator,
                                    self.denominator * other.denominator)
                elif isinstance(other, Real):
                    return float(other) + float(self)
                elif isinstance(other, Complex):
                    return complex(other) + complex(self)
                return NotImplemented


        There are 5 different cases for a mixed-type addition on
        Fraction. I'll refer to all of the above code that doesn't
        refer to Fraction, float, or complex as "boilerplate". 'r'
        will be an instance of Fraction, which is a subtype of
        Rational (r : Fraction <: Rational), and b : B <:
        Complex. The first three involve 'r + b':

            1. If B <: Fraction, int, float, or complex, we handle
               that specially, and all is well.
            2. If Fraction falls back to the boilerplate code, and it
               were to return a value from __add__, we'd miss the
               possibility that B defines a more intelligent __radd__,
               so the boilerplate should return NotImplemented from
               __add__. In particular, we don't handle Rational
               here, even though we could get an exact answer, in case
               the other type wants to do something special.
            3. If B <: Fraction, Python tries B.__radd__ before
               Fraction.__add__. This is ok, because it was
               implemented with knowledge of Fraction, so it can
               handle those instances before delegating to Real or
               Complex.

        The next two situations describe 'b + r'. We assume that b
        didn't know about Fraction in its implementation, and that it
        uses similar boilerplate code:

            4. If B <: Rational, then __radd_ converts both to the
               builtin rational type (hey look, that's us) and
               proceeds.
            5. Otherwise, __radd__ tries to find the nearest common
               base ABC, and fall back to its builtin type. Since this
               class doesn't subclass a concrete type, there's no
               implementation to fall back to, so we need to try as
               hard as possible to return an actual value, or the user
               will get a TypeError.

        'u'Generates forward and reverse operators given a purely-rational
        operator and a function from the operator module.

        Use this like:
        __op__, __rop__ = _operator_fallbacks(just_rational_op, operator.op)

        In general, we want to implement the arithmetic operations so
        that mixed-mode operations either call an implementation whose
        author knew about the types of both arguments, or convert both
        to the nearest built in type and do the operation there. In
        Fraction, that means that we define __add__ and __radd__ as:

            def __add__(self, other):
                # Both types have numerators/denominator attributes,
                # so do the operation directly
                if isinstance(other, (int, Fraction)):
                    return Fraction(self.numerator * other.denominator +
                                    other.numerator * self.denominator,
                                    self.denominator * other.denominator)
                # float and complex don't have those operations, but we
                # know about those types, so special case them.
                elif isinstance(other, float):
                    return float(self) + other
                elif isinstance(other, complex):
                    return complex(self) + other
                # Let the other type take over.
                return NotImplemented

            def __radd__(self, other):
                # radd handles more types than add because there's
                # nothing left to fall back to.
                if isinstance(other, numbers.Rational):
                    return Fraction(self.numerator * other.denominator +
                                    other.numerator * self.denominator,
                                    self.denominator * other.denominator)
                elif isinstance(other, Real):
                    return float(other) + float(self)
                elif isinstance(other, Complex):
                    return complex(other) + complex(self)
                return NotImplemented


        There are 5 different cases for a mixed-type addition on
        Fraction. I'll refer to all of the above code that doesn't
        refer to Fraction, float, or complex as "boilerplate". 'r'
        will be an instance of Fraction, which is a subtype of
        Rational (r : Fraction <: Rational), and b : B <:
        Complex. The first three involve 'r + b':

            1. If B <: Fraction, int, float, or complex, we handle
               that specially, and all is well.
            2. If Fraction falls back to the boilerplate code, and it
               were to return a value from __add__, we'd miss the
               possibility that B defines a more intelligent __radd__,
               so the boilerplate should return NotImplemented from
               __add__. In particular, we don't handle Rational
               here, even though we could get an exact answer, in case
               the other type wants to do something special.
            3. If B <: Fraction, Python tries B.__radd__ before
               Fraction.__add__. This is ok, because it was
               implemented with knowledge of Fraction, so it can
               handle those instances before delegating to Real or
               Complex.

        The next two situations describe 'b + r'. We assume that b
        didn't know about Fraction in its implementation, and that it
        uses similar boilerplate code:

            4. If B <: Rational, then __radd_ converts both to the
               builtin rational type (hey look, that's us) and
               proceeds.
            5. Otherwise, __radd__ tries to find the nearest common
               base ABC, and fall back to its builtin type. Since this
               class doesn't subclass a concrete type, there's no
               implementation to fall back to, so we need to try as
               hard as possible to return an actual value, or the user
               will get a TypeError.

        'b'__r'u'__r'b'a + b'u'a + b'b'a - b'u'a - b'b'a * b'u'a * b'b'a / b'u'a / b'b'a // b'u'a // b'b'(a // b, a % b)'u'(a // b, a % b)'b'a % b'u'a % b'b'a ** b

        If b is not an integer, the result will be a float or complex
        since roots are generally irrational. If b is an integer, the
        result will be rational.

        'u'a ** b

        If b is not an integer, the result will be a float or complex
        since roots are generally irrational. If b is an integer, the
        result will be rational.

        'b'a ** b'u'a ** b'b'+a: Coerces a subclass instance to Fraction'u'+a: Coerces a subclass instance to Fraction'b'abs(a)'u'abs(a)'b'int(a)'u'int(a)'b'math.trunc(a)'u'math.trunc(a)'b'math.floor(a)'u'math.floor(a)'b'math.ceil(a)'u'math.ceil(a)'b'round(self, ndigits)

        Rounds half toward even.
        'u'round(self, ndigits)

        Rounds half toward even.
        'b'hash(self)'u'hash(self)'b'a == b'u'a == b'b'Helper for comparison operators, for internal use only.

        Implement comparison between a Rational instance `self`, and
        either another Rational instance or a float `other`.  If
        `other` is not a Rational instance or a float, return
        NotImplemented. `op` should be one of the six standard
        comparison operators.

        'u'Helper for comparison operators, for internal use only.

        Implement comparison between a Rational instance `self`, and
        either another Rational instance or a float `other`.  If
        `other` is not a Rational instance or a float, return
        NotImplemented. `op` should be one of the six standard
        comparison operators.

        'b'a < b'u'a < b'b'a > b'u'a > b'b'a <= b'u'a <= b'b'a >= b'u'a >= b'b'a != 0'u'a != 0'u'Lib.fractions'u'fractions'functools.py - Tools for working with functions and callable objects
update_wrapperWRAPPER_ASSIGNMENTSWRAPPER_UPDATEStotal_orderingsingledispatchsingledispatchmethodcached_propertywrappedassignedupdatedUpdate a wrapper function to look like the wrapped function

       wrapper is the function to be updated
       wrapped is the original function
       assigned is a tuple naming the attributes assigned directly
       from the wrapped function to the wrapper function (defaults to
       functools.WRAPPER_ASSIGNMENTS)
       updated is a tuple naming the attributes of the wrapper that
       are updated with the corresponding attribute from the wrapped
       function (defaults to functools.WRAPPER_UPDATES)
    Decorator factory to apply update_wrapper() to a wrapper function

       Returns a decorator that invokes update_wrapper() with the decorated
       function as the wrapper argument and the arguments to wraps() as the
       remaining arguments. Default arguments are as for update_wrapper().
       This is a convenience function to simplify applying partial() to
       update_wrapper().
    _gt_from_ltReturn a > b.  Computed by @total_ordering from (not a < b) and (a != b).op_result_le_from_ltReturn a <= b.  Computed by @total_ordering from (a < b) or (a == b)._ge_from_ltReturn a >= b.  Computed by @total_ordering from (not a < b)._ge_from_leReturn a >= b.  Computed by @total_ordering from (not a <= b) or (a == b)._lt_from_leReturn a < b.  Computed by @total_ordering from (a <= b) and (a != b)._gt_from_leReturn a > b.  Computed by @total_ordering from (not a <= b)._lt_from_gtReturn a < b.  Computed by @total_ordering from (not a > b) and (a != b)._ge_from_gtReturn a >= b.  Computed by @total_ordering from (a > b) or (a == b)._le_from_gtReturn a <= b.  Computed by @total_ordering from (not a > b)._le_from_geReturn a <= b.  Computed by @total_ordering from (not a >= b) or (a == b)._gt_from_geReturn a > b.  Computed by @total_ordering from (a >= b) and (a != b)._lt_from_geReturn a < b.  Computed by @total_ordering from (not a >= b).Class decorator that fills in missing ordering methodsrootsmust define at least one ordering operation: < > <= >=opfuncmycmpConvert a cmp= function into a key= functionK_initial_missinginitial
    reduce(function, iterable[, initial]) -> value

    Apply a function of two arguments cumulatively to the items of a sequence
    or iterable, from left to right, so as to reduce the iterable to a single
    value.  For example, reduce(lambda x, y: x+y, [1, 2, 3, 4, 5]) calculates
    ((((1+2)+3)+4)+5).  If initial is present, it is placed before the items
    of the iterable in the calculation, and serves as a default when the
    iterable is empty.
    reduce() of empty iterable with no initial valueNew function with partial application of the given arguments
    and keywords.
    the first argument must be callablefunctools.argument to __setstate__ must be a tupleexpected 4 items in state, got invalid partial stateMethod descriptor with partial application of the given arguments
    and keywords.

    Supports wrapping existing descriptors and handles non-descriptor
    callables as instance methods.
    {!r} is not callable or a descriptor{module}.{cls}({func}, {args}, {keywords})format_string_make_unbound_methodcls_or_self_partialmethodnew_func_unwrap_partialCacheInfomissescurrsize_CacheInfo_HashedSeq This class guarantees that hash() will be called no more than once
        per element.  This is important because the lru_cache() will hash
        the key multiple times on a cache miss.

    hashvalue_make_keykwd_markfasttypesMake a cache key from optionally typed positional and keyword arguments

    The key is constructed in a way that is flat as possible rather than
    as a nested structure that would take more memory.

    If there is only a single argument and its data type is known to cache
    its hash value, then that argument is returned without a wrapper.  This
    saves space and improves lookup speed.

    Least-recently-used cache decorator.

    If *maxsize* is set to None, the LRU features are disabled and the cache
    can grow without bound.

    If *typed* is True, arguments of different types will be cached separately.
    For example, f(3.0) and f(3) will be treated as distinct calls with
    distinct results.

    Arguments to the cached function must be hashable.

    View the cache statistics named tuple (hits, misses, maxsize, currsize)
    with f.cache_info().  Clear the cache and statistics with f.cache_clear().
    Access the underlying function with f.__wrapped__.

    See:  https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)

    cache_parametersExpected first argument to be an integer, a callable, or Nonedecorating_functionsentinelmake_keyPREVNEXTKEYRESULTfullcache_getcache_len_keyoldrootoldkeyoldresultReport cache statisticsClear the cache and cache statisticsSimple lightweight unbounded cache.  Sometimes called "memoize"._c3_mergesequencesMerges MROs in *sequences* to a single MRO using the C3 algorithm.

    Adapted from https://docs.python.org/3/howto/mro.html.

    Inconsistent hierarchy_c3_mroabcsComputes the method resolution order using extended C3 linearization.

    If no *abcs* are given, the algorithm works exactly like the built-in C3
    linearization used for method resolution.

    If given, *abcs* is a list of abstract base classes that should be inserted
    into the resulting MRO. Unrelated ABCs are ignored and don't end up in the
    result. The algorithm inserts ABCs where their functionality is introduced,
    i.e. issubclass(cls, abc) returns True for the class itself but returns
    False for all its direct base classes. Implicit ABCs for a given class
    (either registered or inferred from the presence of a special method like
    __len__) are inserted directly after the last ABC explicitly listed in the
    MRO of said class. If two implicit ABCs end up next to each other in the
    resulting MRO, their ordering depends on the order of types in *abcs*.

    explicit_basesabstract_basesother_basesexplicit_c3_mrosabstract_c3_mrosother_c3_mros_compose_mroCalculates the method resolution order for a given class *cls*.

    Includes relevant abstract base classes (with their respective bases) from
    the *types* iterable. Uses a modified C3 linearization algorithm.

    is_relatedis_strict_basetype_setsubcls_find_implReturns the best matching implementation from *registry* for type *cls*.

    Where there is no registered implementation for a specific type, its method
    resolution order is used to find a more generic implementation.

    Note: if *registry* does not contain an implementation for the base
    *object* type, this function may return None.

    Ambiguous dispatch: {} or {}Single-dispatch generic function decorator.

    Transforms a function into a generic function, which can have different
    behaviours depending upon the type of its first argument. The decorated
    function acts as the default implementation, and additional
    implementations can be registered using the register() attribute of the
    generic function.
    WeakKeyDictionarydispatch_cachecache_tokengeneric_func.dispatch(cls) -> <function implementation>

        Runs the dispatch algorithm to return the best available implementation
        for the given *cls* registered on *generic_func*.

        current_token_is_union_typeget_originUnionUnionType_is_valid_dispatch_typeget_argsgeneric_func.register(cls, func) -> func

        Registers a new implementation for the given *cls* on a *generic_func*.

        Invalid first argument to `register()`. "Invalid first argument to `register()`. " is not a class or union type.annInvalid first argument to `register()`: . Use either `@register(some_class)` or plain `@register` on an annotated function.". ""Use either `@register(some_class)` or plain `@register` ""on an annotated function."get_type_hintsargnameInvalid annotation for .  not all arguments are classes. is not a class. requires at least 1 positional argument' requires at least ''1 positional argument'singledispatch functionSingle-dispatch generic method descriptor.

    Supports wrapping existing descriptors and handles non-descriptor
    callables as instance methods.
     is not callable or a descriptordispatchergeneric_method.register(cls, func) -> func

        Registers a new implementation for the given *cls* on a *generic_method*.
        _NOT_FOUNDattrnameCannot assign the same cached_property to two different names ("Cannot assign the same cached_property to two different names " and ).Cannot use cached_property instance without calling __set_name__ on it.No '__dict__' attribute on  instance to cache "instance to cache " property.The '__dict__' attribute on  instance does not support item assignment for caching " instance ""does not support item assignment for caching "# Python module wrapper for _functools C module# to allow utilities written in Python to be added# to the functools module.# Written by Nick Coghlan <ncoghlan at gmail.com>,# Raymond Hettinger <python at rcn.com>,# and ukasz Langa <lukasz at langa.pl>.#   Copyright (C) 2006-2013 Python Software Foundation.# See C source code for _functools credits/copyright# import types, weakref  # Deferred to single_dispatch()### update_wrapper() and wraps() decorator# update_wrapper() and wraps() are tools to help write# wrapper functions that can handle naive introspection# Issue #17482: set __wrapped__ last so we don't inadvertently copy it# from the wrapped function when updating __dict__# Return the wrapper so this can be used as a decorator via partial()### total_ordering class decorator# The total ordering functions all invoke the root magic method directly# rather than using the corresponding operator.  This avoids possible# infinite recursion that could occur when the operator dispatch logic# detects a NotImplemented result and then calls a reflected method.# Find user-defined comparisons (not those inherited from object).# prefer __lt__ to __le__ to __gt__ to __ge__### cmp_to_key() function converter### reduce() sequence to a single item### partial() argument application# Purely functional, no descriptor behaviour# just in case it's a subclass# XXX does it need to be *exactly* dict?# Descriptor version# func could be a descriptor like classmethod which isn't callable,# so we can't inherit from partial (it verifies func is callable)# flattening is mandatory in order to place cls/self before all# other arguments# it's also more efficient since only one function will be called# Assume __get__ returning something new indicates the# creation of an appropriate callable# If the underlying descriptor didn't do anything, treat this# like an instance method# Helper functions### LRU Cache function decorator# All of code below relies on kwds preserving the order input by the user.# Formerly, we sorted() the kwds before looping.  The new way is *much*# faster; however, it means that f(x=1, y=2) will now be treated as a# distinct call from f(y=2, x=1) which will be cached separately.# Users should only access the lru_cache through its public API:#       cache_info, cache_clear, and f.__wrapped__# The internals of the lru_cache are encapsulated for thread safety and# to allow the implementation to change (including a possible C version).# Negative maxsize is treated as 0# The user_function was passed in directly via the maxsize argument# Constants shared by all lru cache instances:# unique object used to signal cache misses# build a key from the function arguments# names for the link fields# bound method to lookup a key or return None# get cache size without calling len()# because linkedlist updates aren't threadsafe# root of the circular doubly linked list# initialize by pointing to self# No caching -- just a statistics update# Simple caching without ordering or size limit# Size limited caching that tracks accesses by recency# Move the link to the front of the circular queue# Getting here means that this same key was added to the# cache while the lock was released.  Since the link# update is already done, we need only return the# computed result and update the count of misses.# Use the old root to store the new key and result.# Empty the oldest link and make it the new root.# Keep a reference to the old key and old result to# prevent their ref counts from going to zero during the# update. That will prevent potentially arbitrary object# clean-up code (i.e. __del__) from running while we're# still adjusting the links.# Now update the cache dictionary.# Save the potentially reentrant cache[key] assignment# for last, after the root and links have been put in# a consistent state.# Put result in a new link at the front of the queue.# Use the cache_len bound method instead of the len() function# which could potentially be wrapped in an lru_cache itself.### cache -- simplified access to the infinity cache### singledispatch() - single-dispatch generic function decorator# purge empty sequences# find merge candidates among seq heads# reject the current head, it appears later# remove the chosen candidate# Bases up to the last explicit ABC are considered first.# If *cls* is the class that introduces behaviour described by# an ABC *base*, insert said ABC to its MRO.# Remove entries which are already present in the __mro__ or unrelated.# Remove entries which are strict bases of other entries (they will end up# in the MRO anyway.# Subclasses of the ABCs in *types* which are also implemented by# *cls* can be used to stabilize ABC ordering.# Favor subclasses with the biggest number of useful bases# If *match* is an implicit ABC but there is another unrelated,# equally matching implicit ABC, refuse the temptation to guess.# There are many programs that use functools without singledispatch, so we# trade-off making singledispatch marginally slower for the benefit of# making start-up of such applications slightly faster.# only import typing if annotation parsing is necessary### cached_property() - property result cached as instance attribute# not all objects have __dict__ (e.g. class defines slots)b'functools.py - Tools for working with functions and callable objects
'u'functools.py - Tools for working with functions and callable objects
'b'update_wrapper'u'update_wrapper'b'wraps'u'wraps'b'WRAPPER_ASSIGNMENTS'u'WRAPPER_ASSIGNMENTS'b'WRAPPER_UPDATES'u'WRAPPER_UPDATES'b'total_ordering'u'total_ordering'b'cache'u'cache'b'cmp_to_key'u'cmp_to_key'b'lru_cache'u'lru_cache'b'partial'u'partial'b'partialmethod'u'partialmethod'b'singledispatch'u'singledispatch'b'singledispatchmethod'u'singledispatchmethod'b'cached_property'u'cached_property'b'__type_params__'u'__type_params__'b'Update a wrapper function to look like the wrapped function

       wrapper is the function to be updated
       wrapped is the original function
       assigned is a tuple naming the attributes assigned directly
       from the wrapped function to the wrapper function (defaults to
       functools.WRAPPER_ASSIGNMENTS)
       updated is a tuple naming the attributes of the wrapper that
       are updated with the corresponding attribute from the wrapped
       function (defaults to functools.WRAPPER_UPDATES)
    'u'Update a wrapper function to look like the wrapped function

       wrapper is the function to be updated
       wrapped is the original function
       assigned is a tuple naming the attributes assigned directly
       from the wrapped function to the wrapper function (defaults to
       functools.WRAPPER_ASSIGNMENTS)
       updated is a tuple naming the attributes of the wrapper that
       are updated with the corresponding attribute from the wrapped
       function (defaults to functools.WRAPPER_UPDATES)
    'b'Decorator factory to apply update_wrapper() to a wrapper function

       Returns a decorator that invokes update_wrapper() with the decorated
       function as the wrapper argument and the arguments to wraps() as the
       remaining arguments. Default arguments are as for update_wrapper().
       This is a convenience function to simplify applying partial() to
       update_wrapper().
    'u'Decorator factory to apply update_wrapper() to a wrapper function

       Returns a decorator that invokes update_wrapper() with the decorated
       function as the wrapper argument and the arguments to wraps() as the
       remaining arguments. Default arguments are as for update_wrapper().
       This is a convenience function to simplify applying partial() to
       update_wrapper().
    'b'Return a > b.  Computed by @total_ordering from (not a < b) and (a != b).'u'Return a > b.  Computed by @total_ordering from (not a < b) and (a != b).'b'Return a <= b.  Computed by @total_ordering from (a < b) or (a == b).'u'Return a <= b.  Computed by @total_ordering from (a < b) or (a == b).'b'Return a >= b.  Computed by @total_ordering from (not a < b).'u'Return a >= b.  Computed by @total_ordering from (not a < b).'b'Return a >= b.  Computed by @total_ordering from (not a <= b) or (a == b).'u'Return a >= b.  Computed by @total_ordering from (not a <= b) or (a == b).'b'Return a < b.  Computed by @total_ordering from (a <= b) and (a != b).'u'Return a < b.  Computed by @total_ordering from (a <= b) and (a != b).'b'Return a > b.  Computed by @total_ordering from (not a <= b).'u'Return a > b.  Computed by @total_ordering from (not a <= b).'b'Return a < b.  Computed by @total_ordering from (not a > b) and (a != b).'u'Return a < b.  Computed by @total_ordering from (not a > b) and (a != b).'b'Return a >= b.  Computed by @total_ordering from (a > b) or (a == b).'u'Return a >= b.  Computed by @total_ordering from (a > b) or (a == b).'b'Return a <= b.  Computed by @total_ordering from (not a > b).'u'Return a <= b.  Computed by @total_ordering from (not a > b).'b'Return a <= b.  Computed by @total_ordering from (not a >= b) or (a == b).'u'Return a <= b.  Computed by @total_ordering from (not a >= b) or (a == b).'b'Return a > b.  Computed by @total_ordering from (a >= b) and (a != b).'u'Return a > b.  Computed by @total_ordering from (a >= b) and (a != b).'b'Return a < b.  Computed by @total_ordering from (not a >= b).'u'Return a < b.  Computed by @total_ordering from (not a >= b).'b'Class decorator that fills in missing ordering methods'u'Class decorator that fills in missing ordering methods'b'must define at least one ordering operation: < > <= >='u'must define at least one ordering operation: < > <= >='b'Convert a cmp= function into a key= function'u'Convert a cmp= function into a key= function'b'obj'u'obj'b'
    reduce(function, iterable[, initial]) -> value

    Apply a function of two arguments cumulatively to the items of a sequence
    or iterable, from left to right, so as to reduce the iterable to a single
    value.  For example, reduce(lambda x, y: x+y, [1, 2, 3, 4, 5]) calculates
    ((((1+2)+3)+4)+5).  If initial is present, it is placed before the items
    of the iterable in the calculation, and serves as a default when the
    iterable is empty.
    'u'
    reduce(function, iterable[, initial]) -> value

    Apply a function of two arguments cumulatively to the items of a sequence
    or iterable, from left to right, so as to reduce the iterable to a single
    value.  For example, reduce(lambda x, y: x+y, [1, 2, 3, 4, 5]) calculates
    ((((1+2)+3)+4)+5).  If initial is present, it is placed before the items
    of the iterable in the calculation, and serves as a default when the
    iterable is empty.
    'b'reduce() of empty iterable with no initial value'u'reduce() of empty iterable with no initial value'b'New function with partial application of the given arguments
    and keywords.
    'u'New function with partial application of the given arguments
    and keywords.
    'b'func'b'args'b'keywords'b'the first argument must be callable'u'the first argument must be callable'b'functools.'u'functools.'b'argument to __setstate__ must be a tuple'u'argument to __setstate__ must be a tuple'b'expected 4 items in state, got 'u'expected 4 items in state, got 'b'invalid partial state'u'invalid partial state'b'Method descriptor with partial application of the given arguments
    and keywords.

    Supports wrapping existing descriptors and handles non-descriptor
    callables as instance methods.
    'u'Method descriptor with partial application of the given arguments
    and keywords.

    Supports wrapping existing descriptors and handles non-descriptor
    callables as instance methods.
    'b'{!r} is not callable or a descriptor'u'{!r} is not callable or a descriptor'b'{module}.{cls}({func}, {args}, {keywords})'u'{module}.{cls}({func}, {args}, {keywords})'b'CacheInfo'u'CacheInfo'b'hits'u'hits'b'misses'u'misses'b'maxsize'u'maxsize'b'currsize'u'currsize'b' This class guarantees that hash() will be called no more than once
        per element.  This is important because the lru_cache() will hash
        the key multiple times on a cache miss.

    'u' This class guarantees that hash() will be called no more than once
        per element.  This is important because the lru_cache() will hash
        the key multiple times on a cache miss.

    'b'hashvalue'u'hashvalue'b'Make a cache key from optionally typed positional and keyword arguments

    The key is constructed in a way that is flat as possible rather than
    as a nested structure that would take more memory.

    If there is only a single argument and its data type is known to cache
    its hash value, then that argument is returned without a wrapper.  This
    saves space and improves lookup speed.

    'u'Make a cache key from optionally typed positional and keyword arguments

    The key is constructed in a way that is flat as possible rather than
    as a nested structure that would take more memory.

    If there is only a single argument and its data type is known to cache
    its hash value, then that argument is returned without a wrapper.  This
    saves space and improves lookup speed.

    'b'Least-recently-used cache decorator.

    If *maxsize* is set to None, the LRU features are disabled and the cache
    can grow without bound.

    If *typed* is True, arguments of different types will be cached separately.
    For example, f(3.0) and f(3) will be treated as distinct calls with
    distinct results.

    Arguments to the cached function must be hashable.

    View the cache statistics named tuple (hits, misses, maxsize, currsize)
    with f.cache_info().  Clear the cache and statistics with f.cache_clear().
    Access the underlying function with f.__wrapped__.

    See:  https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)

    'u'Least-recently-used cache decorator.

    If *maxsize* is set to None, the LRU features are disabled and the cache
    can grow without bound.

    If *typed* is True, arguments of different types will be cached separately.
    For example, f(3.0) and f(3) will be treated as distinct calls with
    distinct results.

    Arguments to the cached function must be hashable.

    View the cache statistics named tuple (hits, misses, maxsize, currsize)
    with f.cache_info().  Clear the cache and statistics with f.cache_clear().
    Access the underlying function with f.__wrapped__.

    See:  https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)

    'b'typed'u'typed'b'Expected first argument to be an integer, a callable, or None'u'Expected first argument to be an integer, a callable, or None'b'Report cache statistics'u'Report cache statistics'b'Clear the cache and cache statistics'u'Clear the cache and cache statistics'b'Simple lightweight unbounded cache.  Sometimes called "memoize".'u'Simple lightweight unbounded cache.  Sometimes called "memoize".'b'Merges MROs in *sequences* to a single MRO using the C3 algorithm.

    Adapted from https://docs.python.org/3/howto/mro.html.

    'u'Merges MROs in *sequences* to a single MRO using the C3 algorithm.

    Adapted from https://docs.python.org/3/howto/mro.html.

    'b'Inconsistent hierarchy'u'Inconsistent hierarchy'b'Computes the method resolution order using extended C3 linearization.

    If no *abcs* are given, the algorithm works exactly like the built-in C3
    linearization used for method resolution.

    If given, *abcs* is a list of abstract base classes that should be inserted
    into the resulting MRO. Unrelated ABCs are ignored and don't end up in the
    result. The algorithm inserts ABCs where their functionality is introduced,
    i.e. issubclass(cls, abc) returns True for the class itself but returns
    False for all its direct base classes. Implicit ABCs for a given class
    (either registered or inferred from the presence of a special method like
    __len__) are inserted directly after the last ABC explicitly listed in the
    MRO of said class. If two implicit ABCs end up next to each other in the
    resulting MRO, their ordering depends on the order of types in *abcs*.

    'u'Computes the method resolution order using extended C3 linearization.

    If no *abcs* are given, the algorithm works exactly like the built-in C3
    linearization used for method resolution.

    If given, *abcs* is a list of abstract base classes that should be inserted
    into the resulting MRO. Unrelated ABCs are ignored and don't end up in the
    result. The algorithm inserts ABCs where their functionality is introduced,
    i.e. issubclass(cls, abc) returns True for the class itself but returns
    False for all its direct base classes. Implicit ABCs for a given class
    (either registered or inferred from the presence of a special method like
    __len__) are inserted directly after the last ABC explicitly listed in the
    MRO of said class. If two implicit ABCs end up next to each other in the
    resulting MRO, their ordering depends on the order of types in *abcs*.

    'b'Calculates the method resolution order for a given class *cls*.

    Includes relevant abstract base classes (with their respective bases) from
    the *types* iterable. Uses a modified C3 linearization algorithm.

    'u'Calculates the method resolution order for a given class *cls*.

    Includes relevant abstract base classes (with their respective bases) from
    the *types* iterable. Uses a modified C3 linearization algorithm.

    'b'Returns the best matching implementation from *registry* for type *cls*.

    Where there is no registered implementation for a specific type, its method
    resolution order is used to find a more generic implementation.

    Note: if *registry* does not contain an implementation for the base
    *object* type, this function may return None.

    'u'Returns the best matching implementation from *registry* for type *cls*.

    Where there is no registered implementation for a specific type, its method
    resolution order is used to find a more generic implementation.

    Note: if *registry* does not contain an implementation for the base
    *object* type, this function may return None.

    'b'Ambiguous dispatch: {} or {}'u'Ambiguous dispatch: {} or {}'b'Single-dispatch generic function decorator.

    Transforms a function into a generic function, which can have different
    behaviours depending upon the type of its first argument. The decorated
    function acts as the default implementation, and additional
    implementations can be registered using the register() attribute of the
    generic function.
    'u'Single-dispatch generic function decorator.

    Transforms a function into a generic function, which can have different
    behaviours depending upon the type of its first argument. The decorated
    function acts as the default implementation, and additional
    implementations can be registered using the register() attribute of the
    generic function.
    'b'generic_func.dispatch(cls) -> <function implementation>

        Runs the dispatch algorithm to return the best available implementation
        for the given *cls* registered on *generic_func*.

        'u'generic_func.dispatch(cls) -> <function implementation>

        Runs the dispatch algorithm to return the best available implementation
        for the given *cls* registered on *generic_func*.

        'b'generic_func.register(cls, func) -> func

        Registers a new implementation for the given *cls* on a *generic_func*.

        'u'generic_func.register(cls, func) -> func

        Registers a new implementation for the given *cls* on a *generic_func*.

        'b'Invalid first argument to `register()`. 'u'Invalid first argument to `register()`. 'b' is not a class or union type.'u' is not a class or union type.'b'Invalid first argument to `register()`: 'u'Invalid first argument to `register()`: 'b'. Use either `@register(some_class)` or plain `@register` on an annotated function.'u'. Use either `@register(some_class)` or plain `@register` on an annotated function.'b'Invalid annotation for 'u'Invalid annotation for 'b'. 'u'. 'b' not all arguments are classes.'u' not all arguments are classes.'b' is not a class.'u' is not a class.'b' requires at least 1 positional argument'u' requires at least 1 positional argument'b'singledispatch function'u'singledispatch function'b'Single-dispatch generic method descriptor.

    Supports wrapping existing descriptors and handles non-descriptor
    callables as instance methods.
    'u'Single-dispatch generic method descriptor.

    Supports wrapping existing descriptors and handles non-descriptor
    callables as instance methods.
    'b' is not callable or a descriptor'u' is not callable or a descriptor'b'generic_method.register(cls, func) -> func

        Registers a new implementation for the given *cls* on a *generic_method*.
        'u'generic_method.register(cls, func) -> func

        Registers a new implementation for the given *cls* on a *generic_method*.
        'b'Cannot assign the same cached_property to two different names ('u'Cannot assign the same cached_property to two different names ('b' and 'u' and 'b').'u').'b'Cannot use cached_property instance without calling __set_name__ on it.'u'Cannot use cached_property instance without calling __set_name__ on it.'b'No '__dict__' attribute on 'u'No '__dict__' attribute on 'b' instance to cache 'u' instance to cache 'b' property.'u' property.'b'The '__dict__' attribute on 'u'The '__dict__' attribute on 'b' instance does not support item assignment for caching 'u' instance does not support item assignment for caching 'u'Lib.functools'A Future class similar to the one in PEP 3148.STACK_DEBUGThis class is *almost* compatible with concurrent.futures.Future.

    Differences:

    - This class is not thread-safe.

    - result() and exception() do not take a timeout argument and
      raise an exception when the future isn't done yet.

    - Callbacks registered with add_done_callback() are always called
      via the event loop's call_soon().

    - This class is not compatible with the wait() and as_completed()
      methods in the concurrent.futures package.

    (In Python 3.4 or later we may be able to unify the implementations.)
    _cancel_message_cancelled_exc__log_tracebackInitialize the future.

        The optional event_loop argument allows explicitly setting the event
        loop object used by the future. If it's not provided, the future uses
        the default event loop.
         exception was never retrieved_log_traceback_log_traceback can only be set to FalseReturn the event loop the Future is bound to.Future object is not initialized._make_cancelled_errorCreate the CancelledError to raise if the Future is cancelled.

        This should only be called once when handling a cancellation since
        it erases the saved context exception value.
        Cancel the future and schedule callbacks.

        If the future is already done or cancelled, return False.  Otherwise,
        change the future's state to cancelled, schedule the callbacks and
        return True.
        __schedule_callbacksInternal: Ask the event loop to call all callbacks.

        The callbacks are scheduled to be called as soon as possible. Also
        clears the callback list.
        callbacksReturn True if the future is done.

        Done means either that a result / exception are available, or that the
        future was cancelled.
        Return the result this future represents.

        If the future has been cancelled, raises CancelledError.  If the
        future's result isn't yet available, raises InvalidStateError.  If
        the future is done and has an exception set, this exception is raised.
        Result is not ready._exception_tbReturn the exception that was set on this future.

        The exception (or None if no exception was set) is returned only if
        the future is done.  If the future has been cancelled, raises
        CancelledError.  If the future isn't done yet, raises
        InvalidStateError.
        Exception is not set.Add a callback to be run when the future becomes done.

        The callback is called with a single argument - the future object. If
        the future is already done when this is called, the callback is
        scheduled with call_soon.
        Remove all instances of a callback from the "call when done" list.

        Returns the number of callbacks removed.
        filtered_callbacksremoved_countMark the future done and set its result.

        If the future is already done when this method is called, raises
        InvalidStateError.
        Mark the future done and set an exception.

        If the future is already done when this method is called, raises
        InvalidStateError.
        StopIteration interacts badly with generators and cannot be raised into a Future"StopIteration interacts badly with generators ""and cannot be raised into a Future"await wasn't used with future_PyFutureHelper setting the result only if the future was not cancelled._convert_future_excexc_class_set_concurrent_future_stateCopy state from a future to a concurrent.futures.Future._copy_future_stateInternal helper to copy state from another Future.

    The other Future may be a concurrent.futures.Future.
    _chain_futuredestinationChain two futures so that when one completes, so does the other.

    The result (or exception) of source will be copied to destination.
    If destination is cancelled, source gets cancelled too.
    Compatible with both asyncio.Future and concurrent.futures.Future.
    A future is required for source argumentA future is required for destination argumentsource_loopdest_loop_set_state_call_check_cancel_call_set_stateWrap concurrent.futures.Future object.concurrent.futures.Future is expected, got new_future_CFuture# heavy-duty debugging# Class variables serving as defaults for instance variables.# A saved CancelledError for later chaining as an exception context.# This field is used for a dual purpose:# - Its presence is a marker to declare that a class implements#   the Future protocol (i.e. is intended to be duck-type compatible).#   The value must also be not-None, to enable a subclass to declare#   that it is not compatible by setting this to None.# - It is set by __iter__() below so that Task._step() can tell#   the difference between#   `await Future()` or`yield from Future()` (correct) vs.#   `yield Future()` (incorrect).# set_exception() was not called, or result() or exception()# has consumed the exception# Remove the reference since we don't need this anymore.# Don't implement running(); see http://bugs.python.org/issue18699# New method not in PEP 3148.# So-called internal methods (note: no set_running_or_notify_cancel()).# This tells Task to wait for completion.# May raise too.# make compatible with 'yield from'.# Needed for testing purposes.# Tries to call Future.get_loop() if it's available.# Otherwise fallbacks to using the old '_loop' property.# _CFuture is needed for tests.b'A Future class similar to the one in PEP 3148.'u'A Future class similar to the one in PEP 3148.'b'wrap_future'u'wrap_future'b'isfuture'u'isfuture'b'This class is *almost* compatible with concurrent.futures.Future.

    Differences:

    - This class is not thread-safe.

    - result() and exception() do not take a timeout argument and
      raise an exception when the future isn't done yet.

    - Callbacks registered with add_done_callback() are always called
      via the event loop's call_soon().

    - This class is not compatible with the wait() and as_completed()
      methods in the concurrent.futures package.

    (In Python 3.4 or later we may be able to unify the implementations.)
    'u'This class is *almost* compatible with concurrent.futures.Future.

    Differences:

    - This class is not thread-safe.

    - result() and exception() do not take a timeout argument and
      raise an exception when the future isn't done yet.

    - Callbacks registered with add_done_callback() are always called
      via the event loop's call_soon().

    - This class is not compatible with the wait() and as_completed()
      methods in the concurrent.futures package.

    (In Python 3.4 or later we may be able to unify the implementations.)
    'b'Initialize the future.

        The optional event_loop argument allows explicitly setting the event
        loop object used by the future. If it's not provided, the future uses
        the default event loop.
        'u'Initialize the future.

        The optional event_loop argument allows explicitly setting the event
        loop object used by the future. If it's not provided, the future uses
        the default event loop.
        'b' exception was never retrieved'u' exception was never retrieved'b'_log_traceback can only be set to False'u'_log_traceback can only be set to False'b'Return the event loop the Future is bound to.'u'Return the event loop the Future is bound to.'b'Future object is not initialized.'u'Future object is not initialized.'b'Create the CancelledError to raise if the Future is cancelled.

        This should only be called once when handling a cancellation since
        it erases the saved context exception value.
        'u'Create the CancelledError to raise if the Future is cancelled.

        This should only be called once when handling a cancellation since
        it erases the saved context exception value.
        'b'Cancel the future and schedule callbacks.

        If the future is already done or cancelled, return False.  Otherwise,
        change the future's state to cancelled, schedule the callbacks and
        return True.
        'u'Cancel the future and schedule callbacks.

        If the future is already done or cancelled, return False.  Otherwise,
        change the future's state to cancelled, schedule the callbacks and
        return True.
        'b'Internal: Ask the event loop to call all callbacks.

        The callbacks are scheduled to be called as soon as possible. Also
        clears the callback list.
        'u'Internal: Ask the event loop to call all callbacks.

        The callbacks are scheduled to be called as soon as possible. Also
        clears the callback list.
        'b'Return True if the future is done.

        Done means either that a result / exception are available, or that the
        future was cancelled.
        'u'Return True if the future is done.

        Done means either that a result / exception are available, or that the
        future was cancelled.
        'b'Return the result this future represents.

        If the future has been cancelled, raises CancelledError.  If the
        future's result isn't yet available, raises InvalidStateError.  If
        the future is done and has an exception set, this exception is raised.
        'u'Return the result this future represents.

        If the future has been cancelled, raises CancelledError.  If the
        future's result isn't yet available, raises InvalidStateError.  If
        the future is done and has an exception set, this exception is raised.
        'b'Result is not ready.'u'Result is not ready.'b'Return the exception that was set on this future.

        The exception (or None if no exception was set) is returned only if
        the future is done.  If the future has been cancelled, raises
        CancelledError.  If the future isn't done yet, raises
        InvalidStateError.
        'u'Return the exception that was set on this future.

        The exception (or None if no exception was set) is returned only if
        the future is done.  If the future has been cancelled, raises
        CancelledError.  If the future isn't done yet, raises
        InvalidStateError.
        'b'Exception is not set.'u'Exception is not set.'b'Add a callback to be run when the future becomes done.

        The callback is called with a single argument - the future object. If
        the future is already done when this is called, the callback is
        scheduled with call_soon.
        'u'Add a callback to be run when the future becomes done.

        The callback is called with a single argument - the future object. If
        the future is already done when this is called, the callback is
        scheduled with call_soon.
        'b'Remove all instances of a callback from the "call when done" list.

        Returns the number of callbacks removed.
        'u'Remove all instances of a callback from the "call when done" list.

        Returns the number of callbacks removed.
        'b'Mark the future done and set its result.

        If the future is already done when this method is called, raises
        InvalidStateError.
        'u'Mark the future done and set its result.

        If the future is already done when this method is called, raises
        InvalidStateError.
        'b'Mark the future done and set an exception.

        If the future is already done when this method is called, raises
        InvalidStateError.
        'u'Mark the future done and set an exception.

        If the future is already done when this method is called, raises
        InvalidStateError.
        'b'StopIteration interacts badly with generators and cannot be raised into a Future'u'StopIteration interacts badly with generators and cannot be raised into a Future'b'await wasn't used with future'u'await wasn't used with future'b'Helper setting the result only if the future was not cancelled.'u'Helper setting the result only if the future was not cancelled.'b'Copy state from a future to a concurrent.futures.Future.'u'Copy state from a future to a concurrent.futures.Future.'b'Internal helper to copy state from another Future.

    The other Future may be a concurrent.futures.Future.
    'u'Internal helper to copy state from another Future.

    The other Future may be a concurrent.futures.Future.
    'b'Chain two futures so that when one completes, so does the other.

    The result (or exception) of source will be copied to destination.
    If destination is cancelled, source gets cancelled too.
    Compatible with both asyncio.Future and concurrent.futures.Future.
    'u'Chain two futures so that when one completes, so does the other.

    The result (or exception) of source will be copied to destination.
    If destination is cancelled, source gets cancelled too.
    Compatible with both asyncio.Future and concurrent.futures.Future.
    'b'A future is required for source argument'u'A future is required for source argument'b'A future is required for destination argument'u'A future is required for destination argument'b'Wrap concurrent.futures.Future object.'u'Wrap concurrent.futures.Future object.'b'concurrent.futures.Future is expected, got 'u'concurrent.futures.Future is expected, got 'u'Lib.asyncio.futures'u'asyncio.futures'
Path operations common to more than one OS
Do not use directly.  The OS specific modules import the appropriate
functions from this module themselves.
commonprefixgetatimegetctimegetmtimegetsizeislinksamefilesameopenfilesamestatTest whether a path exists.  Returns False for broken symbolic linksTest whether a path is a regular fileReturn true if the pathname refers to an existing directory.Test whether a path is a symbolic linklstatReturn the size of a file, reported by os.stat().Return the last modification time of a file, reported by os.stat().Return the last access time of a file, reported by os.stat().st_atimeReturn the metadata change time of a file, reported by os.stat().st_ctimeGiven a list of pathnames, returns the longest common leading componentTest whether two stat buffers reference the same filest_inost_devf1Test whether two pathnames reference the same actual file or directory

    This is determined by the device number and i-node number and
    raises an exception if an os.stat() call on either pathname fails.
    fp1fp2Test whether two open file objects reference the same filefstat_splitextextsepSplit the extension from a pathname.

    Extension is everything from the last dot to the end, ignoring
    leading dots.  Returns "(root, ext)"; ext may be empty.sepIndexaltsepIndexdotIndexfilenameIndex_check_arg_typeshasstrhasbytes() argument must be str, bytes, or os.PathLike object, not '() argument must be str, bytes, or ''os.PathLike object, not 'Can't mix strings and bytes in path components# Does a path exist?# This is false for dangling symbolic links on systems that support them.# This follows symbolic links, so both islink() and isdir() can be true# for the same path on systems that support symlinks# Is a path a directory?# This follows symbolic links, so both islink() and isdir()# can be true for the same path on systems that support symlinks# Is a path a symbolic link?# This will always return false on systems where os.lstat doesn't exist.# Return the longest prefix of all list elements.# Some people pass in a list of pathname parts to operate in an OS-agnostic# fashion; don't try to translate in that case as that's an abuse of the# API and they are already doing what they need to be OS-agnostic and so# they most likely won't be using an os.PathLike object in the sublists.# Are two stat buffers (obtained from stat, fstat or lstat)# describing the same file?# Are two filenames really pointing to the same file?# Are two open files really referencing the same file?# (Not necessarily the same file descriptor!)# Split a path in root and extension.# The extension is everything starting at the last dot in the last# pathname component; the root is everything before that.# It is always true that root + ext == p.# Generic implementation of splitext, to be parametrized with# the separators# NOTE: This code must work for text and bytes strings.# skip all leading dotsb'
Path operations common to more than one OS
Do not use directly.  The OS specific modules import the appropriate
functions from this module themselves.
'u'
Path operations common to more than one OS
Do not use directly.  The OS specific modules import the appropriate
functions from this module themselves.
'b'commonprefix'u'commonprefix'b'exists'u'exists'b'getatime'u'getatime'b'getctime'u'getctime'b'getmtime'u'getmtime'b'getsize'u'getsize'b'isdir'u'isdir'b'isfile'u'isfile'b'islink'u'islink'b'samefile'u'samefile'b'sameopenfile'u'sameopenfile'b'samestat'u'samestat'b'Test whether a path exists.  Returns False for broken symbolic links'u'Test whether a path exists.  Returns False for broken symbolic links'b'Test whether a path is a regular file'u'Test whether a path is a regular file'b'Return true if the pathname refers to an existing directory.'u'Return true if the pathname refers to an existing directory.'b'Test whether a path is a symbolic link'u'Test whether a path is a symbolic link'b'Return the size of a file, reported by os.stat().'u'Return the size of a file, reported by os.stat().'b'Return the last modification time of a file, reported by os.stat().'u'Return the last modification time of a file, reported by os.stat().'b'Return the last access time of a file, reported by os.stat().'u'Return the last access time of a file, reported by os.stat().'b'Return the metadata change time of a file, reported by os.stat().'u'Return the metadata change time of a file, reported by os.stat().'b'Given a list of pathnames, returns the longest common leading component'u'Given a list of pathnames, returns the longest common leading component'b'Test whether two stat buffers reference the same file'u'Test whether two stat buffers reference the same file'b'Test whether two pathnames reference the same actual file or directory

    This is determined by the device number and i-node number and
    raises an exception if an os.stat() call on either pathname fails.
    'u'Test whether two pathnames reference the same actual file or directory

    This is determined by the device number and i-node number and
    raises an exception if an os.stat() call on either pathname fails.
    'b'Test whether two open file objects reference the same file'u'Test whether two open file objects reference the same file'b'Split the extension from a pathname.

    Extension is everything from the last dot to the end, ignoring
    leading dots.  Returns "(root, ext)"; ext may be empty.'u'Split the extension from a pathname.

    Extension is everything from the last dot to the end, ignoring
    leading dots.  Returns "(root, ext)"; ext may be empty.'b'() argument must be str, bytes, or os.PathLike object, not 'u'() argument must be str, bytes, or os.PathLike object, not 'b'Can't mix strings and bytes in path components'u'Can't mix strings and bytes in path components'u'Lib.genericpath'u'genericpath'Parser for command line options.

This module helps scripts to parse the command line arguments in
sys.argv.  It supports the same conventions as the Unix getopt()
function (including the special meanings of arguments of the form `-'
and `--').  Long options similar to those supported by GNU software
may be used as well via an optional third argument.  This module
provides two functions and an exception:

getopt() -- Parse command line options
gnu_getopt() -- Like getopt(), but allow option and non-option arguments
to be intermixed.
GetoptError -- exception (class) raised with 'opt' attribute, which is the
option involved with the exception.
GetoptErrorgnu_getoptoptshortoptslongoptsgetopt(args, options[, long_options]) -> opts, args

    Parses command line options and parameter list.  args is the
    argument list to be parsed, without the leading reference to the
    running program.  Typically, this means "sys.argv[1:]".  shortopts
    is the string of option letters that the script wants to
    recognize, with options that require an argument followed by a
    colon (i.e., the same format that Unix getopt() uses).  If
    specified, longopts is a list of strings with the names of the
    long options which should be supported.  The leading '--'
    characters should not be included in the option name.  Options
    which require an argument should be followed by an equal sign
    ('=').

    The return value consists of two elements: the first is a list of
    (option, value) pairs; the second is the list of program arguments
    left after the option list was stripped (this is a trailing slice
    of the first argument).  Each option-and-value pair returned has
    the option as its first element, prefixed with a hyphen (e.g.,
    '-x'), and the option argument as its second element, or an empty
    string if the option has no argument.  The options occur in the
    list in the same order in which they were found, thus allowing
    multiple occurrences.  Long and short options may be mixed.

    do_longsdo_shortsgetopt(args, options[, long_options]) -> opts, args

    This function works like getopt(), except that GNU style scanning
    mode is used by default. This means that option and non-option
    arguments may be intermixed. The getopt() function stops
    processing options as soon as a non-option argument is
    encountered.

    If the first character of the option string is `+', or if the
    environment variable POSIXLY_CORRECT is set, then option
    processing stops as soon as a non-option argument is encountered.

    prog_argsall_options_firstPOSIXLY_CORRECToptarglong_has_argshas_argoption --%s requires argumentoption --%s must not have an argumentoption --%s not recognizedoption --%s not a unique prefixunique_matchoptstringshort_has_argoption -%s requires argumentoption -%s not recognizeda:balpha=# Long option support added by Lars Wirzenius <liw@iki.fi>.# Gerrit Holl <gerrit@nl.linux.org> moved the string-based exceptions# to class-based exceptions.# Peter strand <astrand@lysator.liu.se> added gnu_getopt().# TODO for gnu_getopt():# - GNU getopt_long_only mechanism# - allow the caller to specify ordering# - RETURN_IN_ORDER option# - GNU extension with '-' as first character of option string# - optional arguments, specified by double colons# - an option string with a W followed by semicolon should#   treat "-W foo" as "--foo"# Bootstrapping Python: gettext's dependencies not built yet# Allow options after non-option arguments?# Return:#   has_arg?#   full option name# Is there an exact match?# No exact match, so better be unique.# XXX since possibilities contains all valid continuations, might be# nice to work them into the error msgb'Parser for command line options.

This module helps scripts to parse the command line arguments in
sys.argv.  It supports the same conventions as the Unix getopt()
function (including the special meanings of arguments of the form `-'
and `--').  Long options similar to those supported by GNU software
may be used as well via an optional third argument.  This module
provides two functions and an exception:

getopt() -- Parse command line options
gnu_getopt() -- Like getopt(), but allow option and non-option arguments
to be intermixed.
GetoptError -- exception (class) raised with 'opt' attribute, which is the
option involved with the exception.
'u'Parser for command line options.

This module helps scripts to parse the command line arguments in
sys.argv.  It supports the same conventions as the Unix getopt()
function (including the special meanings of arguments of the form `-'
and `--').  Long options similar to those supported by GNU software
may be used as well via an optional third argument.  This module
provides two functions and an exception:

getopt() -- Parse command line options
gnu_getopt() -- Like getopt(), but allow option and non-option arguments
to be intermixed.
GetoptError -- exception (class) raised with 'opt' attribute, which is the
option involved with the exception.
'b'GetoptError'u'GetoptError'b'getopt'u'getopt'b'gnu_getopt'u'gnu_getopt'b'getopt(args, options[, long_options]) -> opts, args

    Parses command line options and parameter list.  args is the
    argument list to be parsed, without the leading reference to the
    running program.  Typically, this means "sys.argv[1:]".  shortopts
    is the string of option letters that the script wants to
    recognize, with options that require an argument followed by a
    colon (i.e., the same format that Unix getopt() uses).  If
    specified, longopts is a list of strings with the names of the
    long options which should be supported.  The leading '--'
    characters should not be included in the option name.  Options
    which require an argument should be followed by an equal sign
    ('=').

    The return value consists of two elements: the first is a list of
    (option, value) pairs; the second is the list of program arguments
    left after the option list was stripped (this is a trailing slice
    of the first argument).  Each option-and-value pair returned has
    the option as its first element, prefixed with a hyphen (e.g.,
    '-x'), and the option argument as its second element, or an empty
    string if the option has no argument.  The options occur in the
    list in the same order in which they were found, thus allowing
    multiple occurrences.  Long and short options may be mixed.

    'u'getopt(args, options[, long_options]) -> opts, args

    Parses command line options and parameter list.  args is the
    argument list to be parsed, without the leading reference to the
    running program.  Typically, this means "sys.argv[1:]".  shortopts
    is the string of option letters that the script wants to
    recognize, with options that require an argument followed by a
    colon (i.e., the same format that Unix getopt() uses).  If
    specified, longopts is a list of strings with the names of the
    long options which should be supported.  The leading '--'
    characters should not be included in the option name.  Options
    which require an argument should be followed by an equal sign
    ('=').

    The return value consists of two elements: the first is a list of
    (option, value) pairs; the second is the list of program arguments
    left after the option list was stripped (this is a trailing slice
    of the first argument).  Each option-and-value pair returned has
    the option as its first element, prefixed with a hyphen (e.g.,
    '-x'), and the option argument as its second element, or an empty
    string if the option has no argument.  The options occur in the
    list in the same order in which they were found, thus allowing
    multiple occurrences.  Long and short options may be mixed.

    'b'getopt(args, options[, long_options]) -> opts, args

    This function works like getopt(), except that GNU style scanning
    mode is used by default. This means that option and non-option
    arguments may be intermixed. The getopt() function stops
    processing options as soon as a non-option argument is
    encountered.

    If the first character of the option string is `+', or if the
    environment variable POSIXLY_CORRECT is set, then option
    processing stops as soon as a non-option argument is encountered.

    'u'getopt(args, options[, long_options]) -> opts, args

    This function works like getopt(), except that GNU style scanning
    mode is used by default. This means that option and non-option
    arguments may be intermixed. The getopt() function stops
    processing options as soon as a non-option argument is
    encountered.

    If the first character of the option string is `+', or if the
    environment variable POSIXLY_CORRECT is set, then option
    processing stops as soon as a non-option argument is encountered.

    'b'POSIXLY_CORRECT'u'POSIXLY_CORRECT'b'option --%s requires argument'u'option --%s requires argument'b'option --%s must not have an argument'u'option --%s must not have an argument'b'option --%s not recognized'u'option --%s not recognized'b'option --%s not a unique prefix'u'option --%s not a unique prefix'b'option -%s requires argument'u'option -%s requires argument'b'option -%s not recognized'u'option -%s not recognized'b'a:b'u'a:b'b'alpha='u'alpha='u'Lib.getopt'Internationalization and localization support.

This module provides internationalization (I18N) and localization (L10N)
support for your Python programs by providing an interface to the GNU gettext
message catalog library.

I18N refers to the operation by which a program is made aware of multiple
languages.  L10N refers to the adaptation of your program, once
internationalized, to the local language and cultural habits.

NullTranslationsGNUTranslationsCatalogbindtextdomaintranslationinstalltextdomaindgettextdngettextpgettextdpgettextnpgettextdnpgettextshare_default_localedir
        (?P<WHITESPACES>[ \t]+)                    | # spaces and horizontal tabs
        (?P<NUMBER>[0-9]+\b)                       | # decimal integer
        (?P<NAME>n\b)                              | # only n is allowed
        (?P<PARENTHESIS>[()])                      |
        (?P<OPERATOR>[-*/%+?:]|[><!]=?|==|&&|\|\|) | # !, *, /, %, +, -, <, >,
                                                     # <=, >=, ==, !=, &&, ||,
                                                     # ? :
                                                     # unary and bitwise ops
                                                     # not allowed
        (?P<INVALID>\w+|.)                           # invalid token
    _token_patternlastgroupWHITESPACESINVALIDinvalid token in plural form: %s_errorunexpected token in plural form: %sunexpected end of plural form||&&_binary_ops_c2py_opstokensprioritynexttoknot unbalanced parenthesis in plural form%s%s%s%d(%s)if_trueif_false%s if %s else %s_as_intPlural value must be an integer, got %sc2pyGets a C expression as used in PO files for plural forms and returns a
    Python function that implements an equivalent expression.
    plural form expression is too longplural form expression is too complexif True:
            def func(n):
                if not isinstance(n, int):
                    n = _as_int(n)
                return int(%s)
            _expand_langlocCOMPONENT_CODESETCOMPONENT_TERRITORYCOMPONENT_MODIFIERmodifiercodesetterritorylanguage_info_fallbackadd_fallbackmsgid1msgid2allowed25000721580x950412deLE_MAGIC37257227730xde120495BE_MAGIC%s%sCONTEXTVERSIONS_get_versionsReturns a tuple of major version, minor versionOverride this method to support alternative .mo formats._catalogcatalogbuflen<I<4Imsgcountmasteridxtransidx<IIii>4I>IIBad magic numbermajor_versionminor_versionBad version number mlenmoffmendtlentofftendtmsgFile is corruptlastkb_item#-#-#-#-#content-typecharset=plural-formsplural=ctxt_msg_idlocaledirlanguagesenvarLANGUAGELC_MESSAGESLANGnelangsnelang%s.momofile_translationsclass_mofilesNo translation file found for domain_localedirsmessages_current_domain# This module represents the integration of work, contributions, feedback, and# suggestions from the following people:# Martin von Loewis, who wrote the initial implementation of the underlying# C-based libintlmodule (later renamed _gettext), along with a skeletal# gettext.py implementation.# Peter Funk, who wrote fintl.py, a fairly complete wrapper around intlmodule,# which also included a pure-Python implementation to read .mo files if# intlmodule wasn't available.# James Henstridge, who also wrote a gettext.py module, which has some# interesting, but currently unsupported experimental features: the notion of# a Catalog class and instances, and the ability to add to a catalog file via# a Python API.# Barry Warsaw integrated these modules, wrote the .install() API and code,# and conformed all C and Python code to Python's coding standards.# Francois Pinard and Marc-Andre Lemburg also contributed valuably to this# J. David Ibanez implemented plural forms. Bruno Haible fixed some bugs.# TODO:# - Lazy loading of .mo files.  Currently the entire catalog is loaded into#   memory, but that's probably bad for large translated programs.  Instead,#   the lexical sort of original strings in GNU .mo files should be exploited#   to do binary searches and lazy initializations.  Or you might want to use#   the undocumented double-hash algorithm for .mo files with hash tables, but#   you'll need to study the GNU gettext code to do this.# - Support Solaris .mo file formats.  Unfortunately, we've been unable to#   find this format documented anywhere.# Expression parsing for plural form selection.# The gettext library supports a small subset of C syntax.  The only# incompatible difference is that integer literals starting with zero are# decimal.# https://www.gnu.org/software/gettext/manual/gettext.html#Plural-forms# http://git.savannah.gnu.org/cgit/gettext.git/tree/gettext-runtime/intl/plural.y# Break chained comparisons# '==', '!=', '<', '>', '<=', '>='# Replace some C operators by their Python equivalents# '<', '>', '<=', '>='# Python compiler limit is about 90.# The most complex example has 2.# Recursion error can be raised in _parse() or exec().# split up the locale into its base components# if all components for this combo exist ...# Magic number of .mo files# The encoding of a msgctxt and a msgid in a .mo file is# msgctxt + "\x04" + msgid (gettext version >= 0.15)# Acceptable .mo versions# Delay struct import for speeding up gettext import when .mo files# are not used.# Parse the .mo file header, which consists of 5 little endian 32# bit words.# germanic plural by default# Are we big endian or little endian?# Now put all messages from the .mo file buffer into the catalog# dictionary.# See if we're looking at GNU .mo conventions for metadata# Catalog description# Skip over comment lines:# Note: we unconditionally convert both msgids and msgstrs to# Unicode using the character encoding specified in the charset# parameter of the Content-Type header.  The gettext documentation# strongly encourages msgids to be us-ascii, but some applications# require alternative encodings (e.g. Zope's ZCML and ZPT).  For# traditional gettext applications, the msgid conversion will# cause no problems since us-ascii should always be a subset of# the charset encoding.  We may want to fall back to 8-bit msgids# if the Unicode conversion fails.# Plural forms# advance to next entry in the seek tables# Locate a .mo file using the gettext strategy# Get some reasonable defaults for arguments that were not supplied# now normalize and expand the languages# select a language# a mapping between absolute .mo file path and Translation object# Avoid opening, reading, and parsing the .mo file after it's been done# once.# Copy the translation object to allow setting fallbacks and# output charset. All other instance data is shared with the# cached object.# Delay copy import for speeding up gettext import when .mo files# a mapping b/w domains and locale directories# current global domain, `messages' used for compatibility w/ GNU gettext# dcgettext() has been deemed unnecessary and is not implemented.# James Henstridge's Catalog constructor from GNOME gettext.  Documented usage# was:#    import gettext#    cat = gettext.Catalog(PACKAGE, localedir=LOCALEDIR)#    _ = cat.gettext#    print _('Hello World')# The resulting catalog object currently don't support access through a# dictionary API, which was supported (but apparently unused) in GNOME# gettext.b'Internationalization and localization support.

This module provides internationalization (I18N) and localization (L10N)
support for your Python programs by providing an interface to the GNU gettext
message catalog library.

I18N refers to the operation by which a program is made aware of multiple
languages.  L10N refers to the adaptation of your program, once
internationalized, to the local language and cultural habits.

'u'Internationalization and localization support.

This module provides internationalization (I18N) and localization (L10N)
support for your Python programs by providing an interface to the GNU gettext
message catalog library.

I18N refers to the operation by which a program is made aware of multiple
languages.  L10N refers to the adaptation of your program, once
internationalized, to the local language and cultural habits.

'b'NullTranslations'u'NullTranslations'b'GNUTranslations'u'GNUTranslations'b'Catalog'u'Catalog'b'bindtextdomain'u'bindtextdomain'b'find'u'find'b'translation'u'translation'b'install'u'install'b'textdomain'u'textdomain'b'dgettext'u'dgettext'b'dngettext'u'dngettext'b'gettext'u'gettext'b'ngettext'u'ngettext'b'pgettext'u'pgettext'b'dpgettext'u'dpgettext'b'npgettext'u'npgettext'b'dnpgettext'u'dnpgettext'b'share'u'share'b'locale'b'
        (?P<WHITESPACES>[ \t]+)                    | # spaces and horizontal tabs
        (?P<NUMBER>[0-9]+\b)                       | # decimal integer
        (?P<NAME>n\b)                              | # only n is allowed
        (?P<PARENTHESIS>[()])                      |
        (?P<OPERATOR>[-*/%+?:]|[><!]=?|==|&&|\|\|) | # !, *, /, %, +, -, <, >,
                                                     # <=, >=, ==, !=, &&, ||,
                                                     # ? :
                                                     # unary and bitwise ops
                                                     # not allowed
        (?P<INVALID>\w+|.)                           # invalid token
    'u'
        (?P<WHITESPACES>[ \t]+)                    | # spaces and horizontal tabs
        (?P<NUMBER>[0-9]+\b)                       | # decimal integer
        (?P<NAME>n\b)                              | # only n is allowed
        (?P<PARENTHESIS>[()])                      |
        (?P<OPERATOR>[-*/%+?:]|[><!]=?|==|&&|\|\|) | # !, *, /, %, +, -, <, >,
                                                     # <=, >=, ==, !=, &&, ||,
                                                     # ? :
                                                     # unary and bitwise ops
                                                     # not allowed
        (?P<INVALID>\w+|.)                           # invalid token
    'b'WHITESPACES'u'WHITESPACES'b'INVALID'u'INVALID'b'invalid token in plural form: %s'u'invalid token in plural form: %s'b'unexpected token in plural form: %s'u'unexpected token in plural form: %s'b'unexpected end of plural form'u'unexpected end of plural form'b'||'u'||'b'&&'u'&&'b'not 'u'not 'b'unbalanced parenthesis in plural form'u'unbalanced parenthesis in plural form'b'%s%s'u'%s%s'b'%s%d'u'%s%d'b'(%s)'u'(%s)'b'%s if %s else %s'u'%s if %s else %s'b'Plural value must be an integer, got %s'u'Plural value must be an integer, got %s'b'Gets a C expression as used in PO files for plural forms and returns a
    Python function that implements an equivalent expression.
    'u'Gets a C expression as used in PO files for plural forms and returns a
    Python function that implements an equivalent expression.
    'b'plural form expression is too long'u'plural form expression is too long'b'plural form expression is too complex'u'plural form expression is too complex'b'_as_int'u'_as_int'b'if True:
            def func(n):
                if not isinstance(n, int):
                    n = _as_int(n)
                return int(%s)
            'u'if True:
            def func(n):
                if not isinstance(n, int):
                    n = _as_int(n)
                return int(%s)
            'b'%s%s'u'%s%s'b'Returns a tuple of major version, minor version'u'Returns a tuple of major version, minor version'b'Override this method to support alternative .mo formats.'u'Override this method to support alternative .mo formats.'b'<I'u'<I'b'<4I'u'<4I'b'<II'u'<II'b'>4I'u'>4I'b'>II'u'>II'b'Bad magic number'u'Bad magic number'b'Bad version number 'u'Bad version number 'b'File is corrupt'u'File is corrupt'b'#-#-#-#-#'u'#-#-#-#-#'b'content-type'u'content-type'b'charset='u'charset='b'plural-forms'u'plural-forms'b'plural='u'plural='b'LANGUAGE'u'LANGUAGE'b'LC_ALL'u'LC_ALL'b'LC_MESSAGES'u'LC_MESSAGES'b'LANG'u'LANG'b'%s.mo'u'%s.mo'b'No translation file found for domain'u'No translation file found for domain'b'messages'u'messages'u'Lib.gettext'
    Given a glob pattern, produce a regex that matches it.

    >>> translate('*.txt')
    '[^/]*\\.txt'
    >>> translate('a?txt')
    'a.txt'
    >>> translate('**/*')
    '.*/[^/]*'
    separate
    Separate out character sets to avoid translating their contents.

    >>> [m.group(0) for m in separate('*.txt')]
    ['*.txt']
    >>> [m.group(0) for m in separate('a[?]txt')]
    ['a', '[?]', 'txt']
    ([^\[]+)|(?P<set>[\[].*?[\]])|([\[][^\]]*$)
    Perform the replacements for a match from :func:`separate`.
    \*\*\*[^/]*\?b'
    Given a glob pattern, produce a regex that matches it.

    >>> translate('*.txt')
    '[^/]*\\.txt'
    >>> translate('a?txt')
    'a.txt'
    >>> translate('**/*')
    '.*/[^/]*'
    'u'
    Given a glob pattern, produce a regex that matches it.

    >>> translate('*.txt')
    '[^/]*\\.txt'
    >>> translate('a?txt')
    'a.txt'
    >>> translate('**/*')
    '.*/[^/]*'
    'b'
    Separate out character sets to avoid translating their contents.

    >>> [m.group(0) for m in separate('*.txt')]
    ['*.txt']
    >>> [m.group(0) for m in separate('a[?]txt')]
    ['a', '[?]', 'txt']
    'u'
    Separate out character sets to avoid translating their contents.

    >>> [m.group(0) for m in separate('*.txt')]
    ['*.txt']
    >>> [m.group(0) for m in separate('a[?]txt')]
    ['a', '[?]', 'txt']
    'b'([^\[]+)|(?P<set>[\[].*?[\]])|([\[][^\]]*$)'u'([^\[]+)|(?P<set>[\[].*?[\]])|([\[][^\]]*$)'b'
    Perform the replacements for a match from :func:`separate`.
    'u'
    Perform the replacements for a match from :func:`separate`.
    'b'\*\*'u'\*\*'b'\*'u'\*'b'[^/]*'u'[^/]*'b'\?'u'\?'u'Lib.zipfile._path.glob'u'zipfile._path.glob'u'_path.glob'u'glob'Filename globbing utility.iglobroot_dirdir_fdinclude_hiddenReturn a list of paths matching a pathname pattern.

    The pattern may contain simple shell-style wildcards a la
    fnmatch. Unlike fnmatch, filenames starting with a
    dot are special cases that are not matched by '*' and '?'
    patterns by default.

    If `include_hidden` is true, the patterns '*', '?', '**'  will match hidden
    directories.

    If `recursive` is true, the pattern '**' will match any files and
    zero or more directories and subdirectories.
    Return an iterator which yields the paths matching a pathname pattern.

    The pattern may contain simple shell-style wildcards a la
    fnmatch. However, unlike fnmatch, filenames starting with a
    dot are special cases that are not matched by '*' and '?'
    patterns.

    If recursive is true, the pattern '**' will match any files and
    zero or more directories and subdirectories.
    glob.globglob.glob/2_iglob_isrecursivedironlyhas_magic_lexists_join_isdir_glob2_glob1dirsglob_in_dir_glob0_listdir_ishiddenglob0glob1_rlistdir_iterdirfsencode_dir_open_flagsscandirlexists([*?[])magic_checkmagic_check_bytesEscape all special characters.
    drive[\1]O_RDONLYO_DIRECTORY# skip empty string# Patterns ending with a slash should match only directories# `os.path.split()` returns the argument itself as a dirname if it is a# drive or UNC path.  Prevent an infinite recursion if a drive or UNC path# contains magic characters (i.e. r'\\?\C:').# These 2 helper functions non-recursively glob inside a literal directory.# They return a list of basenames.  _glob1 accepts a pattern while _glob0# takes a literal basename (so it only has to check for its existence).# `os.path.split()` returns an empty basename for paths ending with a# directory separator.  'q*x/' should match only directories.# Following functions are not public but can be used by third-party code.# This helper function recursively yields relative pathnames inside a literal# directory.# If dironly is false, yields all file names inside a directory.# If dironly is true, yields only directory names.# Recursively yields relative pathnames inside a literal directory.# Same as os.path.lexists(), but with dir_fd# Same as os.path.isdir(), but with dir_fd# It is common if dirname or basename is empty# Escaping is done by wrapping any of "*?[" between square brackets.# Metacharacters do not work in the drive part and shouldn't be escaped.b'Filename globbing utility.'u'Filename globbing utility.'b'glob'b'iglob'u'iglob'b'Return a list of paths matching a pathname pattern.

    The pattern may contain simple shell-style wildcards a la
    fnmatch. Unlike fnmatch, filenames starting with a
    dot are special cases that are not matched by '*' and '?'
    patterns by default.

    If `include_hidden` is true, the patterns '*', '?', '**'  will match hidden
    directories.

    If `recursive` is true, the pattern '**' will match any files and
    zero or more directories and subdirectories.
    'u'Return a list of paths matching a pathname pattern.

    The pattern may contain simple shell-style wildcards a la
    fnmatch. Unlike fnmatch, filenames starting with a
    dot are special cases that are not matched by '*' and '?'
    patterns by default.

    If `include_hidden` is true, the patterns '*', '?', '**'  will match hidden
    directories.

    If `recursive` is true, the pattern '**' will match any files and
    zero or more directories and subdirectories.
    'b'Return an iterator which yields the paths matching a pathname pattern.

    The pattern may contain simple shell-style wildcards a la
    fnmatch. However, unlike fnmatch, filenames starting with a
    dot are special cases that are not matched by '*' and '?'
    patterns.

    If recursive is true, the pattern '**' will match any files and
    zero or more directories and subdirectories.
    'u'Return an iterator which yields the paths matching a pathname pattern.

    The pattern may contain simple shell-style wildcards a la
    fnmatch. However, unlike fnmatch, filenames starting with a
    dot are special cases that are not matched by '*' and '?'
    patterns.

    If recursive is true, the pattern '**' will match any files and
    zero or more directories and subdirectories.
    'b'glob.glob'u'glob.glob'b'glob.glob/2'u'glob.glob/2'b'([*?[])'u'([*?[])'b'Escape all special characters.
    'u'Escape all special characters.
    'b'[\1]'u'[\1]'b'O_DIRECTORY'u'O_DIRECTORY'u'Lib.glob'Functions that read and write gzipped files.

The user of the file doesn't have to worry about the compression,
but random access is not allowed.BadGzipFileFTEXTFHCRCFEXTRAFNAMEFCOMMENTREADWRITE_COMPRESS_LEVEL_FAST_COMPRESS_LEVEL_TRADEOFF_COMPRESS_LEVEL_BESTREAD_BUFFER_SIZE_WRITE_BUFFER_SIZEOpen a gzip-compressed file in binary or text mode.

    The filename argument can be an actual filename (a str or bytes object), or
    an existing file object to read from or write to.

    The mode argument can be "r", "rb", "w", "wb", "x", "xb", "a" or "ab" for
    binary mode, or "rt", "wt", "xt" or "at" for text mode. The default mode is
    "rb", and the default compresslevel is 9.

    For binary mode, this function is equivalent to the GzipFile constructor:
    GzipFile(filename, mode, compresslevel). In this case, the encoding, errors
    and newline arguments must not be provided.

    For text mode, a GzipFile object is created, and wrapped in an
    io.TextIOWrapper instance with the specified encoding, error handling
    behavior, and line ending(s).

    gz_modefilename must be a str or bytes object, or a filewrite32u<L_PaddedFileMinimal read-only file object that prepends a string to the contents
    of an actual file. Shouldn't be used outside of gzip.py, as it lacks
    essential functionality.prepend_lengthException raised in some cases for invalid gzip files._WriteBufferStreamMinimal object to pass WriteBuffer flushes into GzipFilegzip_file_write_rawThe GzipFile class simulates most of the methods of a file object with
    the exception of the truncate() method.

    This class only supports opening files in binary mode. If you need to open a
    compressed file in text mode, use the gzip.open() function.

    myfileobjConstructor for the GzipFile class.

        At least one of fileobj and filename must be given a
        non-trivial value.

        The new class instance is based on fileobj, which can be a regular
        file, an io.BytesIO object, or any other object which simulates a file.
        It defaults to None, in which case filename is opened to provide
        a file object.

        When fileobj is not None, the filename argument is only used to be
        included in the gzip file header, which may include the original
        filename of the uncompressed file.  It defaults to the filename of
        fileobj, if discernible; otherwise, it defaults to the empty string,
        and in this case the original filename is not included in the header.

        The mode argument can be any of 'r', 'rb', 'a', 'ab', 'w', 'wb', 'x', or
        'xb' depending on whether the file will be read or written.  The default
        is the mode of fileobj if discernible; otherwise, the default is 'rb'.
        A mode of 'r' is equivalent to one of 'rb', and similarly for 'w' and
        'wb', 'a' and 'ab', and 'x' and 'xb'.

        The compresslevel argument is an integer from 0 to 9 controlling the
        level of compression; 1 is fastest and produces the least compression,
        and 9 is slowest and produces the most compression. 0 is no compression
        at all. The default is 9.

        The mtime argument is an optional numeric timestamp to be written
        to the last modification time field in the stream when compressing.
        If omitted or None, the current time is used.

        Invalid mode: {!r}origmode_GzipReaderGzipFile was opened for writing, but this will change in future Python releases.  Specify the mode argument for opening it for writing."GzipFile was opened for writing, but this will ""change in future Python releases.  ""Specify the mode argument for opening it for writing."_init_writeMAX_WBITSDEF_MEM_LEVEL_write_mtime_buffer_sizebuffer_size_write_gzip_headerLast modification time read from stream, or None_last_mtime<gzip writebuf.gzxflwrite() on read-only GzipFile objectwrite() on closed GzipFile objectread() on write-only GzipFile objectImplements BufferedIOBase.read1()

        Reads up to a buffer's worth of data if size is negative.read1() on write-only GzipFile objectpeek() on write-only GzipFile objectZ_SYNC_FLUSHzlib_modeInvoke the underlying file object's fileno() method.

        This will raise AttributeError if the underlying file object
        doesn't support fileno().
        rewindReturn the uncompressed stream file position indicator to the
        beginning of the fileCan't rewind in write modeSeek from end not supportedNegative seek in write mode_read_exactRead exactly *n* bytes from `fp`

    This method is required because fp may be unbuffered,
    i.e. return short reads.
    _read_gzip_headerRead a gzip header from `fp` and progress to the end of the header.

    Returns last mtime if header was present or None otherwise.
    Not a gzipped file (%r)<BBIxxlast_mtimeUnknown compression methodextra_len_ZlibDecompressorwbits_new_member_init_read_stream_size_read_eofuncompressisizeCRC check failed %s != %sIncorrect length of data produced_create_simple_gzip_header
    Write a simple gzip header with no extra fields.
    :param compresslevel: Compresslevel used to determine the xfl bytes.
    :param mtime: The mtime (must support conversion to a 32-bit integer).
    :return: A bytes object representing the gzip header.
    <BBBBLBBCompress data in one shot and return the compressed string.

    compresslevel sets the compression level in range of 0-9.
    mtime can be used to set the modification time. The modification time is
    set to the current time by default.
    <LLtrailerDecompress a gzip compressed string in one shot.
    Return the decompressed string.
    decompressed_membersdodecompressed"Compressed file ended before the end-of-stream ""marker was reached"CRC check failedA simple command line interface for the gzip module: act like gzip, but do not delete the input file."A simple command line interface for the gzip module: act like gzip, ""but do not delete the input file."--fastcompress faster--bestcompress better--decompressact like gunzip instead of gzipbestfilename doesn't end in .gz: # based on Andrew Kuchling's minigzip.py distributed with the zlib module# The L format writes the bit pattern correctly whether signed# or unsigned.# Assume data was read since the last prepend() call# Allows fast-forwarding even in unseekable streams# Overridden with internal file object to be closed, if only a filename# is passed in# Current file offset for seek(), tell(), etc# magic header# compression method# RFC 1952 requires the FNAME field to be Latin-1. Do not# include filenames that cannot be represented that way.# Called by our self._buffer underlying WriteBufferStream.# self.size may exceed 2 GiB, or even 4 GiB# Ensure the compressor's buffer is flushed# Flush buffer to ensure validity of self.offset# Read & discard the extra field, if present# Read and discard a null-terminated string containing the filename# Read and discard a null-terminated string containing a comment# Read & discard the 16-bit header CRC# Set flag indicating start of a new member# Decompressed size of unconcatenated stream# size=0 is special because decompress(max_length=0) is not supported# For certain input data, a single# call to decompress() may not return# any data. In this case, retry until we get some data or reach EOF.# Ending case: we've come to the end of a member in the file,# so finish up this member, and read a new gzip header.# Check the CRC and file size, and set the flag so we read# a new member# If the _new_member flag is set, we have to# jump to the next member, if there is one.# Read a chunk of data from the file# Prepend the already read bytes to the fileobj so they can# be seen by _read_eof() and _read_gzip_header()# We've read to the end of the file# We check that the computed CRC and size of the# uncompressed data matches the stored values.  Note that the size# stored is the true file size mod 2**32.# Gzip files can be padded with zeroes and still have archives.# Consume all zero bytes and set the file position to the first# non-zero byte. See http://www.gzip.org/#faq8# Pack ID1 and ID2 magic bytes, method (8=deflate), header flags (no extra# fields added to header), mtime, xfl and os (255 for unknown OS).# Use zlib as it creates the header with 0 mtime by default.# This is faster and with less overhead.# Wbits=-15 creates a raw deflate block.# Use a zlib raw deflate compressor# Read all the data except the headerb'Functions that read and write gzipped files.

The user of the file doesn't have to worry about the compression,
but random access is not allowed.'u'Functions that read and write gzipped files.

The user of the file doesn't have to worry about the compression,
but random access is not allowed.'b'BadGzipFile'u'BadGzipFile'b'GzipFile'u'GzipFile'b'Open a gzip-compressed file in binary or text mode.

    The filename argument can be an actual filename (a str or bytes object), or
    an existing file object to read from or write to.

    The mode argument can be "r", "rb", "w", "wb", "x", "xb", "a" or "ab" for
    binary mode, or "rt", "wt", "xt" or "at" for text mode. The default mode is
    "rb", and the default compresslevel is 9.

    For binary mode, this function is equivalent to the GzipFile constructor:
    GzipFile(filename, mode, compresslevel). In this case, the encoding, errors
    and newline arguments must not be provided.

    For text mode, a GzipFile object is created, and wrapped in an
    io.TextIOWrapper instance with the specified encoding, error handling
    behavior, and line ending(s).

    'u'Open a gzip-compressed file in binary or text mode.

    The filename argument can be an actual filename (a str or bytes object), or
    an existing file object to read from or write to.

    The mode argument can be "r", "rb", "w", "wb", "x", "xb", "a" or "ab" for
    binary mode, or "rt", "wt", "xt" or "at" for text mode. The default mode is
    "rb", and the default compresslevel is 9.

    For binary mode, this function is equivalent to the GzipFile constructor:
    GzipFile(filename, mode, compresslevel). In this case, the encoding, errors
    and newline arguments must not be provided.

    For text mode, a GzipFile object is created, and wrapped in an
    io.TextIOWrapper instance with the specified encoding, error handling
    behavior, and line ending(s).

    'b'filename must be a str or bytes object, or a file'u'filename must be a str or bytes object, or a file'b'<L'u'<L'b'Minimal read-only file object that prepends a string to the contents
    of an actual file. Shouldn't be used outside of gzip.py, as it lacks
    essential functionality.'u'Minimal read-only file object that prepends a string to the contents
    of an actual file. Shouldn't be used outside of gzip.py, as it lacks
    essential functionality.'b'Exception raised in some cases for invalid gzip files.'u'Exception raised in some cases for invalid gzip files.'b'Minimal object to pass WriteBuffer flushes into GzipFile'u'Minimal object to pass WriteBuffer flushes into GzipFile'b'The GzipFile class simulates most of the methods of a file object with
    the exception of the truncate() method.

    This class only supports opening files in binary mode. If you need to open a
    compressed file in text mode, use the gzip.open() function.

    'u'The GzipFile class simulates most of the methods of a file object with
    the exception of the truncate() method.

    This class only supports opening files in binary mode. If you need to open a
    compressed file in text mode, use the gzip.open() function.

    'b'Constructor for the GzipFile class.

        At least one of fileobj and filename must be given a
        non-trivial value.

        The new class instance is based on fileobj, which can be a regular
        file, an io.BytesIO object, or any other object which simulates a file.
        It defaults to None, in which case filename is opened to provide
        a file object.

        When fileobj is not None, the filename argument is only used to be
        included in the gzip file header, which may include the original
        filename of the uncompressed file.  It defaults to the filename of
        fileobj, if discernible; otherwise, it defaults to the empty string,
        and in this case the original filename is not included in the header.

        The mode argument can be any of 'r', 'rb', 'a', 'ab', 'w', 'wb', 'x', or
        'xb' depending on whether the file will be read or written.  The default
        is the mode of fileobj if discernible; otherwise, the default is 'rb'.
        A mode of 'r' is equivalent to one of 'rb', and similarly for 'w' and
        'wb', 'a' and 'ab', and 'x' and 'xb'.

        The compresslevel argument is an integer from 0 to 9 controlling the
        level of compression; 1 is fastest and produces the least compression,
        and 9 is slowest and produces the most compression. 0 is no compression
        at all. The default is 9.

        The mtime argument is an optional numeric timestamp to be written
        to the last modification time field in the stream when compressing.
        If omitted or None, the current time is used.

        'u'Constructor for the GzipFile class.

        At least one of fileobj and filename must be given a
        non-trivial value.

        The new class instance is based on fileobj, which can be a regular
        file, an io.BytesIO object, or any other object which simulates a file.
        It defaults to None, in which case filename is opened to provide
        a file object.

        When fileobj is not None, the filename argument is only used to be
        included in the gzip file header, which may include the original
        filename of the uncompressed file.  It defaults to the filename of
        fileobj, if discernible; otherwise, it defaults to the empty string,
        and in this case the original filename is not included in the header.

        The mode argument can be any of 'r', 'rb', 'a', 'ab', 'w', 'wb', 'x', or
        'xb' depending on whether the file will be read or written.  The default
        is the mode of fileobj if discernible; otherwise, the default is 'rb'.
        A mode of 'r' is equivalent to one of 'rb', and similarly for 'w' and
        'wb', 'a' and 'ab', and 'x' and 'xb'.

        The compresslevel argument is an integer from 0 to 9 controlling the
        level of compression; 1 is fastest and produces the least compression,
        and 9 is slowest and produces the most compression. 0 is no compression
        at all. The default is 9.

        The mtime argument is an optional numeric timestamp to be written
        to the last modification time field in the stream when compressing.
        If omitted or None, the current time is used.

        'b'Invalid mode: {!r}'u'Invalid mode: {!r}'b'GzipFile was opened for writing, but this will change in future Python releases.  Specify the mode argument for opening it for writing.'u'GzipFile was opened for writing, but this will change in future Python releases.  Specify the mode argument for opening it for writing.'b'Last modification time read from stream, or None'u'Last modification time read from stream, or None'b'<gzip 'u'<gzip 'b''b'.gz'b''b''b'write() on read-only GzipFile object'u'write() on read-only GzipFile object'b'write() on closed GzipFile object'u'write() on closed GzipFile object'b'read() on write-only GzipFile object'u'read() on write-only GzipFile object'b'Implements BufferedIOBase.read1()

        Reads up to a buffer's worth of data if size is negative.'u'Implements BufferedIOBase.read1()

        Reads up to a buffer's worth of data if size is negative.'b'read1() on write-only GzipFile object'u'read1() on write-only GzipFile object'b'peek() on write-only GzipFile object'u'peek() on write-only GzipFile object'b'Invoke the underlying file object's fileno() method.

        This will raise AttributeError if the underlying file object
        doesn't support fileno().
        'u'Invoke the underlying file object's fileno() method.

        This will raise AttributeError if the underlying file object
        doesn't support fileno().
        'b'Return the uncompressed stream file position indicator to the
        beginning of the file'u'Return the uncompressed stream file position indicator to the
        beginning of the file'b'Can't rewind in write mode'u'Can't rewind in write mode'b'Seek from end not supported'u'Seek from end not supported'b'Negative seek in write mode'u'Negative seek in write mode'b'Read exactly *n* bytes from `fp`

    This method is required because fp may be unbuffered,
    i.e. return short reads.
    'u'Read exactly *n* bytes from `fp`

    This method is required because fp may be unbuffered,
    i.e. return short reads.
    'b'Read a gzip header from `fp` and progress to the end of the header.

    Returns last mtime if header was present or None otherwise.
    'u'Read a gzip header from `fp` and progress to the end of the header.

    Returns last mtime if header was present or None otherwise.
    'b'Not a gzipped file (%r)'u'Not a gzipped file (%r)'b'<BBIxx'u'<BBIxx'b'Unknown compression method'u'Unknown compression method'b'CRC check failed %s != %s'u'CRC check failed %s != %s'b'Incorrect length of data produced'u'Incorrect length of data produced'b'
    Write a simple gzip header with no extra fields.
    :param compresslevel: Compresslevel used to determine the xfl bytes.
    :param mtime: The mtime (must support conversion to a 32-bit integer).
    :return: A bytes object representing the gzip header.
    'u'
    Write a simple gzip header with no extra fields.
    :param compresslevel: Compresslevel used to determine the xfl bytes.
    :param mtime: The mtime (must support conversion to a 32-bit integer).
    :return: A bytes object representing the gzip header.
    'b'<BBBBLBB'u'<BBBBLBB'b'Compress data in one shot and return the compressed string.

    compresslevel sets the compression level in range of 0-9.
    mtime can be used to set the modification time. The modification time is
    set to the current time by default.
    'u'Compress data in one shot and return the compressed string.

    compresslevel sets the compression level in range of 0-9.
    mtime can be used to set the modification time. The modification time is
    set to the current time by default.
    'b'<LL'u'<LL'b'Decompress a gzip compressed string in one shot.
    Return the decompressed string.
    'u'Decompress a gzip compressed string in one shot.
    Return the decompressed string.
    'b'CRC check failed'u'CRC check failed'b'A simple command line interface for the gzip module: act like gzip, but do not delete the input file.'u'A simple command line interface for the gzip module: act like gzip, but do not delete the input file.'b'--fast'u'--fast'b'compress faster'u'compress faster'b'--best'u'--best'b'compress better'u'compress better'b'--decompress'u'--decompress'b'act like gunzip instead of gzip'u'act like gunzip instead of gzip'u'.gz'b'filename doesn't end in .gz: 'u'filename doesn't end in .gz: 'u'Lib.gzip'hashlib module - A common interface to many hash functions.

new(name, data=b'', **kwargs) - returns a new hash object implementing the
                                given hash function; initializing the hash
                                using the given binary data.

Named constructor functions are also available, these are faster
than using new(name):

md5(), sha1(), sha224(), sha256(), sha384(), sha512(), blake2b(), blake2s(),
sha3_224, sha3_256, sha3_384, sha3_512, shake_128, and shake_256.

More algorithms may be available on your platform but the above are guaranteed
to exist.  See the algorithms_guaranteed and algorithms_available attributes
to find out what algorithm names can be passed to new().

NOTE: If you want the adler32 or crc32 hash functions they are available in
the zlib module.

Choose your hash function wisely.  Some have known collision weaknesses.
sha384 and sha512 will be slow on 32 bit platforms.

Hash objects have these methods:
 - update(data): Update the hash object with the bytes in data. Repeated calls
                 are equivalent to a single call with the concatenation of all
                 the arguments.
 - digest():     Return the digest of the bytes passed to the update() method
                 so far as a bytes object.
 - hexdigest():  Like digest() except the digest is returned as a string
                 of double length, containing only hexadecimal digits.
 - copy():       Return a copy (clone) of the hash object. This can be used to
                 efficiently compute the digests of datas that share a common
                 initial substring.

For example, to obtain the digest of the byte string 'Nobody inspects the
spammish repetition':

    >>> import hashlib
    >>> m = hashlib.md5()
    >>> m.update(b"Nobody inspects")
    >>> m.update(b" the spammish repetition")
    >>> m.digest()
    b'\xbbd\x9c\x83\xdd\x1e\xa5\xc9\xd9\xde\xc9\xa1\x8d\xf0\xff\xe9'

More condensed:

    >>> hashlib.sha224(b"Nobody inspects the spammish repetition").hexdigest()
    'a4337bc45a8fc544c03f52dc550cd6e1e87021bc896588bd79e901e2'

__always_supportedalgorithms_guaranteedalgorithms_availablefile_digest__builtin_constructor_cache__block_openssl_constructor__get_builtin_constructorSHA1MD5SHA256SHA224SHA512SHA384unsupported hash type __get_openssl_constructor_hashlibopenssl_usedforsecurity__py_newnew(name, data=b'', **kwargs) - Return a new hashing object using the
    named algorithm; optionally initialized with data (which must be
    a bytes-like object).
    __hash_newnew(name, data=b'') - Return a new hashing object using the named algorithm;
    optionally initialized with data (which must be a bytes-like object).
    __get_hashopenssl_md_meth_namespbkdf2_hmacscryptHash the contents of a file-like object. Returns a digest object.

    *fileobj* must be a file-like object opened for reading in binary mode.
    It accepts file objects from open(), io.BytesIO(), and SocketIO objects.
    The function may bypass Python's I/O and use the file descriptor *fileno*
    directly.

    *digest* must either be a hash algorithm name as a *str*, a hash
    constructor, or a callable that returns a hash object.
    digestobj' is not a file-like object in binary reading mode.__func_namecode for hash %s was not found.#.  Copyright (C) 2005-2010   Gregory P. Smith (greg@krypto.org)#  Licensed to PSF under a Contributor Agreement.# This tuple and __get_builtin_constructor() must be modified if a new# always available algorithm is added.# Prefer our blake2 implementation# OpenSSL 1.1.0 comes with a limited implementation of blake2b/s. The OpenSSL# implementations neither support keyed blake2 (blake2 MAC) nor advanced# features like salt, personalization, or tree hashing. OpenSSL hash-only# variants are available as 'blake2b512' and 'blake2s256', though.# no extension module, this hash is unsupported.# Prefer our builtin blake2 implementation.# MD5, SHA1, and SHA2 are in all supported OpenSSL versions# SHA3/shake are available in OpenSSL 1.1.1+# Allow the C module to raise ValueError.  The function will be# defined but the hash not actually available.  Don't fall back to# builtin if the current security policy blocks a digest, bpo#40695.# Use the C function directly (very fast)# If the _hashlib module (OpenSSL) doesn't support the named# hash, try using our builtin implementations.# This allows for SHA224/256 and SHA384/512 support even though# the OpenSSL library prior to 0.9.8 doesn't provide them.# OpenSSL's PKCS5_PBKDF2_HMAC requires OpenSSL 1.0+ with HMAC and SHA# OpenSSL's scrypt requires OpenSSL 1.1+# On Linux we could use AF_ALG sockets and sendfile() to archive zero-copy# hashing with hardware acceleration.# io.BytesIO object, use zero-copy buffer# Only binary files implement readinto().# binary file, socket.SocketIO object# Note: socket I/O uses different syscalls than file I/O.# Reusable buffer to reduce allocations.# try them all, some may not work due to the OpenSSL# version not supporting that algorithm.# Cleanup locals()b'hashlib module - A common interface to many hash functions.

new(name, data=b'', **kwargs) - returns a new hash object implementing the
                                given hash function; initializing the hash
                                using the given binary data.

Named constructor functions are also available, these are faster
than using new(name):

md5(), sha1(), sha224(), sha256(), sha384(), sha512(), blake2b(), blake2s(),
sha3_224, sha3_256, sha3_384, sha3_512, shake_128, and shake_256.

More algorithms may be available on your platform but the above are guaranteed
to exist.  See the algorithms_guaranteed and algorithms_available attributes
to find out what algorithm names can be passed to new().

NOTE: If you want the adler32 or crc32 hash functions they are available in
the zlib module.

Choose your hash function wisely.  Some have known collision weaknesses.
sha384 and sha512 will be slow on 32 bit platforms.

Hash objects have these methods:
 - update(data): Update the hash object with the bytes in data. Repeated calls
                 are equivalent to a single call with the concatenation of all
                 the arguments.
 - digest():     Return the digest of the bytes passed to the update() method
                 so far as a bytes object.
 - hexdigest():  Like digest() except the digest is returned as a string
                 of double length, containing only hexadecimal digits.
 - copy():       Return a copy (clone) of the hash object. This can be used to
                 efficiently compute the digests of datas that share a common
                 initial substring.

For example, to obtain the digest of the byte string 'Nobody inspects the
spammish repetition':

    >>> import hashlib
    >>> m = hashlib.md5()
    >>> m.update(b"Nobody inspects")
    >>> m.update(b" the spammish repetition")
    >>> m.digest()
    b'\xbbd\x9c\x83\xdd\x1e\xa5\xc9\xd9\xde\xc9\xa1\x8d\xf0\xff\xe9'

More condensed:

    >>> hashlib.sha224(b"Nobody inspects the spammish repetition").hexdigest()
    'a4337bc45a8fc544c03f52dc550cd6e1e87021bc896588bd79e901e2'

'u'hashlib module - A common interface to many hash functions.

new(name, data=b'', **kwargs) - returns a new hash object implementing the
                                given hash function; initializing the hash
                                using the given binary data.

Named constructor functions are also available, these are faster
than using new(name):

md5(), sha1(), sha224(), sha256(), sha384(), sha512(), blake2b(), blake2s(),
sha3_224, sha3_256, sha3_384, sha3_512, shake_128, and shake_256.

More algorithms may be available on your platform but the above are guaranteed
to exist.  See the algorithms_guaranteed and algorithms_available attributes
to find out what algorithm names can be passed to new().

NOTE: If you want the adler32 or crc32 hash functions they are available in
the zlib module.

Choose your hash function wisely.  Some have known collision weaknesses.
sha384 and sha512 will be slow on 32 bit platforms.

Hash objects have these methods:
 - update(data): Update the hash object with the bytes in data. Repeated calls
                 are equivalent to a single call with the concatenation of all
                 the arguments.
 - digest():     Return the digest of the bytes passed to the update() method
                 so far as a bytes object.
 - hexdigest():  Like digest() except the digest is returned as a string
                 of double length, containing only hexadecimal digits.
 - copy():       Return a copy (clone) of the hash object. This can be used to
                 efficiently compute the digests of datas that share a common
                 initial substring.

For example, to obtain the digest of the byte string 'Nobody inspects the
spammish repetition':

    >>> import hashlib
    >>> m = hashlib.md5()
    >>> m.update(b"Nobody inspects")
    >>> m.update(b" the spammish repetition")
    >>> m.digest()
    b'\xbbd\x9c\x83\xdd\x1e\xa5\xc9\xd9\xde\xc9\xa1\x8d\xf0\xff\xe9'

More condensed:

    >>> hashlib.sha224(b"Nobody inspects the spammish repetition").hexdigest()
    'a4337bc45a8fc544c03f52dc550cd6e1e87021bc896588bd79e901e2'

'b'sha1'u'sha1'b'sha224'u'sha224'u'sha384'b'sha512'u'sha512'b'blake2b'u'blake2b'b'blake2s'u'blake2s'b'sha3_224'u'sha3_224'u'sha3_256'u'sha3_384'b'sha3_512'u'sha3_512'b'shake_128'u'shake_128'b'shake_256'u'shake_256'b'new'u'new'b'algorithms_guaranteed'u'algorithms_guaranteed'b'algorithms_available'u'algorithms_available'b'file_digest'u'file_digest'b'SHA1'u'SHA1'b'MD5'u'MD5'b'SHA256'u'SHA256'b'SHA224'u'SHA224'b'SHA512'u'SHA512'b'SHA384'u'SHA384'b'unsupported hash type 'u'unsupported hash type 'b'openssl_'u'openssl_'b'new(name, data=b'', **kwargs) - Return a new hashing object using the
    named algorithm; optionally initialized with data (which must be
    a bytes-like object).
    'u'new(name, data=b'', **kwargs) - Return a new hashing object using the
    named algorithm; optionally initialized with data (which must be
    a bytes-like object).
    'b'new(name, data=b'') - Return a new hashing object using the named algorithm;
    optionally initialized with data (which must be a bytes-like object).
    'u'new(name, data=b'') - Return a new hashing object using the named algorithm;
    optionally initialized with data (which must be a bytes-like object).
    'b'pbkdf2_hmac'u'pbkdf2_hmac'b'Hash the contents of a file-like object. Returns a digest object.

    *fileobj* must be a file-like object opened for reading in binary mode.
    It accepts file objects from open(), io.BytesIO(), and SocketIO objects.
    The function may bypass Python's I/O and use the file descriptor *fileno*
    directly.

    *digest* must either be a hash algorithm name as a *str*, a hash
    constructor, or a callable that returns a hash object.
    'u'Hash the contents of a file-like object. Returns a digest object.

    *fileobj* must be a file-like object opened for reading in binary mode.
    It accepts file objects from open(), io.BytesIO(), and SocketIO objects.
    The function may bypass Python's I/O and use the file descriptor *fileno*
    directly.

    *digest* must either be a hash algorithm name as a *str*, a hash
    constructor, or a callable that returns a hash object.
    'b'getbuffer'u'getbuffer'b'readinto'u'readinto'b'readable'u'readable'b'' is not a file-like object in binary reading mode.'u'' is not a file-like object in binary reading mode.'b'code for hash %s was not found.'u'code for hash %s was not found.'u'Lib.hashlib'u'hashlib'Header encoding and decoding functionality.decode_headermake_headeremail.errorsBSPACESPACE8MAXLINELENUSASCIIUTF8
  =\?                   # literal =?
  (?P<charset>[^?]*?)   # non-greedy up to the next ? is the charset
  \?                    # literal ?
  (?P<encoding>[qQbB])  # either a "q" or a "b", case insensitive
  \?                    # literal ?
  (?P<encoded>.*?)      # non-greedy up to the next ?= is the encoded string
  \?=                   # literal ?=
  ecre[\041-\176]+:$fcre\n[^ \t]+:_embedded_header_max_appendDecode a message header value without converting charset.

    Returns a list of (string, charset) pairs containing each of the decoded
    parts of the header.  Charset is None for non-encoded parts of the header,
    otherwise a lower-case string containing the name of the character set
    specified in the encoded string.

    header may be a string that may or may not contain RFC2047 encoded words,
    or it may be a Header object.

    An email.errors.HeaderParseError may be raised when certain decoding error
    occurs (e.g. a base64 decoding exception).
    _chunksunencodeddroplistdecoded_wordsencoded_stringheader_decodepaderrBase64 decoding errorUnexpected encoding: collapsedlast_wordlast_charsetdecoded_seqcontinuation_wsCreate a Header from a sequence of pairs as returned by decode_header()

    decode_header() takes a header value string and returns a sequence of
    pairs of the format (decoded_string, charset) where charset is the string
    name of the character set.

    This function takes one of those sequence of pairs and returns a Header
    instance.  Optional maxlinelen, header_name, and continuation_ws are as in
    the Header constructor.
    Create a MIME-compliant header that can contain many character sets.

        Optional s is the initial header value.  If None, the initial header
        value is not set.  You can later append to the header with .append()
        method calls.  s may be a byte string or a Unicode string, but see the
        .append() documentation for semantics.

        Optional charset serves two purposes: it has the same meaning as the
        charset argument to the .append() method.  It also sets the default
        character set for all subsequent .append() calls that omit the charset
        argument.  If charset is not provided in the constructor, the us-ascii
        charset is used both as s's initial charset and as the default for
        subsequent .append() calls.

        The maximum line length can be specified explicitly via maxlinelen. For
        splitting the first line to a shorter value (to account for the field
        header which isn't included in s, e.g. `Subject') pass in the name of
        the field in header_name.  The default maxlinelen is 78 as recommended
        by RFC 2822.

        continuation_ws must be RFC 2822 compliant folding whitespace (usually
        either a space or a hard tab) which will be prepended to continuation
        lines.

        errors is passed through to the .append() call.
        _continuation_ws_maxlinelen_headerlenReturn the string value of the header.uchunkslastcslastspacenextcsoriginal_bytes_nonctexthasspaceAppend a string to the MIME header.

        Optional charset, if given, should be a Charset instance or the name
        of a character set (which will be converted to a Charset instance).  A
        value of None (the default) means that the charset given in the
        constructor is used.

        s may be a byte string or a Unicode string.  If it is a byte string
        (i.e. isinstance(s, str) is false), then charset is the encoding of
        that byte string, and a UnicodeError will be raised if the string
        cannot be decoded with that charset.  If s is a Unicode string, then
        charset is a hint specifying the character set of the characters in
        the string.  In either case, when producing an RFC 2822 compliant
        header using RFC 2047 rules, the string will be encoded using the
        output codec of the charset.  If the string cannot be encoded to the
        output codec, a UnicodeError will be raised.

        Optional `errors' is passed as the errors argument to the decode
        call if s is a byte string.
        True if string s is not a ctext character of RFC822.
        ;, 	splitcharsEncode a message header into an RFC-compliant format.

        There are many issues involved in converting a given string for use in
        an email header.  Only certain character sets are readable in most
        email clients, and as header strings can only contain a subset of
        7-bit ASCII, care must be taken to properly convert and encode (with
        Base64 or quoted-printable) header strings.  In addition, there is a
        75-character length limit on any given encoded header field, so
        line-wrapping must be performed, even with double-byte character sets.

        Optional maxlinelen specifies the maximum length of each generated
        line, exclusive of the linesep string.  Individual lines may be longer
        than maxlinelen if a folding point cannot be found.  The first line
        will be shorter by the length of the header name plus ": " if a header
        name was specified at Header construction time.  The default value for
        maxlinelen is determined at header construction time.

        Optional splitchars is a string containing characters which should be
        given extra weight by the splitting algorithm during normal header
        wrapping.  This is in very rough support of RFC 2822's `higher level
        syntactic breaks':  split points preceded by a splitchar are preferred
        during line splitting, with the characters preferred in the order in
        which they appear in the string.  Space and tab may be included in the
        string to indicate whether preference should be given to one over the
        other as a split point when other split chars do not appear in the line
        being split.  Splitchars does not affect RFC 2047 encoded lines.

        Optional linesep is a string to be used to separate the lines of
        the value.  The default value is the most useful for typical
        Python applications, but it can be set to \r\n to produce RFC-compliant
        line separators when needed.
        _ValueFormatteradd_transitionslinefws_strheader value appears to contain an embedded header: {!r}"header value appears to contain ""an embedded header: {!r}"last_chunkheaderlen_maxlen_continuation_ws_len_splitchars_Accumulator_current_lineend_of_lineis_onlyws_ascii_split_maxlengthsencoded_lines_append_chunklast_line([]+)part_countprevpart_initial_sizepop_frominitial_sizepoppedstartval# Match encoded-word strings in the form =?charset?q?Hello_World?=# Field name regexp, including trailing colon, but not separating whitespace,# according to RFC 2822.  Character range is from tilde to exclamation mark.# For use with .match()# Find a header embedded in a putative header value.  Used to check for# header injection attack.# If it is a Header object, we can just return the encoded chunks.# If no encoding, just return the header with no charset.# First step is to parse all the encoded parts into triplets of the form# (encoded_string, encoding, charset).  For unencoded strings, the last# two parts will be None.# Now loop over words and remove words that consist of whitespace# between two encoded strings.# The next step is to decode each encoded word by applying the reverse# base64 or quopri transformation.  decoded_words is now a list of the# form (decoded_word, charset).# This is an unencoded word.# Postel's law: add missing padding# Now convert all words to bytes and collapse consecutive runs of# similarly encoded words.# None means us-ascii but we can simply pass it on to h.append()# Take the separating colon and space into account.# We must preserve spaces between encoded and non-encoded word# boundaries, which means for us we need to add a space when we go# from a charset to None/us-ascii, or from None/us-ascii to a# charset.  Only do this for the second and subsequent chunks.# Don't add a space if the None/us-ascii string already has# a space (trailing or leading depending on transition)# Rich comparison operators for equality only.  BAW: does it make sense to# have or explicitly disable <, <=, >, >= operators?# other may be a Header or a string.  Both are fine so coerce# ourselves to a unicode (of the unencoded header value), swap the# args and do another comparison.# Ensure that the bytes we're storing can be decoded to the output# character set, otherwise an early error is raised.# A maxlinelen of 0 means don't wrap.  For all practical purposes,# choosing a huge number here accomplishes that and makes the# _ValueFormatter algorithm much simpler.# Step 1: Normalize the chunks so that all runs of identical charsets# get collapsed into a single unicode string.# If the charset has no header encoding (i.e. it is an ASCII encoding)# then we must split the header at the "highest level syntactic break"# possible. Note that we don't have a lot of smarts about field# syntax; we just try to break on semi-colons, then commas, then# whitespace.  Eventually, this should be pluggable.# Otherwise, we're doing either a Base64 or a quoted-printable# encoding which means we don't need to split the line on syntactic# breaks.  We can basically just find enough characters to fit on the# current line, minus the RFC 2047 chrome.  What makes this trickier# though is that we have to split at octet boundaries, not character# boundaries but it's only safe to split at character boundaries so at# best we can only get close.# The first element extends the current line, but if it's None then# nothing more fit on the current line so start a new line.# There are no encoded lines, so we're done.# There was only one line.# Everything else are full lines in themselves.# The first line's length.# The RFC 2822 header folding algorithm is simple in principle but# complex in practice.  Lines may be folded any place where "folding# white space" appears by inserting a linesep character in front of the# FWS.  The complication is that not all spaces or tabs qualify as FWS,# and we are also supposed to prefer to break at "higher level# syntactic breaks".  We can't do either of these without intimate# knowledge of the structure of structured headers, which we don't have# here.  So the best we can do here is prefer to break at the specified# splitchars, and hope that we don't choose any spaces or tabs that# aren't legal FWS.  (This is at least better than the old algorithm,# where we would sometimes *introduce* FWS after a splitchar, or the# algorithm before that, where we would turn all white space runs into# single spaces or tabs.)# Find the best split point, working backward from the end.# There might be none, on a long first line.# There will be a header, so leave it on a line by itself.# We don't use continuation_ws here because the whitespace# after a header should always be a space.b'Header encoding and decoding functionality.'u'Header encoding and decoding functionality.'b'Header'u'Header'b'decode_header'u'decode_header'b'make_header'u'make_header'b'
  =\?                   # literal =?
  (?P<charset>[^?]*?)   # non-greedy up to the next ? is the charset
  \?                    # literal ?
  (?P<encoding>[qQbB])  # either a "q" or a "b", case insensitive
  \?                    # literal ?
  (?P<encoded>.*?)      # non-greedy up to the next ?= is the encoded string
  \?=                   # literal ?=
  'u'
  =\?                   # literal =?
  (?P<charset>[^?]*?)   # non-greedy up to the next ? is the charset
  \?                    # literal ?
  (?P<encoding>[qQbB])  # either a "q" or a "b", case insensitive
  \?                    # literal ?
  (?P<encoded>.*?)      # non-greedy up to the next ?= is the encoded string
  \?=                   # literal ?=
  'b'[\041-\176]+:$'u'[\041-\176]+:$'b'\n[^ \t]+:'u'\n[^ \t]+:'b'Decode a message header value without converting charset.

    Returns a list of (string, charset) pairs containing each of the decoded
    parts of the header.  Charset is None for non-encoded parts of the header,
    otherwise a lower-case string containing the name of the character set
    specified in the encoded string.

    header may be a string that may or may not contain RFC2047 encoded words,
    or it may be a Header object.

    An email.errors.HeaderParseError may be raised when certain decoding error
    occurs (e.g. a base64 decoding exception).
    'u'Decode a message header value without converting charset.

    Returns a list of (string, charset) pairs containing each of the decoded
    parts of the header.  Charset is None for non-encoded parts of the header,
    otherwise a lower-case string containing the name of the character set
    specified in the encoded string.

    header may be a string that may or may not contain RFC2047 encoded words,
    or it may be a Header object.

    An email.errors.HeaderParseError may be raised when certain decoding error
    occurs (e.g. a base64 decoding exception).
    'b'_chunks'u'_chunks'u'==='b'Base64 decoding error'u'Base64 decoding error'b'Unexpected encoding: 'u'Unexpected encoding: 'b'Create a Header from a sequence of pairs as returned by decode_header()

    decode_header() takes a header value string and returns a sequence of
    pairs of the format (decoded_string, charset) where charset is the string
    name of the character set.

    This function takes one of those sequence of pairs and returns a Header
    instance.  Optional maxlinelen, header_name, and continuation_ws are as in
    the Header constructor.
    'u'Create a Header from a sequence of pairs as returned by decode_header()

    decode_header() takes a header value string and returns a sequence of
    pairs of the format (decoded_string, charset) where charset is the string
    name of the character set.

    This function takes one of those sequence of pairs and returns a Header
    instance.  Optional maxlinelen, header_name, and continuation_ws are as in
    the Header constructor.
    'b'Create a MIME-compliant header that can contain many character sets.

        Optional s is the initial header value.  If None, the initial header
        value is not set.  You can later append to the header with .append()
        method calls.  s may be a byte string or a Unicode string, but see the
        .append() documentation for semantics.

        Optional charset serves two purposes: it has the same meaning as the
        charset argument to the .append() method.  It also sets the default
        character set for all subsequent .append() calls that omit the charset
        argument.  If charset is not provided in the constructor, the us-ascii
        charset is used both as s's initial charset and as the default for
        subsequent .append() calls.

        The maximum line length can be specified explicitly via maxlinelen. For
        splitting the first line to a shorter value (to account for the field
        header which isn't included in s, e.g. `Subject') pass in the name of
        the field in header_name.  The default maxlinelen is 78 as recommended
        by RFC 2822.

        continuation_ws must be RFC 2822 compliant folding whitespace (usually
        either a space or a hard tab) which will be prepended to continuation
        lines.

        errors is passed through to the .append() call.
        'u'Create a MIME-compliant header that can contain many character sets.

        Optional s is the initial header value.  If None, the initial header
        value is not set.  You can later append to the header with .append()
        method calls.  s may be a byte string or a Unicode string, but see the
        .append() documentation for semantics.

        Optional charset serves two purposes: it has the same meaning as the
        charset argument to the .append() method.  It also sets the default
        character set for all subsequent .append() calls that omit the charset
        argument.  If charset is not provided in the constructor, the us-ascii
        charset is used both as s's initial charset and as the default for
        subsequent .append() calls.

        The maximum line length can be specified explicitly via maxlinelen. For
        splitting the first line to a shorter value (to account for the field
        header which isn't included in s, e.g. `Subject') pass in the name of
        the field in header_name.  The default maxlinelen is 78 as recommended
        by RFC 2822.

        continuation_ws must be RFC 2822 compliant folding whitespace (usually
        either a space or a hard tab) which will be prepended to continuation
        lines.

        errors is passed through to the .append() call.
        'b'Return the string value of the header.'u'Return the string value of the header.'b'Append a string to the MIME header.

        Optional charset, if given, should be a Charset instance or the name
        of a character set (which will be converted to a Charset instance).  A
        value of None (the default) means that the charset given in the
        constructor is used.

        s may be a byte string or a Unicode string.  If it is a byte string
        (i.e. isinstance(s, str) is false), then charset is the encoding of
        that byte string, and a UnicodeError will be raised if the string
        cannot be decoded with that charset.  If s is a Unicode string, then
        charset is a hint specifying the character set of the characters in
        the string.  In either case, when producing an RFC 2822 compliant
        header using RFC 2047 rules, the string will be encoded using the
        output codec of the charset.  If the string cannot be encoded to the
        output codec, a UnicodeError will be raised.

        Optional `errors' is passed as the errors argument to the decode
        call if s is a byte string.
        'u'Append a string to the MIME header.

        Optional charset, if given, should be a Charset instance or the name
        of a character set (which will be converted to a Charset instance).  A
        value of None (the default) means that the charset given in the
        constructor is used.

        s may be a byte string or a Unicode string.  If it is a byte string
        (i.e. isinstance(s, str) is false), then charset is the encoding of
        that byte string, and a UnicodeError will be raised if the string
        cannot be decoded with that charset.  If s is a Unicode string, then
        charset is a hint specifying the character set of the characters in
        the string.  In either case, when producing an RFC 2822 compliant
        header using RFC 2047 rules, the string will be encoded using the
        output codec of the charset.  If the string cannot be encoded to the
        output codec, a UnicodeError will be raised.

        Optional `errors' is passed as the errors argument to the decode
        call if s is a byte string.
        'b'True if string s is not a ctext character of RFC822.
        'u'True if string s is not a ctext character of RFC822.
        'b';, 	'u';, 	'b'Encode a message header into an RFC-compliant format.

        There are many issues involved in converting a given string for use in
        an email header.  Only certain character sets are readable in most
        email clients, and as header strings can only contain a subset of
        7-bit ASCII, care must be taken to properly convert and encode (with
        Base64 or quoted-printable) header strings.  In addition, there is a
        75-character length limit on any given encoded header field, so
        line-wrapping must be performed, even with double-byte character sets.

        Optional maxlinelen specifies the maximum length of each generated
        line, exclusive of the linesep string.  Individual lines may be longer
        than maxlinelen if a folding point cannot be found.  The first line
        will be shorter by the length of the header name plus ": " if a header
        name was specified at Header construction time.  The default value for
        maxlinelen is determined at header construction time.

        Optional splitchars is a string containing characters which should be
        given extra weight by the splitting algorithm during normal header
        wrapping.  This is in very rough support of RFC 2822's `higher level
        syntactic breaks':  split points preceded by a splitchar are preferred
        during line splitting, with the characters preferred in the order in
        which they appear in the string.  Space and tab may be included in the
        string to indicate whether preference should be given to one over the
        other as a split point when other split chars do not appear in the line
        being split.  Splitchars does not affect RFC 2047 encoded lines.

        Optional linesep is a string to be used to separate the lines of
        the value.  The default value is the most useful for typical
        Python applications, but it can be set to \r\n to produce RFC-compliant
        line separators when needed.
        'u'Encode a message header into an RFC-compliant format.

        There are many issues involved in converting a given string for use in
        an email header.  Only certain character sets are readable in most
        email clients, and as header strings can only contain a subset of
        7-bit ASCII, care must be taken to properly convert and encode (with
        Base64 or quoted-printable) header strings.  In addition, there is a
        75-character length limit on any given encoded header field, so
        line-wrapping must be performed, even with double-byte character sets.

        Optional maxlinelen specifies the maximum length of each generated
        line, exclusive of the linesep string.  Individual lines may be longer
        than maxlinelen if a folding point cannot be found.  The first line
        will be shorter by the length of the header name plus ": " if a header
        name was specified at Header construction time.  The default value for
        maxlinelen is determined at header construction time.

        Optional splitchars is a string containing characters which should be
        given extra weight by the splitting algorithm during normal header
        wrapping.  This is in very rough support of RFC 2822's `higher level
        syntactic breaks':  split points preceded by a splitchar are preferred
        during line splitting, with the characters preferred in the order in
        which they appear in the string.  Space and tab may be included in the
        string to indicate whether preference should be given to one over the
        other as a split point when other split chars do not appear in the line
        being split.  Splitchars does not affect RFC 2047 encoded lines.

        Optional linesep is a string to be used to separate the lines of
        the value.  The default value is the most useful for typical
        Python applications, but it can be set to \r\n to produce RFC-compliant
        line separators when needed.
        'b'header value appears to contain an embedded header: {!r}'u'header value appears to contain an embedded header: {!r}'b'(['u'(['b']+)'u']+)'u'Lib.email.header'u'email.header'Heap queue algorithm (a.k.a. priority queue).

Heaps are arrays for which a[k] <= a[2*k+1] and a[k] <= a[2*k+2] for
all k, counting elements from 0.  For the sake of comparison,
non-existing elements are considered to be infinite.  The interesting
property of a heap is that a[0] is always its smallest element.

Usage:

heap = []            # creates an empty heap
heappush(heap, item) # pushes a new item on the heap
item = heappop(heap) # pops the smallest item from the heap
item = heap[0]       # smallest item on the heap without popping it
heapify(x)           # transforms list into a heap, in-place, in linear time
item = heappushpop(heap, item) # pushes a new item and then returns
                               # the smallest item; the heap size is unchanged
item = heapreplace(heap, item) # pops and returns smallest item, and adds
                               # new item; the heap size is unchanged

Our API differs from textbook heap algorithms as follows:

- We use 0-based indexing.  This makes the relationship between the
  index for a node and the indexes for its children slightly less
  obvious, but is more suitable since Python uses 0-based indexing.

- Our heappop() method returns the smallest item, not the largest.

These two make it possible to view the heap as a regular Python list
without surprises: heap[0] is the smallest item, and heap.sort()
maintains the heap invariant!
Heap queues

[explanation by Franois Pinard]

Heaps are arrays for which a[k] <= a[2*k+1] and a[k] <= a[2*k+2] for
all k, counting elements from 0.  For the sake of comparison,
non-existing elements are considered to be infinite.  The interesting
property of a heap is that a[0] is always its smallest element.

The strange invariant above is meant to be an efficient memory
representation for a tournament.  The numbers below are `k', not a[k]:

                                   0

                  1                                 2

          3               4                5               6

      7       8       9       10      11      12      13      14

    15 16   17 18   19 20   21 22   23 24   25 26   27 28   29 30


In the tree above, each cell `k' is topping `2*k+1' and `2*k+2'.  In
a usual binary tournament we see in sports, each cell is the winner
over the two cells it tops, and we can trace the winner down the tree
to see all opponents s/he had.  However, in many computer applications
of such tournaments, we do not need to trace the history of a winner.
To be more memory efficient, when a winner is promoted, we try to
replace it by something else at a lower level, and the rule becomes
that a cell and the two cells it tops contain three different items,
but the top cell "wins" over the two topped cells.

If this heap invariant is protected at all time, index 0 is clearly
the overall winner.  The simplest algorithmic way to remove it and
find the "next" winner is to move some loser (let's say cell 30 in the
diagram above) into the 0 position, and then percolate this new 0 down
the tree, exchanging values, until the invariant is re-established.
This is clearly logarithmic on the total number of items in the tree.
By iterating over all items, you get an O(n ln n) sort.

A nice feature of this sort is that you can efficiently insert new
items while the sort is going on, provided that the inserted items are
not "better" than the last 0'th element you extracted.  This is
especially useful in simulation contexts, where the tree holds all
incoming events, and the "win" condition means the smallest scheduled
time.  When an event schedule other events for execution, they are
scheduled into the future, so they can easily go into the heap.  So, a
heap is a good structure for implementing schedulers (this is what I
used for my MIDI sequencer :-).

Various structures for implementing schedulers have been extensively
studied, and heaps are good for this, as they are reasonably speedy,
the speed is almost constant, and the worst case is not much different
than the average case.  However, there are other representations which
are more efficient overall, yet the worst cases might be terrible.

Heaps are also very useful in big disk sorts.  You most probably all
know that a big sort implies producing "runs" (which are pre-sorted
sequences, which size is usually related to the amount of CPU memory),
followed by a merging passes for these runs, which merging is often
very cleverly organised[1].  It is very important that the initial
sort produces the longest runs possible.  Tournaments are a good way
to that.  If, using all the memory available to hold a tournament, you
replace and percolate items that happen to fit the current run, you'll
produce runs which are twice the size of the memory for random input,
and much better for input fuzzily ordered.

Moreover, if you output the 0'th item on disk and get an input which
may not fit in the current tournament (because the value "wins" over
the last output value), it cannot fit in the heap, so the size of the
heap decreases.  The freed memory could be cleverly reused immediately
for progressively building a second heap, which grows at exactly the
same rate the first heap is melting.  When the first heap completely
vanishes, you switch heaps and start a new run.  Clever and quite
effective!

In a word, heaps are useful memory structures to know.  I use them in
a few applications, and I think it is good to keep a `heap' module
around. :-)

--------------------
[1] The disk balancing algorithms which are current, nowadays, are
more annoying than clever, and this is a consequence of the seeking
capabilities of the disks.  On devices which cannot seek, like big
tape drives, the story was quite different, and one had to be very
clever to ensure (far in advance) that each tape movement will be the
most effective possible (that is, will best participate at
"progressing" the merge).  Some tapes were even able to read
backwards, and this was also used to avoid the rewinding time.
Believe me, real good tape sorts were quite spectacular to watch!
From all times, sorting has always been a Great Art! :-)
nsmallestheapPush item onto heap, maintaining the heap invariant._siftdownPop the smallest item off the heap, maintaining the heap invariant.lasteltreturnitem_siftupPop and return the current smallest value, and add the new item.

    This is more efficient than heappop() followed by heappush(), and can be
    more appropriate when using a fixed-size heap.  Note that the value
    returned may be larger than item!  That constrains reasonable uses of
    this routine unless written as part of a conditional replacement:

        if item > heap[0]:
            item = heapreplace(heap, item)
    Fast version of a heappush followed by a heappop.Transform list into a heap, in-place, in O(len(x)) time.Maxheap version of a heappop._siftup_maxMaxheap version of a heappop followed by a heappush.Transform list into a maxheap, in-place, in O(len(x)) time.newitemparentposchildposrightpos_siftdown_maxMaxheap variant of _siftdownMaxheap variant of _siftupMerge multiple sorted inputs into a single sorted output.

    Similar to sorted(itertools.chain(*iterables)) but returns a generator,
    does not pull the data into memory all at once, and assumes that each of
    the input streams is already sorted (smallest to largest).

    >>> list(merge([1,3,5,7], [0,2,4,8], [5,10,15,20], [], [25]))
    [0, 1, 2, 3, 4, 5, 5, 7, 8, 10, 15, 20, 25]

    If *key* is not None, applies a key function to each element to determine
    its sort order.

    >>> list(merge(['dog', 'horse'], ['cat', 'fish', 'kangaroo'], key=len))
    ['dog', 'cat', 'fish', 'horse', 'kangaroo']

    h_append_heapify_heappop_heapreplacedirectionkey_valueFind the n smallest elements in a dataset.

    Equivalent to:  sorted(iterable, key=key)[:n]
    top_order_elemFind the n largest elements in a dataset.

    Equivalent to:  sorted(iterable, key=key, reverse=True)[:n]
    # Original code by Kevin O'Connor, augmented by Tim Peters and Raymond Hettinger# raises appropriate IndexError if heap is empty# Transform bottom-up.  The largest index there's any point to looking at# is the largest with a child index in-range, so must have 2*i + 1 < n,# or i < (n-1)/2.  If n is even = 2*j, this is (2*j-1)/2 = j-1/2 so# j-1 is the largest, which is n//2 - 1.  If n is odd = 2*j+1, this is# (2*j+1-1)/2 = j so j-1 is the largest, and that's again n//2-1.# 'heap' is a heap at all indices >= startpos, except possibly for pos.  pos# is the index of a leaf with a possibly out-of-order value.  Restore the# heap invariant.# Follow the path to the root, moving parents down until finding a place# newitem fits.# The child indices of heap index pos are already heaps, and we want to make# a heap at index pos too.  We do this by bubbling the smaller child of# pos up (and so on with that child's children, etc) until hitting a leaf,# then using _siftdown to move the oddball originally at index pos into place.# We *could* break out of the loop as soon as we find a pos where newitem <=# both its children, but turns out that's not a good idea, and despite that# many books write the algorithm that way.  During a heap pop, the last array# element is sifted in, and that tends to be large, so that comparing it# against values starting from the root usually doesn't pay (= usually doesn't# get us out of the loop early).  See Knuth, Volume 3, where this is# explained and quantified in an exercise.# Cutting the # of comparisons is important, since these routines have no# way to extract "the priority" from an array element, so that intelligence# is likely to be hiding in custom comparison methods, or in array elements# storing (priority, record) tuples.  Comparisons are thus potentially# expensive.# On random arrays of length 1000, making this change cut the number of# comparisons made by heapify() a little, and those made by exhaustive# heappop() a lot, in accord with theory.  Here are typical results from 3# runs (3 just to demonstrate how small the variance is):# Compares needed by heapify     Compares needed by 1000 heappops# --------------------------     --------------------------------# 1837 cut to 1663               14996 cut to 8680# 1855 cut to 1659               14966 cut to 8678# 1847 cut to 1660               15024 cut to 8703# Building the heap by using heappush() 1000 times instead required# 2198, 2148, and 2219 compares:  heapify() is more efficient, when# you can use it.# The total compares needed by list.sort() on the same lists were 8627,# 8627, and 8632 (this should be compared to the sum of heapify() and# heappop() compares):  list.sort() is (unsurprisingly!) more efficient# for sorting.# Bubble up the smaller child until hitting a leaf.# leftmost child position# Set childpos to index of smaller child.# Move the smaller child up.# The leaf at pos is empty now.  Put newitem there, and bubble it up# to its final resting place (by sifting its parents down).# Bubble up the larger child until hitting a leaf.# Set childpos to index of larger child.# Move the larger child up.# raises StopIteration when exhausted# restore heap condition# remove empty iterator# fast case when only a single iterator remains# Algorithm notes for nlargest() and nsmallest()# ==============================================# Make a single pass over the data while keeping the k most extreme values# in a heap.  Memory consumption is limited to keeping k values in a list.# Measured performance for random inputs:#                                   number of comparisons#    n inputs     k-extreme values  (average of 5 trials)   % more than min()# -------------   ----------------  ---------------------   -----------------#      1,000           100                  3,317               231.7%#     10,000           100                 14,046                40.5%#    100,000           100                105,749                 5.7%#  1,000,000           100              1,007,751                 0.8%# 10,000,000           100             10,009,401                 0.1%# Theoretical number of comparisons for k smallest of n random inputs:# Step   Comparisons                  Action# ----   --------------------------   ---------------------------#  1     1.66 * k                     heapify the first k-inputs#  2     n - k                        compare remaining elements to top of heap#  3     k * (1 + lg2(k)) * ln(n/k)   replace the topmost value on the heap#  4     k * lg2(k) - (k/2)           final sort of the k most extreme values# Combining and simplifying for a rough estimate gives:#        comparisons = n + k * (log(k, 2) * log(n/k) + log(k, 2) + log(n/k))# Computing the number of comparisons for step 3:# -----------------------------------------------# * For the i-th new value from the iterable, the probability of being in the#   k most extreme values is k/i.  For example, the probability of the 101st#   value seen being in the 100 most extreme values is 100/101.# * If the value is a new extreme value, the cost of inserting it into the#   heap is 1 + log(k, 2).# * The probability times the cost gives:#            (k/i) * (1 + log(k, 2))# * Summing across the remaining n-k elements gives:#            sum((k/i) * (1 + log(k, 2)) for i in range(k+1, n+1))# * This reduces to:#            (H(n) - H(k)) * k * (1 + log(k, 2))# * Where H(n) is the n-th harmonic number estimated by:#            gamma = 0.5772156649#            H(n) = log(n, e) + gamma + 1 / (2 * n)#   http://en.wikipedia.org/wiki/Harmonic_series_(mathematics)#Rate_of_divergence# * Substituting the H(n) formula:#            comparisons = k * (1 + log(k, 2)) * (log(n/k, e) + (1/n - 1/k) / 2)# Worst-case for step 3:# ----------------------# In the worst case, the input data is reversed sorted so that every new element# must be inserted in the heap:#             comparisons = 1.66 * k + log(k, 2) * (n - k)# Alternative Algorithms# Other algorithms were not used because they:# 1) Took much more auxiliary memory,# 2) Made multiple passes over the data.# 3) Made more comparisons in common cases (small k, large n, semi-random input).# See the more detailed comparison of approach at:# http://code.activestate.com/recipes/577573-compare-algorithms-for-heapqsmallest# Short-cut for n==1 is to use min()# When n>=size, it's faster to use sorted()# When key is none, use simpler decoration# put the range(n) first so that zip() doesn't# consume one too many elements from the iterator# General case, slowest method# Short-cut for n==1 is to use max()# If available, use C implementationb'Heap queue algorithm (a.k.a. priority queue).

Heaps are arrays for which a[k] <= a[2*k+1] and a[k] <= a[2*k+2] for
all k, counting elements from 0.  For the sake of comparison,
non-existing elements are considered to be infinite.  The interesting
property of a heap is that a[0] is always its smallest element.

Usage:

heap = []            # creates an empty heap
heappush(heap, item) # pushes a new item on the heap
item = heappop(heap) # pops the smallest item from the heap
item = heap[0]       # smallest item on the heap without popping it
heapify(x)           # transforms list into a heap, in-place, in linear time
item = heappushpop(heap, item) # pushes a new item and then returns
                               # the smallest item; the heap size is unchanged
item = heapreplace(heap, item) # pops and returns smallest item, and adds
                               # new item; the heap size is unchanged

Our API differs from textbook heap algorithms as follows:

- We use 0-based indexing.  This makes the relationship between the
  index for a node and the indexes for its children slightly less
  obvious, but is more suitable since Python uses 0-based indexing.

- Our heappop() method returns the smallest item, not the largest.

These two make it possible to view the heap as a regular Python list
without surprises: heap[0] is the smallest item, and heap.sort()
maintains the heap invariant!
'u'Heap queue algorithm (a.k.a. priority queue).

Heaps are arrays for which a[k] <= a[2*k+1] and a[k] <= a[2*k+2] for
all k, counting elements from 0.  For the sake of comparison,
non-existing elements are considered to be infinite.  The interesting
property of a heap is that a[0] is always its smallest element.

Usage:

heap = []            # creates an empty heap
heappush(heap, item) # pushes a new item on the heap
item = heappop(heap) # pops the smallest item from the heap
item = heap[0]       # smallest item on the heap without popping it
heapify(x)           # transforms list into a heap, in-place, in linear time
item = heappushpop(heap, item) # pushes a new item and then returns
                               # the smallest item; the heap size is unchanged
item = heapreplace(heap, item) # pops and returns smallest item, and adds
                               # new item; the heap size is unchanged

Our API differs from textbook heap algorithms as follows:

- We use 0-based indexing.  This makes the relationship between the
  index for a node and the indexes for its children slightly less
  obvious, but is more suitable since Python uses 0-based indexing.

- Our heappop() method returns the smallest item, not the largest.

These two make it possible to view the heap as a regular Python list
without surprises: heap[0] is the smallest item, and heap.sort()
maintains the heap invariant!
'b'Heap queues

[explanation by Franois Pinard]

Heaps are arrays for which a[k] <= a[2*k+1] and a[k] <= a[2*k+2] for
all k, counting elements from 0.  For the sake of comparison,
non-existing elements are considered to be infinite.  The interesting
property of a heap is that a[0] is always its smallest element.

The strange invariant above is meant to be an efficient memory
representation for a tournament.  The numbers below are `k', not a[k]:

                                   0

                  1                                 2

          3               4                5               6

      7       8       9       10      11      12      13      14

    15 16   17 18   19 20   21 22   23 24   25 26   27 28   29 30


In the tree above, each cell `k' is topping `2*k+1' and `2*k+2'.  In
a usual binary tournament we see in sports, each cell is the winner
over the two cells it tops, and we can trace the winner down the tree
to see all opponents s/he had.  However, in many computer applications
of such tournaments, we do not need to trace the history of a winner.
To be more memory efficient, when a winner is promoted, we try to
replace it by something else at a lower level, and the rule becomes
that a cell and the two cells it tops contain three different items,
but the top cell "wins" over the two topped cells.

If this heap invariant is protected at all time, index 0 is clearly
the overall winner.  The simplest algorithmic way to remove it and
find the "next" winner is to move some loser (let's say cell 30 in the
diagram above) into the 0 position, and then percolate this new 0 down
the tree, exchanging values, until the invariant is re-established.
This is clearly logarithmic on the total number of items in the tree.
By iterating over all items, you get an O(n ln n) sort.

A nice feature of this sort is that you can efficiently insert new
items while the sort is going on, provided that the inserted items are
not "better" than the last 0'th element you extracted.  This is
especially useful in simulation contexts, where the tree holds all
incoming events, and the "win" condition means the smallest scheduled
time.  When an event schedule other events for execution, they are
scheduled into the future, so they can easily go into the heap.  So, a
heap is a good structure for implementing schedulers (this is what I
used for my MIDI sequencer :-).

Various structures for implementing schedulers have been extensively
studied, and heaps are good for this, as they are reasonably speedy,
the speed is almost constant, and the worst case is not much different
than the average case.  However, there are other representations which
are more efficient overall, yet the worst cases might be terrible.

Heaps are also very useful in big disk sorts.  You most probably all
know that a big sort implies producing "runs" (which are pre-sorted
sequences, which size is usually related to the amount of CPU memory),
followed by a merging passes for these runs, which merging is often
very cleverly organised[1].  It is very important that the initial
sort produces the longest runs possible.  Tournaments are a good way
to that.  If, using all the memory available to hold a tournament, you
replace and percolate items that happen to fit the current run, you'll
produce runs which are twice the size of the memory for random input,
and much better for input fuzzily ordered.

Moreover, if you output the 0'th item on disk and get an input which
may not fit in the current tournament (because the value "wins" over
the last output value), it cannot fit in the heap, so the size of the
heap decreases.  The freed memory could be cleverly reused immediately
for progressively building a second heap, which grows at exactly the
same rate the first heap is melting.  When the first heap completely
vanishes, you switch heaps and start a new run.  Clever and quite
effective!

In a word, heaps are useful memory structures to know.  I use them in
a few applications, and I think it is good to keep a `heap' module
around. :-)

--------------------
[1] The disk balancing algorithms which are current, nowadays, are
more annoying than clever, and this is a consequence of the seeking
capabilities of the disks.  On devices which cannot seek, like big
tape drives, the story was quite different, and one had to be very
clever to ensure (far in advance) that each tape movement will be the
most effective possible (that is, will best participate at
"progressing" the merge).  Some tapes were even able to read
backwards, and this was also used to avoid the rewinding time.
Believe me, real good tape sorts were quite spectacular to watch!
From all times, sorting has always been a Great Art! :-)
'b'heappush'u'heappush'b'heappop'u'heappop'b'heapify'u'heapify'b'heapreplace'u'heapreplace'b'merge'u'merge'b'nlargest'u'nlargest'b'nsmallest'u'nsmallest'b'heappushpop'u'heappushpop'b'Push item onto heap, maintaining the heap invariant.'u'Push item onto heap, maintaining the heap invariant.'b'Pop the smallest item off the heap, maintaining the heap invariant.'u'Pop the smallest item off the heap, maintaining the heap invariant.'b'Pop and return the current smallest value, and add the new item.

    This is more efficient than heappop() followed by heappush(), and can be
    more appropriate when using a fixed-size heap.  Note that the value
    returned may be larger than item!  That constrains reasonable uses of
    this routine unless written as part of a conditional replacement:

        if item > heap[0]:
            item = heapreplace(heap, item)
    'u'Pop and return the current smallest value, and add the new item.

    This is more efficient than heappop() followed by heappush(), and can be
    more appropriate when using a fixed-size heap.  Note that the value
    returned may be larger than item!  That constrains reasonable uses of
    this routine unless written as part of a conditional replacement:

        if item > heap[0]:
            item = heapreplace(heap, item)
    'b'Fast version of a heappush followed by a heappop.'u'Fast version of a heappush followed by a heappop.'b'Transform list into a heap, in-place, in O(len(x)) time.'u'Transform list into a heap, in-place, in O(len(x)) time.'b'Maxheap version of a heappop.'u'Maxheap version of a heappop.'b'Maxheap version of a heappop followed by a heappush.'u'Maxheap version of a heappop followed by a heappush.'b'Transform list into a maxheap, in-place, in O(len(x)) time.'u'Transform list into a maxheap, in-place, in O(len(x)) time.'b'Maxheap variant of _siftdown'u'Maxheap variant of _siftdown'b'Maxheap variant of _siftup'u'Maxheap variant of _siftup'b'Merge multiple sorted inputs into a single sorted output.

    Similar to sorted(itertools.chain(*iterables)) but returns a generator,
    does not pull the data into memory all at once, and assumes that each of
    the input streams is already sorted (smallest to largest).

    >>> list(merge([1,3,5,7], [0,2,4,8], [5,10,15,20], [], [25]))
    [0, 1, 2, 3, 4, 5, 5, 7, 8, 10, 15, 20, 25]

    If *key* is not None, applies a key function to each element to determine
    its sort order.

    >>> list(merge(['dog', 'horse'], ['cat', 'fish', 'kangaroo'], key=len))
    ['dog', 'cat', 'fish', 'horse', 'kangaroo']

    'u'Merge multiple sorted inputs into a single sorted output.

    Similar to sorted(itertools.chain(*iterables)) but returns a generator,
    does not pull the data into memory all at once, and assumes that each of
    the input streams is already sorted (smallest to largest).

    >>> list(merge([1,3,5,7], [0,2,4,8], [5,10,15,20], [], [25]))
    [0, 1, 2, 3, 4, 5, 5, 7, 8, 10, 15, 20, 25]

    If *key* is not None, applies a key function to each element to determine
    its sort order.

    >>> list(merge(['dog', 'horse'], ['cat', 'fish', 'kangaroo'], key=len))
    ['dog', 'cat', 'fish', 'horse', 'kangaroo']

    'b'Find the n smallest elements in a dataset.

    Equivalent to:  sorted(iterable, key=key)[:n]
    'u'Find the n smallest elements in a dataset.

    Equivalent to:  sorted(iterable, key=key)[:n]
    'b'Find the n largest elements in a dataset.

    Equivalent to:  sorted(iterable, key=key, reverse=True)[:n]
    'u'Find the n largest elements in a dataset.

    Equivalent to:  sorted(iterable, key=key, reverse=True)[:n]
    'u'Lib.heapq'u'heapq'HMAC (Keyed-Hashing for Message Authentication) module.

Implements the HMAC algorithm as described by RFC 2104.
_hashopensslopenssl_sha256_functypehashlib920x5Ctrans_5C540x36trans_36HMACRFC 2104 HMAC class.  Also complies with RFC 4231.

    This supports the API for Cryptographic Hash Functions (PEP 247).
    _hmac_inner_outerdigestmodCreate a new HMAC object.

        key: bytes or buffer, key for the keyed hash object.
        msg: bytes or buffer, Initial input for the hash or None.
        digestmod: A hash name suitable for hashlib.new(). *OR*
                   A hashlib constructor returning a new hash object. *OR*
                   A module supporting PEP 247.

                   Required as of 3.8, despite its position after the optional
                   msg argument.  Passing it as a keyword argument is
                   recommended, though not required for legacy API reasons.
        key: expected bytes or bytearray, but got %rMissing required argument 'digestmod'._init_hmacUnsupportedDigestmodError_init_oldhmac_newdigest_consblock_size of %d seems too small; using our default of %d.'block_size of %d seems too small; using our ''default of %d.'No block_size attribute on given digest object; Assuming %d.'No block_size attribute on given digest object; ''Assuming %d.'hmac-Feed data from msg into this hashing object.Return a separate copy of this hashing object.

        An update to this copy won't affect the original object.
        _currentReturn a hash object for the current state.

        To be used only internally with digest() and hexdigest().
        Return the hash value of this hashing object.

        This returns the hmac value as bytes.  The object is
        not altered in any way by this function; you can continue
        updating the object after calling this function.
        Like digest(), but returns a string of hexadecimal digits instead.
        Create a new hashing object and return it.

    key: bytes or buffer, The starting key for the hash.
    msg: bytes or buffer, Initial input for the hash, or None.
    digestmod: A hash name suitable for hashlib.new(). *OR*
               A hashlib constructor returning a new hash object. *OR*
               A module supporting PEP 247.

               Required as of 3.8, despite its position after the optional
               msg argument.  Passing it as a keyword argument is
               recommended, though not required for legacy API reasons.

    You can now feed arbitrary bytes into the object using its update()
    method, and can ask for the hash value at any time by calling its digest()
    or hexdigest() methods.
    Fast inline implementation of HMAC.

    key: bytes or buffer, The key for the keyed hash object.
    msg: bytes or buffer, Input message.
    digest: A hash name suitable for hashlib.new() for best performance. *OR*
            A hashlib constructor returning a new hash object. *OR*
            A module supporting PEP 247.
    hmac_digestouter# builtin type# The size of the digests returned by HMAC depends on the underlying# hashing module used.  Use digest_size from the instance of HMAC instead.# 512-bit HMAC; can be changed in subclasses.# self.blocksize is the default blocksize. self.block_size is# effective block size as well as the public API attribute.# Call __new__ directly to avoid the expensive __init__.b'HMAC (Keyed-Hashing for Message Authentication) module.

Implements the HMAC algorithm as described by RFC 2104.
'u'HMAC (Keyed-Hashing for Message Authentication) module.

Implements the HMAC algorithm as described by RFC 2104.
'b'RFC 2104 HMAC class.  Also complies with RFC 4231.

    This supports the API for Cryptographic Hash Functions (PEP 247).
    'u'RFC 2104 HMAC class.  Also complies with RFC 4231.

    This supports the API for Cryptographic Hash Functions (PEP 247).
    'b'_hmac'u'_hmac'b'_inner'u'_inner'b'_outer'u'_outer'b'block_size'u'block_size'b'digest_size'u'digest_size'b'Create a new HMAC object.

        key: bytes or buffer, key for the keyed hash object.
        msg: bytes or buffer, Initial input for the hash or None.
        digestmod: A hash name suitable for hashlib.new(). *OR*
                   A hashlib constructor returning a new hash object. *OR*
                   A module supporting PEP 247.

                   Required as of 3.8, despite its position after the optional
                   msg argument.  Passing it as a keyword argument is
                   recommended, though not required for legacy API reasons.
        'u'Create a new HMAC object.

        key: bytes or buffer, key for the keyed hash object.
        msg: bytes or buffer, Initial input for the hash or None.
        digestmod: A hash name suitable for hashlib.new(). *OR*
                   A hashlib constructor returning a new hash object. *OR*
                   A module supporting PEP 247.

                   Required as of 3.8, despite its position after the optional
                   msg argument.  Passing it as a keyword argument is
                   recommended, though not required for legacy API reasons.
        'b'key: expected bytes or bytearray, but got %r'u'key: expected bytes or bytearray, but got %r'b'Missing required argument 'digestmod'.'u'Missing required argument 'digestmod'.'b'block_size of %d seems too small; using our default of %d.'u'block_size of %d seems too small; using our default of %d.'b'No block_size attribute on given digest object; Assuming %d.'u'No block_size attribute on given digest object; Assuming %d.'b'hmac-'u'hmac-'b'Feed data from msg into this hashing object.'u'Feed data from msg into this hashing object.'b'Return a separate copy of this hashing object.

        An update to this copy won't affect the original object.
        'u'Return a separate copy of this hashing object.

        An update to this copy won't affect the original object.
        'b'Return a hash object for the current state.

        To be used only internally with digest() and hexdigest().
        'u'Return a hash object for the current state.

        To be used only internally with digest() and hexdigest().
        'b'Return the hash value of this hashing object.

        This returns the hmac value as bytes.  The object is
        not altered in any way by this function; you can continue
        updating the object after calling this function.
        'u'Return the hash value of this hashing object.

        This returns the hmac value as bytes.  The object is
        not altered in any way by this function; you can continue
        updating the object after calling this function.
        'b'Like digest(), but returns a string of hexadecimal digits instead.
        'u'Like digest(), but returns a string of hexadecimal digits instead.
        'b'Create a new hashing object and return it.

    key: bytes or buffer, The starting key for the hash.
    msg: bytes or buffer, Initial input for the hash, or None.
    digestmod: A hash name suitable for hashlib.new(). *OR*
               A hashlib constructor returning a new hash object. *OR*
               A module supporting PEP 247.

               Required as of 3.8, despite its position after the optional
               msg argument.  Passing it as a keyword argument is
               recommended, though not required for legacy API reasons.

    You can now feed arbitrary bytes into the object using its update()
    method, and can ask for the hash value at any time by calling its digest()
    or hexdigest() methods.
    'u'Create a new hashing object and return it.

    key: bytes or buffer, The starting key for the hash.
    msg: bytes or buffer, Initial input for the hash, or None.
    digestmod: A hash name suitable for hashlib.new(). *OR*
               A hashlib constructor returning a new hash object. *OR*
               A module supporting PEP 247.

               Required as of 3.8, despite its position after the optional
               msg argument.  Passing it as a keyword argument is
               recommended, though not required for legacy API reasons.

    You can now feed arbitrary bytes into the object using its update()
    method, and can ask for the hash value at any time by calling its digest()
    or hexdigest() methods.
    'b'Fast inline implementation of HMAC.

    key: bytes or buffer, The key for the keyed hash object.
    msg: bytes or buffer, Input message.
    digest: A hash name suitable for hashlib.new() for best performance. *OR*
            A hashlib constructor returning a new hash object. *OR*
            A module supporting PEP 247.
    'u'Fast inline implementation of HMAC.

    key: bytes or buffer, The key for the keyed hash object.
    msg: bytes or buffer, Input message.
    digest: A hash name suitable for hashlib.new() for best performance. *OR*
            A hashlib constructor returning a new hash object. *OR*
            A module supporting PEP 247.
    'u'Lib.hmac'u'hmac'Get useful information from live Python objects.

This module encapsulates the interface provided by the internal special
attributes (co_*, im_*, tb_*, etc.) in a friendlier fashion.
It also provides some help for examining source code and class layout.

Here are some of the useful functions provided by this module:

    ismodule(), isclass(), ismethod(), isfunction(), isgeneratorfunction(),
        isgenerator(), istraceback(), isframe(), iscode(), isbuiltin(),
        isroutine() - check object types
    getmembers() - get members of an object that satisfy a given condition

    getfile(), getsourcefile(), getsource() - find an object's source code
    getdoc(), getcomments() - get documentation on an object
    getmodule() - determine the module that an object came from
    getclasstree() - arrange classes so as to represent their hierarchy

    getargvalues(), getcallargs() - get info about function arguments
    getfullargspec() - same, with support for Python 3 features
    formatargvalues() - format an argument spec
    getouterframes(), getinnerframes() - get info about frames
    currentframe() - get the current stack frame
    stack(), trace() - get info about frames on the stack or in a traceback

    signature() - get a Signature object for the callable

    get_annotations() - safely compute an object's annotations
Ka-Ping Yee <ping@lfw.org>Yury Selivanov <yselivanov@sprymix.com>AGEN_CLOSEDAGEN_CREATEDAGEN_RUNNINGAGEN_SUSPENDEDArgInfoArgumentsBlockFinderBoundArgumentsBufferFlagsCORO_CLOSEDCORO_CREATEDCORO_RUNNINGCORO_SUSPENDEDCO_ITERABLE_COROUTINECO_NEWLOCALSCO_NOFREECO_OPTIMIZEDCO_VARARGSCO_VARKEYWORDSClassFoundExceptionClosureVarsEndOfBlockFrameInfoFullArgSpecGEN_CLOSEDGEN_CREATEDGEN_RUNNINGGEN_SUSPENDEDParameterSignatureTPFLAGS_IS_ABSTRACTTracebackclassify_class_attrsfindsourceformatannotationformatannotationrelativetoformatargvaluesgetabsfilegetargsgetargvaluesgetasyncgenlocalsgetasyncgenstategetattr_staticgetblockgetcallargsgetclasstreegetclosurevarsgetcommentsgetcoroutinelocalsgetcoroutinestategetdocgetframeinfogetfullargspecgetgeneratorlocalsgetgeneratorstategetinnerframesgetlinenogetmembersgetmembers_staticgetmodulenamegetmrogetouterframesgetsourcegetsourcelinesindentsizeisabstractisasyncgenisasyncgenfunctionisawaitableisbuiltinisdatadescriptorisgeneratorisgeneratorfunctionisgetsetdescriptorismemberdescriptormarkcoroutinefunctiontracewalktreeastimportlib.machinerytokenmake_weakrefmod_dictCO_eval_strCompute the annotations dict for an object.

    obj may be a callable, class, or module.
    Passing in an object of any other type raises TypeError.

    Returns a dict.  get_annotations() returns a new dict every time
    it's called; calling it twice on the same object will return two
    different but equivalent dicts.

    This function handles several details for you:

      * If eval_str is true, values of type str will
        be un-stringized using eval().  This is intended
        for use with stringized annotations
        ("from __future__ import annotations").
      * If obj doesn't have an annotations dict, returns an
        empty dict.  (Functions and methods always have an
        annotations dict; classes, modules, and other types of
        callables may not.)
      * Ignores inherited annotations on classes.  If a class
        doesn't have its own annotations dict, returns an empty dict.
      * All accesses to object members and dict values are done
        using getattr() and dict.get() for safety.
      * Always, always, always returns a freshly-created dict.

    eval_str controls whether or not values of type str are replaced
    with the result of calling eval() on those values:

      * If eval_str is true, eval() is called on values of type str.
      * If eval_str is false (the default), values of type str are unchanged.

    globals and locals are passed in to eval(); see the documentation
    for eval() for more information.  If either globals or locals is
    None, this function may replace that value with a context-specific
    default, contingent on type(obj):

      * If obj is a module, globals defaults to obj.__dict__.
      * If obj is a class, globals defaults to
        sys.modules[obj.__module__].__dict__ and locals
        defaults to the obj class namespace.
      * If obj is a callable, globals defaults to obj.__globals__,
        although if obj is a wrapped function (using
        functools.update_wrapper()) it is first unwrapped.
    obj_dictGetSetDescriptorTypeobj_globalsobj_locals is not a module, class, or callable..__annotations__ is neither a dict nor NoneReturn true if the object is a module.Return true if the object is a class.Return true if the object is an instance method.Return true if the object is a method descriptor.

    But not if ismethod() or isclass() or isfunction() are true.

    This is new in Python 2.2, and, for example, is true of int.__add__.
    An object passing this test has a __get__ attribute but not a __set__
    attribute, but beyond that the set of attributes varies.  __name__ is
    usually sensible, and __doc__ often is.

    Methods implemented via descriptors that also pass one of the other
    tests return false from the ismethoddescriptor() test, simply because
    the other tests promise more -- you can, e.g., count on having the
    __func__ attribute (etc) when an object passes ismethod().Return true if the object is a data descriptor.

    Data descriptors have a __set__ or a __delete__ attribute.  Examples are
    properties (defined in Python) and getsets and members (defined in C).
    Typically, data descriptors will also have __name__ and __doc__ attributes
    (properties, getsets, and members have both of these attributes), but this
    is not guaranteed.Return true if the object is a member descriptor.

        Member descriptors are specialized descriptors defined in extension
        modules.Return true if the object is a getset descriptor.

        getset descriptors are specialized descriptors defined in extension
        modules.Return true if the object is a user-defined function.

    Function objects provide these attributes:
        __doc__         documentation string
        __name__        name with which this function was defined
        __code__        code object containing compiled function bytecode
        __defaults__    tuple of any default values for arguments
        __globals__     global namespace in which this function was defined
        __annotations__ dict of parameter annotations
        __kwdefaults__  dict of keyword only parameters with defaults_has_code_flagReturn true if ``f`` is a function (or a method or functools.partial
    wrapper wrapping a function) whose code object has the given ``flag``
    set in its flags._signature_is_functionlikeReturn true if the object is a user-defined generator function.

    Generator function objects provide the same attributes as functions.
    See help(isfunction) for a list of attributes._is_coroutine_marker_has_coroutine_mark
    Decorator to ensure callable is recognised as a coroutine function.
    Return true if the object is a coroutine function.

    Coroutine functions are normally defined with "async def" syntax, but may
    be marked via markcoroutinefunction.
    Return true if the object is an asynchronous generator function.

    Asynchronous generator functions are defined with "async def"
    syntax and have "yield" expressions in their body.
    Return true if the object is an asynchronous generator.AsyncGeneratorTypeReturn true if the object is a generator.

    Generator objects provide these attributes:
        __iter__        defined to support iteration over container
        close           raises a new GeneratorExit exception inside the
                        generator to terminate the iteration
        gi_code         code object
        gi_frame        frame object or possibly None once the generator has
                        been exhausted
        gi_running      set to 1 when generator is executing, 0 otherwise
        next            return the next item from the container
        send            resumes the generator and "sends" a value that becomes
                        the result of the current yield-expression
        throw           used to raise an exception inside the generatorGeneratorTypeReturn true if the object is a coroutine.Return true if object can be passed to an ``await`` expression.Return true if the object is a traceback.

    Traceback objects provide these attributes:
        tb_frame        frame object at this level
        tb_lasti        index of last attempted instruction in bytecode
        tb_lineno       current line number in Python source code
        tb_next         next inner traceback object (called by this level)TracebackTypeReturn true if the object is a frame object.

    Frame objects provide these attributes:
        f_back          next outer frame object (this frame's caller)
        f_builtins      built-in namespace seen by this frame
        f_code          code object being executed in this frame
        f_globals       global namespace seen by this frame
        f_lasti         index of last attempted instruction in bytecode
        f_lineno        current line number in Python source code
        f_locals        local namespace seen by this frame
        f_trace         tracing function for this frame, or NoneFrameTypeReturn true if the object is a code object.

    Code objects provide these attributes:
        co_argcount         number of arguments (not including *, ** args
                            or keyword only arguments)
        co_code             string of raw compiled bytecode
        co_cellvars         tuple of names of cell variables
        co_consts           tuple of constants used in the bytecode
        co_filename         name of file in which this code object was created
        co_firstlineno      number of first line in Python source code
        co_flags            bitmap: 1=optimized | 2=newlocals | 4=*arg | 8=**arg
                            | 16=nested | 32=generator | 64=nofree | 128=coroutine
                            | 256=iterable_coroutine | 512=async_generator
        co_freevars         tuple of names of free variables
        co_posonlyargcount  number of positional only arguments
        co_kwonlyargcount   number of keyword only arguments (not including ** arg)
        co_lnotab           encoded mapping of line numbers to bytecode indices
        co_name             name with which this code object was defined
        co_names            tuple of names other than arguments and function locals
        co_nlocals          number of local variables
        co_stacksize        virtual machine stack space required
        co_varnames         tuple of names of arguments and local variablesReturn true if the object is a built-in function or method.

    Built-in functions and methods provide these attributes:
        __doc__         documentation string
        __name__        original name of this function or method
        __self__        instance to which a method is bound, or NoneReturn true if the object is a method wrapper.MethodWrapperTypeReturn true if the object is any kind of function or method.Return true if the object is an abstract base class (ABC)._getmemberspredicateprocessedReturn all members of an object as (name, value) pairs sorted by name.
    Optionally, only return members that satisfy a given predicate.Return all members of an object as (name, value) pairs sorted by name
    without triggering dynamic lookup via the descriptor protocol,
    __getattr__ or __getattribute__. Optionally, only return members that
    satisfy a given predicate.

    Note: this function may not be able to retrieve all members
       that getmembers can fetch (like dynamically created attributes)
       and may find members that getmembers can't (like descriptors
       that raise AttributeError). It can also return descriptor objects
       instead of instance members in some cases.
    name kind defining_class objectReturn list of attribute-descriptor tuples.

    For each name in dir(cls), the return list contains a 4-tuple
    with these elements:

        0. The name (a string).

        1. The kind of attribute this is, one of these strings:
               'class method'    created via classmethod()
               'static method'   created via staticmethod()
               'property'        created via property()
               'method'          any other flavor of method or descriptor
               'data'            not a method

        2. The class which defined this attribute (a class).

        3. The object as obtained by calling getattr; if this fails, or if the
           resulting object does not live anywhere in the class' mro (including
           metaclasses) then the object is looked up in the defining class's
           dict (found by walking the mro).

    If one of the items in dir(cls) is stored in the metaclass it will now
    be discovered and not have None be listed as the class in which it was
    defined.  Any items whose home class cannot be discovered are skipped.
    metamroclass_basesall_baseshomeclsget_objdict_obj__dict__ is special, don't want the proxylast_clssrch_clssrch_objBuiltinMethodTypestatic methodClassMethodDescriptorTypeclass methodReturn tuple of base classes (including cls) in method resolution order.Get the object wrapped by *func*.

   Follows the chain of :attr:`__wrapped__` attributes returning the last
   object in the chain.

   *stop* is an optional callback accepting an object in the wrapper chain
   as its sole argument that allows the unwrapping to be terminated early if
   the callback returns a true value. If the callback never returns a true
   value, the last object in the chain is returned as usual. For example,
   :func:`signature` uses this to stop unwrapping if any object in the
   chain has a ``__signature__`` attribute defined.

   :exc:`ValueError` is raised if a cycle is encountered.

    recursion_limitid_funcwrapper loop when unwrapping {!r}Return the indent size, in spaces, at the start of a line of text.expline_findclass_finddocGet the documentation string for an object.

    All tabs are expanded to spaces.  To clean up docstrings that are
    indented to line up with blocks of code, any whitespace than can be
    uniformly removed from the second line onwards is removed.Clean up indentation from docstrings.

    Any whitespace that can be uniformly removed from the second line
    onwards is removed.margincontentWork out which source or compiled file an object was defined in.{!r} is a built-in modulesource code not available{!r} is a built-in classmodule, class, method, function, traceback, frame, or code object was expected, got {}'module, class, method, function, traceback, frame, or ''code object was expected, got {}'Return the module name for a given file, or None.machineryall_suffixesneglenReturn the filename that can be used to locate an object's source.
    Return None if no way can be identified to get the source.
    all_bytecode_suffixes_filenameReturn an absolute path to the source or compiled file for an object.

    The idea is for each object to have a unique origin, so this routine
    normalizes the result as much as possible.modulesbyfile_filesbymodnameReturn the module an object was defined in, or None if not found.realpathmainobjectbuiltinbuiltinobject_ClassFinder<locals>line_numberReturn the entire source file and starting line number for an object.

    The argument may be a module, class, method, function, traceback, frame,
    or code object.  The source code is returned as a list of all the lines
    in the file and the line number indexes a line in that list.  An OSError
    is raised if the source code cannot be retrieved.could not get source codeclass_findercould not find class definitioncould not find function definitionlnum^(\s*def\s)|(\s*async\s+def\s)|(.*(?<!\w)lambda(:|\s))|^(\s*@)lineno is out of boundscould not find code objectGet lines of comments immediately preceding an object's source code.

    Returns None when source can't be found.
    #!commentsProvide a tokeneater() method to detect the end of a code block.islambdapasslineindecoratorbody_col0tokeneatersrowcolerowcolclassNEWLINEINDENTDEDENTCOMMENTExtract the block of code at the top of the given list of lines.blockfindergenerate_tokens_tokenunmatched_token_infoReturn a list of source lines and starting line number for an object.

    The argument may be a module, class, method, function, traceback, frame,
    or code object.  The source code is returned as a list of the lines
    corresponding to the object and the line number indicates where in the
    original source file the first line of code was found.  An OSError is
    raised if the source code cannot be retrieved.<module>Return the text of the source code for an object.

    The argument may be a module, class, method, function, traceback, frame,
    or code object.  The source code is returned as a single string.  An
    OSError is raised if the source code cannot be retrieved.classeschildrenRecursive helper function for getclasstree().Arrange the given list of classes into a hierarchy of nested lists.

    Where a nested list appears, it contains classes derived from the class
    whose entry immediately precedes the list.  Each entry is a 2-tuple
    containing a class and a tuple of its base classes.  If the 'unique'
    argument is true, exactly one entry appears in the returned structure
    for each class in the given list.  Otherwise, classes using multiple
    inheritance and their descendants will appear multiple times.args, varargs, varkwGet information about the arguments accepted by a code object.

    Three things are returned: (args, varargs, varkw), where
    'args' is the list of argument names. Keyword-only arguments are
    appended. 'varargs' and 'varkw' are the names of the * and **
    arguments or None.{!r} is not a code objectnkwargsvarargsvarkwargs, varargs, varkw, defaults, kwonlyargs, kwonlydefaults, annotationsGet the names and default values of a callable object's parameters.

    A tuple of seven things is returned:
    (args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults, annotations).
    'args' is a list of the parameter names.
    'varargs' and 'varkw' are the names of the * and ** parameters or None.
    'defaults' is an n-tuple of the default values of the last n parameters.
    'kwonlyargs' is a list of keyword-only parameter names.
    'kwonlydefaults' is a dictionary mapping names from kwonlyargs to defaults.
    'annotations' is a dictionary mapping parameter names to annotations.

    Notable differences from inspect.signature():
      - the "self" parameter is always reported, even for bound methods
      - wrapper chains defined by __wrapped__ *not* unwrapped automatically
    _signature_from_callablefollow_wrapper_chainsskip_bound_argsigclsunsupported callableparamparameters_POSITIONAL_ONLY_POSITIONAL_OR_KEYWORD_VAR_POSITIONAL_KEYWORD_ONLY_VAR_KEYWORDargs varargs keywords localsGet information about arguments passed into a particular frame.

    A tuple of four things is returned: (args, varargs, varkw, locals).
    'args' is a list of the argument names.
    'varargs' and 'varkw' are the names of the * and ** arguments or None.
    'locals' is the locals dictionary of the given frame.base_moduletyping.[\w\.]+_formatannotationformatargformatvarargsformatvarkwformatvalueFormat an argument spec from the 4 values returned by getargvalues.

    The first four arguments are (args, varargs, varkw, locals).  The
    next four arguments are the corresponding optional formatting functions
    that are called to turn names and values into strings.  The ninth
    argument is an optional function to format the sequence of arguments.convert_missing_argumentsf_nameargnames{} and {}, {} and {}%s() missing %i required %s argument%s: %spositionalkeyword-only_too_manykwonlydefcountgivenatleastkwonly_givenat least %dfrom %d to %dkwonly_sig positional argument%s (and %d keyword-only argument%s)%s() takes %s positional argument%s but %d%s %s givenwaswereGet the mapping of arguments to values.

    A dict is returned, with keys the function argument names (including the
    names of the * and ** arguments, if any), and values the respective bound
    values from 'positional' and 'named'.kwonlydefaultsarg2valuenum_posnum_argsnum_defaultspossible_kwargs%s() got an unexpected keyword argument %r%s() got multiple values for argument %rreqnonlocals globals builtins unbound
    Get the mapping of free variables to their current values.

    Returns a named tuple of dicts mapping the current nonlocal, global
    and builtin references as seen by the body of the function. A final
    set of unbound names that could not be resolved is also provided.
    {!r} is not a Python functionnonlocal_varscellcell_contentsglobal_nsbuiltin_nsglobal_varsbuiltin_varsunbound_names_Tracebackfilename lineno function code_context indexcode_contextTraceback(filename={!r}, lineno={!r}, function={!r}, code_context={!r}, index={!r}, positions={!r})'Traceback(filename={!r}, lineno={!r}, function={!r}, ''code_context={!r}, index={!r}, positions={!r})'_get_code_position_from_tbinstruction_index_get_code_positionpositions_genGet information about a frame or traceback object.

    A tuple of five things is returned: the filename, the line number of
    the current line, the function name, a list of lines of context from
    the source code, and the index of the current line within that list.
    The optional second argument specifies the number of lines of context
    to return, which are centered around the current line.f_lasti{!r} is not a frame or traceback objectGet the line number from a frame object, allowing for optimization._FrameInfoFrameInfo(frame={!r}, filename={!r}, lineno={!r}, function={!r}, code_context={!r}, index={!r}, positions={!r})'FrameInfo(frame={!r}, filename={!r}, lineno={!r}, function={!r}, 'Get a list of records for a frame and all higher (calling) frames.

    Each record contains a frame object, filename, line number, function
    name, a list of lines of context, and index within the context.framelisttraceback_infoframeinfoGet a list of records for a traceback's frame and all lower frames.

    Each record contains a frame object, filename, line number, function
    name, a list of lines of context, and index within the context.Return the frame of the caller or None if this is not possible.Return a list of records for the stack above the caller's frame.Return a list of records for the stack below the current exception._sentinel_static_getmro_get_dunder_dict_of_class_check_instanceinstance_dict_check_class_shadowed_dict_shadowed_dict_from_weakref_mro_tupleweakref_mroweakref_entrydunder_dictclass_dictRetrieve attributes without triggering dynamic lookup via the
       descriptor protocol,  __getattr__ or __getattribute__.

       Note: this function may not be able to retrieve all attributes
       that getattr can fetch (like dynamically created attributes)
       and may find attributes that getattr can't (like descriptors
       that raise AttributeError). It can also return descriptor objects
       instead of instance members in some cases. See the
       documentation for details.
    instance_resultobjtypedict_attrklass_resultGet current state of a generator-iterator.

    Possible states are:
      GEN_CREATED: Waiting to start execution.
      GEN_RUNNING: Currently being executed by the interpreter.
      GEN_SUSPENDED: Currently suspended at a yield expression.
      GEN_CLOSED: Execution has completed.
    
    Get the mapping of generator local variables to their current values.

    A dict is returned, with the keys the local variable names and values the
    bound values.{!r} is not a Python generatorGet current state of a coroutine object.

    Possible states are:
      CORO_CREATED: Waiting to start execution.
      CORO_RUNNING: Currently being executed by the interpreter.
      CORO_SUSPENDED: Currently suspended at an await expression.
      CORO_CLOSED: Execution has completed.
    cr_suspended
    Get the mapping of coroutine local variables to their current values.

    A dict is returned, with the keys the local variable names and values the
    bound values.Get current state of an asynchronous generator object.

    Possible states are:
      AGEN_CREATED: Waiting to start execution.
      AGEN_RUNNING: Currently being executed by the interpreter.
      AGEN_SUSPENDED: Currently suspended at a yield expression.
      AGEN_CLOSED: Execution has completed.
    ag_runningag_suspended
    Get the mapping of asynchronous generator local variables to their current
    values.

    A dict is returned, with the keys the local variable names and values the
    bound values. is not a Python async generatorWrapperDescriptorType_NonUserDefinedCallables_signature_get_user_defined_methodmethod_namePrivate helper. Checks if ``cls`` has an attribute
    named ``method_name`` and returns it only if it is a
    pure python function.
    meth_descriptor_get_signature_get_partialwrapped_sigPrivate helper to calculate how 'wrapped_sig' signature will
    look like after applying a 'functools.partial' object (or alike)
    on it.
    old_paramsnew_paramspartial_argspartial_keywordsbind_partialbapartial object {!r} has incorrect argumentstransform_to_kwonlyparam_namearg_valuenew_param_signature_bound_methodPrivate helper to transform signatures for unbound
    functions to bound methods.
    invalid method signatureinvalid argument type_signature_is_builtinPrivate helper to test if `obj` is a callable that might
    support Argument Clinic's __text_signature__ protocol.
    Private helper to test if `obj` is a duck type of FunctionType.
    A good example of such objects are functions compiled with
    Cython, which have all attributes that a pure Python function
    would have, but have their code statically compiled.
    _void_signature_strip_non_python_syntax
    Private helper function. Takes a signature in Argument Clinic's
    extended signature format.

    Returns a tuple of two things:
      * that signature re-rendered in standard Python syntax, and
      * the index of the "self" parameter (generally 0), or None if
        the function does not have a "self" parameter.
    self_parametertoken_streamcurrent_parameterOPERRORTOKENENCODINGclean_signature_signature_fromstrPrivate helper to parse content of '__text_signature__'
    and return a Signature based on it.
    _parameter_clsdef foo: pass{!r} builtin has invalid signaturemodule_dictsys_module_dictparse_nameAnnotations are not currently supportedwrap_valueRewriteSymbolicsname_nodedefault_node_emptytotal_non_kw_argsrequired_non_kw_argsPOSITIONAL_ONLYPOSITIONAL_OR_KEYWORDVAR_POSITIONALKEYWORD_ONLYVAR_KEYWORD_selfself_isboundself_ismodule_signature_from_builtinPrivate helper function to get signature for
    builtin callables.
    {!r} is not a Python builtin function"{!r} is not a Python builtin ""function"no signature found for builtin {!r}_signature_from_functionPrivate helper: constructs Signature for the given python function.is_duck_functionfunc_codepos_countarg_namesposonly_countkeyword_only_countkeyword_onlypos_default_countnon_default_countposonly_left__validate_parameters__descriptorPrivate helper function to get signature for arbitrary
    callable objects.
    _get_signature_of{!r} is not a callable objecto_sigunexpected object {!r} in __signature__ attribute'unexpected object {!r} in __signature__ ''attribute'first_wrapped_paramsig_paramsfrom_callableno signature found for builtin type {!r}callable {!r} is not supported by signatureA private marker - used in Parameter & Signature.Marker object for Signature.empty and Parameter.empty._ParameterKindpositional-onlypositional or keywordvariadic positionalvariadic keywordRepresents a parameter in a function signature.

    Has the following public attributes:

    * name : str
        The name of the parameter as a string.
    * default : object
        The default value for the parameter if specified.  If the
        parameter has no default value, this attribute is set to
        `Parameter.empty`.
    * annotation
        The annotation for the parameter if specified.  If the
        parameter has no annotation, this attribute is set to
        `Parameter.empty`.
    * kind : str
        Describes how argument values are bound to the parameter.
        Possible values: `Parameter.POSITIONAL_ONLY`,
        `Parameter.POSITIONAL_OR_KEYWORD`, `Parameter.VAR_POSITIONAL`,
        `Parameter.KEYWORD_ONLY`, `Parameter.VAR_KEYWORD`.
    _kind_default_annotationvalue  is not a valid Parameter.kind{} parameters cannot have default valuesname is a required attribute for Parametername must be a str, not a {}implicit arguments must be passed as positional or keyword arguments, not {}'implicit arguments must be passed as ''positional or keyword arguments, not {}'implicit{}is_keyword{!r} is not a valid parameter nameCreates a customized copy of the Parameter.formatted{}: {}{} = {}{}={}<{} "{}">Result of `Signature.bind` call.  Holds the mapping of arguments
    to the function's parameters.

    Has the following public attributes:

    * arguments : dict
        An ordered mutable mapping of parameters' names to arguments' values.
        Does not contain arguments' default values.
    * signature : Signature
        The Signature object that created this instance.
    * args : tuple
        Tuple of positional arguments values.
    * kwargs : dict
        Dict of keyword arguments values.
    _signaturekwargs_startedapply_defaultsSet default values for missing arguments.

        For variable-positional arguments (*args) the default is an
        empty tuple.

        For variable-keyword arguments (**kwargs) the default is an
        empty dict.
        new_arguments<{} ({})>A Signature object represents the overall signature of a function.
    It stores a Parameter object for each parameter accepted by the
    function, as well as information specific to the function itself.

    A Signature object has the following public attributes and methods:

    * parameters : OrderedDict
        An ordered mapping of parameters' names to the corresponding
        Parameter objects (keyword-only arguments are in the same order
        as listed in `code.co_varnames`).
    * return_annotation : object
        The annotation for the return type of the function if specified.
        If the function has no annotation for its return type, this
        attribute is set to `Signature.empty`.
    * bind(*args, **kwargs) -> BoundArguments
        Creates a mapping from positional and keyword arguments to
        parameters.
    * bind_partial(*args, **kwargs) -> BoundArguments
        Creates a partial mapping from positional and keyword arguments
        to parameters (simulating 'functools.partial' behavior.)
    _return_annotation_parameters_bound_arguments_clsConstructs Signature from the given list of Parameter
        objects and 'return_annotation'.  All arguments are optional.
        top_kindwrong parameter order: {} parameter before {} parameter'wrong parameter order: {} parameter before {} ''parameter'non-default argument follows default argument'non-default argument follows default ''argument'duplicate parameter name: {!r}follow_wrappedConstructs Signature for the given callable object.Creates a customized copy of the Signature.
        Pass 'parameters' and/or 'return_annotation' arguments
        to override them in the new copy.
        _hash_basiskwo_params_bindPrivate method. Don't use directly.parameters_exarg_valspos_only_param_in_kwargsarg_valtoo many positional argumentsmultiple values for argument {arg!r} keyword-onlyargtypemissing a required{argtype} argument: {arg!r}kwargs_parammissing a required argument: {arg!r}got some positional-only arguments passed as keyword arguments: {arg!r}'got some positional-only arguments passed as ''keyword arguments: {arg!r}'got an unexpected keyword argument {arg!r}Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        Get a BoundArguments object, that partially maps the
        passed `args` and `kwargs` to the function's signature.
        Raises `TypeError` if the passed arguments can not be bound.
        <{} {}>render_pos_only_separatorrender_kw_only_separatorrenderedanno -> {}Get a signature object for the passed callable.0x0SIMPLEWRITABLEFORMATNDSTRIDES0x20C_CONTIGUOUS0x40F_CONTIGUOUSANY_CONTIGUOUS0x100INDIRECTCONTIGCONTIG_ROSTRIDEDSTRIDED_RORECORDSRECORDS_ROFULLFULL_RO Logic for inspecting an object given at command line The object to be analysed. It supports the 'module:qualname' syntax"The object to be analysed. ""It supports the 'module:qualname' syntax"--detailsDisplay info about the module rather than its source codemod_namehas_attrsFailed to import {} ({}: {})Can't get info for builtin modules.detailsTarget: {}Origin: {}Cached: {}Loader: {}Submodule search path: {}Line: {}# This module is in the public domain.  No warranties.# Create constants for the compiler flags in Include/code.h# We try to get them from dis to avoid duplication# See Include/object.h# class# module# this includes types.Function, types.BuiltinFunctionType,# types.BuiltinMethodType, functools.partial, functools.singledispatch,# "class funclike" from Lib/test/test_inspect... on and on it goes.# ----------------------------------------------------------- type-checking# mutual exclusion# CPython and equivalent# Other implementations# A marker for markcoroutinefunction and iscoroutinefunction.# It looks like ABCMeta.__new__ has finished running;# TPFLAGS_IS_ABSTRACT should have been accurate.# It looks like ABCMeta.__new__ has not finished running yet; we're# probably in __init_subclass__. We'll look for abstractmethods manually.# add any DynamicClassAttributes to the list of names if object is a class;# this may result in duplicate entries if, for example, a virtual# attribute with the same name as a DynamicClassAttribute exists# First try to get the value via getattr.  Some descriptors don't# like calling their __get__ (see bug #1785), so fall back to# looking in the __dict__.# handle the duplicate key# could be a (currently) missing slot member, or a buggy# __dir__; discard and move on# for attributes stored in the metaclass# :dd any DynamicClassAttributes to the list of names;# attribute with the same name as a DynamicClassAttribute exists.# Get the object associated with the name, and where it was defined.# Normal objects will be looked up with both getattr and directly in# its class' dict (in case getattr fails [bug #1785], and also to look# for a docstring).# For DynamicClassAttributes on the second pass we only look in the# class's dict.# Getting an obj from the __dict__ sometimes reveals more than# using getattr.  Static and class methods are dramatic examples.# if the resulting object does not live somewhere in the# mro, drop it and search the mro manually# first look in the classes# then check the metaclasses# unable to locate the attribute anywhere, most likely due to# buggy custom __dir__; discard and move on# Classify the object or its descriptor.# ----------------------------------------------------------- class helpers# -------------------------------------------------------- function helpers# remember the original func for error reporting# Memoise by id to tolerate non-hashable objects, but store objects to# ensure they aren't destroyed, which would allow their IDs to be reused.# -------------------------------------------------- source code extraction# classmethod# Should be tested before isdatadescriptor().# Find minimum indentation of any non-blank lines after first line.# Remove indentation.# Remove any trailing or leading blank lines.# Check for paths that look like an actual module file# try longest suffixes first, in case they overlap# return a filename found in the linecache even if it doesn't exist on disk# only return a non-existent filename if the module has a PEP 302 loader# Try the filename to modulename cache# Try the cache again with the absolute file name# Update the filename to module name cache and check yet again# Copy sys.modules in order to cope with changes while iterating# Have already mapped this module, so skip it# Always map to the name the module knows itself by# Check the main module# Check builtins# Return the decorator for the class if present# decrement by one since lines starts with indexing by zero# Invalidate cache if needed.# Allow filenames in form of "<something>" to pass through.# `doctest` monkeypatches `linecache` module to enable# inspection, so let `linecache.getlines` to be called.# Look for a comment block at the top of the file.# Look for a preceding block of comments at the same indentation.# skip any decorators# look for the first "def", "class" or "lambda"# skip to the end of the line# stop skipping when a NEWLINE is seen# lambdas always end at the first NEWLINE# hitting a NEWLINE when in a decorator without args# ends the decorator# the end of matching indent/dedent pairs end a block# (note that this only works for "def"/"class" blocks,#  not e.g. for "if: else:" or "try: finally:" blocks)# Include comments if indented at least as much as the block# any other token on the same indentation level end the previous# block as well, except the pseudo-tokens COMMENT and NL.# for module or frame that corresponds to module, return all source lines# --------------------------------------------------- class tree extraction# ------------------------------------------------ argument list extraction# Re: `skip_bound_arg=False`# There is a notable difference in behaviour between getfullargspec# and Signature: the former always returns 'self' parameter for bound# methods, whereas the Signature always shows the actual calling# signature of the passed object.# To simulate this behaviour, we "unbind" bound methods, to trick# inspect.signature to always return their first parameter ("self",# usually)# Re: `follow_wrapper_chains=False`# getfullargspec() historically ignored __wrapped__ attributes,# so we ensure that remains the case in 3.3+# Most of the times 'signature' will raise ValueError.# But, it can also raise AttributeError, and, maybe something# else. So to be fully backwards compatible, we catch all# possible exceptions here, and reraise a TypeError.# compatibility with 'func.__kwdefaults__'# compatibility with 'func.__defaults__'# implicit 'self' (or 'cls' for classmethods) argument# Nonlocal references are named in co_freevars and resolved# by looking them up in __closure__ by positional index# Global and builtin references are named in co_names and resolved# by looking them up in __globals__ or __builtins__# Because these used to be builtins instead of keywords, they# may still show up as name references. We ignore them.# -------------------------------------------------- stack frame extraction# The nth entry in code.co_positions() corresponds to instruction (2*n)th since Python 3.10+# FrameType.f_lineno is now a descriptor that grovels co_lnotab# ------------------------------------------------ static version of getattr# Normally we'd have to check whether the result of weakref_entry()# is None here, in case the object the weakref is pointing to has died.# In this specific case, however, we know that the only caller of this# function is `_shadowed_dict()`, and that therefore this weakref is# guaranteed to point to an object that is still alive.# gh-118013: the inner function here is decorated with lru_cache for# performance reasons, *but* make sure not to pass strong references# to the items in the mro. Doing so can lead to unexpected memory# consumption in cases where classes are dynamically created and# destroyed, and the dynamically created classes happen to be the only# objects that hold strong references to other objects that take up a# significant amount of memory.# for types we check the metaclass too# ------------------------------------------------ generator introspection# ------------------------------------------------ coroutine introspection# ----------------------------------- asynchronous generator introspection################################################################################## Function Signature Object (PEP 362)# Once '__signature__' will be added to 'C'-level# callables, this check won't be necessary# If positional-only parameter is bound by partial,# it effectively disappears from the signature# This means that this parameter, and all parameters# after it should be keyword-only (and var-positional# should be removed). Here's why. Consider the following# function:#     foo(a, b, *args, c):#         pass# "partial(foo, a='spam')" will have the following# signature: "(*, a='spam', b, c)". Because attempting# to call that partial with "(10, 20)" arguments will# raise a TypeError, saying that "a" argument received# multiple values.# Set the new default value# was passed as a positional argument# Drop first parameter:# '(p1, p2[, ...])' -> '(p2[, ...])'# Unless we add a new parameter type we never# get here# It's a var-positional parameter.# Do nothing. '(*args[, ...])' -> '(*args[, ...])'# Can't test 'isinstance(type)' here, as it would# also be True for regular python classes.# Can't use the `in` operator here, as it would# invoke the custom __eq__ method.# All function-like objects are obviously callables,# and not classes.# Important to use _void ...# ... and not None here# token stream always starts with ENCODING token, skip it# Support constant folding of a couple simple binary operations# commonly used to define default values in text signatures# non-keyword-only parameters# *args# **kwargs# Possibly strip the bound argument:#    - We *always* strip first bound argument if#      it is a module.#    - We don't strip first bound argument if#      skip_bound_arg is False.# for builtins, self parameter is always positional-only!# If it's not a pure Python function, and not a duck type# of pure function:# Parameter information.# Non-keyword-only parameters w/o defaults.# ... w/ defaults.# Keyword-only parameters.# Is 'func' is a pure Python function - don't validate the# parameters list (for correct order and defaults), it should be OK.# In this case we skip the first parameter of the underlying# function (usually `self` or `cls`).# Was this function wrapped by a decorator?# Unwrap until we find an explicit signature or a MethodType (which will be# handled explicitly below).# If the unwrapped object is a *method*, we might want to# skip its first parameter (self).# See test_signature_wrapped_bound_method for details.# since __text_signature__ is not writable on classes, __signature__# may contain text (or be a callable that returns text);# if so, convert it# Unbound partialmethod (see functools.partialmethod)# This means, that we need to calculate the signature# as if it's a regular partial object, but taking into# account that the first positional argument# (usually `self`, or `cls`) will not be passed# automatically (as for boundmethods)# First argument of the wrapped callable is `*args`, as in# `partialmethod(lambda *args)`.# If it's a pure Python function, or an object that is duck type# of a Python function (Cython functions, for instance), then:# obj is a class or a metaclass# First, let's see if it has an overloaded __call__ defined# in its metaclass# Go through the MRO and see if any class has user-defined# pure Python __new__ or __init__ method# Now we check if the 'obj' class has an own '__new__' method# or an own '__init__' method# At this point we know, that `obj` is a class, with no user-# defined '__init__', '__new__', or class-level '__call__'# Since '__text_signature__' is implemented as a# descriptor that extracts text signature from the# class docstring, if 'obj' is derived from a builtin# class, its own '__text_signature__' may be 'None'.# Therefore, we go through the MRO (except the last# class in there, which is 'object') to find the first# class with non-empty text signature.# If 'base' class has a __text_signature__ attribute:# return a signature based on it# No '__text_signature__' was found for the 'obj' class.# Last option is to check if its '__init__' is# object.__init__ or type.__init__.# We have a class (not metaclass), but no user-defined# __init__ or __new__ for it# Return a signature of 'object' builtin.# An object with __call__# These are implicit arguments generated by comprehensions. In# order to provide a friendlier interface to users, we recast# their name as "implicitN" and treat them as positional-only.# See issue 19611.# It's possible for C functions to have a positional-only parameter# where the name is a keyword, so for compatibility we'll allow it.# Add annotation and default value# We're done here. Other arguments# will be mapped in 'BoundArguments.kwargs'# plain argument# plain keyword argument# This BoundArguments was likely produced by# Signature.bind_partial().# No default for this parameter, but the# previous parameter of had a default# There is a default for this parameter.# Let's iterate through the positional arguments and corresponding# parameters# No more positional arguments# No more parameters. That's it. Just need to check that# we have no `kwargs` after this while loop# That's OK, just empty *args.  Let's start parsing# Raise a TypeError once we are sure there is no# **kwargs param later.# That's fine too - we have a default value for this# parameter.  So, lets start parsing `kwargs`, starting# with the current parameter# No default, not VAR_KEYWORD, not VAR_POSITIONAL,# not in `kwargs`# We have a positional argument to process# Looks like we have no parameter for this positional# We have an '*args'-like argument, let's fill it with# all positional arguments we have left and move on to# the next phase# Now, we iterate through the remaining parameters to process# keyword arguments# Memorize that we have a '**kwargs'-like parameter# Named arguments don't refer to '*args'-like parameters.# We only arrive here if the positional arguments ended# before reaching the last parameter before *args.# We have no value for this parameter.  It's fine though,# if it has a default value, or it is an '*args'-like# parameter, left alone by the processing of positional# arguments.# Process our '**kwargs'-like parameter# It's not a positional-only parameter, and the flag# is set to 'True' (there were pos-only params before.)# OK, we have an '*args'-like parameter, so we won't need# a '*' to separate keyword-only arguments# We have a keyword-only parameter to render and we haven't# rendered an '*args'-like parameter before, so add a '*'# separator to the parameters list ("foo(arg1, *, arg2)" case)# This condition should be only triggered once, so# reset the flag# There were only positional-only parameters, hence the# flag was not reset to 'False'b'Get useful information from live Python objects.

This module encapsulates the interface provided by the internal special
attributes (co_*, im_*, tb_*, etc.) in a friendlier fashion.
It also provides some help for examining source code and class layout.

Here are some of the useful functions provided by this module:

    ismodule(), isclass(), ismethod(), isfunction(), isgeneratorfunction(),
        isgenerator(), istraceback(), isframe(), iscode(), isbuiltin(),
        isroutine() - check object types
    getmembers() - get members of an object that satisfy a given condition

    getfile(), getsourcefile(), getsource() - find an object's source code
    getdoc(), getcomments() - get documentation on an object
    getmodule() - determine the module that an object came from
    getclasstree() - arrange classes so as to represent their hierarchy

    getargvalues(), getcallargs() - get info about function arguments
    getfullargspec() - same, with support for Python 3 features
    formatargvalues() - format an argument spec
    getouterframes(), getinnerframes() - get info about frames
    currentframe() - get the current stack frame
    stack(), trace() - get info about frames on the stack or in a traceback

    signature() - get a Signature object for the callable

    get_annotations() - safely compute an object's annotations
'u'Get useful information from live Python objects.

This module encapsulates the interface provided by the internal special
attributes (co_*, im_*, tb_*, etc.) in a friendlier fashion.
It also provides some help for examining source code and class layout.

Here are some of the useful functions provided by this module:

    ismodule(), isclass(), ismethod(), isfunction(), isgeneratorfunction(),
        isgenerator(), istraceback(), isframe(), iscode(), isbuiltin(),
        isroutine() - check object types
    getmembers() - get members of an object that satisfy a given condition

    getfile(), getsourcefile(), getsource() - find an object's source code
    getdoc(), getcomments() - get documentation on an object
    getmodule() - determine the module that an object came from
    getclasstree() - arrange classes so as to represent their hierarchy

    getargvalues(), getcallargs() - get info about function arguments
    getfullargspec() - same, with support for Python 3 features
    formatargvalues() - format an argument spec
    getouterframes(), getinnerframes() - get info about frames
    currentframe() - get the current stack frame
    stack(), trace() - get info about frames on the stack or in a traceback

    signature() - get a Signature object for the callable

    get_annotations() - safely compute an object's annotations
'b'Ka-Ping Yee <ping@lfw.org>'u'Ka-Ping Yee <ping@lfw.org>'b'Yury Selivanov <yselivanov@sprymix.com>'u'Yury Selivanov <yselivanov@sprymix.com>'b'AGEN_CLOSED'u'AGEN_CLOSED'b'AGEN_CREATED'u'AGEN_CREATED'b'AGEN_RUNNING'u'AGEN_RUNNING'b'AGEN_SUSPENDED'u'AGEN_SUSPENDED'b'ArgInfo'u'ArgInfo'b'Arguments'u'Arguments'b'Attribute'u'Attribute'b'BlockFinder'u'BlockFinder'b'BoundArguments'u'BoundArguments'b'BufferFlags'u'BufferFlags'b'CORO_CLOSED'u'CORO_CLOSED'b'CORO_CREATED'u'CORO_CREATED'b'CORO_RUNNING'u'CORO_RUNNING'b'CORO_SUSPENDED'u'CORO_SUSPENDED'b'CO_ASYNC_GENERATOR'u'CO_ASYNC_GENERATOR'b'CO_COROUTINE'u'CO_COROUTINE'b'CO_GENERATOR'u'CO_GENERATOR'b'CO_ITERABLE_COROUTINE'u'CO_ITERABLE_COROUTINE'b'CO_NESTED'u'CO_NESTED'b'CO_NEWLOCALS'u'CO_NEWLOCALS'b'CO_NOFREE'u'CO_NOFREE'b'CO_OPTIMIZED'u'CO_OPTIMIZED'b'CO_VARARGS'u'CO_VARARGS'b'CO_VARKEYWORDS'u'CO_VARKEYWORDS'b'ClassFoundException'u'ClassFoundException'b'ClosureVars'u'ClosureVars'b'EndOfBlock'u'EndOfBlock'b'FrameInfo'u'FrameInfo'b'FullArgSpec'u'FullArgSpec'b'GEN_CLOSED'u'GEN_CLOSED'b'GEN_CREATED'u'GEN_CREATED'b'GEN_RUNNING'u'GEN_RUNNING'b'GEN_SUSPENDED'u'GEN_SUSPENDED'b'Parameter'u'Parameter'b'Signature'u'Signature'b'TPFLAGS_IS_ABSTRACT'u'TPFLAGS_IS_ABSTRACT'b'Traceback'u'Traceback'b'classify_class_attrs'u'classify_class_attrs'b'cleandoc'u'cleandoc'b'currentframe'u'currentframe'b'findsource'u'findsource'b'formatannotation'u'formatannotation'b'formatannotationrelativeto'u'formatannotationrelativeto'b'formatargvalues'u'formatargvalues'b'get_annotations'u'get_annotations'b'getabsfile'u'getabsfile'b'getargs'u'getargs'b'getargvalues'u'getargvalues'b'getasyncgenlocals'u'getasyncgenlocals'b'getasyncgenstate'u'getasyncgenstate'b'getattr_static'u'getattr_static'b'getblock'u'getblock'b'getcallargs'u'getcallargs'b'getclasstree'u'getclasstree'b'getclosurevars'u'getclosurevars'b'getcomments'u'getcomments'b'getcoroutinelocals'u'getcoroutinelocals'b'getcoroutinestate'u'getcoroutinestate'b'getdoc'u'getdoc'b'getfile'u'getfile'b'getframeinfo'u'getframeinfo'b'getfullargspec'u'getfullargspec'b'getgeneratorlocals'u'getgeneratorlocals'b'getgeneratorstate'u'getgeneratorstate'b'getinnerframes'u'getinnerframes'b'getlineno'u'getlineno'b'getmembers'u'getmembers'b'getmembers_static'u'getmembers_static'b'getmodule'u'getmodule'b'getmodulename'u'getmodulename'b'getmro'u'getmro'b'getouterframes'u'getouterframes'b'getsource'u'getsource'b'getsourcefile'u'getsourcefile'b'getsourcelines'u'getsourcelines'b'indentsize'u'indentsize'b'isabstract'u'isabstract'b'isasyncgen'u'isasyncgen'b'isasyncgenfunction'u'isasyncgenfunction'b'isawaitable'u'isawaitable'b'isbuiltin'u'isbuiltin'b'isclass'u'isclass'b'iscode'u'iscode'b'isdatadescriptor'u'isdatadescriptor'b'isframe'u'isframe'b'isfunction'u'isfunction'b'isgenerator'u'isgenerator'b'isgeneratorfunction'u'isgeneratorfunction'b'isgetsetdescriptor'u'isgetsetdescriptor'b'ismemberdescriptor'u'ismemberdescriptor'b'ismethod'u'ismethod'b'ismethoddescriptor'u'ismethoddescriptor'b'ismethodwrapper'u'ismethodwrapper'b'ismodule'u'ismodule'b'isroutine'u'isroutine'b'istraceback'u'istraceback'b'markcoroutinefunction'u'markcoroutinefunction'b'signature'u'signature'b'stack'u'stack'b'trace'u'trace'b'unwrap'u'unwrap'b'walktree'u'walktree'b'CO_'u'CO_'b'Compute the annotations dict for an object.

    obj may be a callable, class, or module.
    Passing in an object of any other type raises TypeError.

    Returns a dict.  get_annotations() returns a new dict every time
    it's called; calling it twice on the same object will return two
    different but equivalent dicts.

    This function handles several details for you:

      * If eval_str is true, values of type str will
        be un-stringized using eval().  This is intended
        for use with stringized annotations
        ("from __future__ import annotations").
      * If obj doesn't have an annotations dict, returns an
        empty dict.  (Functions and methods always have an
        annotations dict; classes, modules, and other types of
        callables may not.)
      * Ignores inherited annotations on classes.  If a class
        doesn't have its own annotations dict, returns an empty dict.
      * All accesses to object members and dict values are done
        using getattr() and dict.get() for safety.
      * Always, always, always returns a freshly-created dict.

    eval_str controls whether or not values of type str are replaced
    with the result of calling eval() on those values:

      * If eval_str is true, eval() is called on values of type str.
      * If eval_str is false (the default), values of type str are unchanged.

    globals and locals are passed in to eval(); see the documentation
    for eval() for more information.  If either globals or locals is
    None, this function may replace that value with a context-specific
    default, contingent on type(obj):

      * If obj is a module, globals defaults to obj.__dict__.
      * If obj is a class, globals defaults to
        sys.modules[obj.__module__].__dict__ and locals
        defaults to the obj class namespace.
      * If obj is a callable, globals defaults to obj.__globals__,
        although if obj is a wrapped function (using
        functools.update_wrapper()) it is first unwrapped.
    'u'Compute the annotations dict for an object.

    obj may be a callable, class, or module.
    Passing in an object of any other type raises TypeError.

    Returns a dict.  get_annotations() returns a new dict every time
    it's called; calling it twice on the same object will return two
    different but equivalent dicts.

    This function handles several details for you:

      * If eval_str is true, values of type str will
        be un-stringized using eval().  This is intended
        for use with stringized annotations
        ("from __future__ import annotations").
      * If obj doesn't have an annotations dict, returns an
        empty dict.  (Functions and methods always have an
        annotations dict; classes, modules, and other types of
        callables may not.)
      * Ignores inherited annotations on classes.  If a class
        doesn't have its own annotations dict, returns an empty dict.
      * All accesses to object members and dict values are done
        using getattr() and dict.get() for safety.
      * Always, always, always returns a freshly-created dict.

    eval_str controls whether or not values of type str are replaced
    with the result of calling eval() on those values:

      * If eval_str is true, eval() is called on values of type str.
      * If eval_str is false (the default), values of type str are unchanged.

    globals and locals are passed in to eval(); see the documentation
    for eval() for more information.  If either globals or locals is
    None, this function may replace that value with a context-specific
    default, contingent on type(obj):

      * If obj is a module, globals defaults to obj.__dict__.
      * If obj is a class, globals defaults to
        sys.modules[obj.__module__].__dict__ and locals
        defaults to the obj class namespace.
      * If obj is a callable, globals defaults to obj.__globals__,
        although if obj is a wrapped function (using
        functools.update_wrapper()) it is first unwrapped.
    'b'get'u'get'b'__globals__'u'__globals__'b' is not a module, class, or callable.'u' is not a module, class, or callable.'b'.__annotations__ is neither a dict nor None'u'.__annotations__ is neither a dict nor None'b'__wrapped__'u'__wrapped__'b'Return true if the object is a module.'u'Return true if the object is a module.'b'Return true if the object is a class.'u'Return true if the object is a class.'b'Return true if the object is an instance method.'u'Return true if the object is an instance method.'b'Return true if the object is a method descriptor.

    But not if ismethod() or isclass() or isfunction() are true.

    This is new in Python 2.2, and, for example, is true of int.__add__.
    An object passing this test has a __get__ attribute but not a __set__
    attribute, but beyond that the set of attributes varies.  __name__ is
    usually sensible, and __doc__ often is.

    Methods implemented via descriptors that also pass one of the other
    tests return false from the ismethoddescriptor() test, simply because
    the other tests promise more -- you can, e.g., count on having the
    __func__ attribute (etc) when an object passes ismethod().'u'Return true if the object is a method descriptor.

    But not if ismethod() or isclass() or isfunction() are true.

    This is new in Python 2.2, and, for example, is true of int.__add__.
    An object passing this test has a __get__ attribute but not a __set__
    attribute, but beyond that the set of attributes varies.  __name__ is
    usually sensible, and __doc__ often is.

    Methods implemented via descriptors that also pass one of the other
    tests return false from the ismethoddescriptor() test, simply because
    the other tests promise more -- you can, e.g., count on having the
    __func__ attribute (etc) when an object passes ismethod().'b'Return true if the object is a data descriptor.

    Data descriptors have a __set__ or a __delete__ attribute.  Examples are
    properties (defined in Python) and getsets and members (defined in C).
    Typically, data descriptors will also have __name__ and __doc__ attributes
    (properties, getsets, and members have both of these attributes), but this
    is not guaranteed.'u'Return true if the object is a data descriptor.

    Data descriptors have a __set__ or a __delete__ attribute.  Examples are
    properties (defined in Python) and getsets and members (defined in C).
    Typically, data descriptors will also have __name__ and __doc__ attributes
    (properties, getsets, and members have both of these attributes), but this
    is not guaranteed.'b'MemberDescriptorType'u'MemberDescriptorType'b'Return true if the object is a member descriptor.

        Member descriptors are specialized descriptors defined in extension
        modules.'u'Return true if the object is a member descriptor.

        Member descriptors are specialized descriptors defined in extension
        modules.'b'GetSetDescriptorType'u'GetSetDescriptorType'b'Return true if the object is a getset descriptor.

        getset descriptors are specialized descriptors defined in extension
        modules.'u'Return true if the object is a getset descriptor.

        getset descriptors are specialized descriptors defined in extension
        modules.'b'Return true if the object is a user-defined function.

    Function objects provide these attributes:
        __doc__         documentation string
        __name__        name with which this function was defined
        __code__        code object containing compiled function bytecode
        __defaults__    tuple of any default values for arguments
        __globals__     global namespace in which this function was defined
        __annotations__ dict of parameter annotations
        __kwdefaults__  dict of keyword only parameters with defaults'u'Return true if the object is a user-defined function.

    Function objects provide these attributes:
        __doc__         documentation string
        __name__        name with which this function was defined
        __code__        code object containing compiled function bytecode
        __defaults__    tuple of any default values for arguments
        __globals__     global namespace in which this function was defined
        __annotations__ dict of parameter annotations
        __kwdefaults__  dict of keyword only parameters with defaults'b'Return true if ``f`` is a function (or a method or functools.partial
    wrapper wrapping a function) whose code object has the given ``flag``
    set in its flags.'u'Return true if ``f`` is a function (or a method or functools.partial
    wrapper wrapping a function) whose code object has the given ``flag``
    set in its flags.'b'Return true if the object is a user-defined generator function.

    Generator function objects provide the same attributes as functions.
    See help(isfunction) for a list of attributes.'u'Return true if the object is a user-defined generator function.

    Generator function objects provide the same attributes as functions.
    See help(isfunction) for a list of attributes.'b'_is_coroutine_marker'u'_is_coroutine_marker'b'
    Decorator to ensure callable is recognised as a coroutine function.
    'u'
    Decorator to ensure callable is recognised as a coroutine function.
    'b'Return true if the object is a coroutine function.

    Coroutine functions are normally defined with "async def" syntax, but may
    be marked via markcoroutinefunction.
    'u'Return true if the object is a coroutine function.

    Coroutine functions are normally defined with "async def" syntax, but may
    be marked via markcoroutinefunction.
    'b'Return true if the object is an asynchronous generator function.

    Asynchronous generator functions are defined with "async def"
    syntax and have "yield" expressions in their body.
    'u'Return true if the object is an asynchronous generator function.

    Asynchronous generator functions are defined with "async def"
    syntax and have "yield" expressions in their body.
    'b'Return true if the object is an asynchronous generator.'u'Return true if the object is an asynchronous generator.'b'Return true if the object is a generator.

    Generator objects provide these attributes:
        __iter__        defined to support iteration over container
        close           raises a new GeneratorExit exception inside the
                        generator to terminate the iteration
        gi_code         code object
        gi_frame        frame object or possibly None once the generator has
                        been exhausted
        gi_running      set to 1 when generator is executing, 0 otherwise
        next            return the next item from the container
        send            resumes the generator and "sends" a value that becomes
                        the result of the current yield-expression
        throw           used to raise an exception inside the generator'u'Return true if the object is a generator.

    Generator objects provide these attributes:
        __iter__        defined to support iteration over container
        close           raises a new GeneratorExit exception inside the
                        generator to terminate the iteration
        gi_code         code object
        gi_frame        frame object or possibly None once the generator has
                        been exhausted
        gi_running      set to 1 when generator is executing, 0 otherwise
        next            return the next item from the container
        send            resumes the generator and "sends" a value that becomes
                        the result of the current yield-expression
        throw           used to raise an exception inside the generator'b'Return true if the object is a coroutine.'u'Return true if the object is a coroutine.'b'Return true if object can be passed to an ``await`` expression.'u'Return true if object can be passed to an ``await`` expression.'b'Return true if the object is a traceback.

    Traceback objects provide these attributes:
        tb_frame        frame object at this level
        tb_lasti        index of last attempted instruction in bytecode
        tb_lineno       current line number in Python source code
        tb_next         next inner traceback object (called by this level)'u'Return true if the object is a traceback.

    Traceback objects provide these attributes:
        tb_frame        frame object at this level
        tb_lasti        index of last attempted instruction in bytecode
        tb_lineno       current line number in Python source code
        tb_next         next inner traceback object (called by this level)'b'Return true if the object is a frame object.

    Frame objects provide these attributes:
        f_back          next outer frame object (this frame's caller)
        f_builtins      built-in namespace seen by this frame
        f_code          code object being executed in this frame
        f_globals       global namespace seen by this frame
        f_lasti         index of last attempted instruction in bytecode
        f_lineno        current line number in Python source code
        f_locals        local namespace seen by this frame
        f_trace         tracing function for this frame, or None'u'Return true if the object is a frame object.

    Frame objects provide these attributes:
        f_back          next outer frame object (this frame's caller)
        f_builtins      built-in namespace seen by this frame
        f_code          code object being executed in this frame
        f_globals       global namespace seen by this frame
        f_lasti         index of last attempted instruction in bytecode
        f_lineno        current line number in Python source code
        f_locals        local namespace seen by this frame
        f_trace         tracing function for this frame, or None'b'Return true if the object is a code object.

    Code objects provide these attributes:
        co_argcount         number of arguments (not including *, ** args
                            or keyword only arguments)
        co_code             string of raw compiled bytecode
        co_cellvars         tuple of names of cell variables
        co_consts           tuple of constants used in the bytecode
        co_filename         name of file in which this code object was created
        co_firstlineno      number of first line in Python source code
        co_flags            bitmap: 1=optimized | 2=newlocals | 4=*arg | 8=**arg
                            | 16=nested | 32=generator | 64=nofree | 128=coroutine
                            | 256=iterable_coroutine | 512=async_generator
        co_freevars         tuple of names of free variables
        co_posonlyargcount  number of positional only arguments
        co_kwonlyargcount   number of keyword only arguments (not including ** arg)
        co_lnotab           encoded mapping of line numbers to bytecode indices
        co_name             name with which this code object was defined
        co_names            tuple of names other than arguments and function locals
        co_nlocals          number of local variables
        co_stacksize        virtual machine stack space required
        co_varnames         tuple of names of arguments and local variables'u'Return true if the object is a code object.

    Code objects provide these attributes:
        co_argcount         number of arguments (not including *, ** args
                            or keyword only arguments)
        co_code             string of raw compiled bytecode
        co_cellvars         tuple of names of cell variables
        co_consts           tuple of constants used in the bytecode
        co_filename         name of file in which this code object was created
        co_firstlineno      number of first line in Python source code
        co_flags            bitmap: 1=optimized | 2=newlocals | 4=*arg | 8=**arg
                            | 16=nested | 32=generator | 64=nofree | 128=coroutine
                            | 256=iterable_coroutine | 512=async_generator
        co_freevars         tuple of names of free variables
        co_posonlyargcount  number of positional only arguments
        co_kwonlyargcount   number of keyword only arguments (not including ** arg)
        co_lnotab           encoded mapping of line numbers to bytecode indices
        co_name             name with which this code object was defined
        co_names            tuple of names other than arguments and function locals
        co_nlocals          number of local variables
        co_stacksize        virtual machine stack space required
        co_varnames         tuple of names of arguments and local variables'b'Return true if the object is a built-in function or method.

    Built-in functions and methods provide these attributes:
        __doc__         documentation string
        __name__        original name of this function or method
        __self__        instance to which a method is bound, or None'u'Return true if the object is a built-in function or method.

    Built-in functions and methods provide these attributes:
        __doc__         documentation string
        __name__        original name of this function or method
        __self__        instance to which a method is bound, or None'b'Return true if the object is a method wrapper.'u'Return true if the object is a method wrapper.'b'Return true if the object is any kind of function or method.'u'Return true if the object is any kind of function or method.'b'Return true if the object is an abstract base class (ABC).'u'Return true if the object is an abstract base class (ABC).'b'Return all members of an object as (name, value) pairs sorted by name.
    Optionally, only return members that satisfy a given predicate.'u'Return all members of an object as (name, value) pairs sorted by name.
    Optionally, only return members that satisfy a given predicate.'b'Return all members of an object as (name, value) pairs sorted by name
    without triggering dynamic lookup via the descriptor protocol,
    __getattr__ or __getattribute__. Optionally, only return members that
    satisfy a given predicate.

    Note: this function may not be able to retrieve all members
       that getmembers can fetch (like dynamically created attributes)
       and may find members that getmembers can't (like descriptors
       that raise AttributeError). It can also return descriptor objects
       instead of instance members in some cases.
    'u'Return all members of an object as (name, value) pairs sorted by name
    without triggering dynamic lookup via the descriptor protocol,
    __getattr__ or __getattribute__. Optionally, only return members that
    satisfy a given predicate.

    Note: this function may not be able to retrieve all members
       that getmembers can fetch (like dynamically created attributes)
       and may find members that getmembers can't (like descriptors
       that raise AttributeError). It can also return descriptor objects
       instead of instance members in some cases.
    'b'name kind defining_class object'u'name kind defining_class object'b'Return list of attribute-descriptor tuples.

    For each name in dir(cls), the return list contains a 4-tuple
    with these elements:

        0. The name (a string).

        1. The kind of attribute this is, one of these strings:
               'class method'    created via classmethod()
               'static method'   created via staticmethod()
               'property'        created via property()
               'method'          any other flavor of method or descriptor
               'data'            not a method

        2. The class which defined this attribute (a class).

        3. The object as obtained by calling getattr; if this fails, or if the
           resulting object does not live anywhere in the class' mro (including
           metaclasses) then the object is looked up in the defining class's
           dict (found by walking the mro).

    If one of the items in dir(cls) is stored in the metaclass it will now
    be discovered and not have None be listed as the class in which it was
    defined.  Any items whose home class cannot be discovered are skipped.
    'u'Return list of attribute-descriptor tuples.

    For each name in dir(cls), the return list contains a 4-tuple
    with these elements:

        0. The name (a string).

        1. The kind of attribute this is, one of these strings:
               'class method'    created via classmethod()
               'static method'   created via staticmethod()
               'property'        created via property()
               'method'          any other flavor of method or descriptor
               'data'            not a method

        2. The class which defined this attribute (a class).

        3. The object as obtained by calling getattr; if this fails, or if the
           resulting object does not live anywhere in the class' mro (including
           metaclasses) then the object is looked up in the defining class's
           dict (found by walking the mro).

    If one of the items in dir(cls) is stored in the metaclass it will now
    be discovered and not have None be listed as the class in which it was
    defined.  Any items whose home class cannot be discovered are skipped.
    'b'__dict__ is special, don't want the proxy'u'__dict__ is special, don't want the proxy'b'static method'u'static method'b'class method'u'class method'b'method'u'method'b'Return tuple of base classes (including cls) in method resolution order.'u'Return tuple of base classes (including cls) in method resolution order.'b'Get the object wrapped by *func*.

   Follows the chain of :attr:`__wrapped__` attributes returning the last
   object in the chain.

   *stop* is an optional callback accepting an object in the wrapper chain
   as its sole argument that allows the unwrapping to be terminated early if
   the callback returns a true value. If the callback never returns a true
   value, the last object in the chain is returned as usual. For example,
   :func:`signature` uses this to stop unwrapping if any object in the
   chain has a ``__signature__`` attribute defined.

   :exc:`ValueError` is raised if a cycle is encountered.

    'u'Get the object wrapped by *func*.

   Follows the chain of :attr:`__wrapped__` attributes returning the last
   object in the chain.

   *stop* is an optional callback accepting an object in the wrapper chain
   as its sole argument that allows the unwrapping to be terminated early if
   the callback returns a true value. If the callback never returns a true
   value, the last object in the chain is returned as usual. For example,
   :func:`signature` uses this to stop unwrapping if any object in the
   chain has a ``__signature__`` attribute defined.

   :exc:`ValueError` is raised if a cycle is encountered.

    'b'wrapper loop when unwrapping {!r}'u'wrapper loop when unwrapping {!r}'b'Return the indent size, in spaces, at the start of a line of text.'u'Return the indent size, in spaces, at the start of a line of text.'b'Get the documentation string for an object.

    All tabs are expanded to spaces.  To clean up docstrings that are
    indented to line up with blocks of code, any whitespace than can be
    uniformly removed from the second line onwards is removed.'u'Get the documentation string for an object.

    All tabs are expanded to spaces.  To clean up docstrings that are
    indented to line up with blocks of code, any whitespace than can be
    uniformly removed from the second line onwards is removed.'b'Clean up indentation from docstrings.

    Any whitespace that can be uniformly removed from the second line
    onwards is removed.'u'Clean up indentation from docstrings.

    Any whitespace that can be uniformly removed from the second line
    onwards is removed.'b'Work out which source or compiled file an object was defined in.'u'Work out which source or compiled file an object was defined in.'b'{!r} is a built-in module'u'{!r} is a built-in module'b'source code not available'u'source code not available'b'{!r} is a built-in class'u'{!r} is a built-in class'b'module, class, method, function, traceback, frame, or code object was expected, got {}'u'module, class, method, function, traceback, frame, or code object was expected, got {}'b'Return the module name for a given file, or None.'u'Return the module name for a given file, or None.'b'Return the filename that can be used to locate an object's source.
    Return None if no way can be identified to get the source.
    'u'Return the filename that can be used to locate an object's source.
    Return None if no way can be identified to get the source.
    'b'Return an absolute path to the source or compiled file for an object.

    The idea is for each object to have a unique origin, so this routine
    normalizes the result as much as possible.'u'Return an absolute path to the source or compiled file for an object.

    The idea is for each object to have a unique origin, so this routine
    normalizes the result as much as possible.'b'Return the module an object was defined in, or None if not found.'u'Return the module an object was defined in, or None if not found.'b'<locals>'u'<locals>'b'Return the entire source file and starting line number for an object.

    The argument may be a module, class, method, function, traceback, frame,
    or code object.  The source code is returned as a list of all the lines
    in the file and the line number indexes a line in that list.  An OSError
    is raised if the source code cannot be retrieved.'u'Return the entire source file and starting line number for an object.

    The argument may be a module, class, method, function, traceback, frame,
    or code object.  The source code is returned as a list of all the lines
    in the file and the line number indexes a line in that list.  An OSError
    is raised if the source code cannot be retrieved.'b'could not get source code'u'could not get source code'b'could not find class definition'u'could not find class definition'b'co_firstlineno'u'co_firstlineno'b'could not find function definition'u'could not find function definition'b'^(\s*def\s)|(\s*async\s+def\s)|(.*(?<!\w)lambda(:|\s))|^(\s*@)'u'^(\s*def\s)|(\s*async\s+def\s)|(.*(?<!\w)lambda(:|\s))|^(\s*@)'b'lineno is out of bounds'u'lineno is out of bounds'b'could not find code object'u'could not find code object'b'Get lines of comments immediately preceding an object's source code.

    Returns None when source can't be found.
    'u'Get lines of comments immediately preceding an object's source code.

    Returns None when source can't be found.
    'b'#!'u'#!'b'Provide a tokeneater() method to detect the end of a code block.'u'Provide a tokeneater() method to detect the end of a code block.'b'class'u'class'b'Extract the block of code at the top of the given list of lines.'u'Extract the block of code at the top of the given list of lines.'b'unmatched'u'unmatched'b'Return a list of source lines and starting line number for an object.

    The argument may be a module, class, method, function, traceback, frame,
    or code object.  The source code is returned as a list of the lines
    corresponding to the object and the line number indicates where in the
    original source file the first line of code was found.  An OSError is
    raised if the source code cannot be retrieved.'u'Return a list of source lines and starting line number for an object.

    The argument may be a module, class, method, function, traceback, frame,
    or code object.  The source code is returned as a list of the lines
    corresponding to the object and the line number indicates where in the
    original source file the first line of code was found.  An OSError is
    raised if the source code cannot be retrieved.'b'<module>'u'<module>'b'Return the text of the source code for an object.

    The argument may be a module, class, method, function, traceback, frame,
    or code object.  The source code is returned as a single string.  An
    OSError is raised if the source code cannot be retrieved.'u'Return the text of the source code for an object.

    The argument may be a module, class, method, function, traceback, frame,
    or code object.  The source code is returned as a single string.  An
    OSError is raised if the source code cannot be retrieved.'b'Recursive helper function for getclasstree().'u'Recursive helper function for getclasstree().'b'Arrange the given list of classes into a hierarchy of nested lists.

    Where a nested list appears, it contains classes derived from the class
    whose entry immediately precedes the list.  Each entry is a 2-tuple
    containing a class and a tuple of its base classes.  If the 'unique'
    argument is true, exactly one entry appears in the returned structure
    for each class in the given list.  Otherwise, classes using multiple
    inheritance and their descendants will appear multiple times.'u'Arrange the given list of classes into a hierarchy of nested lists.

    Where a nested list appears, it contains classes derived from the class
    whose entry immediately precedes the list.  Each entry is a 2-tuple
    containing a class and a tuple of its base classes.  If the 'unique'
    argument is true, exactly one entry appears in the returned structure
    for each class in the given list.  Otherwise, classes using multiple
    inheritance and their descendants will appear multiple times.'b'args, varargs, varkw'u'args, varargs, varkw'b'Get information about the arguments accepted by a code object.

    Three things are returned: (args, varargs, varkw), where
    'args' is the list of argument names. Keyword-only arguments are
    appended. 'varargs' and 'varkw' are the names of the * and **
    arguments or None.'u'Get information about the arguments accepted by a code object.

    Three things are returned: (args, varargs, varkw), where
    'args' is the list of argument names. Keyword-only arguments are
    appended. 'varargs' and 'varkw' are the names of the * and **
    arguments or None.'b'{!r} is not a code object'u'{!r} is not a code object'b'args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults, annotations'u'args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults, annotations'b'Get the names and default values of a callable object's parameters.

    A tuple of seven things is returned:
    (args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults, annotations).
    'args' is a list of the parameter names.
    'varargs' and 'varkw' are the names of the * and ** parameters or None.
    'defaults' is an n-tuple of the default values of the last n parameters.
    'kwonlyargs' is a list of keyword-only parameter names.
    'kwonlydefaults' is a dictionary mapping names from kwonlyargs to defaults.
    'annotations' is a dictionary mapping parameter names to annotations.

    Notable differences from inspect.signature():
      - the "self" parameter is always reported, even for bound methods
      - wrapper chains defined by __wrapped__ *not* unwrapped automatically
    'u'Get the names and default values of a callable object's parameters.

    A tuple of seven things is returned:
    (args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults, annotations).
    'args' is a list of the parameter names.
    'varargs' and 'varkw' are the names of the * and ** parameters or None.
    'defaults' is an n-tuple of the default values of the last n parameters.
    'kwonlyargs' is a list of keyword-only parameter names.
    'kwonlydefaults' is a dictionary mapping names from kwonlyargs to defaults.
    'annotations' is a dictionary mapping parameter names to annotations.

    Notable differences from inspect.signature():
      - the "self" parameter is always reported, even for bound methods
      - wrapper chains defined by __wrapped__ *not* unwrapped automatically
    'b'unsupported callable'u'unsupported callable'b'args varargs keywords locals'u'args varargs keywords locals'b'Get information about arguments passed into a particular frame.

    A tuple of four things is returned: (args, varargs, varkw, locals).
    'args' is a list of the argument names.
    'varargs' and 'varkw' are the names of the * and ** arguments or None.
    'locals' is the locals dictionary of the given frame.'u'Get information about arguments passed into a particular frame.

    A tuple of four things is returned: (args, varargs, varkw, locals).
    'args' is a list of the argument names.
    'varargs' and 'varkw' are the names of the * and ** arguments or None.
    'locals' is the locals dictionary of the given frame.'b'typing.'u'typing.'b'[\w\.]+'u'[\w\.]+'b'Format an argument spec from the 4 values returned by getargvalues.

    The first four arguments are (args, varargs, varkw, locals).  The
    next four arguments are the corresponding optional formatting functions
    that are called to turn names and values into strings.  The ninth
    argument is an optional function to format the sequence of arguments.'u'Format an argument spec from the 4 values returned by getargvalues.

    The first four arguments are (args, varargs, varkw, locals).  The
    next four arguments are the corresponding optional formatting functions
    that are called to turn names and values into strings.  The ninth
    argument is an optional function to format the sequence of arguments.'b'{} and {}'u'{} and {}'b', {} and {}'u', {} and {}'b'%s() missing %i required %s argument%s: %s'u'%s() missing %i required %s argument%s: %s'b'positional'u'positional'b'keyword-only'u'keyword-only'b'at least %d'u'at least %d'b'from %d to %d'u'from %d to %d'b' positional argument%s (and %d keyword-only argument%s)'u' positional argument%s (and %d keyword-only argument%s)'b'%s() takes %s positional argument%s but %d%s %s given'u'%s() takes %s positional argument%s but %d%s %s given'b'was'u'was'b'were'u'were'b'Get the mapping of arguments to values.

    A dict is returned, with keys the function argument names (including the
    names of the * and ** arguments, if any), and values the respective bound
    values from 'positional' and 'named'.'u'Get the mapping of arguments to values.

    A dict is returned, with keys the function argument names (including the
    names of the * and ** arguments, if any), and values the respective bound
    values from 'positional' and 'named'.'b'%s() got an unexpected keyword argument %r'u'%s() got an unexpected keyword argument %r'b'%s() got multiple values for argument %r'u'%s() got multiple values for argument %r'b'nonlocals globals builtins unbound'u'nonlocals globals builtins unbound'b'
    Get the mapping of free variables to their current values.

    Returns a named tuple of dicts mapping the current nonlocal, global
    and builtin references as seen by the body of the function. A final
    set of unbound names that could not be resolved is also provided.
    'u'
    Get the mapping of free variables to their current values.

    Returns a named tuple of dicts mapping the current nonlocal, global
    and builtin references as seen by the body of the function. A final
    set of unbound names that could not be resolved is also provided.
    'b'{!r} is not a Python function'u'{!r} is not a Python function'b'None'u'None'b'True'u'True'b'False'u'False'b'_Traceback'u'_Traceback'b'filename lineno function code_context index'u'filename lineno function code_context index'b'Traceback(filename={!r}, lineno={!r}, function={!r}, code_context={!r}, index={!r}, positions={!r})'u'Traceback(filename={!r}, lineno={!r}, function={!r}, code_context={!r}, index={!r}, positions={!r})'b'Get information about a frame or traceback object.

    A tuple of five things is returned: the filename, the line number of
    the current line, the function name, a list of lines of context from
    the source code, and the index of the current line within that list.
    The optional second argument specifies the number of lines of context
    to return, which are centered around the current line.'u'Get information about a frame or traceback object.

    A tuple of five things is returned: the filename, the line number of
    the current line, the function name, a list of lines of context from
    the source code, and the index of the current line within that list.
    The optional second argument specifies the number of lines of context
    to return, which are centered around the current line.'b'{!r} is not a frame or traceback object'u'{!r} is not a frame or traceback object'b'Get the line number from a frame object, allowing for optimization.'u'Get the line number from a frame object, allowing for optimization.'b'_FrameInfo'u'_FrameInfo'b'frame'u'frame'b'FrameInfo(frame={!r}, filename={!r}, lineno={!r}, function={!r}, code_context={!r}, index={!r}, positions={!r})'u'FrameInfo(frame={!r}, filename={!r}, lineno={!r}, function={!r}, code_context={!r}, index={!r}, positions={!r})'b'Get a list of records for a frame and all higher (calling) frames.

    Each record contains a frame object, filename, line number, function
    name, a list of lines of context, and index within the context.'u'Get a list of records for a frame and all higher (calling) frames.

    Each record contains a frame object, filename, line number, function
    name, a list of lines of context, and index within the context.'b'Get a list of records for a traceback's frame and all lower frames.

    Each record contains a frame object, filename, line number, function
    name, a list of lines of context, and index within the context.'u'Get a list of records for a traceback's frame and all lower frames.

    Each record contains a frame object, filename, line number, function
    name, a list of lines of context, and index within the context.'b'Return the frame of the caller or None if this is not possible.'u'Return the frame of the caller or None if this is not possible.'b'Return a list of records for the stack above the caller's frame.'u'Return a list of records for the stack above the caller's frame.'b'Return a list of records for the stack below the current exception.'u'Return a list of records for the stack below the current exception.'b'Retrieve attributes without triggering dynamic lookup via the
       descriptor protocol,  __getattr__ or __getattribute__.

       Note: this function may not be able to retrieve all attributes
       that getattr can fetch (like dynamically created attributes)
       and may find attributes that getattr can't (like descriptors
       that raise AttributeError). It can also return descriptor objects
       instead of instance members in some cases. See the
       documentation for details.
    'u'Retrieve attributes without triggering dynamic lookup via the
       descriptor protocol,  __getattr__ or __getattribute__.

       Note: this function may not be able to retrieve all attributes
       that getattr can fetch (like dynamically created attributes)
       and may find attributes that getattr can't (like descriptors
       that raise AttributeError). It can also return descriptor objects
       instead of instance members in some cases. See the
       documentation for details.
    'b'Get current state of a generator-iterator.

    Possible states are:
      GEN_CREATED: Waiting to start execution.
      GEN_RUNNING: Currently being executed by the interpreter.
      GEN_SUSPENDED: Currently suspended at a yield expression.
      GEN_CLOSED: Execution has completed.
    'u'Get current state of a generator-iterator.

    Possible states are:
      GEN_CREATED: Waiting to start execution.
      GEN_RUNNING: Currently being executed by the interpreter.
      GEN_SUSPENDED: Currently suspended at a yield expression.
      GEN_CLOSED: Execution has completed.
    'b'
    Get the mapping of generator local variables to their current values.

    A dict is returned, with the keys the local variable names and values the
    bound values.'u'
    Get the mapping of generator local variables to their current values.

    A dict is returned, with the keys the local variable names and values the
    bound values.'b'{!r} is not a Python generator'u'{!r} is not a Python generator'b'Get current state of a coroutine object.

    Possible states are:
      CORO_CREATED: Waiting to start execution.
      CORO_RUNNING: Currently being executed by the interpreter.
      CORO_SUSPENDED: Currently suspended at an await expression.
      CORO_CLOSED: Execution has completed.
    'u'Get current state of a coroutine object.

    Possible states are:
      CORO_CREATED: Waiting to start execution.
      CORO_RUNNING: Currently being executed by the interpreter.
      CORO_SUSPENDED: Currently suspended at an await expression.
      CORO_CLOSED: Execution has completed.
    'b'
    Get the mapping of coroutine local variables to their current values.

    A dict is returned, with the keys the local variable names and values the
    bound values.'u'
    Get the mapping of coroutine local variables to their current values.

    A dict is returned, with the keys the local variable names and values the
    bound values.'b'Get current state of an asynchronous generator object.

    Possible states are:
      AGEN_CREATED: Waiting to start execution.
      AGEN_RUNNING: Currently being executed by the interpreter.
      AGEN_SUSPENDED: Currently suspended at a yield expression.
      AGEN_CLOSED: Execution has completed.
    'u'Get current state of an asynchronous generator object.

    Possible states are:
      AGEN_CREATED: Waiting to start execution.
      AGEN_RUNNING: Currently being executed by the interpreter.
      AGEN_SUSPENDED: Currently suspended at a yield expression.
      AGEN_CLOSED: Execution has completed.
    'b'
    Get the mapping of asynchronous generator local variables to their current
    values.

    A dict is returned, with the keys the local variable names and values the
    bound values.'u'
    Get the mapping of asynchronous generator local variables to their current
    values.

    A dict is returned, with the keys the local variable names and values the
    bound values.'b' is not a Python async generator'u' is not a Python async generator'b'Private helper. Checks if ``cls`` has an attribute
    named ``method_name`` and returns it only if it is a
    pure python function.
    'u'Private helper. Checks if ``cls`` has an attribute
    named ``method_name`` and returns it only if it is a
    pure python function.
    'b'Private helper to calculate how 'wrapped_sig' signature will
    look like after applying a 'functools.partial' object (or alike)
    on it.
    'u'Private helper to calculate how 'wrapped_sig' signature will
    look like after applying a 'functools.partial' object (or alike)
    on it.
    'b'partial object {!r} has incorrect arguments'u'partial object {!r} has incorrect arguments'b'Private helper to transform signatures for unbound
    functions to bound methods.
    'u'Private helper to transform signatures for unbound
    functions to bound methods.
    'b'invalid method signature'u'invalid method signature'b'invalid argument type'u'invalid argument type'b'Private helper to test if `obj` is a callable that might
    support Argument Clinic's __text_signature__ protocol.
    'u'Private helper to test if `obj` is a callable that might
    support Argument Clinic's __text_signature__ protocol.
    'b'Private helper to test if `obj` is a duck type of FunctionType.
    A good example of such objects are functions compiled with
    Cython, which have all attributes that a pure Python function
    would have, but have their code statically compiled.
    'u'Private helper to test if `obj` is a duck type of FunctionType.
    A good example of such objects are functions compiled with
    Cython, which have all attributes that a pure Python function
    would have, but have their code statically compiled.
    'b'__defaults__'u'__defaults__'b'__kwdefaults__'u'__kwdefaults__'b'
    Private helper function. Takes a signature in Argument Clinic's
    extended signature format.

    Returns a tuple of two things:
      * that signature re-rendered in standard Python syntax, and
      * the index of the "self" parameter (generally 0), or None if
        the function does not have a "self" parameter.
    'u'
    Private helper function. Takes a signature in Argument Clinic's
    extended signature format.

    Returns a tuple of two things:
      * that signature re-rendered in standard Python syntax, and
      * the index of the "self" parameter (generally 0), or None if
        the function does not have a "self" parameter.
    'b'Private helper to parse content of '__text_signature__'
    and return a Signature based on it.
    'u'Private helper to parse content of '__text_signature__'
    and return a Signature based on it.
    'b'def foo'u'def foo'b': pass'u': pass'b'{!r} builtin has invalid signature'u'{!r} builtin has invalid signature'b'Annotations are not currently supported'u'Annotations are not currently supported'b'Private helper function to get signature for
    builtin callables.
    'u'Private helper function to get signature for
    builtin callables.
    'b'{!r} is not a Python builtin function'u'{!r} is not a Python builtin function'b'__text_signature__'u'__text_signature__'b'no signature found for builtin {!r}'u'no signature found for builtin {!r}'b'Private helper: constructs Signature for the given python function.'u'Private helper: constructs Signature for the given python function.'b'Private helper function to get signature for arbitrary
    callable objects.
    'u'Private helper function to get signature for arbitrary
    callable objects.
    'b'{!r} is not a callable object'u'{!r} is not a callable object'b'__signature__'u'__signature__'b'unexpected object {!r} in __signature__ attribute'u'unexpected object {!r} in __signature__ attribute'b'no signature found for builtin type {!r}'u'no signature found for builtin type {!r}'b'callable {!r} is not supported by signature'u'callable {!r} is not supported by signature'b'A private marker - used in Parameter & Signature.'u'A private marker - used in Parameter & Signature.'b'Marker object for Signature.empty and Parameter.empty.'u'Marker object for Signature.empty and Parameter.empty.'b'positional-only'u'positional-only'b'positional or keyword'u'positional or keyword'b'variadic positional'u'variadic positional'b'variadic keyword'u'variadic keyword'b'Represents a parameter in a function signature.

    Has the following public attributes:

    * name : str
        The name of the parameter as a string.
    * default : object
        The default value for the parameter if specified.  If the
        parameter has no default value, this attribute is set to
        `Parameter.empty`.
    * annotation
        The annotation for the parameter if specified.  If the
        parameter has no annotation, this attribute is set to
        `Parameter.empty`.
    * kind : str
        Describes how argument values are bound to the parameter.
        Possible values: `Parameter.POSITIONAL_ONLY`,
        `Parameter.POSITIONAL_OR_KEYWORD`, `Parameter.VAR_POSITIONAL`,
        `Parameter.KEYWORD_ONLY`, `Parameter.VAR_KEYWORD`.
    'u'Represents a parameter in a function signature.

    Has the following public attributes:

    * name : str
        The name of the parameter as a string.
    * default : object
        The default value for the parameter if specified.  If the
        parameter has no default value, this attribute is set to
        `Parameter.empty`.
    * annotation
        The annotation for the parameter if specified.  If the
        parameter has no annotation, this attribute is set to
        `Parameter.empty`.
    * kind : str
        Describes how argument values are bound to the parameter.
        Possible values: `Parameter.POSITIONAL_ONLY`,
        `Parameter.POSITIONAL_OR_KEYWORD`, `Parameter.VAR_POSITIONAL`,
        `Parameter.KEYWORD_ONLY`, `Parameter.VAR_KEYWORD`.
    'b'_kind'u'_kind'b'_default'u'_default'b'_annotation'u'_annotation'b'value 'u'value 'b' is not a valid Parameter.kind'u' is not a valid Parameter.kind'b'{} parameters cannot have default values'u'{} parameters cannot have default values'b'name is a required attribute for Parameter'u'name is a required attribute for Parameter'b'name must be a str, not a {}'u'name must be a str, not a {}'b'implicit arguments must be passed as positional or keyword arguments, not {}'u'implicit arguments must be passed as positional or keyword arguments, not {}'b'implicit{}'u'implicit{}'b'{!r} is not a valid parameter name'u'{!r} is not a valid parameter name'b'Creates a customized copy of the Parameter.'u'Creates a customized copy of the Parameter.'b'{}: {}'u'{}: {}'b'{} = {}'u'{} = {}'b'{}={}'u'{}={}'b'<{} "{}">'u'<{} "{}">'b'Result of `Signature.bind` call.  Holds the mapping of arguments
    to the function's parameters.

    Has the following public attributes:

    * arguments : dict
        An ordered mutable mapping of parameters' names to arguments' values.
        Does not contain arguments' default values.
    * signature : Signature
        The Signature object that created this instance.
    * args : tuple
        Tuple of positional arguments values.
    * kwargs : dict
        Dict of keyword arguments values.
    'u'Result of `Signature.bind` call.  Holds the mapping of arguments
    to the function's parameters.

    Has the following public attributes:

    * arguments : dict
        An ordered mutable mapping of parameters' names to arguments' values.
        Does not contain arguments' default values.
    * signature : Signature
        The Signature object that created this instance.
    * args : tuple
        Tuple of positional arguments values.
    * kwargs : dict
        Dict of keyword arguments values.
    'b'arguments'u'arguments'b'_signature'u'_signature'b'Set default values for missing arguments.

        For variable-positional arguments (*args) the default is an
        empty tuple.

        For variable-keyword arguments (**kwargs) the default is an
        empty dict.
        'u'Set default values for missing arguments.

        For variable-positional arguments (*args) the default is an
        empty tuple.

        For variable-keyword arguments (**kwargs) the default is an
        empty dict.
        'b'<{} ({})>'u'<{} ({})>'b'A Signature object represents the overall signature of a function.
    It stores a Parameter object for each parameter accepted by the
    function, as well as information specific to the function itself.

    A Signature object has the following public attributes and methods:

    * parameters : OrderedDict
        An ordered mapping of parameters' names to the corresponding
        Parameter objects (keyword-only arguments are in the same order
        as listed in `code.co_varnames`).
    * return_annotation : object
        The annotation for the return type of the function if specified.
        If the function has no annotation for its return type, this
        attribute is set to `Signature.empty`.
    * bind(*args, **kwargs) -> BoundArguments
        Creates a mapping from positional and keyword arguments to
        parameters.
    * bind_partial(*args, **kwargs) -> BoundArguments
        Creates a partial mapping from positional and keyword arguments
        to parameters (simulating 'functools.partial' behavior.)
    'u'A Signature object represents the overall signature of a function.
    It stores a Parameter object for each parameter accepted by the
    function, as well as information specific to the function itself.

    A Signature object has the following public attributes and methods:

    * parameters : OrderedDict
        An ordered mapping of parameters' names to the corresponding
        Parameter objects (keyword-only arguments are in the same order
        as listed in `code.co_varnames`).
    * return_annotation : object
        The annotation for the return type of the function if specified.
        If the function has no annotation for its return type, this
        attribute is set to `Signature.empty`.
    * bind(*args, **kwargs) -> BoundArguments
        Creates a mapping from positional and keyword arguments to
        parameters.
    * bind_partial(*args, **kwargs) -> BoundArguments
        Creates a partial mapping from positional and keyword arguments
        to parameters (simulating 'functools.partial' behavior.)
    'b'_return_annotation'u'_return_annotation'b'_parameters'u'_parameters'b'Constructs Signature from the given list of Parameter
        objects and 'return_annotation'.  All arguments are optional.
        'u'Constructs Signature from the given list of Parameter
        objects and 'return_annotation'.  All arguments are optional.
        'b'wrong parameter order: {} parameter before {} parameter'u'wrong parameter order: {} parameter before {} parameter'b'non-default argument follows default argument'u'non-default argument follows default argument'b'duplicate parameter name: {!r}'u'duplicate parameter name: {!r}'b'Constructs Signature for the given callable object.'u'Constructs Signature for the given callable object.'b'Creates a customized copy of the Signature.
        Pass 'parameters' and/or 'return_annotation' arguments
        to override them in the new copy.
        'u'Creates a customized copy of the Signature.
        Pass 'parameters' and/or 'return_annotation' arguments
        to override them in the new copy.
        'b'Private method. Don't use directly.'u'Private method. Don't use directly.'b'too many positional arguments'u'too many positional arguments'b'multiple values for argument {arg!r}'u'multiple values for argument {arg!r}'b' keyword-only'u' keyword-only'b'missing a required{argtype} argument: {arg!r}'u'missing a required{argtype} argument: {arg!r}'b'missing a required argument: {arg!r}'u'missing a required argument: {arg!r}'b'got some positional-only arguments passed as keyword arguments: {arg!r}'u'got some positional-only arguments passed as keyword arguments: {arg!r}'b'got an unexpected keyword argument {arg!r}'u'got an unexpected keyword argument {arg!r}'b'Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        'u'Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        'b'Get a BoundArguments object, that partially maps the
        passed `args` and `kwargs` to the function's signature.
        Raises `TypeError` if the passed arguments can not be bound.
        'u'Get a BoundArguments object, that partially maps the
        passed `args` and `kwargs` to the function's signature.
        Raises `TypeError` if the passed arguments can not be bound.
        'b'<{} {}>'u'<{} {}>'b' -> {}'u' -> {}'b'Get a signature object for the passed callable.'u'Get a signature object for the passed callable.'b' Logic for inspecting an object given at command line 'u' Logic for inspecting an object given at command line 'b'object'u'object'b'The object to be analysed. It supports the 'module:qualname' syntax'u'The object to be analysed. It supports the 'module:qualname' syntax'b'--details'u'--details'b'Display info about the module rather than its source code'u'Display info about the module rather than its source code'b'Failed to import {} ({}: {})'u'Failed to import {} ({}: {})'b'Can't get info for builtin modules.'u'Can't get info for builtin modules.'b'Target: {}'u'Target: {}'b'Origin: {}'u'Origin: {}'b'Cached: {}'u'Cached: {}'b'Loader: {}'u'Loader: {}'b'Submodule search path: {}'u'Submodule search path: {}'b'Line: {}'u'Line: {}'u'Lib.inspect'The io module provides the Python interfaces to stream handling. The
builtin open function is defined in this module.

At the top of the I/O hierarchy is the abstract base class IOBase. It
defines the basic interface to a stream. Note, however, that there is no
separation between reading and writing to streams; implementations are
allowed to raise an OSError if they do not support a given operation.

Extending IOBase is RawIOBase which deals simply with the reading and
writing of raw bytes to a stream. FileIO subclasses RawIOBase to provide
an interface to OS files.

BufferedIOBase deals with buffering on a raw byte stream (RawIOBase). Its
subclasses, BufferedWriter, BufferedReader, and BufferedRWPair buffer
streams that are readable, writable, and both respectively.
BufferedRandom provides a buffered interface to random access
streams. BytesIO is a simple stream of in-memory bytes.

Another IOBase subclass, TextIOBase, deals with the encoding and decoding
of streams into text. TextIOWrapper, which extends it, is a buffered text
interface to a buffered raw stream (`BufferedIOBase`). Finally, StringIO
is an in-memory stream for text.

Argument names are not part of the specification, and only the arguments
of open() are intended to be used as keyword arguments.

data:

DEFAULT_BUFFER_SIZE

   An int containing the default buffer size used by the module's buffered
   I/O classes. open() uses the file's blksize (as obtained by os.stat) if
   possible.
Guido van Rossum <guido@python.org>, Mike Verdone <mike.verdone@gmail.com>, Mark Russell <mark.russell@zen.co.uk>, Antoine Pitrou <solipsis@pitrou.net>, Amaury Forgeot d'Arc <amauryfa@gmail.com>, Benjamin Peterson <benjamin@python.org>"Guido van Rossum <guido@python.org>, ""Mike Verdone <mike.verdone@gmail.com>, ""Mark Russell <mark.russell@zen.co.uk>, ""Antoine Pitrou <solipsis@pitrou.net>, ""Amaury Forgeot d'Arc <amauryfa@gmail.com>, ""Benjamin Peterson <benjamin@python.org>"IOBase# New I/O library conforming to PEP 3116.# Pretend this exception was created here.# for seek()# Declaring ABCs in C is tricky so we do it here.# Method descriptions and default implementations are inherited from the C# version however.b'The io module provides the Python interfaces to stream handling. The
builtin open function is defined in this module.

At the top of the I/O hierarchy is the abstract base class IOBase. It
defines the basic interface to a stream. Note, however, that there is no
separation between reading and writing to streams; implementations are
allowed to raise an OSError if they do not support a given operation.

Extending IOBase is RawIOBase which deals simply with the reading and
writing of raw bytes to a stream. FileIO subclasses RawIOBase to provide
an interface to OS files.

BufferedIOBase deals with buffering on a raw byte stream (RawIOBase). Its
subclasses, BufferedWriter, BufferedReader, and BufferedRWPair buffer
streams that are readable, writable, and both respectively.
BufferedRandom provides a buffered interface to random access
streams. BytesIO is a simple stream of in-memory bytes.

Another IOBase subclass, TextIOBase, deals with the encoding and decoding
of streams into text. TextIOWrapper, which extends it, is a buffered text
interface to a buffered raw stream (`BufferedIOBase`). Finally, StringIO
is an in-memory stream for text.

Argument names are not part of the specification, and only the arguments
of open() are intended to be used as keyword arguments.

data:

DEFAULT_BUFFER_SIZE

   An int containing the default buffer size used by the module's buffered
   I/O classes. open() uses the file's blksize (as obtained by os.stat) if
   possible.
'b'Guido van Rossum <guido@python.org>, Mike Verdone <mike.verdone@gmail.com>, Mark Russell <mark.russell@zen.co.uk>, Antoine Pitrou <solipsis@pitrou.net>, Amaury Forgeot d'Arc <amauryfa@gmail.com>, Benjamin Peterson <benjamin@python.org>'u'Guido van Rossum <guido@python.org>, Mike Verdone <mike.verdone@gmail.com>, Mark Russell <mark.russell@zen.co.uk>, Antoine Pitrou <solipsis@pitrou.net>, Amaury Forgeot d'Arc <amauryfa@gmail.com>, Benjamin Peterson <benjamin@python.org>'b'BlockingIOError'u'BlockingIOError'b'open_code'u'open_code'b'IOBase'u'IOBase'b'RawIOBase'u'RawIOBase'b'FileIO'u'FileIO'b'BytesIO'u'BytesIO'b'BufferedIOBase'u'BufferedIOBase'b'BufferedReader'u'BufferedReader'b'BufferedWriter'u'BufferedWriter'b'BufferedRWPair'u'BufferedRWPair'b'BufferedRandom'u'BufferedRandom'b'TextIOBase'u'TextIOBase'b'TextIOWrapper'u'TextIOWrapper'b'UnsupportedOperation'u'UnsupportedOperation'b'SEEK_SET'u'SEEK_SET'b'SEEK_CUR'u'SEEK_CUR'b'SEEK_END'u'SEEK_END'b'DEFAULT_BUFFER_SIZE'u'DEFAULT_BUFFER_SIZE'b'text_encoding'u'text_encoding'b'IncrementalNewlineDecoder'u'IncrementalNewlineDecoder'u'Lib.io'A fast, lightweight IPv4/IPv6 manipulation library in Python.

This library is used to create/poke/manipulate IPv4 and IPv6 addresses
and networks.

IPV4LENGTHIPV6LENGTHAddressValueErrorA Value Error related to the address.NetmaskValueErrorA Value Error related to the netmask.ip_addressTake an IP string/int and return an object of the correct type.

    Args:
        address: A string or integer, the IP address.  Either IPv4 or
          IPv6 addresses may be supplied; integers less than 2**32 will
          be considered to be IPv4 by default.

    Returns:
        An IPv4Address or IPv6Address object.

    Raises:
        ValueError: if the *address* passed isn't either a v4 or a v6
          address

    IPv4AddressIPv6Address does not appear to be an IPv4 or IPv6 addressip_networkTake an IP string/int and return an object of the correct type.

    Args:
        address: A string or integer, the IP network.  Either IPv4 or
          IPv6 networks may be supplied; integers less than 2**32 will
          be considered to be IPv4 by default.

    Returns:
        An IPv4Network or IPv6Network object.

    Raises:
        ValueError: if the string passed isn't either a v4 or a v6
          address. Or if the network has host bits set.

    IPv4NetworkIPv6Network does not appear to be an IPv4 or IPv6 networkip_interfaceTake an IP string/int and return an object of the correct type.

    Args:
        address: A string or integer, the IP address.  Either IPv4 or
          IPv6 addresses may be supplied; integers less than 2**32 will
          be considered to be IPv4 by default.

    Returns:
        An IPv4Interface or IPv6Interface object.

    Raises:
        ValueError: if the string passed isn't either a v4 or a v6
          address.

    Notes:
        The IPv?Interface classes describe an Address on a particular
        Network, so they're basically a combination of both the Address
        and Network classes.

    IPv4InterfaceIPv6Interface does not appear to be an IPv4 or IPv6 interfacev4_int_to_packedRepresent an address as 4 packed bytes in network (big-endian) order.

    Args:
        address: An integer representation of an IPv4 IP address.

    Returns:
        The integer address packed as 4 bytes in network (big-endian) order.

    Raises:
        ValueError: If the integer is negative or too large to be an
          IPv4 IP address.

    Address negative or too large for IPv4v6_int_to_packedRepresent an address as 16 packed bytes in network (big-endian) order.

    Args:
        address: An integer representation of an IPv6 IP address.

    Returns:
        The integer address packed as 16 bytes in network (big-endian) order.

    Address negative or too large for IPv6_split_optional_netmaskHelper to split the netmask and raise AddressValueError if neededOnly one '/' permitted in _find_address_rangeaddressesFind a sequence of sorted deduplicated IPv#Address.

    Args:
        addresses: a list of IPv#Address objects.

    Yields:
        A tuple containing the first and last IP addresses in the sequence.

    _ip_count_righthand_zero_bitsCount the number of zero bits on the right hand side.

    Args:
        number: an integer.
        bits: maximum number of bits to count.

    Returns:
        The number of zero bits on the right hand side of the number.

    summarize_address_rangeSummarize a network range given the first and last IP addresses.

    Example:
        >>> list(summarize_address_range(IPv4Address('192.0.2.0'),
        ...                              IPv4Address('192.0.2.130')))
        ...                                #doctest: +NORMALIZE_WHITESPACE
        [IPv4Network('192.0.2.0/25'), IPv4Network('192.0.2.128/31'),
         IPv4Network('192.0.2.130/32')]

    Args:
        first: the first IPv4Address or IPv6Address in the range.
        last: the last IPv4Address or IPv6Address in the range.

    Returns:
        An iterator of the summarized IPv(4|6) network objects.

    Raise:
        TypeError:
            If the first and last objects are not IP addresses.
            If the first and last objects are not the same version.
        ValueError:
            If the last object is not greater than the first.
            If the version of the first address is not 4 or 6.

    _BaseAddressfirst and last must be IP addresses, not networks%s and %s are not of the same versionlast IP address must be greater than firstunknown IP version_max_prefixlenip_bitsfirst_intlast_intnbitsnet_ALL_ONES_collapse_addresses_internalLoops through the addresses, collapsing concurrent netblocks.

    Example:

        ip1 = IPv4Network('192.0.2.0/26')
        ip2 = IPv4Network('192.0.2.64/26')
        ip3 = IPv4Network('192.0.2.128/26')
        ip4 = IPv4Network('192.0.2.192/26')

        _collapse_addresses_internal([ip1, ip2, ip3, ip4]) ->
          [IPv4Network('192.0.2.0/24')]

        This shouldn't be called directly; it is called via
          collapse_addresses([]).

    Args:
        addresses: A list of IPv4Network's or IPv6Network's

    Returns:
        A list of IPv4Network's or IPv6Network's depending on what we were
        passed.

    to_mergesubnetssupernetexistingbroadcast_addresscollapse_addressesCollapse a list of IP objects.

    Example:
        collapse_addresses([IPv4Network('192.0.2.0/25'),
                            IPv4Network('192.0.2.128/25')]) ->
                           [IPv4Network('192.0.2.0/24')]

    Args:
        addresses: An iterator of IPv4Network or IPv6Network objects.

    Returns:
        An iterator of the collapsed IPv(4|6)Network objects.

    Raises:
        TypeError: If passed a list of mixed version objects.

    addrsipsnets_version_prefixlennetwork_addressget_mixed_type_keyReturn a key suitable for sorting between networks and addresses.

    Address and Network objects are not sortable by default; they're
    fundamentally different so the expression

        IPv4Address('192.0.2.0') <= IPv4Network('192.0.2.0/24')

    doesn't make any sense.  There are some times however, where you may wish
    to have ipaddress sort these for you anyway. If you need to do this, you
    can use this function as the key= argument to sorted().

    Args:
      obj: either a Network or Address object.
    Returns:
      appropriate key.

    _BaseNetwork_get_networks_key_get_address_key_IPAddressBaseThe mother class.explodedReturn the longhand version of the IP address as a string._explode_shorthand_ip_stringReturn the shorthand version of the IP address as a string.reverse_pointerThe name of the reverse DNS pointer for the IP address, e.g.:
            >>> ipaddress.ip_address("127.0.0.1").reverse_pointer
            '1.0.0.127.in-addr.arpa'
            >>> ipaddress.ip_address("2001:db8::1").reverse_pointer
            '1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.8.b.d.0.1.0.0.2.ip6.arpa'

        _reverse_pointer%200s has no version specified_check_int_address%d (< 0) is not permitted as an IPv%d address%d (>= 2**%d) is not permitted as an IPv%d address_check_packed_addressexpected_lenaddress_len%r (len %d != %d) is not permitted as an IPv%d address_ip_int_from_prefixprefixlenTurn the prefix length into a bitwise netmask

        Args:
            prefixlen: An integer, the prefix length.

        Returns:
            An integer.

        _prefix_from_ip_intip_intReturn prefix length from the bitwise netmask.

        Args:
            ip_int: An integer, the netmask in expanded bitwise format

        Returns:
            An integer, the prefix length.

        Raises:
            ValueError: If the input intermingles zeroes & ones
        trailing_zeroesleading_onesall_onesbyteslenbigNetmask pattern %r mixes zeroes & ones_report_invalid_netmasknetmask_str%r is not a valid netmask_prefix_from_prefix_stringprefixlen_strReturn prefix length from a numeric string

        Args:
            prefixlen_str: The string to be converted

        Returns:
            An integer, the prefix length.

        Raises:
            NetmaskValueError: If the input is not a valid netmask
        _prefix_from_ip_stringip_strTurn a netmask/hostmask string into a prefix length

        Args:
            ip_str: The netmask/hostmask to be converted

        Returns:
            An integer, the prefix length.

        Raises:
            NetmaskValueError: If the input is not a valid netmask/hostmask
        _ip_int_from_string_split_addr_prefixHelper function to parse address of Network/Interface.

        Arg:
            address: Argument of Network/Interface.

        Returns:
            (addr, prefix) tuple.
        _address_fmt_reA generic IP object.

    This IP class contains the version independent methods which are
    used by single IP addresses.
    _string_from_ip_intReturns an IP address as a formatted string.

        Supported presentation types are:
        's': returns the IP address as a string (default)
        'b': converts to binary and returns a zero-padded string
        'X' or 'x': converts to upper- or lower-case hex and returns a zero-padded string
        'n': the same as 'b' for IPv4 and 'x' for IPv6

        For binary and hex presentation types, the alternate form specifier
        '#' and the grouping option '_' are supported.
        (#?)(_?)([xbnX])alternatefmt_basepadlenA generic IP network object.

    This IP class contains the version independent methods which are
    used by networks.
    %s/%dGenerate Iterator over usable hosts in a network.

        This is like __iter__ except it doesn't return the network
        or broadcast addresses.

        networkbroadcast_address_classaddress out of rangenetmaskoverlapsTell if self is partly contained in other.hostmaskwith_prefixlenwith_netmaskwith_hostmasknum_addressesNumber of hosts in the current subnet.%200s has no associated address classaddress_excludeRemove an address from a larger block.

        For example:

            addr1 = ip_network('192.0.2.0/28')
            addr2 = ip_network('192.0.2.1/32')
            list(addr1.address_exclude(addr2)) =
                [IPv4Network('192.0.2.0/32'), IPv4Network('192.0.2.2/31'),
                 IPv4Network('192.0.2.4/30'), IPv4Network('192.0.2.8/29')]

        or IPv6:

            addr1 = ip_network('2001:db8::1/32')
            addr2 = ip_network('2001:db8::1/128')
            list(addr1.address_exclude(addr2)) =
                [ip_network('2001:db8::1/128'),
                 ip_network('2001:db8::2/127'),
                 ip_network('2001:db8::4/126'),
                 ip_network('2001:db8::8/125'),
                 ...
                 ip_network('2001:db8:8000::/33')]

        Args:
            other: An IPv4Network or IPv6Network object of the same type.

        Returns:
            An iterator of the IPv(4|6)Network objects which is self
            minus other.

        Raises:
            TypeError: If self and other are of differing address
              versions, or if other is not a network object.
            ValueError: If other is not completely contained by self.

        %s is not a network objectsubnet_of%s not contained in %sError performing exclusion: s1: %s s2: %s other: %s'Error performing exclusion: ''s1: %s s2: %s other: %s'compare_networksCompare two IP objects.

        This is only concerned about the comparison of the integer
        representation of the network addresses.  This means that the
        host bits aren't considered at all in this method.  If you want
        to compare host bits, you can easily enough do a
        'HostA._ip < HostB._ip'

        Args:
            other: An IP object.

        Returns:
            If the IP versions of self and other are the same, returns:

            -1 if self < other:
              eg: IPv4Network('192.0.2.0/25') < IPv4Network('192.0.2.128/25')
              IPv6Network('2001:db8::1000/124') <
                  IPv6Network('2001:db8::2000/124')
            0 if self == other
              eg: IPv4Network('192.0.2.0/24') == IPv4Network('192.0.2.0/24')
              IPv6Network('2001:db8::1000/124') ==
                  IPv6Network('2001:db8::1000/124')
            1 if self > other
              eg: IPv4Network('192.0.2.128/25') > IPv4Network('192.0.2.0/25')
                  IPv6Network('2001:db8::2000/124') >
                      IPv6Network('2001:db8::1000/124')

          Raises:
              TypeError if the IP versions are different.

        %s and %s are not of the same typeNetwork-only key function.

        Returns an object that identifies this address' network and
        netmask. This function is a suitable "key" argument for sorted()
        and list.sort().

        prefixlen_diffnew_prefixThe subnets which join to make the current subnet.

        In the case that self contains only one IP
        (self._prefixlen == 32 for IPv4 or self._prefixlen == 128
        for IPv6), yield an iterator with just ourself.

        Args:
            prefixlen_diff: An integer, the amount the prefix length
              should be increased by. This should not be set if
              new_prefix is also set.
            new_prefix: The desired new prefix length. This must be a
              larger number (smaller prefix) than the existing prefix.
              This should not be set if prefixlen_diff is also set.

        Returns:
            An iterator of IPv(4|6) objects.

        Raises:
            ValueError: The prefixlen_diff is too small or too large.
                OR
            prefixlen_diff and new_prefix are both set or new_prefix
              is a smaller number than the current prefix (smaller
              number means a larger network)

        new prefix must be longercannot set prefixlen_diff and new_prefixprefix length diff must be > 0new_prefixlenprefix length diff %d is invalid for netblock %snew_addrcurrentThe supernet containing the current network.

        Args:
            prefixlen_diff: An integer, the amount the prefix length of
              the network should be decreased by.  For example, given a
              /24 network and a prefixlen_diff of 3, a supernet with a
              /21 netmask is returned.

        Returns:
            An IPv4 network object.

        Raises:
            ValueError: If self.prefixlen - prefixlen_diff < 0. I.e., you have
              a negative prefix length.
                OR
            If prefixlen_diff and new_prefix are both set or new_prefix is a
              larger number than the current prefix (larger number means a
              smaller network)

        new prefix must be shortercurrent prefixlen is %d, cannot have a prefixlen_diff of %dis_multicastTest if the address is reserved for multicast use.

        Returns:
            A boolean, True if the address is a multicast address.
            See RFC 2373 2.7 for details.

        _is_subnet_of are not of the same versionUnable to test subnet containment between "Unable to test subnet containment ""between "Return True if this network is a subnet of other.supernet_ofReturn True if this network is a supernet of other.is_reservedTest if the address is otherwise IETF reserved.

        Returns:
            A boolean, True if the address is within one of the
            reserved IPv6 Network ranges.

        is_link_localTest if the address is reserved for link-local.

        Returns:
            A boolean, True if the address is reserved per RFC 4291.

        is_privateTest if this network belongs to a private range.

        Returns:
            A boolean, True if the network is reserved per
            iana-ipv4-special-registry or iana-ipv6-special-registry.

        priv_network_private_networks_private_networks_exceptionsis_globalTest if this address is allocated for public networks.

        Returns:
            A boolean, True if the address is not reserved per
            iana-ipv4-special-registry or iana-ipv6-special-registry.

        is_unspecifiedTest if the address is unspecified.

        Returns:
            A boolean, True if this is the unspecified address as defined in
            RFC 2373 2.5.2.

        is_loopbackTest if the address is a loopback address.

        Returns:
            A boolean, True if the address is a loopback address as defined in
            RFC 2373 2.5.3.

        _BaseConstants_BaseV4Base IPv4 object.

    The following methods are used by IPv4 objects in both single IP
    addresses and networks.

    _netmask_cache_make_netmaskMake a (netmask, prefix_len) tuple from the given argument.

        Argument can be:
        - an integer (the prefix length)
        - a string representing the prefix length (e.g. "24")
        - a string representing the prefix netmask (e.g. "255.255.255.0")
        Turn the given IP string into an integer for comparison.

        Args:
            ip_str: A string, the IP ip_str.

        Returns:
            The IP ip_str as an integer.

        Raises:
            AddressValueError: if ip_str isn't a valid IPv4 Address.

        Address cannot be emptyoctetsExpected 4 octets in %r_parse_octet%s in %roctet_strConvert a decimal octet into an integer.

        Args:
            octet_str: A string, the number to parse.

        Returns:
            The octet as an integer.

        Raises:
            ValueError: if the octet isn't strictly a decimal from [0..255].

        Empty octet not permittedOnly decimal digits permitted in %rAt most 3 characters permitted in %rLeading zeros are not permitted in %roctet_intOctet %d (> 255) not permittedTurns a 32-bit integer into dotted decimal notation.

        Args:
            ip_int: An integer, the IP address.

        Returns:
            The IP address as a string in dotted decimal notation.

        Return the reverse DNS pointer name for the IPv4 address.

        This implements the method described in RFC1035 3.5.

        reverse_octets.in-addr.arpamax_prefixlenRepresent and manipulate single IPv4 Addresses.
        Args:
            address: A string or integer representing the IP

              Additionally, an integer can be passed, so
              IPv4Address('192.0.2.1') == IPv4Address(3221225985).
              or, more generally
              IPv4Address(int(IPv4Address('192.0.2.1'))) ==
                IPv4Address('192.0.2.1')

        Raises:
            AddressValueError: If ipaddress isn't a valid IPv4 address.

        addr_strUnexpected '/' in packedThe binary representation of this address.Test if the address is otherwise IETF reserved.

         Returns:
             A boolean, True if the address is within the
             reserved IPv4 Network range.

        _reserved_network``True`` if the address is defined as not globally reachable by
        iana-ipv4-special-registry_ (for IPv4) or iana-ipv6-special-registry_
        (for IPv6) with the following exceptions:

        * ``is_private`` is ``False`` for ``100.64.0.0/10``
        * For IPv4-mapped IPv6-addresses the ``is_private`` value is determined by the
            semantics of the underlying IPv4 addresses and the following condition holds
            (see :attr:`IPv6Address.ipv4_mapped`)::

                address.is_private == address.ipv4_mapped.is_private

        ``is_private`` has value opposite to :attr:`is_global`, except for the ``100.64.0.0/10``
        IPv4 range where they are both ``False``.
        ``True`` if the address is defined as globally reachable by
        iana-ipv4-special-registry_ (for IPv4) or iana-ipv6-special-registry_
        (for IPv6) with the following exception:

        For IPv4-mapped IPv6-addresses the ``is_private`` value is determined by the
        semantics of the underlying IPv4 addresses and the following condition holds
        (see :attr:`IPv6Address.ipv4_mapped`)::

            address.is_global == address.ipv4_mapped.is_global

        ``is_global`` has value opposite to :attr:`is_private`, except for the ``100.64.0.0/10``
        IPv4 range where they are both ``False``.
        _public_networkTest if the address is reserved for multicast use.

        Returns:
            A boolean, True if the address is multicast.
            See RFC 3171 for details.

        _multicast_networkTest if the address is unspecified.

        Returns:
            A boolean, True if this is the unspecified address as defined in
            RFC 5735 3.

        _unspecified_addressTest if the address is a loopback address.

        Returns:
            A boolean, True if the address is a loopback per RFC 3330.

        _loopback_networkTest if the address is reserved for link-local.

        Returns:
            A boolean, True if the address is link-local per RFC 3927.

        _linklocal_networkaddress_equaladdress_lessThis class represents and manipulates 32-bit IPv4 network + addresses..

    Attributes: [examples for IPv4Network('192.0.2.0/27')]
        .network_address: IPv4Address('192.0.2.0')
        .hostmask: IPv4Address('0.0.0.31')
        .broadcast_address: IPv4Address('192.0.2.32')
        .netmask: IPv4Address('255.255.255.224')
        .prefixlen: 27

    Instantiate a new IPv4 network object.

        Args:
            address: A string or integer representing the IP [& network].
              '192.0.2.0/24'
              '192.0.2.0/255.255.255.0'
              '192.0.2.0/0.0.0.255'
              are all functionally the same in IPv4. Similarly,
              '192.0.2.1'
              '192.0.2.1/255.255.255.255'
              '192.0.2.1/32'
              are also functionally equivalent. That is to say, failing to
              provide a subnetmask will create an object with a mask of /32.

              If the mask (portion after the / in the argument) is given in
              dotted quad form, it is treated as a netmask if it starts with a
              non-zero field (e.g. /255.0.0.0 == /8) and as a hostmask if it
              starts with a zero field (e.g. 0.255.255.255 == /8), with the
              single exception of an all-zero mask which is treated as a
              netmask == /0. If no mask is given, a default of /32 is used.

              Additionally, an integer can be passed, so
              IPv4Network('192.0.2.1') == IPv4Network(3221225985)
              or, more generally
              IPv4Interface(int(IPv4Interface('192.0.2.1'))) ==
                IPv4Interface('192.0.2.1')

        Raises:
            AddressValueError: If ipaddress isn't a valid IPv4 address.
            NetmaskValueError: If the netmask isn't valid for
              an IPv4 address.
            ValueError: If strict is True and a network address is not
              supplied.
        %s has host bits setTest if this address is allocated for public networks.

        Returns:
            A boolean, True if the address is not reserved per
            iana-ipv4-special-registry.

        100.64.0.0/10_IPv4Constants169.254.0.0/16127.0.0.0/8224.0.0.0/40.0.0.0/810.0.0.0/8172.16.0.0/12192.0.0.0/24192.0.0.170/31192.0.2.0/24192.168.0.0/16198.18.0.0/15198.51.100.0/24203.0.113.0/24240.0.0.0/4255.255.255.255/32192.0.0.9/32192.0.0.10/320.0.0.0_BaseV6Base IPv6 object.

    The following methods are used by IPv6 objects in both single IP
    addresses and networks.

    _HEXTET_COUNT0123456789ABCDEFabcdef_HEX_DIGITSTurn an IPv6 ip_str into an integer.

        Args:
            ip_str: A string, the IPv6 ip_str.

        Returns:
            An int, the IPv6 address

        Raises:
            AddressValueError: if ip_str isn't a valid IPv6 Address.

        _min_partsAt least %d parts expected in %ripv4_int%x_max_partsAt most %d colons permitted in %rskip_indexAt most one '::' permitted in %rparts_hiparts_loLeading ':' only permitted as part of '::' in %rTrailing ':' only permitted as part of '::' in %rparts_skippedExpected at most %d other parts with '::' in %rExactly %d parts expected without '::' in %r_parse_hextethextet_strConvert an IPv6 hextet string into an integer.

        Args:
            hextet_str: A string, the number to parse.

        Returns:
            The hextet as an integer.

        Raises:
            ValueError: if the input isn't strictly a hex number from
              [0..FFFF].

        Only hex digits permitted in %rAt most 4 characters permitted in %r_compress_hextetshextetsCompresses a list of hextets.

        Compresses a list of strings, replacing the longest continuous
        sequence of "0" in the list with "" and adding empty strings at
        the beginning or at the end of the string such that subsequently
        calling ":".join(hextets) will produce the compressed version of
        the IPv6 address.

        Args:
            hextets: A list of strings, the hextets to compress.

        Returns:
            A list of strings.

        best_doublecolon_startbest_doublecolon_lendoublecolon_startdoublecolon_lenhextetbest_doublecolon_endTurns a 128-bit integer into hexadecimal notation.

        Args:
            ip_int: An integer, the IP address.

        Returns:
            A string, the hexadecimal representation of the address.

        Raises:
            ValueError: The address is bigger than 128 bits of all ones.

        IPv6 address is too large%032xhex_strExpand a shortened IPv6 address.

        Returns:
            A string, the expanded IPv6 address.

        Return the reverse DNS pointer name for the IPv6 address.

        This implements the method described in RFC3596 2.5.

        reverse_chars.ip6.arpa_split_scope_idHelper function to parse IPv6 string address with scope id.

        See RFC 4007 for details.

        Args:
            ip_str: A string, the IPv6 address.

        Returns:
            (addr, scope_id) tuple.

        scope_idInvalid IPv6 address: "%r"Represent and manipulate single IPv6 Addresses._scope_idInstantiate a new IPv6 address object.

        Args:
            address: A string or integer representing the IP

              Additionally, an integer can be passed, so
              IPv6Address('2001:db8::') ==
                IPv6Address(42540766411282592856903984951653826560)
              or, more generally
              IPv6Address(int(IPv6Address('2001:db8::'))) ==
                IPv6Address('2001:db8::')

        Raises:
            AddressValueError: If address isn't a valid IPv6 address.

        Identifier of a particular zone of the address's scope.

        See RFC 4007 for details.

        Returns:
            A string identifying the zone of the address if specified, else None.

        _reserved_networksis_site_localTest if the address is reserved for site-local.

        Note that the site-local address space has been deprecated by RFC 3879.
        Use is_private to test if this address is in the space of unique local
        addresses as defined by RFC 4193.

        Returns:
            A boolean, True if the address is reserved per RFC 3513 2.5.6.

        _sitelocal_networkipv4_mappedReturn the IPv4 mapped address.

        Returns:
            If the IPv6 address is a v4 mapped address, return the
            IPv4 mapped address. Return None otherwise.

        teredoTuple of embedded teredo IPs.

        Returns:
            Tuple of the (server, client) IPs or None if the address
            doesn't appear to be a teredo address (doesn't start with
            2001::/32)

        965369364480x20010000sixtofourReturn the IPv4 6to4 embedded address.

        Returns:
            The IPv4 6to4-embedded address if present or None if the
            address doesn't appear to contain a 6to4 embedded address.

        112This class represents and manipulates 128-bit IPv6 networks.

    Attributes: [examples for IPv6('2001:db8::1000/124')]
        .network_address: IPv6Address('2001:db8::1000')
        .hostmask: IPv6Address('::f')
        .broadcast_address: IPv6Address('2001:db8::100f')
        .netmask: IPv6Address('ffff:ffff:ffff:ffff:ffff:ffff:ffff:fff0')
        .prefixlen: 124

    Instantiate a new IPv6 Network object.

        Args:
            address: A string or integer representing the IPv6 network or the
              IP and prefix/netmask.
              '2001:db8::/128'
              '2001:db8:0000:0000:0000:0000:0000:0000/128'
              '2001:db8::'
              are all functionally the same in IPv6.  That is to say,
              failing to provide a subnetmask will create an object with
              a mask of /128.

              Additionally, an integer can be passed, so
              IPv6Network('2001:db8::') ==
                IPv6Network(42540766411282592856903984951653826560)
              or, more generally
              IPv6Network(int(IPv6Network('2001:db8::'))) ==
                IPv6Network('2001:db8::')

            strict: A boolean. If true, ensure that we have been passed
              A true network address, eg, 2001:db8::1000/124 and not an
              IP address on a network, eg, 2001:db8::1/124.

        Raises:
            AddressValueError: If address isn't a valid IPv6 address.
            NetmaskValueError: If the netmask isn't valid for
              an IPv6 address.
            ValueError: If strict was True and a network address was not
              supplied.
        Generate Iterator over usable hosts in a network.

          This is like __iter__ except it doesn't return the
          Subnet-Router anycast address.

        _IPv6Constantsfe80::/10ff00::/8::1/128::/128::ffff:0:0/9664:ff9b:1::/48100::/642001::/232001:db8::/322002::/16fc00::/72001:1::1/1282001:1::2/1282001:3::/322001:4:112::/482001:20::/282001:30::/28::/8100::/8200::/7400::/6800::/51000::/44000::/36000::/38000::/3A000::/3C000::/3E000::/4F000::/5F800::/6FE00::/9fec0::/10# Copyright 2007 Google Inc.# First merge# Merge consecutive subnets# Then iterate over resulting networks, skipping subsumed subnets# Since they are sorted, last.network_address <= net.network_address# is a given.# split IP addresses and networks# sort and dedup# find consecutive address ranges in the sorted sequence and summarize them# int allows a leading +/- as well as surrounding whitespace,# so we ensure that isn't the case# Parse the netmask/hostmask like an IP address.# Try matching a netmask (this would be /1*0*/ as a bitwise regexp).# Note that the two ambiguous cases (all-ones and all-zeroes) are# treated as netmasks.# Invert the bits, and try matching a /0+1+/ hostmask instead.# a packed address or integer# Assume input argument to be string or any object representation# which converts into a formatted IP prefix string.# Constructing from a tuple (addr, [mask])# Shorthand for Integer addition and subtraction. This is not# meant to ever support addition/subtraction of addresses.# Support string formatting# From here on down, support for 'bnXx'# Set some defaults# Binary is default for ipv4# Hex is default for ipv6# 0b or 0x# always false if one is v4 and the other is v6.# dealing with another network.# dealing with another address# address# Returning bare address objects (rather than interfaces) allows for# more consistent behaviour across the network address, broadcast# address and individual host addresses.# Make sure we're comparing the network of other.# If we got here, there's a bug somewhere.# does this need to raise a ValueError?# self._version == other._version below here:# self.network_address == other.network_address below here:# Always false if one is v4 and the other is v6.# Equivalent to 255.255.255.255 or 32 bits of 1's.# There are only a handful of valid v4 netmasks, so we cache them all# when constructed (see _make_netmask()).# Check for a netmask in prefix length form# Check for a netmask or hostmask in dotted-quad form.# This may raise NetmaskValueError.# Reject non-ASCII digits.# We do the length check second, since the invalid character error# is likely to be more informative for the user# Handle leading zeros as strict as glibc's inet_pton()# See security bug bpo-36384# Convert to integer (we know digits are legal)# Efficient constructor from integer.# Constructing from a packed address# which converts into a formatted IP string.# An interface with an associated network is NOT the# same as an unassociated address. That's why the hash# takes the extra info into account.# We *do* allow addresses and interfaces to be sorted. The# unassociated address is considered less than all interfaces.# Class to use when creating address objects# Not globally reachable address blocks listed on# https://www.iana.org/assignments/iana-ipv4-special-registry/iana-ipv4-special-registry.xhtml# There are only a bunch of valid v6 netmasks, so we cache them all# An IPv6 address needs at least 2 colons (3 parts).# If the address has an IPv4-style suffix, convert it to hexadecimal.# An IPv6 address can't have more than 8 colons (9 parts).# The extra colon comes from using the "::" notation for a single# leading or trailing zero part.# Disregarding the endpoints, find '::' with nothing in between.# This indicates that a run of zeroes has been skipped.# Can't have more than one '::'# parts_hi is the number of parts to copy from above/before the '::'# parts_lo is the number of parts to copy from below/after the '::'# If we found a '::', then check if it also covers the endpoints.# ^: requires ^::# :$ requires ::$# Otherwise, allocate the entire address to parts_hi.  The# endpoints could still be empty, but _parse_hextet() will check# for that.# Now, parse the hextets into a 128-bit integer.# Length check means we can skip checking the integer value# Start of a sequence of zeros.# This is the longest sequence of zeros so far.# For zeros at the end of the address.# For zeros at the beginning of the address.# https://www.iana.org/assignments/iana-ipv6-special-registry/iana-ipv6-special-registry.xhtml# IANA says N/A, let's consider it not globally reachable to be safeb'A fast, lightweight IPv4/IPv6 manipulation library in Python.

This library is used to create/poke/manipulate IPv4 and IPv6 addresses
and networks.

'u'A fast, lightweight IPv4/IPv6 manipulation library in Python.

This library is used to create/poke/manipulate IPv4 and IPv6 addresses
and networks.

'b'1.0'u'1.0'b'A Value Error related to the address.'u'A Value Error related to the address.'b'A Value Error related to the netmask.'u'A Value Error related to the netmask.'b'Take an IP string/int and return an object of the correct type.

    Args:
        address: A string or integer, the IP address.  Either IPv4 or
          IPv6 addresses may be supplied; integers less than 2**32 will
          be considered to be IPv4 by default.

    Returns:
        An IPv4Address or IPv6Address object.

    Raises:
        ValueError: if the *address* passed isn't either a v4 or a v6
          address

    'u'Take an IP string/int and return an object of the correct type.

    Args:
        address: A string or integer, the IP address.  Either IPv4 or
          IPv6 addresses may be supplied; integers less than 2**32 will
          be considered to be IPv4 by default.

    Returns:
        An IPv4Address or IPv6Address object.

    Raises:
        ValueError: if the *address* passed isn't either a v4 or a v6
          address

    'b' does not appear to be an IPv4 or IPv6 address'u' does not appear to be an IPv4 or IPv6 address'b'Take an IP string/int and return an object of the correct type.

    Args:
        address: A string or integer, the IP network.  Either IPv4 or
          IPv6 networks may be supplied; integers less than 2**32 will
          be considered to be IPv4 by default.

    Returns:
        An IPv4Network or IPv6Network object.

    Raises:
        ValueError: if the string passed isn't either a v4 or a v6
          address. Or if the network has host bits set.

    'u'Take an IP string/int and return an object of the correct type.

    Args:
        address: A string or integer, the IP network.  Either IPv4 or
          IPv6 networks may be supplied; integers less than 2**32 will
          be considered to be IPv4 by default.

    Returns:
        An IPv4Network or IPv6Network object.

    Raises:
        ValueError: if the string passed isn't either a v4 or a v6
          address. Or if the network has host bits set.

    'b' does not appear to be an IPv4 or IPv6 network'u' does not appear to be an IPv4 or IPv6 network'b'Take an IP string/int and return an object of the correct type.

    Args:
        address: A string or integer, the IP address.  Either IPv4 or
          IPv6 addresses may be supplied; integers less than 2**32 will
          be considered to be IPv4 by default.

    Returns:
        An IPv4Interface or IPv6Interface object.

    Raises:
        ValueError: if the string passed isn't either a v4 or a v6
          address.

    Notes:
        The IPv?Interface classes describe an Address on a particular
        Network, so they're basically a combination of both the Address
        and Network classes.

    'u'Take an IP string/int and return an object of the correct type.

    Args:
        address: A string or integer, the IP address.  Either IPv4 or
          IPv6 addresses may be supplied; integers less than 2**32 will
          be considered to be IPv4 by default.

    Returns:
        An IPv4Interface or IPv6Interface object.

    Raises:
        ValueError: if the string passed isn't either a v4 or a v6
          address.

    Notes:
        The IPv?Interface classes describe an Address on a particular
        Network, so they're basically a combination of both the Address
        and Network classes.

    'b' does not appear to be an IPv4 or IPv6 interface'u' does not appear to be an IPv4 or IPv6 interface'b'Represent an address as 4 packed bytes in network (big-endian) order.

    Args:
        address: An integer representation of an IPv4 IP address.

    Returns:
        The integer address packed as 4 bytes in network (big-endian) order.

    Raises:
        ValueError: If the integer is negative or too large to be an
          IPv4 IP address.

    'u'Represent an address as 4 packed bytes in network (big-endian) order.

    Args:
        address: An integer representation of an IPv4 IP address.

    Returns:
        The integer address packed as 4 bytes in network (big-endian) order.

    Raises:
        ValueError: If the integer is negative or too large to be an
          IPv4 IP address.

    'b'Address negative or too large for IPv4'u'Address negative or too large for IPv4'b'Represent an address as 16 packed bytes in network (big-endian) order.

    Args:
        address: An integer representation of an IPv6 IP address.

    Returns:
        The integer address packed as 16 bytes in network (big-endian) order.

    'u'Represent an address as 16 packed bytes in network (big-endian) order.

    Args:
        address: An integer representation of an IPv6 IP address.

    Returns:
        The integer address packed as 16 bytes in network (big-endian) order.

    'b'Address negative or too large for IPv6'u'Address negative or too large for IPv6'b'Helper to split the netmask and raise AddressValueError if needed'u'Helper to split the netmask and raise AddressValueError if needed'b'Only one '/' permitted in 'u'Only one '/' permitted in 'b'Find a sequence of sorted deduplicated IPv#Address.

    Args:
        addresses: a list of IPv#Address objects.

    Yields:
        A tuple containing the first and last IP addresses in the sequence.

    'u'Find a sequence of sorted deduplicated IPv#Address.

    Args:
        addresses: a list of IPv#Address objects.

    Yields:
        A tuple containing the first and last IP addresses in the sequence.

    'b'Count the number of zero bits on the right hand side.

    Args:
        number: an integer.
        bits: maximum number of bits to count.

    Returns:
        The number of zero bits on the right hand side of the number.

    'u'Count the number of zero bits on the right hand side.

    Args:
        number: an integer.
        bits: maximum number of bits to count.

    Returns:
        The number of zero bits on the right hand side of the number.

    'b'Summarize a network range given the first and last IP addresses.

    Example:
        >>> list(summarize_address_range(IPv4Address('192.0.2.0'),
        ...                              IPv4Address('192.0.2.130')))
        ...                                #doctest: +NORMALIZE_WHITESPACE
        [IPv4Network('192.0.2.0/25'), IPv4Network('192.0.2.128/31'),
         IPv4Network('192.0.2.130/32')]

    Args:
        first: the first IPv4Address or IPv6Address in the range.
        last: the last IPv4Address or IPv6Address in the range.

    Returns:
        An iterator of the summarized IPv(4|6) network objects.

    Raise:
        TypeError:
            If the first and last objects are not IP addresses.
            If the first and last objects are not the same version.
        ValueError:
            If the last object is not greater than the first.
            If the version of the first address is not 4 or 6.

    'u'Summarize a network range given the first and last IP addresses.

    Example:
        >>> list(summarize_address_range(IPv4Address('192.0.2.0'),
        ...                              IPv4Address('192.0.2.130')))
        ...                                #doctest: +NORMALIZE_WHITESPACE
        [IPv4Network('192.0.2.0/25'), IPv4Network('192.0.2.128/31'),
         IPv4Network('192.0.2.130/32')]

    Args:
        first: the first IPv4Address or IPv6Address in the range.
        last: the last IPv4Address or IPv6Address in the range.

    Returns:
        An iterator of the summarized IPv(4|6) network objects.

    Raise:
        TypeError:
            If the first and last objects are not IP addresses.
            If the first and last objects are not the same version.
        ValueError:
            If the last object is not greater than the first.
            If the version of the first address is not 4 or 6.

    'b'first and last must be IP addresses, not networks'u'first and last must be IP addresses, not networks'b'%s and %s are not of the same version'u'%s and %s are not of the same version'b'last IP address must be greater than first'u'last IP address must be greater than first'b'unknown IP version'u'unknown IP version'b'Loops through the addresses, collapsing concurrent netblocks.

    Example:

        ip1 = IPv4Network('192.0.2.0/26')
        ip2 = IPv4Network('192.0.2.64/26')
        ip3 = IPv4Network('192.0.2.128/26')
        ip4 = IPv4Network('192.0.2.192/26')

        _collapse_addresses_internal([ip1, ip2, ip3, ip4]) ->
          [IPv4Network('192.0.2.0/24')]

        This shouldn't be called directly; it is called via
          collapse_addresses([]).

    Args:
        addresses: A list of IPv4Network's or IPv6Network's

    Returns:
        A list of IPv4Network's or IPv6Network's depending on what we were
        passed.

    'u'Loops through the addresses, collapsing concurrent netblocks.

    Example:

        ip1 = IPv4Network('192.0.2.0/26')
        ip2 = IPv4Network('192.0.2.64/26')
        ip3 = IPv4Network('192.0.2.128/26')
        ip4 = IPv4Network('192.0.2.192/26')

        _collapse_addresses_internal([ip1, ip2, ip3, ip4]) ->
          [IPv4Network('192.0.2.0/24')]

        This shouldn't be called directly; it is called via
          collapse_addresses([]).

    Args:
        addresses: A list of IPv4Network's or IPv6Network's

    Returns:
        A list of IPv4Network's or IPv6Network's depending on what we were
        passed.

    'b'Collapse a list of IP objects.

    Example:
        collapse_addresses([IPv4Network('192.0.2.0/25'),
                            IPv4Network('192.0.2.128/25')]) ->
                           [IPv4Network('192.0.2.0/24')]

    Args:
        addresses: An iterator of IPv4Network or IPv6Network objects.

    Returns:
        An iterator of the collapsed IPv(4|6)Network objects.

    Raises:
        TypeError: If passed a list of mixed version objects.

    'u'Collapse a list of IP objects.

    Example:
        collapse_addresses([IPv4Network('192.0.2.0/25'),
                            IPv4Network('192.0.2.128/25')]) ->
                           [IPv4Network('192.0.2.0/24')]

    Args:
        addresses: An iterator of IPv4Network or IPv6Network objects.

    Returns:
        An iterator of the collapsed IPv(4|6)Network objects.

    Raises:
        TypeError: If passed a list of mixed version objects.

    'b'Return a key suitable for sorting between networks and addresses.

    Address and Network objects are not sortable by default; they're
    fundamentally different so the expression

        IPv4Address('192.0.2.0') <= IPv4Network('192.0.2.0/24')

    doesn't make any sense.  There are some times however, where you may wish
    to have ipaddress sort these for you anyway. If you need to do this, you
    can use this function as the key= argument to sorted().

    Args:
      obj: either a Network or Address object.
    Returns:
      appropriate key.

    'u'Return a key suitable for sorting between networks and addresses.

    Address and Network objects are not sortable by default; they're
    fundamentally different so the expression

        IPv4Address('192.0.2.0') <= IPv4Network('192.0.2.0/24')

    doesn't make any sense.  There are some times however, where you may wish
    to have ipaddress sort these for you anyway. If you need to do this, you
    can use this function as the key= argument to sorted().

    Args:
      obj: either a Network or Address object.
    Returns:
      appropriate key.

    'b'The mother class.'u'The mother class.'b'Return the longhand version of the IP address as a string.'u'Return the longhand version of the IP address as a string.'b'Return the shorthand version of the IP address as a string.'u'Return the shorthand version of the IP address as a string.'b'The name of the reverse DNS pointer for the IP address, e.g.:
            >>> ipaddress.ip_address("127.0.0.1").reverse_pointer
            '1.0.0.127.in-addr.arpa'
            >>> ipaddress.ip_address("2001:db8::1").reverse_pointer
            '1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.8.b.d.0.1.0.0.2.ip6.arpa'

        'u'The name of the reverse DNS pointer for the IP address, e.g.:
            >>> ipaddress.ip_address("127.0.0.1").reverse_pointer
            '1.0.0.127.in-addr.arpa'
            >>> ipaddress.ip_address("2001:db8::1").reverse_pointer
            '1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.8.b.d.0.1.0.0.2.ip6.arpa'

        'b'%200s has no version specified'u'%200s has no version specified'b'%d (< 0) is not permitted as an IPv%d address'u'%d (< 0) is not permitted as an IPv%d address'b'%d (>= 2**%d) is not permitted as an IPv%d address'u'%d (>= 2**%d) is not permitted as an IPv%d address'b'%r (len %d != %d) is not permitted as an IPv%d address'u'%r (len %d != %d) is not permitted as an IPv%d address'b'Turn the prefix length into a bitwise netmask

        Args:
            prefixlen: An integer, the prefix length.

        Returns:
            An integer.

        'u'Turn the prefix length into a bitwise netmask

        Args:
            prefixlen: An integer, the prefix length.

        Returns:
            An integer.

        'b'Return prefix length from the bitwise netmask.

        Args:
            ip_int: An integer, the netmask in expanded bitwise format

        Returns:
            An integer, the prefix length.

        Raises:
            ValueError: If the input intermingles zeroes & ones
        'u'Return prefix length from the bitwise netmask.

        Args:
            ip_int: An integer, the netmask in expanded bitwise format

        Returns:
            An integer, the prefix length.

        Raises:
            ValueError: If the input intermingles zeroes & ones
        'b'big'u'big'b'Netmask pattern %r mixes zeroes & ones'u'Netmask pattern %r mixes zeroes & ones'b'%r is not a valid netmask'u'%r is not a valid netmask'b'Return prefix length from a numeric string

        Args:
            prefixlen_str: The string to be converted

        Returns:
            An integer, the prefix length.

        Raises:
            NetmaskValueError: If the input is not a valid netmask
        'u'Return prefix length from a numeric string

        Args:
            prefixlen_str: The string to be converted

        Returns:
            An integer, the prefix length.

        Raises:
            NetmaskValueError: If the input is not a valid netmask
        'b'Turn a netmask/hostmask string into a prefix length

        Args:
            ip_str: The netmask/hostmask to be converted

        Returns:
            An integer, the prefix length.

        Raises:
            NetmaskValueError: If the input is not a valid netmask/hostmask
        'u'Turn a netmask/hostmask string into a prefix length

        Args:
            ip_str: The netmask/hostmask to be converted

        Returns:
            An integer, the prefix length.

        Raises:
            NetmaskValueError: If the input is not a valid netmask/hostmask
        'b'Helper function to parse address of Network/Interface.

        Arg:
            address: Argument of Network/Interface.

        Returns:
            (addr, prefix) tuple.
        'u'Helper function to parse address of Network/Interface.

        Arg:
            address: Argument of Network/Interface.

        Returns:
            (addr, prefix) tuple.
        'b'A generic IP object.

    This IP class contains the version independent methods which are
    used by single IP addresses.
    'u'A generic IP object.

    This IP class contains the version independent methods which are
    used by single IP addresses.
    'b'Returns an IP address as a formatted string.

        Supported presentation types are:
        's': returns the IP address as a string (default)
        'b': converts to binary and returns a zero-padded string
        'X' or 'x': converts to upper- or lower-case hex and returns a zero-padded string
        'n': the same as 'b' for IPv4 and 'x' for IPv6

        For binary and hex presentation types, the alternate form specifier
        '#' and the grouping option '_' are supported.
        'u'Returns an IP address as a formatted string.

        Supported presentation types are:
        's': returns the IP address as a string (default)
        'b': converts to binary and returns a zero-padded string
        'X' or 'x': converts to upper- or lower-case hex and returns a zero-padded string
        'n': the same as 'b' for IPv4 and 'x' for IPv6

        For binary and hex presentation types, the alternate form specifier
        '#' and the grouping option '_' are supported.
        'b'(#?)(_?)([xbnX])'u'(#?)(_?)([xbnX])'b'A generic IP network object.

    This IP class contains the version independent methods which are
    used by networks.
    'u'A generic IP network object.

    This IP class contains the version independent methods which are
    used by networks.
    'b'%s/%d'u'%s/%d'b'Generate Iterator over usable hosts in a network.

        This is like __iter__ except it doesn't return the network
        or broadcast addresses.

        'u'Generate Iterator over usable hosts in a network.

        This is like __iter__ except it doesn't return the network
        or broadcast addresses.

        'b'address out of range'u'address out of range'b'Tell if self is partly contained in other.'u'Tell if self is partly contained in other.'b'Number of hosts in the current subnet.'u'Number of hosts in the current subnet.'b'%200s has no associated address class'u'%200s has no associated address class'b'Remove an address from a larger block.

        For example:

            addr1 = ip_network('192.0.2.0/28')
            addr2 = ip_network('192.0.2.1/32')
            list(addr1.address_exclude(addr2)) =
                [IPv4Network('192.0.2.0/32'), IPv4Network('192.0.2.2/31'),
                 IPv4Network('192.0.2.4/30'), IPv4Network('192.0.2.8/29')]

        or IPv6:

            addr1 = ip_network('2001:db8::1/32')
            addr2 = ip_network('2001:db8::1/128')
            list(addr1.address_exclude(addr2)) =
                [ip_network('2001:db8::1/128'),
                 ip_network('2001:db8::2/127'),
                 ip_network('2001:db8::4/126'),
                 ip_network('2001:db8::8/125'),
                 ...
                 ip_network('2001:db8:8000::/33')]

        Args:
            other: An IPv4Network or IPv6Network object of the same type.

        Returns:
            An iterator of the IPv(4|6)Network objects which is self
            minus other.

        Raises:
            TypeError: If self and other are of differing address
              versions, or if other is not a network object.
            ValueError: If other is not completely contained by self.

        'u'Remove an address from a larger block.

        For example:

            addr1 = ip_network('192.0.2.0/28')
            addr2 = ip_network('192.0.2.1/32')
            list(addr1.address_exclude(addr2)) =
                [IPv4Network('192.0.2.0/32'), IPv4Network('192.0.2.2/31'),
                 IPv4Network('192.0.2.4/30'), IPv4Network('192.0.2.8/29')]

        or IPv6:

            addr1 = ip_network('2001:db8::1/32')
            addr2 = ip_network('2001:db8::1/128')
            list(addr1.address_exclude(addr2)) =
                [ip_network('2001:db8::1/128'),
                 ip_network('2001:db8::2/127'),
                 ip_network('2001:db8::4/126'),
                 ip_network('2001:db8::8/125'),
                 ...
                 ip_network('2001:db8:8000::/33')]

        Args:
            other: An IPv4Network or IPv6Network object of the same type.

        Returns:
            An iterator of the IPv(4|6)Network objects which is self
            minus other.

        Raises:
            TypeError: If self and other are of differing address
              versions, or if other is not a network object.
            ValueError: If other is not completely contained by self.

        'b'%s is not a network object'u'%s is not a network object'b'%s not contained in %s'u'%s not contained in %s'b'Error performing exclusion: s1: %s s2: %s other: %s'u'Error performing exclusion: s1: %s s2: %s other: %s'b'Compare two IP objects.

        This is only concerned about the comparison of the integer
        representation of the network addresses.  This means that the
        host bits aren't considered at all in this method.  If you want
        to compare host bits, you can easily enough do a
        'HostA._ip < HostB._ip'

        Args:
            other: An IP object.

        Returns:
            If the IP versions of self and other are the same, returns:

            -1 if self < other:
              eg: IPv4Network('192.0.2.0/25') < IPv4Network('192.0.2.128/25')
              IPv6Network('2001:db8::1000/124') <
                  IPv6Network('2001:db8::2000/124')
            0 if self == other
              eg: IPv4Network('192.0.2.0/24') == IPv4Network('192.0.2.0/24')
              IPv6Network('2001:db8::1000/124') ==
                  IPv6Network('2001:db8::1000/124')
            1 if self > other
              eg: IPv4Network('192.0.2.128/25') > IPv4Network('192.0.2.0/25')
                  IPv6Network('2001:db8::2000/124') >
                      IPv6Network('2001:db8::1000/124')

          Raises:
              TypeError if the IP versions are different.

        'u'Compare two IP objects.

        This is only concerned about the comparison of the integer
        representation of the network addresses.  This means that the
        host bits aren't considered at all in this method.  If you want
        to compare host bits, you can easily enough do a
        'HostA._ip < HostB._ip'

        Args:
            other: An IP object.

        Returns:
            If the IP versions of self and other are the same, returns:

            -1 if self < other:
              eg: IPv4Network('192.0.2.0/25') < IPv4Network('192.0.2.128/25')
              IPv6Network('2001:db8::1000/124') <
                  IPv6Network('2001:db8::2000/124')
            0 if self == other
              eg: IPv4Network('192.0.2.0/24') == IPv4Network('192.0.2.0/24')
              IPv6Network('2001:db8::1000/124') ==
                  IPv6Network('2001:db8::1000/124')
            1 if self > other
              eg: IPv4Network('192.0.2.128/25') > IPv4Network('192.0.2.0/25')
                  IPv6Network('2001:db8::2000/124') >
                      IPv6Network('2001:db8::1000/124')

          Raises:
              TypeError if the IP versions are different.

        'b'%s and %s are not of the same type'u'%s and %s are not of the same type'b'Network-only key function.

        Returns an object that identifies this address' network and
        netmask. This function is a suitable "key" argument for sorted()
        and list.sort().

        'u'Network-only key function.

        Returns an object that identifies this address' network and
        netmask. This function is a suitable "key" argument for sorted()
        and list.sort().

        'b'The subnets which join to make the current subnet.

        In the case that self contains only one IP
        (self._prefixlen == 32 for IPv4 or self._prefixlen == 128
        for IPv6), yield an iterator with just ourself.

        Args:
            prefixlen_diff: An integer, the amount the prefix length
              should be increased by. This should not be set if
              new_prefix is also set.
            new_prefix: The desired new prefix length. This must be a
              larger number (smaller prefix) than the existing prefix.
              This should not be set if prefixlen_diff is also set.

        Returns:
            An iterator of IPv(4|6) objects.

        Raises:
            ValueError: The prefixlen_diff is too small or too large.
                OR
            prefixlen_diff and new_prefix are both set or new_prefix
              is a smaller number than the current prefix (smaller
              number means a larger network)

        'u'The subnets which join to make the current subnet.

        In the case that self contains only one IP
        (self._prefixlen == 32 for IPv4 or self._prefixlen == 128
        for IPv6), yield an iterator with just ourself.

        Args:
            prefixlen_diff: An integer, the amount the prefix length
              should be increased by. This should not be set if
              new_prefix is also set.
            new_prefix: The desired new prefix length. This must be a
              larger number (smaller prefix) than the existing prefix.
              This should not be set if prefixlen_diff is also set.

        Returns:
            An iterator of IPv(4|6) objects.

        Raises:
            ValueError: The prefixlen_diff is too small or too large.
                OR
            prefixlen_diff and new_prefix are both set or new_prefix
              is a smaller number than the current prefix (smaller
              number means a larger network)

        'b'new prefix must be longer'u'new prefix must be longer'b'cannot set prefixlen_diff and new_prefix'u'cannot set prefixlen_diff and new_prefix'b'prefix length diff must be > 0'u'prefix length diff must be > 0'b'prefix length diff %d is invalid for netblock %s'u'prefix length diff %d is invalid for netblock %s'b'The supernet containing the current network.

        Args:
            prefixlen_diff: An integer, the amount the prefix length of
              the network should be decreased by.  For example, given a
              /24 network and a prefixlen_diff of 3, a supernet with a
              /21 netmask is returned.

        Returns:
            An IPv4 network object.

        Raises:
            ValueError: If self.prefixlen - prefixlen_diff < 0. I.e., you have
              a negative prefix length.
                OR
            If prefixlen_diff and new_prefix are both set or new_prefix is a
              larger number than the current prefix (larger number means a
              smaller network)

        'u'The supernet containing the current network.

        Args:
            prefixlen_diff: An integer, the amount the prefix length of
              the network should be decreased by.  For example, given a
              /24 network and a prefixlen_diff of 3, a supernet with a
              /21 netmask is returned.

        Returns:
            An IPv4 network object.

        Raises:
            ValueError: If self.prefixlen - prefixlen_diff < 0. I.e., you have
              a negative prefix length.
                OR
            If prefixlen_diff and new_prefix are both set or new_prefix is a
              larger number than the current prefix (larger number means a
              smaller network)

        'b'new prefix must be shorter'u'new prefix must be shorter'b'current prefixlen is %d, cannot have a prefixlen_diff of %d'u'current prefixlen is %d, cannot have a prefixlen_diff of %d'b'Test if the address is reserved for multicast use.

        Returns:
            A boolean, True if the address is a multicast address.
            See RFC 2373 2.7 for details.

        'u'Test if the address is reserved for multicast use.

        Returns:
            A boolean, True if the address is a multicast address.
            See RFC 2373 2.7 for details.

        'b' are not of the same version'u' are not of the same version'b'Unable to test subnet containment between 'u'Unable to test subnet containment between 'b'Return True if this network is a subnet of other.'u'Return True if this network is a subnet of other.'b'Return True if this network is a supernet of other.'u'Return True if this network is a supernet of other.'b'Test if the address is otherwise IETF reserved.

        Returns:
            A boolean, True if the address is within one of the
            reserved IPv6 Network ranges.

        'u'Test if the address is otherwise IETF reserved.

        Returns:
            A boolean, True if the address is within one of the
            reserved IPv6 Network ranges.

        'b'Test if the address is reserved for link-local.

        Returns:
            A boolean, True if the address is reserved per RFC 4291.

        'u'Test if the address is reserved for link-local.

        Returns:
            A boolean, True if the address is reserved per RFC 4291.

        'b'Test if this network belongs to a private range.

        Returns:
            A boolean, True if the network is reserved per
            iana-ipv4-special-registry or iana-ipv6-special-registry.

        'u'Test if this network belongs to a private range.

        Returns:
            A boolean, True if the network is reserved per
            iana-ipv4-special-registry or iana-ipv6-special-registry.

        'b'Test if this address is allocated for public networks.

        Returns:
            A boolean, True if the address is not reserved per
            iana-ipv4-special-registry or iana-ipv6-special-registry.

        'u'Test if this address is allocated for public networks.

        Returns:
            A boolean, True if the address is not reserved per
            iana-ipv4-special-registry or iana-ipv6-special-registry.

        'b'Test if the address is unspecified.

        Returns:
            A boolean, True if this is the unspecified address as defined in
            RFC 2373 2.5.2.

        'u'Test if the address is unspecified.

        Returns:
            A boolean, True if this is the unspecified address as defined in
            RFC 2373 2.5.2.

        'b'Test if the address is a loopback address.

        Returns:
            A boolean, True if the address is a loopback address as defined in
            RFC 2373 2.5.3.

        'u'Test if the address is a loopback address.

        Returns:
            A boolean, True if the address is a loopback address as defined in
            RFC 2373 2.5.3.

        'b'Base IPv4 object.

    The following methods are used by IPv4 objects in both single IP
    addresses and networks.

    'u'Base IPv4 object.

    The following methods are used by IPv4 objects in both single IP
    addresses and networks.

    'b'Make a (netmask, prefix_len) tuple from the given argument.

        Argument can be:
        - an integer (the prefix length)
        - a string representing the prefix length (e.g. "24")
        - a string representing the prefix netmask (e.g. "255.255.255.0")
        'u'Make a (netmask, prefix_len) tuple from the given argument.

        Argument can be:
        - an integer (the prefix length)
        - a string representing the prefix length (e.g. "24")
        - a string representing the prefix netmask (e.g. "255.255.255.0")
        'b'Turn the given IP string into an integer for comparison.

        Args:
            ip_str: A string, the IP ip_str.

        Returns:
            The IP ip_str as an integer.

        Raises:
            AddressValueError: if ip_str isn't a valid IPv4 Address.

        'u'Turn the given IP string into an integer for comparison.

        Args:
            ip_str: A string, the IP ip_str.

        Returns:
            The IP ip_str as an integer.

        Raises:
            AddressValueError: if ip_str isn't a valid IPv4 Address.

        'b'Address cannot be empty'u'Address cannot be empty'b'Expected 4 octets in %r'u'Expected 4 octets in %r'b'%s in %r'u'%s in %r'b'Convert a decimal octet into an integer.

        Args:
            octet_str: A string, the number to parse.

        Returns:
            The octet as an integer.

        Raises:
            ValueError: if the octet isn't strictly a decimal from [0..255].

        'u'Convert a decimal octet into an integer.

        Args:
            octet_str: A string, the number to parse.

        Returns:
            The octet as an integer.

        Raises:
            ValueError: if the octet isn't strictly a decimal from [0..255].

        'b'Empty octet not permitted'u'Empty octet not permitted'b'Only decimal digits permitted in %r'u'Only decimal digits permitted in %r'b'At most 3 characters permitted in %r'u'At most 3 characters permitted in %r'b'Leading zeros are not permitted in %r'u'Leading zeros are not permitted in %r'b'Octet %d (> 255) not permitted'u'Octet %d (> 255) not permitted'b'Turns a 32-bit integer into dotted decimal notation.

        Args:
            ip_int: An integer, the IP address.

        Returns:
            The IP address as a string in dotted decimal notation.

        'u'Turns a 32-bit integer into dotted decimal notation.

        Args:
            ip_int: An integer, the IP address.

        Returns:
            The IP address as a string in dotted decimal notation.

        'b'Return the reverse DNS pointer name for the IPv4 address.

        This implements the method described in RFC1035 3.5.

        'u'Return the reverse DNS pointer name for the IPv4 address.

        This implements the method described in RFC1035 3.5.

        'b'.in-addr.arpa'u'.in-addr.arpa'b'Represent and manipulate single IPv4 Addresses.'u'Represent and manipulate single IPv4 Addresses.'b'_ip'u'_ip'b'
        Args:
            address: A string or integer representing the IP

              Additionally, an integer can be passed, so
              IPv4Address('192.0.2.1') == IPv4Address(3221225985).
              or, more generally
              IPv4Address(int(IPv4Address('192.0.2.1'))) ==
                IPv4Address('192.0.2.1')

        Raises:
            AddressValueError: If ipaddress isn't a valid IPv4 address.

        'u'
        Args:
            address: A string or integer representing the IP

              Additionally, an integer can be passed, so
              IPv4Address('192.0.2.1') == IPv4Address(3221225985).
              or, more generally
              IPv4Address(int(IPv4Address('192.0.2.1'))) ==
                IPv4Address('192.0.2.1')

        Raises:
            AddressValueError: If ipaddress isn't a valid IPv4 address.

        'b'Unexpected '/' in 'u'Unexpected '/' in 'b'The binary representation of this address.'u'The binary representation of this address.'b'Test if the address is otherwise IETF reserved.

         Returns:
             A boolean, True if the address is within the
             reserved IPv4 Network range.

        'u'Test if the address is otherwise IETF reserved.

         Returns:
             A boolean, True if the address is within the
             reserved IPv4 Network range.

        'b'``True`` if the address is defined as not globally reachable by
        iana-ipv4-special-registry_ (for IPv4) or iana-ipv6-special-registry_
        (for IPv6) with the following exceptions:

        * ``is_private`` is ``False`` for ``100.64.0.0/10``
        * For IPv4-mapped IPv6-addresses the ``is_private`` value is determined by the
            semantics of the underlying IPv4 addresses and the following condition holds
            (see :attr:`IPv6Address.ipv4_mapped`)::

                address.is_private == address.ipv4_mapped.is_private

        ``is_private`` has value opposite to :attr:`is_global`, except for the ``100.64.0.0/10``
        IPv4 range where they are both ``False``.
        'u'``True`` if the address is defined as not globally reachable by
        iana-ipv4-special-registry_ (for IPv4) or iana-ipv6-special-registry_
        (for IPv6) with the following exceptions:

        * ``is_private`` is ``False`` for ``100.64.0.0/10``
        * For IPv4-mapped IPv6-addresses the ``is_private`` value is determined by the
            semantics of the underlying IPv4 addresses and the following condition holds
            (see :attr:`IPv6Address.ipv4_mapped`)::

                address.is_private == address.ipv4_mapped.is_private

        ``is_private`` has value opposite to :attr:`is_global`, except for the ``100.64.0.0/10``
        IPv4 range where they are both ``False``.
        'b'``True`` if the address is defined as globally reachable by
        iana-ipv4-special-registry_ (for IPv4) or iana-ipv6-special-registry_
        (for IPv6) with the following exception:

        For IPv4-mapped IPv6-addresses the ``is_private`` value is determined by the
        semantics of the underlying IPv4 addresses and the following condition holds
        (see :attr:`IPv6Address.ipv4_mapped`)::

            address.is_global == address.ipv4_mapped.is_global

        ``is_global`` has value opposite to :attr:`is_private`, except for the ``100.64.0.0/10``
        IPv4 range where they are both ``False``.
        'u'``True`` if the address is defined as globally reachable by
        iana-ipv4-special-registry_ (for IPv4) or iana-ipv6-special-registry_
        (for IPv6) with the following exception:

        For IPv4-mapped IPv6-addresses the ``is_private`` value is determined by the
        semantics of the underlying IPv4 addresses and the following condition holds
        (see :attr:`IPv6Address.ipv4_mapped`)::

            address.is_global == address.ipv4_mapped.is_global

        ``is_global`` has value opposite to :attr:`is_private`, except for the ``100.64.0.0/10``
        IPv4 range where they are both ``False``.
        'b'Test if the address is reserved for multicast use.

        Returns:
            A boolean, True if the address is multicast.
            See RFC 3171 for details.

        'u'Test if the address is reserved for multicast use.

        Returns:
            A boolean, True if the address is multicast.
            See RFC 3171 for details.

        'b'Test if the address is unspecified.

        Returns:
            A boolean, True if this is the unspecified address as defined in
            RFC 5735 3.

        'u'Test if the address is unspecified.

        Returns:
            A boolean, True if this is the unspecified address as defined in
            RFC 5735 3.

        'b'Test if the address is a loopback address.

        Returns:
            A boolean, True if the address is a loopback per RFC 3330.

        'u'Test if the address is a loopback address.

        Returns:
            A boolean, True if the address is a loopback per RFC 3330.

        'b'Test if the address is reserved for link-local.

        Returns:
            A boolean, True if the address is link-local per RFC 3927.

        'u'Test if the address is reserved for link-local.

        Returns:
            A boolean, True if the address is link-local per RFC 3927.

        'b'This class represents and manipulates 32-bit IPv4 network + addresses..

    Attributes: [examples for IPv4Network('192.0.2.0/27')]
        .network_address: IPv4Address('192.0.2.0')
        .hostmask: IPv4Address('0.0.0.31')
        .broadcast_address: IPv4Address('192.0.2.32')
        .netmask: IPv4Address('255.255.255.224')
        .prefixlen: 27

    'u'This class represents and manipulates 32-bit IPv4 network + addresses..

    Attributes: [examples for IPv4Network('192.0.2.0/27')]
        .network_address: IPv4Address('192.0.2.0')
        .hostmask: IPv4Address('0.0.0.31')
        .broadcast_address: IPv4Address('192.0.2.32')
        .netmask: IPv4Address('255.255.255.224')
        .prefixlen: 27

    'b'Instantiate a new IPv4 network object.

        Args:
            address: A string or integer representing the IP [& network].
              '192.0.2.0/24'
              '192.0.2.0/255.255.255.0'
              '192.0.2.0/0.0.0.255'
              are all functionally the same in IPv4. Similarly,
              '192.0.2.1'
              '192.0.2.1/255.255.255.255'
              '192.0.2.1/32'
              are also functionally equivalent. That is to say, failing to
              provide a subnetmask will create an object with a mask of /32.

              If the mask (portion after the / in the argument) is given in
              dotted quad form, it is treated as a netmask if it starts with a
              non-zero field (e.g. /255.0.0.0 == /8) and as a hostmask if it
              starts with a zero field (e.g. 0.255.255.255 == /8), with the
              single exception of an all-zero mask which is treated as a
              netmask == /0. If no mask is given, a default of /32 is used.

              Additionally, an integer can be passed, so
              IPv4Network('192.0.2.1') == IPv4Network(3221225985)
              or, more generally
              IPv4Interface(int(IPv4Interface('192.0.2.1'))) ==
                IPv4Interface('192.0.2.1')

        Raises:
            AddressValueError: If ipaddress isn't a valid IPv4 address.
            NetmaskValueError: If the netmask isn't valid for
              an IPv4 address.
            ValueError: If strict is True and a network address is not
              supplied.
        'u'Instantiate a new IPv4 network object.

        Args:
            address: A string or integer representing the IP [& network].
              '192.0.2.0/24'
              '192.0.2.0/255.255.255.0'
              '192.0.2.0/0.0.0.255'
              are all functionally the same in IPv4. Similarly,
              '192.0.2.1'
              '192.0.2.1/255.255.255.255'
              '192.0.2.1/32'
              are also functionally equivalent. That is to say, failing to
              provide a subnetmask will create an object with a mask of /32.

              If the mask (portion after the / in the argument) is given in
              dotted quad form, it is treated as a netmask if it starts with a
              non-zero field (e.g. /255.0.0.0 == /8) and as a hostmask if it
              starts with a zero field (e.g. 0.255.255.255 == /8), with the
              single exception of an all-zero mask which is treated as a
              netmask == /0. If no mask is given, a default of /32 is used.

              Additionally, an integer can be passed, so
              IPv4Network('192.0.2.1') == IPv4Network(3221225985)
              or, more generally
              IPv4Interface(int(IPv4Interface('192.0.2.1'))) ==
                IPv4Interface('192.0.2.1')

        Raises:
            AddressValueError: If ipaddress isn't a valid IPv4 address.
            NetmaskValueError: If the netmask isn't valid for
              an IPv4 address.
            ValueError: If strict is True and a network address is not
              supplied.
        'b'%s has host bits set'u'%s has host bits set'b'Test if this address is allocated for public networks.

        Returns:
            A boolean, True if the address is not reserved per
            iana-ipv4-special-registry.

        'u'Test if this address is allocated for public networks.

        Returns:
            A boolean, True if the address is not reserved per
            iana-ipv4-special-registry.

        'b'100.64.0.0/10'u'100.64.0.0/10'b'169.254.0.0/16'u'169.254.0.0/16'b'127.0.0.0/8'u'127.0.0.0/8'b'224.0.0.0/4'u'224.0.0.0/4'b'0.0.0.0/8'u'0.0.0.0/8'b'10.0.0.0/8'u'10.0.0.0/8'b'172.16.0.0/12'u'172.16.0.0/12'b'192.0.0.0/24'u'192.0.0.0/24'b'192.0.0.170/31'u'192.0.0.170/31'b'192.0.2.0/24'u'192.0.2.0/24'b'192.168.0.0/16'u'192.168.0.0/16'b'198.18.0.0/15'u'198.18.0.0/15'b'198.51.100.0/24'u'198.51.100.0/24'b'203.0.113.0/24'u'203.0.113.0/24'b'240.0.0.0/4'u'240.0.0.0/4'b'255.255.255.255/32'u'255.255.255.255/32'b'192.0.0.9/32'u'192.0.0.9/32'b'192.0.0.10/32'u'192.0.0.10/32'b'0.0.0.0'u'0.0.0.0'b'Base IPv6 object.

    The following methods are used by IPv6 objects in both single IP
    addresses and networks.

    'u'Base IPv6 object.

    The following methods are used by IPv6 objects in both single IP
    addresses and networks.

    'b'0123456789ABCDEFabcdef'u'0123456789ABCDEFabcdef'b'Turn an IPv6 ip_str into an integer.

        Args:
            ip_str: A string, the IPv6 ip_str.

        Returns:
            An int, the IPv6 address

        Raises:
            AddressValueError: if ip_str isn't a valid IPv6 Address.

        'u'Turn an IPv6 ip_str into an integer.

        Args:
            ip_str: A string, the IPv6 ip_str.

        Returns:
            An int, the IPv6 address

        Raises:
            AddressValueError: if ip_str isn't a valid IPv6 Address.

        'b'At least %d parts expected in %r'u'At least %d parts expected in %r'b'%x'u'%x'b'At most %d colons permitted in %r'u'At most %d colons permitted in %r'b'At most one '::' permitted in %r'u'At most one '::' permitted in %r'b'Leading ':' only permitted as part of '::' in %r'u'Leading ':' only permitted as part of '::' in %r'b'Trailing ':' only permitted as part of '::' in %r'u'Trailing ':' only permitted as part of '::' in %r'b'Expected at most %d other parts with '::' in %r'u'Expected at most %d other parts with '::' in %r'b'Exactly %d parts expected without '::' in %r'u'Exactly %d parts expected without '::' in %r'b'Convert an IPv6 hextet string into an integer.

        Args:
            hextet_str: A string, the number to parse.

        Returns:
            The hextet as an integer.

        Raises:
            ValueError: if the input isn't strictly a hex number from
              [0..FFFF].

        'u'Convert an IPv6 hextet string into an integer.

        Args:
            hextet_str: A string, the number to parse.

        Returns:
            The hextet as an integer.

        Raises:
            ValueError: if the input isn't strictly a hex number from
              [0..FFFF].

        'b'Only hex digits permitted in %r'u'Only hex digits permitted in %r'b'At most 4 characters permitted in %r'u'At most 4 characters permitted in %r'b'Compresses a list of hextets.

        Compresses a list of strings, replacing the longest continuous
        sequence of "0" in the list with "" and adding empty strings at
        the beginning or at the end of the string such that subsequently
        calling ":".join(hextets) will produce the compressed version of
        the IPv6 address.

        Args:
            hextets: A list of strings, the hextets to compress.

        Returns:
            A list of strings.

        'u'Compresses a list of hextets.

        Compresses a list of strings, replacing the longest continuous
        sequence of "0" in the list with "" and adding empty strings at
        the beginning or at the end of the string such that subsequently
        calling ":".join(hextets) will produce the compressed version of
        the IPv6 address.

        Args:
            hextets: A list of strings, the hextets to compress.

        Returns:
            A list of strings.

        'b'Turns a 128-bit integer into hexadecimal notation.

        Args:
            ip_int: An integer, the IP address.

        Returns:
            A string, the hexadecimal representation of the address.

        Raises:
            ValueError: The address is bigger than 128 bits of all ones.

        'u'Turns a 128-bit integer into hexadecimal notation.

        Args:
            ip_int: An integer, the IP address.

        Returns:
            A string, the hexadecimal representation of the address.

        Raises:
            ValueError: The address is bigger than 128 bits of all ones.

        'b'IPv6 address is too large'u'IPv6 address is too large'b'%032x'u'%032x'b'Expand a shortened IPv6 address.

        Returns:
            A string, the expanded IPv6 address.

        'u'Expand a shortened IPv6 address.

        Returns:
            A string, the expanded IPv6 address.

        'b'Return the reverse DNS pointer name for the IPv6 address.

        This implements the method described in RFC3596 2.5.

        'u'Return the reverse DNS pointer name for the IPv6 address.

        This implements the method described in RFC3596 2.5.

        'b'.ip6.arpa'u'.ip6.arpa'b'Helper function to parse IPv6 string address with scope id.

        See RFC 4007 for details.

        Args:
            ip_str: A string, the IPv6 address.

        Returns:
            (addr, scope_id) tuple.

        'u'Helper function to parse IPv6 string address with scope id.

        See RFC 4007 for details.

        Args:
            ip_str: A string, the IPv6 address.

        Returns:
            (addr, scope_id) tuple.

        'b'Invalid IPv6 address: "%r"'u'Invalid IPv6 address: "%r"'b'Represent and manipulate single IPv6 Addresses.'u'Represent and manipulate single IPv6 Addresses.'b'_scope_id'u'_scope_id'b'Instantiate a new IPv6 address object.

        Args:
            address: A string or integer representing the IP

              Additionally, an integer can be passed, so
              IPv6Address('2001:db8::') ==
                IPv6Address(42540766411282592856903984951653826560)
              or, more generally
              IPv6Address(int(IPv6Address('2001:db8::'))) ==
                IPv6Address('2001:db8::')

        Raises:
            AddressValueError: If address isn't a valid IPv6 address.

        'u'Instantiate a new IPv6 address object.

        Args:
            address: A string or integer representing the IP

              Additionally, an integer can be passed, so
              IPv6Address('2001:db8::') ==
                IPv6Address(42540766411282592856903984951653826560)
              or, more generally
              IPv6Address(int(IPv6Address('2001:db8::'))) ==
                IPv6Address('2001:db8::')

        Raises:
            AddressValueError: If address isn't a valid IPv6 address.

        'b'Identifier of a particular zone of the address's scope.

        See RFC 4007 for details.

        Returns:
            A string identifying the zone of the address if specified, else None.

        'u'Identifier of a particular zone of the address's scope.

        See RFC 4007 for details.

        Returns:
            A string identifying the zone of the address if specified, else None.

        'b'Test if the address is reserved for site-local.

        Note that the site-local address space has been deprecated by RFC 3879.
        Use is_private to test if this address is in the space of unique local
        addresses as defined by RFC 4193.

        Returns:
            A boolean, True if the address is reserved per RFC 3513 2.5.6.

        'u'Test if the address is reserved for site-local.

        Note that the site-local address space has been deprecated by RFC 3879.
        Use is_private to test if this address is in the space of unique local
        addresses as defined by RFC 4193.

        Returns:
            A boolean, True if the address is reserved per RFC 3513 2.5.6.

        'b'Return the IPv4 mapped address.

        Returns:
            If the IPv6 address is a v4 mapped address, return the
            IPv4 mapped address. Return None otherwise.

        'u'Return the IPv4 mapped address.

        Returns:
            If the IPv6 address is a v4 mapped address, return the
            IPv4 mapped address. Return None otherwise.

        'b'Tuple of embedded teredo IPs.

        Returns:
            Tuple of the (server, client) IPs or None if the address
            doesn't appear to be a teredo address (doesn't start with
            2001::/32)

        'u'Tuple of embedded teredo IPs.

        Returns:
            Tuple of the (server, client) IPs or None if the address
            doesn't appear to be a teredo address (doesn't start with
            2001::/32)

        'b'Return the IPv4 6to4 embedded address.

        Returns:
            The IPv4 6to4-embedded address if present or None if the
            address doesn't appear to contain a 6to4 embedded address.

        'u'Return the IPv4 6to4 embedded address.

        Returns:
            The IPv4 6to4-embedded address if present or None if the
            address doesn't appear to contain a 6to4 embedded address.

        'b'This class represents and manipulates 128-bit IPv6 networks.

    Attributes: [examples for IPv6('2001:db8::1000/124')]
        .network_address: IPv6Address('2001:db8::1000')
        .hostmask: IPv6Address('::f')
        .broadcast_address: IPv6Address('2001:db8::100f')
        .netmask: IPv6Address('ffff:ffff:ffff:ffff:ffff:ffff:ffff:fff0')
        .prefixlen: 124

    'u'This class represents and manipulates 128-bit IPv6 networks.

    Attributes: [examples for IPv6('2001:db8::1000/124')]
        .network_address: IPv6Address('2001:db8::1000')
        .hostmask: IPv6Address('::f')
        .broadcast_address: IPv6Address('2001:db8::100f')
        .netmask: IPv6Address('ffff:ffff:ffff:ffff:ffff:ffff:ffff:fff0')
        .prefixlen: 124

    'b'Instantiate a new IPv6 Network object.

        Args:
            address: A string or integer representing the IPv6 network or the
              IP and prefix/netmask.
              '2001:db8::/128'
              '2001:db8:0000:0000:0000:0000:0000:0000/128'
              '2001:db8::'
              are all functionally the same in IPv6.  That is to say,
              failing to provide a subnetmask will create an object with
              a mask of /128.

              Additionally, an integer can be passed, so
              IPv6Network('2001:db8::') ==
                IPv6Network(42540766411282592856903984951653826560)
              or, more generally
              IPv6Network(int(IPv6Network('2001:db8::'))) ==
                IPv6Network('2001:db8::')

            strict: A boolean. If true, ensure that we have been passed
              A true network address, eg, 2001:db8::1000/124 and not an
              IP address on a network, eg, 2001:db8::1/124.

        Raises:
            AddressValueError: If address isn't a valid IPv6 address.
            NetmaskValueError: If the netmask isn't valid for
              an IPv6 address.
            ValueError: If strict was True and a network address was not
              supplied.
        'u'Instantiate a new IPv6 Network object.

        Args:
            address: A string or integer representing the IPv6 network or the
              IP and prefix/netmask.
              '2001:db8::/128'
              '2001:db8:0000:0000:0000:0000:0000:0000/128'
              '2001:db8::'
              are all functionally the same in IPv6.  That is to say,
              failing to provide a subnetmask will create an object with
              a mask of /128.

              Additionally, an integer can be passed, so
              IPv6Network('2001:db8::') ==
                IPv6Network(42540766411282592856903984951653826560)
              or, more generally
              IPv6Network(int(IPv6Network('2001:db8::'))) ==
                IPv6Network('2001:db8::')

            strict: A boolean. If true, ensure that we have been passed
              A true network address, eg, 2001:db8::1000/124 and not an
              IP address on a network, eg, 2001:db8::1/124.

        Raises:
            AddressValueError: If address isn't a valid IPv6 address.
            NetmaskValueError: If the netmask isn't valid for
              an IPv6 address.
            ValueError: If strict was True and a network address was not
              supplied.
        'b'Generate Iterator over usable hosts in a network.

          This is like __iter__ except it doesn't return the
          Subnet-Router anycast address.

        'u'Generate Iterator over usable hosts in a network.

          This is like __iter__ except it doesn't return the
          Subnet-Router anycast address.

        'b'fe80::/10'u'fe80::/10'b'ff00::/8'u'ff00::/8'b'::1/128'u'::1/128'b'::/128'u'::/128'b'::ffff:0:0/96'u'::ffff:0:0/96'b'64:ff9b:1::/48'u'64:ff9b:1::/48'b'100::/64'u'100::/64'b'2001::/23'u'2001::/23'b'2001:db8::/32'u'2001:db8::/32'b'2002::/16'u'2002::/16'b'fc00::/7'u'fc00::/7'b'2001:1::1/128'u'2001:1::1/128'b'2001:1::2/128'u'2001:1::2/128'b'2001:3::/32'u'2001:3::/32'b'2001:4:112::/48'u'2001:4:112::/48'b'2001:20::/28'u'2001:20::/28'b'2001:30::/28'u'2001:30::/28'b'::/8'u'::/8'b'100::/8'u'100::/8'b'200::/7'u'200::/7'b'400::/6'u'400::/6'b'800::/5'u'800::/5'b'1000::/4'u'1000::/4'b'4000::/3'u'4000::/3'b'6000::/3'u'6000::/3'b'8000::/3'u'8000::/3'b'A000::/3'u'A000::/3'b'C000::/3'u'C000::/3'b'E000::/4'u'E000::/4'b'F000::/5'u'F000::/5'b'F800::/6'u'F800::/6'b'FE00::/9'u'FE00::/9'b'fec0::/10'u'fec0::/10'u'Lib.ipaddress'u'ipaddress'u'Functional tools for creating and using iterators.

Infinite iterators:
count(start=0, step=1) --> start, start+step, start+2*step, ...
cycle(p) --> p0, p1, ... plast, p0, p1, ...
repeat(elem [,n]) --> elem, elem, elem, ... endlessly or up to n times

Iterators terminating on the shortest input sequence:
accumulate(p[, func]) --> p0, p0+p1, p0+p1+p2
batched(p, n) --> [p0, p1, ..., p_n-1], [p_n, p_n+1, ..., p_2n-1], ...
chain(p, q, ...) --> p0, p1, ... plast, q0, q1, ...
chain.from_iterable([p, q, ...]) --> p0, p1, ... plast, q0, q1, ...
compress(data, selectors) --> (d[0] if s[0]), (d[1] if s[1]), ...
dropwhile(predicate, seq) --> seq[n], seq[n+1], starting when predicate fails
groupby(iterable[, keyfunc]) --> sub-iterators grouped by value of keyfunc(v)
filterfalse(predicate, seq) --> elements of seq where predicate(elem) is False
islice(seq, [start,] stop [, step]) --> elements from
       seq[start:stop:step]
pairwise(s) --> (s[0],s[1]), (s[1],s[2]), (s[2], s[3]), ...
starmap(fun, seq) --> fun(*seq[0]), fun(*seq[1]), ...
tee(it, n=2) --> (it1, it2 , ... itn) splits one iterator into n
takewhile(predicate, seq) --> seq[0], seq[1], until predicate fails
zip_longest(p, q, ...) --> (p[0], q[0]), (p[1], q[1]), ...

Combinatoric generators:
product(p, q, ... [repeat=1]) --> cartesian product
permutations(p[, r])
combinations(p, r)
combinations_with_replacement(p, r)
'itertools._grouper_grouperu'Iterator wrapped to make it copyable.'itertools._tee_teeu'teedataobject(iterable, values, next, /)
--

Data container common to multiple tee objects.'itertools._tee_dataobject_tee_dataobjectu'Return series of accumulated sums (or other binary function results).'itertools.accumulateaccumulateu'Batch data into tuples of length n. The last batch may be shorter than n.

Loops over the input iterable and accumulates data into tuples
up to size n.  The input is consumed lazily, just enough to
fill a batch.  The result is yielded as soon as a batch is full
or when the input iterable is exhausted.

    >>> for batch in batched('ABCDEFG', 3):
    ...     print(batch)
    ...
    ('A', 'B', 'C')
    ('D', 'E', 'F')
    ('G',)'itertools.batchedbatchedu'chain(*iterables) --> chain object

Return a chain object whose .__next__() method returns elements from the
first iterable until it is exhausted, then elements from the next
iterable, until all of the iterables are exhausted.'itertools.chainu'Return successive r-length combinations of elements in the iterable.

combinations(range(4), 3) --> (0,1,2), (0,1,3), (0,2,3), (1,2,3)'itertools.combinationscombinationsu'Return successive r-length combinations of elements in the iterable allowing individual elements to have successive repeats.

combinations_with_replacement('ABC', 2) --> ('A','A'), ('A','B'), ('A','C'), ('B','B'), ('B','C'), ('C','C')'itertools.combinations_with_replacementcombinations_with_replacementu'Return data elements corresponding to true selector elements.

Forms a shorter iterator from selected data elements using the selectors to
choose the data elements.'itertools.compressu'Return a count object whose .__next__() method returns consecutive values.

Equivalent to:
    def count(firstval=0, step=1):
        x = firstval
        while 1:
            yield x
            x += step'itertools.countu'Return elements from the iterable until it is exhausted. Then repeat the sequence indefinitely.'itertools.cyclecycleu'Drop items from the iterable while predicate(item) is true.

Afterwards, return every element until the iterable is exhausted.'itertools.dropwhiledropwhileu'Return those items of iterable for which function(item) is false.

If function is None, return the items that are false.'itertools.filterfalseu'make an iterator that returns consecutive keys and groups from the iterable

  iterable
    Elements to divide into groups according to the key function.
  key
    A function for computing the group category for each element.
    If the key function is not specified or is None, the element itself
    is used for grouping.'itertools.groupbygroupbyu'islice(iterable, stop) --> islice object
islice(iterable, start, stop[, step]) --> islice object

Return an iterator whose next() method returns selected values from an
iterable.  If start is specified, will skip all preceding elements;
otherwise, start defaults to zero.  Step defaults to one.  If
specified as another value, step determines how many values are
skipped between successive calls.  Works like a slice() on a list
but returns an iterator.'itertools.isliceu'Return an iterator of overlapping pairs taken from the input iterator.

    s -> (s0,s1), (s1,s2), (s2, s3), ...'itertools.pairwisepairwiseu'Return successive r-length permutations of elements in the iterable.

permutations(range(3), 2) --> (0,1), (0,2), (1,0), (1,2), (2,0), (2,1)'itertools.permutationspermutationsu'product(*iterables, repeat=1) --> product object

Cartesian product of input iterables.  Equivalent to nested for-loops.

For example, product(A, B) returns the same as:  ((x,y) for x in A for y in B).
The leftmost iterators are in the outermost for-loop, so the output tuples
cycle in a manner similar to an odometer (with the rightmost element changing
on every iteration).

To compute the product of an iterable with itself, specify the number
of repetitions with the optional repeat keyword argument. For example,
product(A, repeat=4) means the same as product(A, A, A, A).

product('ab', range(3)) --> ('a',0) ('a',1) ('a',2) ('b',0) ('b',1) ('b',2)
product((0,1), (0,1), (0,1)) --> (0,0,0) (0,0,1) (0,1,0) (0,1,1) (1,0,0) ...'itertools.productu'repeat(object [,times]) -> create an iterator which returns the object
for the specified number of times.  If not specified, returns the object
endlessly.'itertools.repeatu'Return an iterator whose values are returned from the function evaluated with an argument tuple taken from the given sequence.'itertools.starmapu'Return successive entries from an iterable as long as the predicate evaluates to true for each entry.'itertools.takewhiletakewhileteeu'zip_longest(iter1 [,iter2 [...]], [fillvalue=None]) --> zip_longest object

Return a zip_longest object whose .__next__() method returns a tuple where
the i-th element comes from the i-th iterable argument.  The .__next__()
method continues until the longest iterable in the argument sequence
is exhausted and then it raises StopIteration.  When the shorter iterables
are exhausted, the fillvalue is substituted in their place.  The fillvalue
defaults to None or can be specified by a keyword argument.
'itertools.zip_longestKeywords (from "Grammar/python.gram")

This file is automatically generated; please don't muck it up!

To update the symbols in this file, 'cd' to the top directory of
the python source tree and run:

    PYTHONPATH=Tools/peg_generator python3 -m pegen.keywordgen         Grammar/python.gram         Grammar/Tokens         Lib/keyword.py

Alternatively, you can run 'make regen-keyword'.
issoftkeywordkwlistsoftkwlistassertasyncdelelifforfromglobalifimportnonlocalwhilewithb'Keywords (from "Grammar/python.gram")

This file is automatically generated; please don't muck it up!

To update the symbols in this file, 'cd' to the top directory of
the python source tree and run:

    PYTHONPATH=Tools/peg_generator python3 -m pegen.keywordgen         Grammar/python.gram         Grammar/Tokens         Lib/keyword.py

Alternatively, you can run 'make regen-keyword'.
'u'Keywords (from "Grammar/python.gram")

This file is automatically generated; please don't muck it up!

To update the symbols in this file, 'cd' to the top directory of
the python source tree and run:

    PYTHONPATH=Tools/peg_generator python3 -m pegen.keywordgen         Grammar/python.gram         Grammar/Tokens         Lib/keyword.py

Alternatively, you can run 'make regen-keyword'.
'b'iskeyword'u'iskeyword'b'issoftkeyword'u'issoftkeyword'b'kwlist'u'kwlist'b'softkwlist'u'softkwlist'b'assert'u'assert'b'async'u'async'b'del'u'del'b'elif'u'elif'b'for'u'for'b'from'u'from'b'global'u'global'b'if'u'if'b'import'u'import'b'nonlocal'u'nonlocal'b'while'u'while'b'with'u'with'b'case'u'Lib.keyword'u'keyword'Cache lines from Python source files.

This is intended to read lines from modules imported -- hence if a filename
is not found, it will look down the module search path for a file by
that name.
clearcachelazycacheClear the cache entirely.Get a line for a Python source file from the cache.
    Update the cache if it doesn't contain an entry for this file already.Get the lines for a Python source file from the cache.
    Update the cache if it doesn't contain an entry for this file already.updatecacheDiscard cache entries that are out of date.
    (This is not checked upon each call!)filenamesUpdate a cache entry and return its list of lines.
    If something's wrong, print a message, discard the cache entry,
    and return an empty list.isabsSeed the cache for filename with module_globals.

    The module loader will be asked for the source only when getlines is
    called, not immediately.

    If there is an entry in the cache already, it is not altered.

    :return: True if a lazy load is registered in the cache,
        otherwise False. To register such a load a module loader with a
        get_source method must be found, the filename must be a cacheable
        filename, and the filename must not be already cached.
    # The cache. Maps filenames to either a thunk which will provide source code,# or a tuple (size, mtime, lines, fullname) once loaded.# lazy cache entry, leave it lazy.# no-op for files loaded via a __loader__# Realise a lazy loader based lookup if there is one# otherwise try to lookup right now.# No luck, the PEP302 loader cannot find the source# for this module.# Try looking through the module search path, which is only useful# when handling a relative filename.# Not sufficiently string-like to do anything useful with.# Try for a __loader__, if availableb'Cache lines from Python source files.

This is intended to read lines from modules imported -- hence if a filename
is not found, it will look down the module search path for a file by
that name.
'u'Cache lines from Python source files.

This is intended to read lines from modules imported -- hence if a filename
is not found, it will look down the module search path for a file by
that name.
'b'getline'u'getline'b'clearcache'u'clearcache'b'checkcache'u'checkcache'b'lazycache'u'lazycache'b'Clear the cache entirely.'u'Clear the cache entirely.'b'Get a line for a Python source file from the cache.
    Update the cache if it doesn't contain an entry for this file already.'u'Get a line for a Python source file from the cache.
    Update the cache if it doesn't contain an entry for this file already.'b'Get the lines for a Python source file from the cache.
    Update the cache if it doesn't contain an entry for this file already.'u'Get the lines for a Python source file from the cache.
    Update the cache if it doesn't contain an entry for this file already.'b'Discard cache entries that are out of date.
    (This is not checked upon each call!)'u'Discard cache entries that are out of date.
    (This is not checked upon each call!)'b'Update a cache entry and return its list of lines.
    If something's wrong, print a message, discard the cache entry,
    and return an empty list.'u'Update a cache entry and return its list of lines.
    If something's wrong, print a message, discard the cache entry,
    and return an empty list.'b'Seed the cache for filename with module_globals.

    The module loader will be asked for the source only when getlines is
    called, not immediately.

    If there is an entry in the cache already, it is not altered.

    :return: True if a lazy load is registered in the cache,
        otherwise False. To register such a load a module loader with a
        get_source method must be found, the filename must be a cacheable
        filename, and the filename must not be already cached.
    'u'Seed the cache for filename with module_globals.

    The module loader will be asked for the source only when getlines is
    called, not immediately.

    If there is an entry in the cache already, it is not altered.

    :return: True if a lazy load is registered in the cache,
        otherwise False. To register such a load a module loader with a
        get_source method must be found, the filename must be a cacheable
        filename, and the filename must not be already cached.
    'b'get_source'u'get_source'u'Lib.linecache'u'linecache'Loading unittests.[_a-z]\w*\.py$VALID_MODULE_NAME_FailedTesttestFailure_make_failed_import_testsuiteClassFailed to import test module: %s
%sformat_exc_make_failed_test_make_failed_load_testsFailed to call load_tests:
%s_make_skipped_testtestSkippedModuleSkippedTestClass
    This class is responsible for loading tests according to various criteria
    and returning them wrapped in a TestSuite
    testMethodPrefixthree_way_cmpsortTestMethodsUsingtestNamePatterns_top_level_dir_loading_packagesloadTestsFromTestCasetestCaseClassReturn a suite of all test cases contained in testCaseClassTest cases should not be derived from TestSuite. Maybe you meant to derive from TestCase?"Test cases should not be derived from ""TestSuite. Maybe you meant to derive from ""TestCase?"testCaseNamesloaded_suiteloadTestsFromModuleReturn a suite of all test cases contained in the given moduleload_testserror_caseerror_messageloadTestsFromNameReturn a suite of all test cases given a string specifier.

        The name may resolve either to a module, a test case class, a
        test method within a test case class, or a callable object which
        returns a TestCase or TestSuite instance.

        The method optionally resolves the names relative to a given module.
        parts_copynext_attributeFailed to access attribute:
%scalling %s returned %s, not a testdon't know how to make test from: %sloadTestsFromNamesReturn a suite of all test cases found using the given sequence
        of string specifiers. See 'loadTestsFromName()'.
        suitesReturn a sorted sequence of method names found within testCaseClass
        shouldIncludeMethod%s.%s.%sfullNametestFnNamesdiscovertest*.pytop_level_dirFind and return all test modules from the specified start
        directory, recursing into subdirectories to find them and return all
        tests found within them. Only test files that match the pattern will
        be loaded. (Using shell style pattern matching.)

        All test modules must be importable from the top level of the project.
        If the start directory is not the top level directory then the top
        level directory must be specified separately.

        If a test package name (directory with '__init__.py') matches the
        pattern then the package will be checked for a 'load_tests' function. If
        this exists then it will be called with (loader, tests, pattern) unless
        the package has already had load_tests called from the same discovery
        invocation, in which case the package module object is not scanned for
        tests - this ensures that when a package uses discover to further
        discover child tests that infinite recursion does not happen.

        If load_tests exists then discovery does *not* recurse into the package,
        load_tests is responsible for loading all tests in the package.

        The pattern is deliberately not stored as a loader attribute so that
        packages can continue discovery themselves. top_level_dir is stored so
        load_tests does not need to pass this argument in to loader.discover().

        Paths are sorted before being imported to ensure reproducible execution
        order even on filesystems with non-alphabetical ordering like ext3/4.
        original_top_level_dirset_implicit_topis_not_importablethe_moduletop_partCan not use builtin modules as dotted module names'Can not use builtin modules ''as dotted module names'don't know how to discover from _get_directory_containing_moduleStart directory is not importable: %r_find_tests_get_name_from_path_relpathPath must be within the project.._get_module_from_name_match_pathUsed by discovery. Yields test suites it loads._find_test_pathshould_recurseUsed by discovery.

        Loads tests from a single file, or a directories' __init__.py when
        passed the directory.

        Returns a tuple (None_or_tests_from_file, should_recurse).
        mod_filefullpath_noextmodule_direxpected_dir%r module incorrectly imported from %r. Expected %r. Is this module globally installed?"%r module incorrectly imported from %r. Expected ""%r. Is this module globally installed?"_makeLoadersortUsingunittest.getTestCaseNames() is deprecated and will be removed in Python 3.13. Please use unittest.TestLoader.getTestCaseNames() instead."unittest.getTestCaseNames() is deprecated and will be removed in Python 3.13. ""Please use unittest.TestLoader.getTestCaseNames() instead."unittest.makeSuite() is deprecated and will be removed in Python 3.13. Please use unittest.TestLoader.loadTestsFromTestCase() instead."unittest.makeSuite() is deprecated and will be removed in Python 3.13. ""Please use unittest.TestLoader.loadTestsFromTestCase() instead."unittest.findTestCases() is deprecated and will be removed in Python 3.13. Please use unittest.TestLoader.loadTestsFromModule() instead."unittest.findTestCases() is deprecated and will be removed in Python 3.13. ""Please use unittest.TestLoader.loadTestsFromModule() instead."# what about .pyc (etc)# we would need to avoid loading the same tests multiple times# from '.py', *and* '.pyc'# Tracks packages which we have called into via load_tests, to# avoid infinite re-entrancy.# We don't load any tests from base types that should not be loaded.# Last error so we can give it to the user if needed.# Even the top level import failed: report that error.# We can't traverse some part of the name.# This is a package (no __path__ per importlib docs), and we# encountered an error importing something. We cannot tell# the difference between package.WrongNameTestClass and# package.wrong_module_name so we just report the# ImportError - it is more informative.# Otherwise, we signal that an AttributeError has occurred.# static methods follow a different path# make top_level_dir optional if called from load_tests in a package# all test modules must be importable from the top level directory# should we *unconditionally* put the start directory in first# in sys.path to minimise likelihood of conflicts between installed# modules and development versions?# support for discovery from dotted module names# builtin module# here we have been given a module rather than a package - so# all we can do is search the *same* directory the module is in# should an exception be raised instead# override this method to use alternative matching strategy# Handle the __init__ in this package# name is '.' when start_dir == top_level_dir (and top_level_dir is by# definition not a package).# name is in self._loading_packages while we have called into# loadTestsFromModule with name.# Either an error occurred, or load_tests was used by the# package.# Handle the contents.# we found a package that didn't use load_tests.# valid Python identifiers only# if the test file matches, load it# Mark this package as being in load_tests (possibly ;))# loadTestsFromModule(package) has loaded tests for us.# These functions are considered obsolete for long time.# They will be removed in Python 3.13.b'Loading unittests.'u'Loading unittests.'b'[_a-z]\w*\.py$'u'[_a-z]\w*\.py$'b'Failed to import test module: %s
%s'u'Failed to import test module: %s
%s'b'Failed to call load_tests:
%s'u'Failed to call load_tests:
%s'b'ModuleSkipped'u'ModuleSkipped'b'
    This class is responsible for loading tests according to various criteria
    and returning them wrapped in a TestSuite
    'u'
    This class is responsible for loading tests according to various criteria
    and returning them wrapped in a TestSuite
    'b'test'b'Return a suite of all test cases contained in testCaseClass'u'Return a suite of all test cases contained in testCaseClass'b'Test cases should not be derived from TestSuite. Maybe you meant to derive from TestCase?'u'Test cases should not be derived from TestSuite. Maybe you meant to derive from TestCase?'b'Return a suite of all test cases contained in the given module'u'Return a suite of all test cases contained in the given module'b'load_tests'u'load_tests'b'Return a suite of all test cases given a string specifier.

        The name may resolve either to a module, a test case class, a
        test method within a test case class, or a callable object which
        returns a TestCase or TestSuite instance.

        The method optionally resolves the names relative to a given module.
        'u'Return a suite of all test cases given a string specifier.

        The name may resolve either to a module, a test case class, a
        test method within a test case class, or a callable object which
        returns a TestCase or TestSuite instance.

        The method optionally resolves the names relative to a given module.
        'b'Failed to access attribute:
%s'u'Failed to access attribute:
%s'b'calling %s returned %s, not a test'u'calling %s returned %s, not a test'b'don't know how to make test from: %s'u'don't know how to make test from: %s'b'Return a suite of all test cases found using the given sequence
        of string specifiers. See 'loadTestsFromName()'.
        'u'Return a suite of all test cases found using the given sequence
        of string specifiers. See 'loadTestsFromName()'.
        'b'Return a sorted sequence of method names found within testCaseClass
        'u'Return a sorted sequence of method names found within testCaseClass
        'b'%s.%s.%s'u'%s.%s.%s'b'test*.py'u'test*.py'b'Find and return all test modules from the specified start
        directory, recursing into subdirectories to find them and return all
        tests found within them. Only test files that match the pattern will
        be loaded. (Using shell style pattern matching.)

        All test modules must be importable from the top level of the project.
        If the start directory is not the top level directory then the top
        level directory must be specified separately.

        If a test package name (directory with '__init__.py') matches the
        pattern then the package will be checked for a 'load_tests' function. If
        this exists then it will be called with (loader, tests, pattern) unless
        the package has already had load_tests called from the same discovery
        invocation, in which case the package module object is not scanned for
        tests - this ensures that when a package uses discover to further
        discover child tests that infinite recursion does not happen.

        If load_tests exists then discovery does *not* recurse into the package,
        load_tests is responsible for loading all tests in the package.

        The pattern is deliberately not stored as a loader attribute so that
        packages can continue discovery themselves. top_level_dir is stored so
        load_tests does not need to pass this argument in to loader.discover().

        Paths are sorted before being imported to ensure reproducible execution
        order even on filesystems with non-alphabetical ordering like ext3/4.
        'u'Find and return all test modules from the specified start
        directory, recursing into subdirectories to find them and return all
        tests found within them. Only test files that match the pattern will
        be loaded. (Using shell style pattern matching.)

        All test modules must be importable from the top level of the project.
        If the start directory is not the top level directory then the top
        level directory must be specified separately.

        If a test package name (directory with '__init__.py') matches the
        pattern then the package will be checked for a 'load_tests' function. If
        this exists then it will be called with (loader, tests, pattern) unless
        the package has already had load_tests called from the same discovery
        invocation, in which case the package module object is not scanned for
        tests - this ensures that when a package uses discover to further
        discover child tests that infinite recursion does not happen.

        If load_tests exists then discovery does *not* recurse into the package,
        load_tests is responsible for loading all tests in the package.

        The pattern is deliberately not stored as a loader attribute so that
        packages can continue discovery themselves. top_level_dir is stored so
        load_tests does not need to pass this argument in to loader.discover().

        Paths are sorted before being imported to ensure reproducible execution
        order even on filesystems with non-alphabetical ordering like ext3/4.
        'b'Can not use builtin modules as dotted module names'u'Can not use builtin modules as dotted module names'b'don't know how to discover from 'u'don't know how to discover from 'b'Start directory is not importable: %r'u'Start directory is not importable: %r'b'Path must be within the project'u'Path must be within the project'b'..'u'..'b'Used by discovery. Yields test suites it loads.'u'Used by discovery. Yields test suites it loads.'b'Used by discovery.

        Loads tests from a single file, or a directories' __init__.py when
        passed the directory.

        Returns a tuple (None_or_tests_from_file, should_recurse).
        'u'Used by discovery.

        Loads tests from a single file, or a directories' __init__.py when
        passed the directory.

        Returns a tuple (None_or_tests_from_file, should_recurse).
        'b'%r module incorrectly imported from %r. Expected %r. Is this module globally installed?'u'%r module incorrectly imported from %r. Expected %r. Is this module globally installed?'b'unittest.getTestCaseNames() is deprecated and will be removed in Python 3.13. Please use unittest.TestLoader.getTestCaseNames() instead.'u'unittest.getTestCaseNames() is deprecated and will be removed in Python 3.13. Please use unittest.TestLoader.getTestCaseNames() instead.'b'unittest.makeSuite() is deprecated and will be removed in Python 3.13. Please use unittest.TestLoader.loadTestsFromTestCase() instead.'u'unittest.makeSuite() is deprecated and will be removed in Python 3.13. Please use unittest.TestLoader.loadTestsFromTestCase() instead.'b'unittest.findTestCases() is deprecated and will be removed in Python 3.13. Please use unittest.TestLoader.loadTestsFromModule() instead.'u'unittest.findTestCases() is deprecated and will be removed in Python 3.13. Please use unittest.TestLoader.loadTestsFromModule() instead.'u'Lib.unittest.loader'u'unittest.loader'Locale support module.

The module provides low-level access to the C lib's locale APIs and adds high
level number formatting APIs as well as a locale aliasing engine to complement
these.

The aliasing engine includes support for many commonly used locale names and
maps them to values suitable for passing to the C lib's setlocale() function. It
also includes default encodings for all supported locale names.

encodings.aliases_builtin_strgetlocalegetdefaultlocalegetpreferredencodingresetlocaleatofatoicurrency_strcoll strcoll(string,string) -> int.
        Compares two strings according to the locale.
    _strxfrm strxfrm(string) -> string.
        Returns a string that behaves for cmp locale-aware.
     localeconv() -> dict.
            Returns numeric and monetary locale-specific parameters.
        currency_symboln_sign_posnp_cs_precedesn_cs_precedesmon_groupingn_sep_by_spacenegative_signpositive_signp_sep_by_spaceint_curr_symbolp_sign_posnmon_thousands_sepfrac_digitsmon_decimal_pointint_frac_digits setlocale(integer,string=None) -> string.
            Activates/queries locale processing.
        _locale emulation only supports "C" locale_override_localeconv_grouping_intervalslast_intervalintervalinvalid grouping_groupmonetaryright_spacesleft_spaces_strip_paddingamountlposrpos%(?:\((?P<key>.*?)\))?(?P<modifiers>[-#0-9 +*.hlL]*?)[eEfFgGdiouxXcrs%]r'%(?:\((?P<key>.*?)\))?'r'(?P<modifiers>[-#0-9 +*.hlL]*?)[eEfFgGdiouxXcrs%]'_percent_readditionaleEfFgGdiu_localizesepsFormats a string in the same way that the % formatting would use,
    but takes the current locale into account.

    Grouping is applied if the third parameter is true.
    Conversion uses monetary thousands separator and grouping strings if
    forth parameter monetary is true.percentsnew_fnew_valpercmodifiersstarcountinternationalFormats val according to the currency settings
    in the current locale.Currency formatting is not possible using the 'C' locale."Currency formatting is not possible using ""the 'C' locale."smbprecedesseparatedsign_posConvert float to string, taking the locale into account.%.12gdelocalizeParses a string as a normalized number according to the locale settings.localizeParses a string as locale number according to the locale settings.Parses a string as a float according to the locale settings.Converts a string to an integer according to the locale settings.1234567893.14_setlocale_replace_encodinglangnamelocale_encoding_alias_append_modifier.ISO8859-15ISO8859-15UTF-8ISO8859-1localename Returns a normalized locale code for the given locale
        name.

        The returned locale code is formatted for use with
        setlocale().

        If normalization fails, the original name is returned
        unchanged.

        If the given encoding is not known, the function defaults to
        the default encoding for the locale code just like setlocale()
        does.

    lang_enclookup_namelocale_aliasdefmod_parse_localename Parses the locale code for localename and returns the
        result as tuple (language code, encoding).

        The localename is normalized and passed through the locale
        alias engine. A ValueError is raised in case the locale name
        cannot be parsed.

        The language code corresponds to RFC 1766.  code and encoding
        can be None in case the values cannot be determined or are
        unknown to this implementation.

    unknown locale: %s_build_localenamelocaletuple Builds a locale code from the given tuple (language code,
        encoding).

        No aliasing or normalizing takes place.

    Locale must be None, a string, or an iterable of two strings -- language code, encoding.'Locale must be None, a string, or an iterable of ''two strings -- language code, encoding.'envvars Tries to determine the default locale settings and returns
        them as tuple (language code, encoding).

        According to POSIX, a program which has not called
        setlocale(LC_ALL, "") runs using the portable 'C' locale.
        Calling setlocale(LC_ALL, "") lets it use the default locale as
        defined by the LANG variable. Since we don't want to interfere
        with the current locale setting we thus emulate the behavior
        in the way described above.

        To maintain compatibility with other platforms, not only the
        LANG variable is tested, but a list of variables given as
        envvars parameter. The first found to be defined will be
        used. envvars defaults to the search path used in GNU gettext;
        it must always contain the variable name 'LANG'.

        Except for the code 'C', the language code corresponds to RFC
        1766.  code and encoding can be None in case the values cannot
        be determined.

    locale.getdefaultlocale{name!r} is deprecated and slated for removal in Python {remove}. Use setlocale(), getencoding() and getlocale() instead."{name!r} is deprecated and slated for removal in Python {remove}. ""Use setlocale(), getencoding() and getlocale() instead."0xwindows_localevariable Returns the current setting for the given locale category as
        tuple (language code, encoding).

        category may be one of the LC_* value except LC_ALL. It
        defaults to LC_CTYPE.

        Except for the code 'C', the language code corresponds to RFC
        1766.  code and encoding can be None in case the values cannot
        be determined.

    category LC_ALL is not supported Set the locale for the given category.  The locale can be
        a string, an iterable of two strings (language code and encoding),
        or None.

        Iterables are converted to strings using the locale aliasing
        engine.  Locale strings are passed directly to the C lib.

        category may be given as one of the LC_* values.

     Sets the locale for category to the default setting.

        The default setting is determined by calling
        getdefaultlocale(). category defaults to LC_ALL.

    Use locale.setlocale(locale.LC_ALL, "") insteadgetandroidapilevelCODESETdo_setlocaleReturn the charset that the user is likely using,
        according to the system configuration.UTF-8 Mode affects locale.getpreferredencoding(). Consider locale.getencoding() instead.old_locReturn the charset that the user is likely using.enJIS7jisjis7eucJPajecKOI8-Ckoi8cCP1251microsoftcp1251CP1255microsoftcp1255CP1256microsoftcp125688591ISO8859-288592ISO8859-588595885915ISO8859-10ISO8859-11ISO8859-13ISO8859-14ISO8859-16ISO8859-3ISO8859-4ISO8859-6ISO8859-7ISO8859-8ISO8859-9SJISTACTIStactiseucKRKOI8-RKOI8-Tkoi8_tKOI8-Ukoi8_uRK1048az_AZ.KOI8-Ca3a3_aza3_az.koicaa_DJ.ISO8859-1aa_djaa_ER.UTF-8aa_eraa_ET.UTF-8aa_etaf_ZA.ISO8859-1af_zaagr_PE.UTF-8agr_peak_GH.UTF-8ak_gham_ET.UTF-8amam_eten_US.ISO8859-1americanan_ES.ISO8859-15an_esanp_IN.UTF-8anp_inar_AA.ISO8859-6arar_aaar_AE.ISO8859-6ar_aear_BH.ISO8859-6ar_bhar_DZ.ISO8859-6ar_dzar_EG.ISO8859-6ar_egar_IN.UTF-8ar_inar_IQ.ISO8859-6ar_iqar_JO.ISO8859-6ar_joar_KW.ISO8859-6ar_kwar_LB.ISO8859-6ar_lbar_LY.ISO8859-6ar_lyar_MA.ISO8859-6ar_maar_OM.ISO8859-6ar_omar_QA.ISO8859-6ar_qaar_SA.ISO8859-6ar_saar_SD.ISO8859-6ar_sdar_SS.UTF-8ar_ssar_SY.ISO8859-6ar_syar_TN.ISO8859-6ar_tnar_YE.ISO8859-6ar_yeas_IN.UTF-8as_inast_ES.ISO8859-15ast_esayc_PE.UTF-8ayc_peaz_AZ.ISO8859-9Eazaz_azaz_az.iso88599eaz_IR.UTF-8az_irbe_BY.CP1251bebe_BY.UTF-8@latinbe@latinbg_BG.UTF-8be_bg.utf8be_bybe_by@latinbem_ZM.UTF-8bem_zmber_DZ.UTF-8ber_dzber_MA.UTF-8ber_mabg_BG.CP1251bgbg_bgbhb_IN.UTF-8bhb_in.utf8bho_IN.UTF-8bho_inbho_NP.UTF-8bho_npbi_VU.UTF-8bi_vubn_BD.UTF-8bn_bdbn_IN.UTF-8bn_inbo_CN.UTF-8bo_cnbo_IN.UTF-8bo_innb_NO.ISO8859-1bokmalbokmlbr_FR.ISO8859-1brbr_frbrx_IN.UTF-8brx_inbs_BA.ISO8859-2bsbs_babulgarianbyn_ER.UTF-8byn_erfr_CA.ISO8859-1c-frenchc.asciic.enc.iso88591C.UTF-8c.utf8c_cc_c.cca_ES.ISO8859-1caca_AD.ISO8859-1ca_adca_esca_ES.UTF-8@valenciaca_es@valenciaca_FR.ISO8859-1ca_frca_IT.ISO8859-1ca_itcatalance_RU.UTF-8ce_rucextendzh_CN.eucCNchinese-szh_TW.eucTWchinese-tchr_US.UTF-8chr_usckb_IQ.UTF-8ckb_iqcmn_TW.UTF-8cmn_twcrh_UA.UTF-8crh_uahr_HR.ISO8859-2croatiancs_CZ.ISO8859-2cscs_cscs_czcsb_PL.UTF-8csb_plcv_RU.UTF-8cv_rucy_GB.ISO8859-1cycy_gbczcz_czczechda_DK.ISO8859-1da_dkdanishdanskde_DE.ISO8859-1dede_AT.ISO8859-1de_atde_BE.ISO8859-1de_bede_CH.ISO8859-1de_chde_dede_IT.ISO8859-1de_itde_LI.UTF-8de_li.utf8de_LU.ISO8859-1de_ludeutschdoi_IN.UTF-8doi_innl_NL.ISO8859-1dutchnl_BE.ISO8859-1dutch.iso88591dv_MV.UTF-8dv_mvdz_BT.UTF-8dz_btee_EE.ISO8859-4eeee_eeet_EE.ISO8859-1eestiel_GR.ISO8859-7elel_CY.ISO8859-7el_cyel_grel_GR.ISO8859-15el_gr@euroen_AG.UTF-8en_agen_AU.ISO8859-1en_auen_BE.ISO8859-1en_been_BW.ISO8859-1en_bwen_CA.ISO8859-1en_caen_DK.ISO8859-1en_dken_DL.UTF-8en_dl.utf8en_GB.ISO8859-1en_gben_HK.ISO8859-1en_hken_IE.ISO8859-1en_ieen_IL.UTF-8en_ilen_IN.ISO8859-1en_inen_NG.UTF-8en_ngen_NZ.ISO8859-1en_nzen_PH.ISO8859-1en_phen_SC.UTF-8en_sc.utf8en_SG.ISO8859-1en_sgen_uken_usen_US.ISO8859-15en_us@euro@euroen_ZA.ISO8859-1en_zaen_ZM.UTF-8en_zmen_ZW.ISO8859-1en_zwen_ZS.UTF-8en_zw.utf8eng_gben_EN.ISO8859-1englishenglish.iso88591english_ukenglish_united-statesenglish_united-states.437english_useo_XX.ISO8859-3eoeo.UTF-8eo.utf8eo_EO.ISO8859-3eo_eoeo_US.UTF-8eo_us.utf8eo_xxes_ES.ISO8859-1eses_AR.ISO8859-1es_ares_BO.ISO8859-1es_boes_CL.ISO8859-1es_cles_CO.ISO8859-1es_coes_CR.ISO8859-1es_cres_CU.UTF-8es_cues_DO.ISO8859-1es_does_EC.ISO8859-1es_eces_eses_GT.ISO8859-1es_gtes_HN.ISO8859-1es_hnes_MX.ISO8859-1es_mxes_NI.ISO8859-1es_nies_PA.ISO8859-1es_paes_PE.ISO8859-1es_pees_PR.ISO8859-1es_pres_PY.ISO8859-1es_pyes_SV.ISO8859-1es_sves_US.ISO8859-1es_uses_UY.ISO8859-1es_uyes_VE.ISO8859-1es_veestonianet_EE.ISO8859-15etet_eeeu_ES.ISO8859-1eueu_eseu_FR.ISO8859-1eu_frfa_IR.UTF-8fafa_irfa_IR.ISIRI-3342fa_ir.isiri3342ff_SN.UTF-8ff_snfi_FI.ISO8859-15fifi_fifil_PH.UTF-8fil_phfi_FI.ISO8859-1finnishfo_FO.ISO8859-1fofo_fofr_FR.ISO8859-1frfr_BE.ISO8859-1fr_befr_cafr_CH.ISO8859-1fr_chfr_frfr_LU.ISO8859-1fr_lufranaisfre_frfrenchfrench.iso88591french_francefur_IT.UTF-8fur_itfy_DE.UTF-8fy_defy_NL.UTF-8fy_nlga_IE.ISO8859-1gaga_iegl_ES.ISO8859-1galegogaliciangd_GB.ISO8859-1gdgd_gbger_degermangerman.iso88591german_germanygez_ER.UTF-8gez_ergez_ET.UTF-8gez_etglgl_esgu_IN.UTF-8gu_ingv_GB.ISO8859-1gvgv_gbha_NG.UTF-8ha_nghak_TW.UTF-8hak_twhe_IL.ISO8859-8hehe_ilhi_IN.ISCII-DEVhi_inhi_in.isciidevhif_FJ.UTF-8hif_fjhne_IN.UTF-8hnehne_inhrhr_hrhrvatskihsb_DE.ISO8859-2hsb_deht_HT.UTF-8ht_hthu_HU.ISO8859-2huhu_huhungarianhy_AM.UTF-8hy_amhy_AM.ARMSCII_8hy_am.armscii8ia.UTF-8iaia_FR.UTF-8ia_fris_IS.ISO8859-1icelandicid_ID.ISO8859-1id_idig_NG.UTF-8ig_ngik_CA.UTF-8ik_cain_idis_isiso8859-1iso8859-15it_IT.ISO8859-1it_CH.ISO8859-1it_chit_ititalianiu_CA.NUNACOM-8iuiu_caiu_ca.nunacom8iwiw_iliw_IL.UTF-8iw_il.utf8ja_JP.eucJPjaja_jpja_jp.eucja_JP.SJISja_jp.mscodeja_jp.pckjapanjapanesejapanese-eucjapanese.eucjp_jpka_GE.GEORGIAN-ACADEMYkaka_geka_ge.georgianacademyka_GE.GEORGIAN-PSka_ge.georgianpska_ge.georgianrskab_DZ.UTF-8kab_dzkk_KZ.ptcp154kk_kzkl_GL.ISO8859-1klkl_glkm_KH.UTF-8km_khkn_IN.UTF-8knkn_inko_KR.eucKRkoko_krko_kr.euckok_IN.UTF-8kok_inkorean.eucks_IN.UTF-8ksks_inks_IN.UTF-8@devanagariks_in@devanagari.utf8ku_TR.ISO8859-9ku_trkw_GB.ISO8859-1kw_gbky_KG.UTF-8kyky_kglb_LU.UTF-8lb_lulg_UG.ISO8859-10lg_ugli_BE.UTF-8li_beli_NL.UTF-8li_nllij_IT.UTF-8lij_itlt_LT.ISO8859-13lithuanianln_CD.UTF-8ln_cdlo_LA.MULELAO-1lo_lalo_LA.IBM-CP1133lo_la.cp1133lo_la.ibmcp1133lo_la.mulelao1lt_ltlv_LV.ISO8859-13lvlv_lvlzh_TW.UTF-8lzh_twmag_IN.UTF-8mag_inmai_IN.UTF-8maimai_inmai_NP.UTF-8mai_npmfe_MU.UTF-8mfe_mumg_MG.ISO8859-15mg_mgmhr_RU.UTF-8mhr_rumi_NZ.ISO8859-1mimi_nzmiq_NI.UTF-8miq_nimjw_IN.UTF-8mjw_inmk_MK.ISO8859-5mkmk_mkml_IN.UTF-8mlml_inmn_MN.UTF-8mn_mnmni_IN.UTF-8mni_inmr_IN.UTF-8mrmr_inms_MY.ISO8859-1msms_mymt_MT.ISO8859-3mtmt_mtmy_MM.UTF-8my_mmnan_TW.UTF-8nan_twnb_nonds_DE.UTF-8nds_dends_NL.UTF-8nds_nlne_NP.UTF-8ne_npnhn_MX.UTF-8nhn_mxniu_NU.UTF-8niu_nuniu_NZ.UTF-8niu_nznl_AW.UTF-8nl_awnl_benl_nlnn_NO.ISO8859-1nn_nono_NO.ISO8859-1nony_NO.ISO8859-1no@nynorskno_nono_no.iso88591@bokmalno_no.iso88591@nynorsknorwegiannr_ZA.ISO8859-1nrnr_zanso_ZA.ISO8859-15nsonso_zanyny_nonynorskoc_FR.ISO8859-1ococ_from_ET.UTF-8om_etom_KE.ISO8859-1om_keor_IN.UTF-8or_inos_RU.UTF-8os_rupa_IN.UTF-8papa_inpa_PK.UTF-8pa_pkpap_AN.UTF-8pap_anpap_AW.UTF-8pap_awpap_CW.UTF-8pap_cwpd_US.ISO8859-1pdpd_DE.ISO8859-1pd_depd_usph_PH.ISO8859-1ph_phpl_PL.ISO8859-2plpl_plpolishpt_PT.ISO8859-1portuguesept_BR.ISO8859-1portuguese_brazilposix-utf2pp_AN.ISO8859-1pppp_anps_AF.UTF-8ps_afptpt_brpt_ptquz_PE.UTF-8quz_peraj_IN.UTF-8raj_inro_RO.ISO8859-2roro_roromanianru_RU.UTF-8ruru_ruru_UA.KOI8-Uru_uarumanianru_RU.KOI8-Rrussianrw_RW.ISO8859-1rwrw_rwsa_IN.UTF-8sa_insat_IN.UTF-8sat_insc_IT.UTF-8sc_itsd_IN.UTF-8sdsd_insd_IN.UTF-8@devanagarisd_in@devanagari.utf8sd_PK.UTF-8sd_pkse_NO.UTF-8se_nosr_RS.UTF-8@latinserbocroatiansgs_LT.UTF-8sgs_ltshsr_CS.ISO8859-2sh_ba.iso88592@bosniash_HR.ISO8859-2sh_hrsh_hr.iso88592sh_spsh_yushn_MM.UTF-8shn_mmshs_CA.UTF-8shs_casi_LK.UTF-8sisi_lksid_ET.UTF-8sid_etsinhalask_SK.ISO8859-2sksk_sksl_SI.ISO8859-2sl_CS.ISO8859-2sl_cssl_sislovakslovenesloveniansm_WS.UTF-8sm_wsso_DJ.ISO8859-1so_djso_ET.UTF-8so_etso_KE.ISO8859-1so_keso_SO.ISO8859-1so_sosr_CS.ISO8859-5spsp_yuspanishspanish_spainsq_AL.ISO8859-2sqsq_alsq_MK.UTF-8sq_mksr_RS.UTF-8sr@cyrillicsr_CS.UTF-8@latinsr@latnsr_CS.UTF-8sr_cssr_cs.iso88592@latnsr_cs@latnsr_ME.UTF-8sr_mesr_rssr_rs@latnsr_spsr_yusr_CS.CP1251sr_yu.cp1251@cyrillicsr_yu.iso88592sr_yu.iso88595sr_yu.iso88595@cyrillicsr_yu.microsoftcp1251@cyrillicsr_yu.utf8sr_yu.utf8@cyrillicsr_yu@cyrillicss_ZA.ISO8859-1ss_zast_ZA.ISO8859-1st_zasv_SE.ISO8859-1svsv_FI.ISO8859-1sv_fisv_sesw_KE.UTF-8sw_kesw_TZ.UTF-8sw_tzswedishszl_PL.UTF-8szl_plta_IN.TSCII-0tata_inta_in.tsciita_in.tscii0ta_LK.UTF-8ta_lktcy_IN.UTF-8tcy_in.utf8te_IN.UTF-8te_intg_TJ.KOI8-Ctgtg_tjth_TH.ISO8859-11thth_thth_TH.TIS620th_th.tactisth_th.tis620the_NP.UTF-8the_npti_ER.UTF-8ti_erti_ET.UTF-8ti_ettig_ER.UTF-8tig_ertk_TM.UTF-8tk_tmtl_PH.ISO8859-1tl_phtn_ZA.ISO8859-15tntn_zato_TO.UTF-8to_totpi_PG.UTF-8tpi_pgtr_TR.ISO8859-9trtr_CY.ISO8859-9tr_cytr_trts_ZA.ISO8859-1ts_zatt_RU.TATAR-CYRtttt_rutt_ru.tatarcyrtt_RU.UTF-8@iqteliftt_ru@iqtelifturkishug_CN.UTF-8ug_cnuk_UA.KOI8-Uukuk_uaen_US.utfuniven_US.UTF-8universal.utf8@ucs4unm_US.UTF-8unm_usur_PK.CP1256urur_IN.UTF-8ur_inur_pkuz_UZ.UTF-8uzuz_uzuz_uz@cyrillicve_ZA.UTF-8veve_zavi_VN.TCVNvivi_vnvi_vn.tcvnvi_vn.tcvn5712vi_VN.VISCIIvi_vn.visciivi_vn.viscii111wa_BE.ISO8859-1wawa_bewae_CH.UTF-8wae_chwal_ET.UTF-8wal_etwo_SN.UTF-8wo_snxh_ZA.ISO8859-1xhxh_zayi_US.CP1255yiyi_usyo_NG.UTF-8yo_ngyue_HK.UTF-8yue_hkyuw_PG.UTF-8yuw_pgzhzh_CN.gb2312zh_cnzh_TW.big5zh_cn.big5zh_cn.euczh_HK.big5hkscszh_hkzh_hk.big5hkzh_SG.GB2312zh_sgzh_SG.GBKzh_sg.gbkzh_twzh_tw.euczh_tw.euctwzu_ZA.ISO8859-1zuzu_zaaf_ZA10780x0436sq_AL10520x041cgsw_FR11560x0484am_ET11180x045ear_SA10250x0401ar_IQ20490x0801ar_EG30730x0c01ar_LY40970x1001ar_DZ51210x1401ar_MA61450x1801ar_TN71690x1c01ar_OM81930x2001ar_YE92170x2401ar_SY102410x2801ar_JO112650x2c01ar_LB122890x3001ar_KW133130x3401ar_AE143370x3801ar_BH153610x3c01ar_QA163850x4001hy_AM10670x042bas_IN11010x044daz_AZ10680x042c20920x082cba_RU11330x046deu_ES10690x042dbe_BY10590x0423bn_IN10930x0445bs_BA51460x141abr_FR11500x047ebg_BG0x0402ca_ES10270x0403zh_CHS0x0004zh_TW10280x0404zh_CN20520x0804zh_HK30760x0c04zh_SG41000x1004zh_MO51240x1404zh_CHT317480x7c04co_FR11550x0483hr_HR10500x041ahr_BA41220x101acs_CZ10290x0405da_DK10300x0406gbz_AF11640x048cdiv_MV0x0465nl_NL10430x0413nl_BE20670x0813en_US10330x0409en_GB20570x0809en_AU30810x0c09en_CA41050x1009en_NZ51290x1409en_IE61530x1809en_ZA71770x1c09en_JAen_CB92250x2409en_BZ102490x2809en_TT112730x2c09en_ZW122970x3009en_PH133210x3409en_IN163930x4009en_MY174170x4409184410x4809et_EE10610x0425fo_FO10800x0438fil_PH11240x0464fi_FI10350x040bfr_FR10360x040cfr_BE20600x080cfr_CA30840x0c0cfr_CH41080x100cfr_LU51320x140cfr_MC61560x180cfy_NL11220x0462gl_ES11100x0456ka_GE10790x0437de_DE10310x0407de_CH20550x0807de_AT30790x0c07de_LU41030x1007de_LI51270x1407el_GR10320x0408kl_GL11350x046fgu_IN10950x0447ha_NG11280x0468he_IL10370x040dhi_IN10810x0439hu_HU10380x040eis_IS10390x040fid_ID10570x0421iu_CA11170x045d21410x085dga_IE21080x083cit_IT10400x0410it_CH20640x0810ja_JP10410x0411kn_IN10990x044bkk_KZ10870x043fkh_KH11070x0453qut_GT11580x0486rw_RW11590x0487kok_IN11110x0457ko_KR10420x0412ky_KG10880x0440lo_LA11080x0454lv_LV10620x0426lt_LT10630x0427dsb_DE20940x082elb_LU11340x046emk_MK10710x042fms_MYms_BN21100x083eml_IN11000x044cmt_MT10820x043ami_NZ11530x0481arn_CL11460x047amr_IN11020x044emoh_CA11480x047cmn_MN11040x0450mn_CN21280x0850ne_NP11210x0461nb_NO10440x0414nn_NO20680x0814oc_FR11540x0482or_IN10960x0448ps_AFfa_IR10650x0429pl_PL10450x0415pt_BR10460x0416pt_PT20700x0816pa_IN10940x0446quz_BO11310x046bquz_EC21550x086bquz_PE31790x0c6bro_RO10480x0418rm_CH10470x0417ru_RU10490x0419smn_FI92750x243bsmj_NO41550x103bsmj_SE51790x143bse_NO10830x043bse_SE0x083bse_FI31310x0c3bsms_FI82510x203bsma_NO62030x183bsma_SE72270x1c3bsa_IN11030x044fsr_SP30980x0c1asr_BA71940x1c1a20740x081a61700x181asi_LK11150x045bns_ZA11320x046ctn_ZAsk_SK10510x041bsl_SI10600x0424es_ES10340x040aes_MX20580x080a30820x0c0aes_GT41060x100aes_CR51300x140aes_PA61540x180aes_DO71780x1c0aes_VE82020x200aes_CO92260x240aes_PE102500x280aes_AR112740x2c0aes_EC122980x300aes_CL133220x340aes_UR143460x380aes_PY153700x3c0aes_BO163940x400aes_SV174180x440aes_HN184420x480aes_NI194660x4c0aes_PR204900x500aes_US215140x540asw_KEsv_SE10530x041dsv_FI20770x081dsyr_SY11140x045atg_TJ10640x0428tmz_DZ21430x085fta_IN10970x0449tt_RU10920x0444te_INth_TH10540x041ebo_BT21290x0851bo_CN11050x0451tr_TR10550x041ftk_TMug_CN11520x0480uk_UA10580x0422wen_DE10700x042eur_PK10560x0420ur_IN20800x0820uz_UZ10910x044321150x0843vi_VN10660x042acy_GB11060x0452wo_SN11600x0488xh_ZAsah_RU11570x0485ii_CN11440x0478yo_NG11300x046azu_ZA10770x0435_print_locale Test function.
    categories_init_categoriesLC_Locale defaults as determined by getdefaultlocale():Language: (undefined)Encoding: Locale settings on startup:   Language:    Encoding: Locale settings after calling resetlocale():Locale settings after calling setlocale(LC_ALL, ""):NOTE:setlocale(LC_ALL, "") does not support the default localegiven in the OS environment variables.Locale aliasing:Number formatting:# Try importing the _locale module.# If this fails, fall back on a basic 'C' locale emulation.# Yuck:  LC_MESSAGES is non-standard:  can't tell whether it exists before# trying the import.  So __all__ is also fiddled at the end of the file.# Locale emulation# 'C' locale default values# These may or may not exist in _locale, so be sure to set them.# With this dict, you can override some items of localeconv's return value.# This is useful for testing purposes.### Number formatting APIs# Author: Martin von Loewis# improved by Georg Brandl# Iterate over grouping intervals# if grouping is -1, we are done# 0: re-use last group ad infinitum#perform the grouping from right to left# only non-digit characters remain (sign, spaces)# Strip a given amount of excess padding from the given string# Transform formatted as locale number according to the locale settings# floats and decimal ints need special action!# check for illegal values# '<' and '>' are markers if the sign must be inserted between symbol and value# the default if nothing specified;# this should be the most fitting sign position#First, get rid of the grouping#next, replace the decimal point with a dot#do grouping#standard formatting### Locale name aliasing engine# Author: Marc-Andre Lemburg, mal@lemburg.com# Various tweaks by Fredrik Lundh <fredrik@pythonware.com># store away the low-level version of setlocale (it's# overridden below)# Convert the encoding to a C lib compatible encoding string#print('norm encoding: %r' % norm_encoding)#print('aliased encoding: %r' % norm_encoding)#print('found encoding %r' % encoding)# Normalize the locale name and extract the encoding and modifier# ':' is sometimes used as encoding delimiter.# First lookup: fullname (possibly with encoding and modifier)#print('first lookup failed')# Second try: fullname without modifier (possibly with encoding)#print('lookup without modifier succeeded')#print('second lookup failed')# Third try: langname (without encoding, possibly with modifier)#print('lookup without encoding succeeded')# Fourth try: langname (without encoding and modifier)#print('lookup without modifier and encoding succeeded')# Deal with locale modifiers# Assume Latin-9 for @euro locales. This is bogus,# since some systems may use other encodings for these# locales. Also, we ignore other modifiers.# On macOS "LC_CTYPE=UTF-8" is a valid locale setting# for getting UTF-8 handling for text.# check if it's supported by the _locale module# make sure the code/encoding values are valid# map windows language identifier to language name# ...add other platform-specific processing here, if# necessary...# fall back on POSIX behaviour# convert to string# On Android langinfo.h and CODESET are missing, and UTF-8 is# always used in mbstowcs() and wcstombs().# LANG not set, default to UTF-8# On Unix, if CODESET is available, use that.### Database# The following data was extracted from the locale.alias file which# comes with X11 and then hand edited removing the explicit encoding# definitions and adding some more aliases. The file is usually# available as /usr/lib/X11/locale/locale.alias.# The local_encoding_alias table maps lowercase encoding alias names# to C locale encoding names (case-sensitive). Note that normalize()# first looks up the encoding in the encodings.aliases dictionary and# then applies this mapping to find the correct C lib name for the# encoding.# Mappings for non-standard encoding names used in locale names# Mappings from Python codec names to C lib encoding names# XXX This list is still incomplete. If you know more# mappings, please file a bug report. Thanks.# The locale_alias table maps lowercase alias names to C locale names# (case-sensitive). Encodings are always separated from the locale# name using a dot ('.'); they should only be given in case the# language name is needed to interpret the given encoding alias# correctly (CJK codes often have this need).# Note that the normalize() function which uses this tables# removes '_' and '-' characters from the encoding part of the# locale name before doing the lookup. This saves a lot of# space in the table.# MAL 2004-12-10:# Updated alias mapping to most recent locale.alias file# from X.org distribution using makelocalealias.py.# These are the differences compared to the old mapping (Python 2.4# and older):#    updated 'bg' -> 'bg_BG.ISO8859-5' to 'bg_BG.CP1251'#    updated 'bg_bg' -> 'bg_BG.ISO8859-5' to 'bg_BG.CP1251'#    updated 'bulgarian' -> 'bg_BG.ISO8859-5' to 'bg_BG.CP1251'#    updated 'cz' -> 'cz_CZ.ISO8859-2' to 'cs_CZ.ISO8859-2'#    updated 'cz_cz' -> 'cz_CZ.ISO8859-2' to 'cs_CZ.ISO8859-2'#    updated 'czech' -> 'cs_CS.ISO8859-2' to 'cs_CZ.ISO8859-2'#    updated 'dutch' -> 'nl_BE.ISO8859-1' to 'nl_NL.ISO8859-1'#    updated 'et' -> 'et_EE.ISO8859-4' to 'et_EE.ISO8859-15'#    updated 'et_ee' -> 'et_EE.ISO8859-4' to 'et_EE.ISO8859-15'#    updated 'fi' -> 'fi_FI.ISO8859-1' to 'fi_FI.ISO8859-15'#    updated 'fi_fi' -> 'fi_FI.ISO8859-1' to 'fi_FI.ISO8859-15'#    updated 'iw' -> 'iw_IL.ISO8859-8' to 'he_IL.ISO8859-8'#    updated 'iw_il' -> 'iw_IL.ISO8859-8' to 'he_IL.ISO8859-8'#    updated 'japanese' -> 'ja_JP.SJIS' to 'ja_JP.eucJP'#    updated 'lt' -> 'lt_LT.ISO8859-4' to 'lt_LT.ISO8859-13'#    updated 'lv' -> 'lv_LV.ISO8859-4' to 'lv_LV.ISO8859-13'#    updated 'sl' -> 'sl_CS.ISO8859-2' to 'sl_SI.ISO8859-2'#    updated 'slovene' -> 'sl_CS.ISO8859-2' to 'sl_SI.ISO8859-2'#    updated 'th_th' -> 'th_TH.TACTIS' to 'th_TH.ISO8859-11'#    updated 'zh_cn' -> 'zh_CN.eucCN' to 'zh_CN.gb2312'#    updated 'zh_cn.big5' -> 'zh_TW.eucTW' to 'zh_TW.big5'#    updated 'zh_tw' -> 'zh_TW.eucTW' to 'zh_TW.big5'# MAL 2008-05-30:# These are the differences compared to the old mapping (Python 2.5#    updated 'cs_cs.iso88592' -> 'cs_CZ.ISO8859-2' to 'cs_CS.ISO8859-2'#    updated 'serbocroatian' -> 'sh_YU.ISO8859-2' to 'sr_CS.ISO8859-2'#    updated 'sh' -> 'sh_YU.ISO8859-2' to 'sr_CS.ISO8859-2'#    updated 'sh_hr.iso88592' -> 'sh_HR.ISO8859-2' to 'hr_HR.ISO8859-2'#    updated 'sh_sp' -> 'sh_YU.ISO8859-2' to 'sr_CS.ISO8859-2'#    updated 'sh_yu' -> 'sh_YU.ISO8859-2' to 'sr_CS.ISO8859-2'#    updated 'sp' -> 'sp_YU.ISO8859-5' to 'sr_CS.ISO8859-5'#    updated 'sp_yu' -> 'sp_YU.ISO8859-5' to 'sr_CS.ISO8859-5'#    updated 'sr' -> 'sr_YU.ISO8859-5' to 'sr_CS.ISO8859-5'#    updated 'sr@cyrillic' -> 'sr_YU.ISO8859-5' to 'sr_CS.ISO8859-5'#    updated 'sr_sp' -> 'sr_SP.ISO8859-2' to 'sr_CS.ISO8859-2'#    updated 'sr_yu' -> 'sr_YU.ISO8859-5' to 'sr_CS.ISO8859-5'#    updated 'sr_yu.cp1251@cyrillic' -> 'sr_YU.CP1251' to 'sr_CS.CP1251'#    updated 'sr_yu.iso88592' -> 'sr_YU.ISO8859-2' to 'sr_CS.ISO8859-2'#    updated 'sr_yu.iso88595' -> 'sr_YU.ISO8859-5' to 'sr_CS.ISO8859-5'#    updated 'sr_yu.iso88595@cyrillic' -> 'sr_YU.ISO8859-5' to 'sr_CS.ISO8859-5'#    updated 'sr_yu.microsoftcp1251@cyrillic' -> 'sr_YU.CP1251' to 'sr_CS.CP1251'#    updated 'sr_yu.utf8@cyrillic' -> 'sr_YU.UTF-8' to 'sr_CS.UTF-8'#    updated 'sr_yu@cyrillic' -> 'sr_YU.ISO8859-5' to 'sr_CS.ISO8859-5'# AP 2010-04-12:# These are the differences compared to the old mapping (Python 2.6.5#    updated 'ru' -> 'ru_RU.ISO8859-5' to 'ru_RU.UTF-8'#    updated 'ru_ru' -> 'ru_RU.ISO8859-5' to 'ru_RU.UTF-8'#    updated 'serbocroatian' -> 'sr_CS.ISO8859-2' to 'sr_RS.UTF-8@latin'#    updated 'sh' -> 'sr_CS.ISO8859-2' to 'sr_RS.UTF-8@latin'#    updated 'sh_yu' -> 'sr_CS.ISO8859-2' to 'sr_RS.UTF-8@latin'#    updated 'sr' -> 'sr_CS.ISO8859-5' to 'sr_RS.UTF-8'#    updated 'sr@cyrillic' -> 'sr_CS.ISO8859-5' to 'sr_RS.UTF-8'#    updated 'sr@latn' -> 'sr_CS.ISO8859-2' to 'sr_RS.UTF-8@latin'#    updated 'sr_cs.utf8@latn' -> 'sr_CS.UTF-8' to 'sr_RS.UTF-8@latin'#    updated 'sr_cs@latn' -> 'sr_CS.ISO8859-2' to 'sr_RS.UTF-8@latin'#    updated 'sr_yu' -> 'sr_CS.ISO8859-5' to 'sr_RS.UTF-8@latin'#    updated 'sr_yu.utf8@cyrillic' -> 'sr_CS.UTF-8' to 'sr_RS.UTF-8'#    updated 'sr_yu@cyrillic' -> 'sr_CS.ISO8859-5' to 'sr_RS.UTF-8'# SS 2013-12-20:# These are the differences compared to the old mapping (Python 3.3.3#    updated 'a3' -> 'a3_AZ.KOI8-C' to 'az_AZ.KOI8-C'#    updated 'a3_az' -> 'a3_AZ.KOI8-C' to 'az_AZ.KOI8-C'#    updated 'a3_az.koi8c' -> 'a3_AZ.KOI8-C' to 'az_AZ.KOI8-C'#    updated 'cs_cs.iso88592' -> 'cs_CS.ISO8859-2' to 'cs_CZ.ISO8859-2'#    updated 'hebrew' -> 'iw_IL.ISO8859-8' to 'he_IL.ISO8859-8'#    updated 'hebrew.iso88598' -> 'iw_IL.ISO8859-8' to 'he_IL.ISO8859-8'#    updated 'sd' -> 'sd_IN@devanagari.UTF-8' to 'sd_IN.UTF-8'#    updated 'sr@latn' -> 'sr_RS.UTF-8@latin' to 'sr_CS.UTF-8@latin'#    updated 'sr_cs' -> 'sr_RS.UTF-8' to 'sr_CS.UTF-8'#    updated 'sr_cs.utf8@latn' -> 'sr_RS.UTF-8@latin' to 'sr_CS.UTF-8@latin'#    updated 'sr_cs@latn' -> 'sr_RS.UTF-8@latin' to 'sr_CS.UTF-8@latin'# SS 2014-10-01:# Updated alias mapping with glibc 2.19 supported locales.# SS 2018-05-05:# Updated alias mapping with glibc 2.27 supported locales.# These are the differences compared to the old mapping (Python 3.6.5#    updated 'ca_es@valencia' -> 'ca_ES.ISO8859-15@valencia' to 'ca_ES.UTF-8@valencia'#    updated 'kk_kz' -> 'kk_KZ.RK1048' to 'kk_KZ.ptcp154'#    updated 'russian' -> 'ru_RU.ISO8859-5' to 'ru_RU.KOI8-R'# This maps Windows language identifiers to locale strings.# This list has been updated from# http://msdn.microsoft.com/library/default.asp?url=/library/en-us/intl/nls_238z.asp# to include every locale up to Windows Vista.# NOTE: this mapping is incomplete.  If your language is missing, please# submit a bug report as detailed in the Python devguide at:#    https://devguide.python.org/triage/issue-tracker/# Make sure you include the missing language identifier and the suggested# locale code.# Afrikaans# Albanian# Alsatian - France# Amharic - Ethiopia# Arabic - Saudi Arabia# Arabic - Iraq# Arabic - Egypt# Arabic - Libya# Arabic - Algeria# Arabic - Morocco# Arabic - Tunisia# Arabic - Oman# Arabic - Yemen# Arabic - Syria# Arabic - Jordan# Arabic - Lebanon# Arabic - Kuwait# Arabic - United Arab Emirates# Arabic - Bahrain# Arabic - Qatar# Armenian# Assamese - India# Azeri - Latin# Azeri - Cyrillic# Bashkir# Basque - Russia# Belarusian# Begali# Bosnian - Cyrillic# Bosnian - Latin# Breton - France# Bulgarian#    0x0455: "my_MM", # Burmese - Not supported# Catalan# Chinese - Simplified# Chinese - Taiwan# Chinese - PRC# Chinese - Hong Kong S.A.R.# Chinese - Singapore# Chinese - Macao S.A.R.# Chinese - Traditional# Corsican - France# Croatian# Croatian - Bosnia# Czech# Danish# Dari - Afghanistan# Divehi - Maldives# Dutch - The Netherlands# Dutch - Belgium# English - United States# English - United Kingdom# English - Australia# English - Canada# English - New Zealand# English - Ireland# English - South Africa# English - Jamaica# English - Caribbean# English - Belize# English - Trinidad# English - Zimbabwe# English - Philippines# English - India# English - Malaysia# English - Singapore# Estonian# Faroese# Filipino# Finnish# French - France# French - Belgium# French - Canada# French - Switzerland# French - Luxembourg# French - Monaco# Frisian - Netherlands# Galician# Georgian# German - Germany# German - Switzerland# German - Austria# German - Luxembourg# German - Liechtenstein# Greek# Greenlandic - Greenland# Gujarati# Hausa - Latin# Hebrew# Hindi# Hungarian# Icelandic# Indonesian# Inuktitut - Syllabics# Inuktitut - Latin# Irish - Ireland# Italian - Italy# Italian - Switzerland# Japanese# Kannada - India# Kazakh# Khmer - Cambodia# K'iche - Guatemala# Kinyarwanda - Rwanda# Konkani# Korean# Kyrgyz# Lao - Lao PDR# Latvian# Lithuanian# Lower Sorbian - Germany# Luxembourgish# FYROM Macedonian# Malay - Malaysia# Malay - Brunei Darussalam# Malayalam - India# Maltese# Maori# Mapudungun# Marathi# Mohawk - Canada# Mongolian - Cyrillic# Mongolian - PRC# Nepali# Norwegian - Bokmal# Norwegian - Nynorsk# Occitan - France# Oriya - India# Pashto - Afghanistan# Persian# Polish# Portuguese - Brazil# Portuguese - Portugal# Punjabi# Quechua (Bolivia)# Quechua (Ecuador)# Quechua (Peru)# Romanian - Romania# Romansh# Russian# Sami Finland# Sami Norway# Sami Sweden# Sami Northern Norway# Sami Northern Sweden# Sami Northern Finland# Sami Skolt# Sami Southern Norway# Sami Southern Sweden# Sanskrit# Serbian - Cyrillic# Serbian - Bosnia Cyrillic# Serbian - Latin# Serbian - Bosnia Latin# Sinhala - Sri Lanka# Northern Sotho# Setswana - Southern Africa# Slovak# Slovenian# Spanish - Spain# Spanish - Mexico# Spanish - Spain (Modern)# Spanish - Guatemala# Spanish - Costa Rica# Spanish - Panama# Spanish - Dominican Republic# Spanish - Venezuela# Spanish - Colombia# Spanish - Peru# Spanish - Argentina# Spanish - Ecuador# Spanish - Chile# Spanish - Uruguay# Spanish - Paraguay# Spanish - Bolivia# Spanish - El Salvador# Spanish - Honduras# Spanish - Nicaragua# Spanish - Puerto Rico# Spanish - United States#    0x0430: "", # Sutu - Not supported# Swahili# Swedish - Sweden# Swedish - Finland# Syriac# Tajik - Cyrillic# Tamazight - Latin# Tamil# Tatar# Telugu# Thai# Tibetan - Bhutan# Tibetan - PRC# Turkish# Turkmen - Cyrillic# Uighur - Arabic# Ukrainian# Upper Sorbian - Germany# Urdu# Urdu - India# Uzbek - Latin# Uzbek - Cyrillic# Vietnamese# Welsh# Wolof - Senegal# Xhosa - South Africa# Yakut - Cyrillic# Yi - PRC# Yoruba - Nigeria# Zulub'Locale support module.

The module provides low-level access to the C lib's locale APIs and adds high
level number formatting APIs as well as a locale aliasing engine to complement
these.

The aliasing engine includes support for many commonly used locale names and
maps them to values suitable for passing to the C lib's setlocale() function. It
also includes default encodings for all supported locale names.

'u'Locale support module.

The module provides low-level access to the C lib's locale APIs and adds high
level number formatting APIs as well as a locale aliasing engine to complement
these.

The aliasing engine includes support for many commonly used locale names and
maps them to values suitable for passing to the C lib's setlocale() function. It
also includes default encodings for all supported locale names.

'b'getlocale'u'getlocale'b'getdefaultlocale'u'getdefaultlocale'b'getpreferredencoding'u'getpreferredencoding'b'setlocale'u'setlocale'b'resetlocale'u'resetlocale'b'localeconv'u'localeconv'b'strcoll'u'strcoll'b'strxfrm'u'strxfrm'b'atof'u'atof'b'atoi'u'atoi'b'format_string'u'format_string'b'currency'u'currency'b'normalize'u'normalize'b'LC_CTYPE'u'LC_CTYPE'b'LC_COLLATE'u'LC_COLLATE'b'LC_TIME'u'LC_TIME'b'LC_MONETARY'u'LC_MONETARY'b'LC_NUMERIC'u'LC_NUMERIC'b'CHAR_MAX'u'CHAR_MAX'b'getencoding'u'getencoding'b' strcoll(string,string) -> int.
        Compares two strings according to the locale.
    'u' strcoll(string,string) -> int.
        Compares two strings according to the locale.
    'b' strxfrm(string) -> string.
        Returns a string that behaves for cmp locale-aware.
    'u' strxfrm(string) -> string.
        Returns a string that behaves for cmp locale-aware.
    'b' localeconv() -> dict.
            Returns numeric and monetary locale-specific parameters.
        'u' localeconv() -> dict.
            Returns numeric and monetary locale-specific parameters.
        'b'currency_symbol'u'currency_symbol'b'n_sign_posn'u'n_sign_posn'b'p_cs_precedes'u'p_cs_precedes'b'n_cs_precedes'u'n_cs_precedes'b'mon_grouping'u'mon_grouping'b'n_sep_by_space'u'n_sep_by_space'b'negative_sign'u'negative_sign'b'positive_sign'u'positive_sign'b'p_sep_by_space'u'p_sep_by_space'b'int_curr_symbol'u'int_curr_symbol'b'p_sign_posn'u'p_sign_posn'b'mon_thousands_sep'u'mon_thousands_sep'b'frac_digits'u'frac_digits'b'mon_decimal_point'u'mon_decimal_point'b'int_frac_digits'u'int_frac_digits'b' setlocale(integer,string=None) -> string.
            Activates/queries locale processing.
        'u' setlocale(integer,string=None) -> string.
            Activates/queries locale processing.
        'b'_locale emulation only supports "C" locale'u'_locale emulation only supports "C" locale'b'invalid grouping'u'invalid grouping'b'%(?:\((?P<key>.*?)\))?(?P<modifiers>[-#0-9 +*.hlL]*?)[eEfFgGdiouxXcrs%]'u'%(?:\((?P<key>.*?)\))?(?P<modifiers>[-#0-9 +*.hlL]*?)[eEfFgGdiouxXcrs%]'b'eEfFgGdiu'u'eEfFgGdiu'b'Formats a string in the same way that the % formatting would use,
    but takes the current locale into account.

    Grouping is applied if the third parameter is true.
    Conversion uses monetary thousands separator and grouping strings if
    forth parameter monetary is true.'u'Formats a string in the same way that the % formatting would use,
    but takes the current locale into account.

    Grouping is applied if the third parameter is true.
    Conversion uses monetary thousands separator and grouping strings if
    forth parameter monetary is true.'b'modifiers'u'modifiers'b'Formats val according to the currency settings
    in the current locale.'u'Formats val according to the currency settings
    in the current locale.'b'Currency formatting is not possible using the 'C' locale.'u'Currency formatting is not possible using the 'C' locale.'b'Convert float to string, taking the locale into account.'u'Convert float to string, taking the locale into account.'b'%.12g'u'%.12g'b'Parses a string as a normalized number according to the locale settings.'u'Parses a string as a normalized number according to the locale settings.'b'Parses a string as locale number according to the locale settings.'u'Parses a string as locale number according to the locale settings.'b'Parses a string as a float according to the locale settings.'u'Parses a string as a float according to the locale settings.'b'Converts a string to an integer according to the locale settings.'u'Converts a string to an integer according to the locale settings.'b'.ISO8859-15'u'.ISO8859-15'b'ISO8859-15'u'ISO8859-15'b'UTF-8'u'UTF-8'b'ISO8859-1'u'ISO8859-1'b' Returns a normalized locale code for the given locale
        name.

        The returned locale code is formatted for use with
        setlocale().

        If normalization fails, the original name is returned
        unchanged.

        If the given encoding is not known, the function defaults to
        the default encoding for the locale code just like setlocale()
        does.

    'u' Returns a normalized locale code for the given locale
        name.

        The returned locale code is formatted for use with
        setlocale().

        If normalization fails, the original name is returned
        unchanged.

        If the given encoding is not known, the function defaults to
        the default encoding for the locale code just like setlocale()
        does.

    'b' Parses the locale code for localename and returns the
        result as tuple (language code, encoding).

        The localename is normalized and passed through the locale
        alias engine. A ValueError is raised in case the locale name
        cannot be parsed.

        The language code corresponds to RFC 1766.  code and encoding
        can be None in case the values cannot be determined or are
        unknown to this implementation.

    'u' Parses the locale code for localename and returns the
        result as tuple (language code, encoding).

        The localename is normalized and passed through the locale
        alias engine. A ValueError is raised in case the locale name
        cannot be parsed.

        The language code corresponds to RFC 1766.  code and encoding
        can be None in case the values cannot be determined or are
        unknown to this implementation.

    'b'unknown locale: %s'u'unknown locale: %s'b' Builds a locale code from the given tuple (language code,
        encoding).

        No aliasing or normalizing takes place.

    'u' Builds a locale code from the given tuple (language code,
        encoding).

        No aliasing or normalizing takes place.

    'b'Locale must be None, a string, or an iterable of two strings -- language code, encoding.'u'Locale must be None, a string, or an iterable of two strings -- language code, encoding.'b' Tries to determine the default locale settings and returns
        them as tuple (language code, encoding).

        According to POSIX, a program which has not called
        setlocale(LC_ALL, "") runs using the portable 'C' locale.
        Calling setlocale(LC_ALL, "") lets it use the default locale as
        defined by the LANG variable. Since we don't want to interfere
        with the current locale setting we thus emulate the behavior
        in the way described above.

        To maintain compatibility with other platforms, not only the
        LANG variable is tested, but a list of variables given as
        envvars parameter. The first found to be defined will be
        used. envvars defaults to the search path used in GNU gettext;
        it must always contain the variable name 'LANG'.

        Except for the code 'C', the language code corresponds to RFC
        1766.  code and encoding can be None in case the values cannot
        be determined.

    'u' Tries to determine the default locale settings and returns
        them as tuple (language code, encoding).

        According to POSIX, a program which has not called
        setlocale(LC_ALL, "") runs using the portable 'C' locale.
        Calling setlocale(LC_ALL, "") lets it use the default locale as
        defined by the LANG variable. Since we don't want to interfere
        with the current locale setting we thus emulate the behavior
        in the way described above.

        To maintain compatibility with other platforms, not only the
        LANG variable is tested, but a list of variables given as
        envvars parameter. The first found to be defined will be
        used. envvars defaults to the search path used in GNU gettext;
        it must always contain the variable name 'LANG'.

        Except for the code 'C', the language code corresponds to RFC
        1766.  code and encoding can be None in case the values cannot
        be determined.

    'b'locale.getdefaultlocale'u'locale.getdefaultlocale'b'{name!r} is deprecated and slated for removal in Python {remove}. Use setlocale(), getencoding() and getlocale() instead.'u'{name!r} is deprecated and slated for removal in Python {remove}. Use setlocale(), getencoding() and getlocale() instead.'b'0x'u'0x'b' Returns the current setting for the given locale category as
        tuple (language code, encoding).

        category may be one of the LC_* value except LC_ALL. It
        defaults to LC_CTYPE.

        Except for the code 'C', the language code corresponds to RFC
        1766.  code and encoding can be None in case the values cannot
        be determined.

    'u' Returns the current setting for the given locale category as
        tuple (language code, encoding).

        category may be one of the LC_* value except LC_ALL. It
        defaults to LC_CTYPE.

        Except for the code 'C', the language code corresponds to RFC
        1766.  code and encoding can be None in case the values cannot
        be determined.

    'b'category LC_ALL is not supported'u'category LC_ALL is not supported'b' Set the locale for the given category.  The locale can be
        a string, an iterable of two strings (language code and encoding),
        or None.

        Iterables are converted to strings using the locale aliasing
        engine.  Locale strings are passed directly to the C lib.

        category may be given as one of the LC_* values.

    'u' Set the locale for the given category.  The locale can be
        a string, an iterable of two strings (language code and encoding),
        or None.

        Iterables are converted to strings using the locale aliasing
        engine.  Locale strings are passed directly to the C lib.

        category may be given as one of the LC_* values.

    'b' Sets the locale for category to the default setting.

        The default setting is determined by calling
        getdefaultlocale(). category defaults to LC_ALL.

    'u' Sets the locale for category to the default setting.

        The default setting is determined by calling
        getdefaultlocale(). category defaults to LC_ALL.

    'b'Use locale.setlocale(locale.LC_ALL, "") instead'u'Use locale.setlocale(locale.LC_ALL, "") instead'b'getandroidapilevel'u'getandroidapilevel'b'Return the charset that the user is likely using,
        according to the system configuration.'u'Return the charset that the user is likely using,
        according to the system configuration.'b'UTF-8 Mode affects locale.getpreferredencoding(). Consider locale.getencoding() instead.'u'UTF-8 Mode affects locale.getpreferredencoding(). Consider locale.getencoding() instead.'b'Return the charset that the user is likely using.'u'Return the charset that the user is likely using.'b'en'u'en'b'JIS7'u'JIS7'b'jis'u'jis'b'jis7'u'jis7'b'eucJP'u'eucJP'b'ajec'u'ajec'b'KOI8-C'u'KOI8-C'b'koi8c'u'koi8c'b'CP1251'u'CP1251'b'microsoftcp1251'u'microsoftcp1251'b'CP1255'u'CP1255'b'microsoftcp1255'u'microsoftcp1255'b'CP1256'u'CP1256'b'microsoftcp1256'u'microsoftcp1256'b'88591'u'88591'b'ISO8859-2'u'ISO8859-2'b'88592'u'88592'b'ISO8859-5'u'ISO8859-5'b'88595'u'88595'b'885915'u'885915'b'ISO8859-10'u'ISO8859-10'b'ISO8859-11'u'ISO8859-11'b'ISO8859-13'u'ISO8859-13'b'ISO8859-14'u'ISO8859-14'b'ISO8859-16'u'ISO8859-16'b'ISO8859-3'u'ISO8859-3'b'ISO8859-4'u'ISO8859-4'b'ISO8859-6'u'ISO8859-6'b'ISO8859-7'u'ISO8859-7'b'ISO8859-8'u'ISO8859-8'b'ISO8859-9'u'ISO8859-9'b'SJIS'u'SJIS'b'TACTIS'u'TACTIS'b'tactis'u'tactis'b'eucKR'u'eucKR'b'KOI8-R'u'KOI8-R'b'KOI8-T'u'KOI8-T'b'koi8_t'u'koi8_t'b'KOI8-U'u'KOI8-U'b'koi8_u'u'koi8_u'b'RK1048'u'RK1048'b'az_AZ.KOI8-C'u'az_AZ.KOI8-C'b'a3'u'a3'b'a3_az'u'a3_az'b'a3_az.koic'u'a3_az.koic'b'aa_DJ.ISO8859-1'u'aa_DJ.ISO8859-1'b'aa_dj'u'aa_dj'b'aa_ER.UTF-8'u'aa_ER.UTF-8'b'aa_er'u'aa_er'b'aa_ET.UTF-8'u'aa_ET.UTF-8'b'aa_et'u'aa_et'b'af_ZA.ISO8859-1'u'af_ZA.ISO8859-1'b'af'u'af'b'af_za'u'af_za'b'agr_PE.UTF-8'u'agr_PE.UTF-8'b'agr_pe'u'agr_pe'b'ak_GH.UTF-8'u'ak_GH.UTF-8'b'ak_gh'u'ak_gh'b'am_ET.UTF-8'u'am_ET.UTF-8'b'am'u'am'b'am_et'u'am_et'b'en_US.ISO8859-1'u'en_US.ISO8859-1'b'american'u'american'b'an_ES.ISO8859-15'u'an_ES.ISO8859-15'b'an_es'u'an_es'b'anp_IN.UTF-8'u'anp_IN.UTF-8'b'anp_in'u'anp_in'b'ar_AA.ISO8859-6'u'ar_AA.ISO8859-6'b'ar'u'ar'b'ar_aa'u'ar_aa'b'ar_AE.ISO8859-6'u'ar_AE.ISO8859-6'b'ar_ae'u'ar_ae'b'ar_BH.ISO8859-6'u'ar_BH.ISO8859-6'b'ar_bh'u'ar_bh'b'ar_DZ.ISO8859-6'u'ar_DZ.ISO8859-6'b'ar_dz'u'ar_dz'b'ar_EG.ISO8859-6'u'ar_EG.ISO8859-6'b'ar_eg'u'ar_eg'b'ar_IN.UTF-8'u'ar_IN.UTF-8'b'ar_in'u'ar_in'b'ar_IQ.ISO8859-6'u'ar_IQ.ISO8859-6'b'ar_iq'u'ar_iq'b'ar_JO.ISO8859-6'u'ar_JO.ISO8859-6'b'ar_jo'u'ar_jo'b'ar_KW.ISO8859-6'u'ar_KW.ISO8859-6'b'ar_kw'u'ar_kw'b'ar_LB.ISO8859-6'u'ar_LB.ISO8859-6'b'ar_lb'u'ar_lb'b'ar_LY.ISO8859-6'u'ar_LY.ISO8859-6'b'ar_ly'u'ar_ly'b'ar_MA.ISO8859-6'u'ar_MA.ISO8859-6'b'ar_ma'u'ar_ma'b'ar_OM.ISO8859-6'u'ar_OM.ISO8859-6'b'ar_om'u'ar_om'b'ar_QA.ISO8859-6'u'ar_QA.ISO8859-6'b'ar_qa'u'ar_qa'b'ar_SA.ISO8859-6'u'ar_SA.ISO8859-6'b'ar_sa'u'ar_sa'b'ar_SD.ISO8859-6'u'ar_SD.ISO8859-6'b'ar_sd'u'ar_sd'b'ar_SS.UTF-8'u'ar_SS.UTF-8'b'ar_ss'u'ar_ss'b'ar_SY.ISO8859-6'u'ar_SY.ISO8859-6'b'ar_sy'u'ar_sy'b'ar_TN.ISO8859-6'u'ar_TN.ISO8859-6'b'ar_tn'u'ar_tn'b'ar_YE.ISO8859-6'u'ar_YE.ISO8859-6'b'ar_ye'u'ar_ye'b'as_IN.UTF-8'u'as_IN.UTF-8'b'as_in'u'as_in'b'ast_ES.ISO8859-15'u'ast_ES.ISO8859-15'b'ast_es'u'ast_es'b'ayc_PE.UTF-8'u'ayc_PE.UTF-8'b'ayc_pe'u'ayc_pe'b'az_AZ.ISO8859-9E'u'az_AZ.ISO8859-9E'b'az'u'az'b'az_az'u'az_az'b'az_az.iso88599e'u'az_az.iso88599e'b'az_IR.UTF-8'u'az_IR.UTF-8'b'az_ir'u'az_ir'b'be_BY.CP1251'u'be_BY.CP1251'b'be'u'be'b'be_BY.UTF-8@latin'u'be_BY.UTF-8@latin'b'be@latin'u'be@latin'b'bg_BG.UTF-8'u'bg_BG.UTF-8'b'be_bg.utf8'u'be_bg.utf8'b'be_by'u'be_by'b'be_by@latin'u'be_by@latin'b'bem_ZM.UTF-8'u'bem_ZM.UTF-8'b'bem_zm'u'bem_zm'b'ber_DZ.UTF-8'u'ber_DZ.UTF-8'b'ber_dz'u'ber_dz'b'ber_MA.UTF-8'u'ber_MA.UTF-8'b'ber_ma'u'ber_ma'b'bg_BG.CP1251'u'bg_BG.CP1251'b'bg'u'bg'b'bg_bg'u'bg_bg'b'bhb_IN.UTF-8'u'bhb_IN.UTF-8'b'bhb_in.utf8'u'bhb_in.utf8'b'bho_IN.UTF-8'u'bho_IN.UTF-8'b'bho_in'u'bho_in'b'bho_NP.UTF-8'u'bho_NP.UTF-8'b'bho_np'u'bho_np'b'bi_VU.UTF-8'u'bi_VU.UTF-8'b'bi_vu'u'bi_vu'b'bn_BD.UTF-8'u'bn_BD.UTF-8'b'bn_bd'u'bn_bd'b'bn_IN.UTF-8'u'bn_IN.UTF-8'b'bn_in'u'bn_in'b'bo_CN.UTF-8'u'bo_CN.UTF-8'b'bo_cn'u'bo_cn'b'bo_IN.UTF-8'u'bo_IN.UTF-8'b'bo_in'u'bo_in'b'nb_NO.ISO8859-1'u'nb_NO.ISO8859-1'b'bokmal'u'bokmal'b'bokml'u'bokml'b'br_FR.ISO8859-1'u'br_FR.ISO8859-1'b'br'u'br'b'br_fr'u'br_fr'b'brx_IN.UTF-8'u'brx_IN.UTF-8'b'brx_in'u'brx_in'b'bs_BA.ISO8859-2'u'bs_BA.ISO8859-2'b'bs'u'bs'b'bs_ba'u'bs_ba'b'bulgarian'u'bulgarian'b'byn_ER.UTF-8'u'byn_ER.UTF-8'b'byn_er'u'byn_er'b'fr_CA.ISO8859-1'u'fr_CA.ISO8859-1'b'c-french'u'c-french'b'c.ascii'u'c.ascii'b'c.en'u'c.en'b'c.iso88591'u'c.iso88591'b'C.UTF-8'u'C.UTF-8'b'c.utf8'u'c.utf8'b'c_c'u'c_c'b'c_c.c'u'c_c.c'b'ca_ES.ISO8859-1'u'ca_ES.ISO8859-1'b'ca'u'ca'b'ca_AD.ISO8859-1'u'ca_AD.ISO8859-1'b'ca_ad'u'ca_ad'b'ca_es'u'ca_es'b'ca_ES.UTF-8@valencia'u'ca_ES.UTF-8@valencia'b'ca_es@valencia'u'ca_es@valencia'b'ca_FR.ISO8859-1'u'ca_FR.ISO8859-1'b'ca_fr'u'ca_fr'b'ca_IT.ISO8859-1'u'ca_IT.ISO8859-1'b'ca_it'u'ca_it'b'catalan'u'catalan'b'ce_RU.UTF-8'u'ce_RU.UTF-8'b'ce_ru'u'ce_ru'b'cextend'u'cextend'b'zh_CN.eucCN'u'zh_CN.eucCN'b'chinese-s'u'chinese-s'b'zh_TW.eucTW'u'zh_TW.eucTW'b'chinese-t'u'chinese-t'b'chr_US.UTF-8'u'chr_US.UTF-8'b'chr_us'u'chr_us'b'ckb_IQ.UTF-8'u'ckb_IQ.UTF-8'b'ckb_iq'u'ckb_iq'b'cmn_TW.UTF-8'u'cmn_TW.UTF-8'b'cmn_tw'u'cmn_tw'b'crh_UA.UTF-8'u'crh_UA.UTF-8'b'crh_ua'u'crh_ua'b'hr_HR.ISO8859-2'u'hr_HR.ISO8859-2'b'croatian'u'croatian'b'cs_CZ.ISO8859-2'u'cs_CZ.ISO8859-2'b'cs'u'cs'b'cs_cs'u'cs_cs'b'cs_cz'u'cs_cz'b'csb_PL.UTF-8'u'csb_PL.UTF-8'b'csb_pl'u'csb_pl'b'cv_RU.UTF-8'u'cv_RU.UTF-8'b'cv_ru'u'cv_ru'b'cy_GB.ISO8859-1'u'cy_GB.ISO8859-1'b'cy'u'cy'b'cy_gb'u'cy_gb'b'cz'u'cz'b'cz_cz'u'cz_cz'b'czech'u'czech'b'da_DK.ISO8859-1'u'da_DK.ISO8859-1'b'da'u'da'b'da_dk'u'da_dk'b'danish'u'danish'b'dansk'u'dansk'b'de_DE.ISO8859-1'u'de_DE.ISO8859-1'b'de'u'de'b'de_AT.ISO8859-1'u'de_AT.ISO8859-1'b'de_at'u'de_at'b'de_BE.ISO8859-1'u'de_BE.ISO8859-1'b'de_be'u'de_be'b'de_CH.ISO8859-1'u'de_CH.ISO8859-1'b'de_ch'u'de_ch'b'de_de'u'de_de'b'de_IT.ISO8859-1'u'de_IT.ISO8859-1'b'de_it'u'de_it'b'de_LI.UTF-8'u'de_LI.UTF-8'b'de_li.utf8'u'de_li.utf8'b'de_LU.ISO8859-1'u'de_LU.ISO8859-1'b'de_lu'u'de_lu'b'deutsch'u'deutsch'b'doi_IN.UTF-8'u'doi_IN.UTF-8'b'doi_in'u'doi_in'b'nl_NL.ISO8859-1'u'nl_NL.ISO8859-1'b'dutch'u'dutch'b'nl_BE.ISO8859-1'u'nl_BE.ISO8859-1'b'dutch.iso88591'u'dutch.iso88591'b'dv_MV.UTF-8'u'dv_MV.UTF-8'b'dv_mv'u'dv_mv'b'dz_BT.UTF-8'u'dz_BT.UTF-8'b'dz_bt'u'dz_bt'b'ee_EE.ISO8859-4'u'ee_EE.ISO8859-4'b'ee'u'ee'b'ee_ee'u'ee_ee'b'et_EE.ISO8859-1'u'et_EE.ISO8859-1'b'eesti'u'eesti'b'el_GR.ISO8859-7'u'el_GR.ISO8859-7'b'el'u'el'b'el_CY.ISO8859-7'u'el_CY.ISO8859-7'b'el_cy'u'el_cy'b'el_gr'u'el_gr'b'el_GR.ISO8859-15'u'el_GR.ISO8859-15'b'el_gr@euro'u'el_gr@euro'b'en_AG.UTF-8'u'en_AG.UTF-8'b'en_ag'u'en_ag'b'en_AU.ISO8859-1'u'en_AU.ISO8859-1'b'en_au'u'en_au'b'en_BE.ISO8859-1'u'en_BE.ISO8859-1'b'en_be'u'en_be'b'en_BW.ISO8859-1'u'en_BW.ISO8859-1'b'en_bw'u'en_bw'b'en_CA.ISO8859-1'u'en_CA.ISO8859-1'b'en_ca'u'en_ca'b'en_DK.ISO8859-1'u'en_DK.ISO8859-1'b'en_dk'u'en_dk'b'en_DL.UTF-8'u'en_DL.UTF-8'b'en_dl.utf8'u'en_dl.utf8'b'en_GB.ISO8859-1'u'en_GB.ISO8859-1'b'en_gb'u'en_gb'b'en_HK.ISO8859-1'u'en_HK.ISO8859-1'b'en_hk'u'en_hk'b'en_IE.ISO8859-1'u'en_IE.ISO8859-1'b'en_ie'u'en_ie'b'en_IL.UTF-8'u'en_IL.UTF-8'b'en_il'u'en_il'b'en_IN.ISO8859-1'u'en_IN.ISO8859-1'b'en_in'u'en_in'b'en_NG.UTF-8'u'en_NG.UTF-8'b'en_ng'u'en_ng'b'en_NZ.ISO8859-1'u'en_NZ.ISO8859-1'b'en_nz'u'en_nz'b'en_PH.ISO8859-1'u'en_PH.ISO8859-1'b'en_ph'u'en_ph'b'en_SC.UTF-8'u'en_SC.UTF-8'b'en_sc.utf8'u'en_sc.utf8'b'en_SG.ISO8859-1'u'en_SG.ISO8859-1'b'en_sg'u'en_sg'b'en_uk'u'en_uk'b'en_us'u'en_us'b'en_US.ISO8859-15'u'en_US.ISO8859-15'b'en_us@euro@euro'u'en_us@euro@euro'b'en_ZA.ISO8859-1'u'en_ZA.ISO8859-1'b'en_za'u'en_za'b'en_ZM.UTF-8'u'en_ZM.UTF-8'b'en_zm'u'en_zm'b'en_ZW.ISO8859-1'u'en_ZW.ISO8859-1'b'en_zw'u'en_zw'b'en_ZS.UTF-8'u'en_ZS.UTF-8'b'en_zw.utf8'u'en_zw.utf8'b'eng_gb'u'eng_gb'b'en_EN.ISO8859-1'u'en_EN.ISO8859-1'b'english'u'english'b'english.iso88591'u'english.iso88591'b'english_uk'u'english_uk'b'english_united-states'u'english_united-states'b'english_united-states.437'u'english_united-states.437'b'english_us'u'english_us'b'eo_XX.ISO8859-3'u'eo_XX.ISO8859-3'b'eo'u'eo'b'eo.UTF-8'u'eo.UTF-8'b'eo.utf8'u'eo.utf8'b'eo_EO.ISO8859-3'u'eo_EO.ISO8859-3'b'eo_eo'u'eo_eo'b'eo_US.UTF-8'u'eo_US.UTF-8'b'eo_us.utf8'u'eo_us.utf8'b'eo_xx'u'eo_xx'b'es_ES.ISO8859-1'u'es_ES.ISO8859-1'b'es'u'es'b'es_AR.ISO8859-1'u'es_AR.ISO8859-1'b'es_ar'u'es_ar'b'es_BO.ISO8859-1'u'es_BO.ISO8859-1'b'es_bo'u'es_bo'b'es_CL.ISO8859-1'u'es_CL.ISO8859-1'b'es_cl'u'es_cl'b'es_CO.ISO8859-1'u'es_CO.ISO8859-1'b'es_co'u'es_co'b'es_CR.ISO8859-1'u'es_CR.ISO8859-1'b'es_cr'u'es_cr'b'es_CU.UTF-8'u'es_CU.UTF-8'b'es_cu'u'es_cu'b'es_DO.ISO8859-1'u'es_DO.ISO8859-1'b'es_do'u'es_do'b'es_EC.ISO8859-1'u'es_EC.ISO8859-1'b'es_ec'u'es_ec'b'es_es'u'es_es'b'es_GT.ISO8859-1'u'es_GT.ISO8859-1'b'es_gt'u'es_gt'b'es_HN.ISO8859-1'u'es_HN.ISO8859-1'b'es_hn'u'es_hn'b'es_MX.ISO8859-1'u'es_MX.ISO8859-1'b'es_mx'u'es_mx'b'es_NI.ISO8859-1'u'es_NI.ISO8859-1'b'es_ni'u'es_ni'b'es_PA.ISO8859-1'u'es_PA.ISO8859-1'b'es_pa'u'es_pa'b'es_PE.ISO8859-1'u'es_PE.ISO8859-1'b'es_pe'u'es_pe'b'es_PR.ISO8859-1'u'es_PR.ISO8859-1'b'es_pr'u'es_pr'b'es_PY.ISO8859-1'u'es_PY.ISO8859-1'b'es_py'u'es_py'b'es_SV.ISO8859-1'u'es_SV.ISO8859-1'b'es_sv'u'es_sv'b'es_US.ISO8859-1'u'es_US.ISO8859-1'b'es_us'u'es_us'b'es_UY.ISO8859-1'u'es_UY.ISO8859-1'b'es_uy'u'es_uy'b'es_VE.ISO8859-1'u'es_VE.ISO8859-1'b'es_ve'u'es_ve'b'estonian'u'estonian'b'et_EE.ISO8859-15'u'et_EE.ISO8859-15'b'et'u'et'b'et_ee'u'et_ee'b'eu_ES.ISO8859-1'u'eu_ES.ISO8859-1'b'eu'u'eu'b'eu_es'u'eu_es'b'eu_FR.ISO8859-1'u'eu_FR.ISO8859-1'b'eu_fr'u'eu_fr'b'fa_IR.UTF-8'u'fa_IR.UTF-8'b'fa'u'fa'b'fa_ir'u'fa_ir'b'fa_IR.ISIRI-3342'u'fa_IR.ISIRI-3342'b'fa_ir.isiri3342'u'fa_ir.isiri3342'b'ff_SN.UTF-8'u'ff_SN.UTF-8'b'ff_sn'u'ff_sn'b'fi_FI.ISO8859-15'u'fi_FI.ISO8859-15'b'fi'u'fi'b'fi_fi'u'fi_fi'b'fil_PH.UTF-8'u'fil_PH.UTF-8'b'fil_ph'u'fil_ph'b'fi_FI.ISO8859-1'u'fi_FI.ISO8859-1'b'finnish'u'finnish'b'fo_FO.ISO8859-1'u'fo_FO.ISO8859-1'b'fo'u'fo'b'fo_fo'u'fo_fo'b'fr_FR.ISO8859-1'u'fr_FR.ISO8859-1'b'fr'u'fr'b'fr_BE.ISO8859-1'u'fr_BE.ISO8859-1'b'fr_be'u'fr_be'b'fr_ca'u'fr_ca'b'fr_CH.ISO8859-1'u'fr_CH.ISO8859-1'b'fr_ch'u'fr_ch'b'fr_fr'u'fr_fr'b'fr_LU.ISO8859-1'u'fr_LU.ISO8859-1'b'fr_lu'u'fr_lu'b'franais'u'franais'b'fre_fr'u'fre_fr'b'french'u'french'b'french.iso88591'u'french.iso88591'b'french_france'u'french_france'b'fur_IT.UTF-8'u'fur_IT.UTF-8'b'fur_it'u'fur_it'b'fy_DE.UTF-8'u'fy_DE.UTF-8'b'fy_de'u'fy_de'b'fy_NL.UTF-8'u'fy_NL.UTF-8'b'fy_nl'u'fy_nl'b'ga_IE.ISO8859-1'u'ga_IE.ISO8859-1'b'ga'u'ga'b'ga_ie'u'ga_ie'b'gl_ES.ISO8859-1'u'gl_ES.ISO8859-1'b'galego'u'galego'b'galician'u'galician'b'gd_GB.ISO8859-1'u'gd_GB.ISO8859-1'b'gd'u'gd'b'gd_gb'u'gd_gb'b'ger_de'u'ger_de'b'german'u'german'b'german.iso88591'u'german.iso88591'b'german_germany'u'german_germany'b'gez_ER.UTF-8'u'gez_ER.UTF-8'b'gez_er'u'gez_er'b'gez_ET.UTF-8'u'gez_ET.UTF-8'b'gez_et'u'gez_et'b'gl'u'gl'b'gl_es'u'gl_es'b'gu_IN.UTF-8'u'gu_IN.UTF-8'b'gu_in'u'gu_in'b'gv_GB.ISO8859-1'u'gv_GB.ISO8859-1'b'gv'u'gv'b'gv_gb'u'gv_gb'b'ha_NG.UTF-8'u'ha_NG.UTF-8'b'ha_ng'u'ha_ng'b'hak_TW.UTF-8'u'hak_TW.UTF-8'b'hak_tw'u'hak_tw'b'he_IL.ISO8859-8'u'he_IL.ISO8859-8'b'he'u'he'b'he_il'u'he_il'b'hi_IN.ISCII-DEV'u'hi_IN.ISCII-DEV'b'hi'u'hi'b'hi_in'u'hi_in'b'hi_in.isciidev'u'hi_in.isciidev'b'hif_FJ.UTF-8'u'hif_FJ.UTF-8'b'hif_fj'u'hif_fj'b'hne_IN.UTF-8'u'hne_IN.UTF-8'b'hne'u'hne'b'hne_in'u'hne_in'b'hr'u'hr'b'hr_hr'u'hr_hr'b'hrvatski'u'hrvatski'b'hsb_DE.ISO8859-2'u'hsb_DE.ISO8859-2'b'hsb_de'u'hsb_de'b'ht_HT.UTF-8'u'ht_HT.UTF-8'b'ht_ht'u'ht_ht'b'hu_HU.ISO8859-2'u'hu_HU.ISO8859-2'b'hu'u'hu'b'hu_hu'u'hu_hu'b'hungarian'u'hungarian'b'hy_AM.UTF-8'u'hy_AM.UTF-8'b'hy_am'u'hy_am'b'hy_AM.ARMSCII_8'u'hy_AM.ARMSCII_8'b'hy_am.armscii8'u'hy_am.armscii8'b'ia.UTF-8'u'ia.UTF-8'b'ia'u'ia'b'ia_FR.UTF-8'u'ia_FR.UTF-8'b'ia_fr'u'ia_fr'b'is_IS.ISO8859-1'u'is_IS.ISO8859-1'b'icelandic'u'icelandic'b'id_ID.ISO8859-1'u'id_ID.ISO8859-1'b'id_id'u'id_id'b'ig_NG.UTF-8'u'ig_NG.UTF-8'b'ig_ng'u'ig_ng'b'ik_CA.UTF-8'u'ik_CA.UTF-8'b'ik_ca'u'ik_ca'b'in_id'u'in_id'b'is_is'u'is_is'b'iso8859-1'u'iso8859-1'b'iso8859-15'u'iso8859-15'b'it_IT.ISO8859-1'u'it_IT.ISO8859-1'b'it'u'it'b'it_CH.ISO8859-1'u'it_CH.ISO8859-1'b'it_ch'u'it_ch'b'it_it'u'it_it'b'italian'u'italian'b'iu_CA.NUNACOM-8'u'iu_CA.NUNACOM-8'b'iu'u'iu'b'iu_ca'u'iu_ca'b'iu_ca.nunacom8'u'iu_ca.nunacom8'b'iw'u'iw'b'iw_il'u'iw_il'b'iw_IL.UTF-8'u'iw_IL.UTF-8'b'iw_il.utf8'u'iw_il.utf8'b'ja_JP.eucJP'u'ja_JP.eucJP'b'ja'u'ja'b'ja_jp'u'ja_jp'b'ja_jp.euc'u'ja_jp.euc'b'ja_JP.SJIS'u'ja_JP.SJIS'b'ja_jp.mscode'u'ja_jp.mscode'b'ja_jp.pck'u'ja_jp.pck'b'japan'u'japan'b'japanese'u'japanese'b'japanese-euc'u'japanese-euc'b'japanese.euc'u'japanese.euc'b'jp_jp'u'jp_jp'b'ka_GE.GEORGIAN-ACADEMY'u'ka_GE.GEORGIAN-ACADEMY'b'ka'u'ka'b'ka_ge'u'ka_ge'b'ka_ge.georgianacademy'u'ka_ge.georgianacademy'b'ka_GE.GEORGIAN-PS'u'ka_GE.GEORGIAN-PS'b'ka_ge.georgianps'u'ka_ge.georgianps'b'ka_ge.georgianrs'u'ka_ge.georgianrs'b'kab_DZ.UTF-8'u'kab_DZ.UTF-8'b'kab_dz'u'kab_dz'b'kk_KZ.ptcp154'u'kk_KZ.ptcp154'b'kk_kz'u'kk_kz'b'kl_GL.ISO8859-1'u'kl_GL.ISO8859-1'b'kl'u'kl'b'kl_gl'u'kl_gl'b'km_KH.UTF-8'u'km_KH.UTF-8'b'km_kh'u'km_kh'b'kn_IN.UTF-8'u'kn_IN.UTF-8'b'kn'u'kn'b'kn_in'u'kn_in'b'ko_KR.eucKR'u'ko_KR.eucKR'b'ko'u'ko'b'ko_kr'u'ko_kr'b'ko_kr.euc'u'ko_kr.euc'b'kok_IN.UTF-8'u'kok_IN.UTF-8'b'kok_in'u'kok_in'b'korean.euc'u'korean.euc'b'ks_IN.UTF-8'u'ks_IN.UTF-8'b'ks'u'ks'b'ks_in'u'ks_in'b'ks_IN.UTF-8@devanagari'u'ks_IN.UTF-8@devanagari'b'ks_in@devanagari.utf8'u'ks_in@devanagari.utf8'b'ku_TR.ISO8859-9'u'ku_TR.ISO8859-9'b'ku_tr'u'ku_tr'b'kw_GB.ISO8859-1'u'kw_GB.ISO8859-1'b'kw'u'kw'b'kw_gb'u'kw_gb'b'ky_KG.UTF-8'u'ky_KG.UTF-8'b'ky'u'ky'b'ky_kg'u'ky_kg'b'lb_LU.UTF-8'u'lb_LU.UTF-8'b'lb_lu'u'lb_lu'b'lg_UG.ISO8859-10'u'lg_UG.ISO8859-10'b'lg_ug'u'lg_ug'b'li_BE.UTF-8'u'li_BE.UTF-8'b'li_be'u'li_be'b'li_NL.UTF-8'u'li_NL.UTF-8'b'li_nl'u'li_nl'b'lij_IT.UTF-8'u'lij_IT.UTF-8'b'lij_it'u'lij_it'b'lt_LT.ISO8859-13'u'lt_LT.ISO8859-13'b'lithuanian'u'lithuanian'b'ln_CD.UTF-8'u'ln_CD.UTF-8'b'ln_cd'u'ln_cd'b'lo_LA.MULELAO-1'u'lo_LA.MULELAO-1'b'lo'u'lo'b'lo_la'u'lo_la'b'lo_LA.IBM-CP1133'u'lo_LA.IBM-CP1133'b'lo_la.cp1133'u'lo_la.cp1133'b'lo_la.ibmcp1133'u'lo_la.ibmcp1133'b'lo_la.mulelao1'u'lo_la.mulelao1'b'lt_lt'u'lt_lt'b'lv_LV.ISO8859-13'u'lv_LV.ISO8859-13'b'lv'u'lv'b'lv_lv'u'lv_lv'b'lzh_TW.UTF-8'u'lzh_TW.UTF-8'b'lzh_tw'u'lzh_tw'b'mag_IN.UTF-8'u'mag_IN.UTF-8'b'mag_in'u'mag_in'b'mai_IN.UTF-8'u'mai_IN.UTF-8'b'mai'u'mai'b'mai_in'u'mai_in'b'mai_NP.UTF-8'u'mai_NP.UTF-8'b'mai_np'u'mai_np'b'mfe_MU.UTF-8'u'mfe_MU.UTF-8'b'mfe_mu'u'mfe_mu'b'mg_MG.ISO8859-15'u'mg_MG.ISO8859-15'b'mg_mg'u'mg_mg'b'mhr_RU.UTF-8'u'mhr_RU.UTF-8'b'mhr_ru'u'mhr_ru'b'mi_NZ.ISO8859-1'u'mi_NZ.ISO8859-1'b'mi'u'mi'b'mi_nz'u'mi_nz'b'miq_NI.UTF-8'u'miq_NI.UTF-8'b'miq_ni'u'miq_ni'b'mjw_IN.UTF-8'u'mjw_IN.UTF-8'b'mjw_in'u'mjw_in'b'mk_MK.ISO8859-5'u'mk_MK.ISO8859-5'b'mk'u'mk'b'mk_mk'u'mk_mk'b'ml_IN.UTF-8'u'ml_IN.UTF-8'b'ml'u'ml'b'ml_in'u'ml_in'b'mn_MN.UTF-8'u'mn_MN.UTF-8'b'mn_mn'u'mn_mn'b'mni_IN.UTF-8'u'mni_IN.UTF-8'b'mni_in'u'mni_in'b'mr_IN.UTF-8'u'mr_IN.UTF-8'b'mr'u'mr'b'mr_in'u'mr_in'b'ms_MY.ISO8859-1'u'ms_MY.ISO8859-1'b'ms'u'ms'b'ms_my'u'ms_my'b'mt_MT.ISO8859-3'u'mt_MT.ISO8859-3'b'mt'u'mt'b'mt_mt'u'mt_mt'b'my_MM.UTF-8'u'my_MM.UTF-8'b'my_mm'u'my_mm'b'nan_TW.UTF-8'u'nan_TW.UTF-8'b'nan_tw'u'nan_tw'b'nb'u'nb'b'nb_no'u'nb_no'b'nds_DE.UTF-8'u'nds_DE.UTF-8'b'nds_de'u'nds_de'b'nds_NL.UTF-8'u'nds_NL.UTF-8'b'nds_nl'u'nds_nl'b'ne_NP.UTF-8'u'ne_NP.UTF-8'b'ne_np'u'ne_np'b'nhn_MX.UTF-8'u'nhn_MX.UTF-8'b'nhn_mx'u'nhn_mx'b'niu_NU.UTF-8'u'niu_NU.UTF-8'b'niu_nu'u'niu_nu'b'niu_NZ.UTF-8'u'niu_NZ.UTF-8'b'niu_nz'u'niu_nz'b'nl'u'nl'b'nl_AW.UTF-8'u'nl_AW.UTF-8'b'nl_aw'u'nl_aw'b'nl_be'u'nl_be'b'nl_nl'u'nl_nl'b'nn_NO.ISO8859-1'u'nn_NO.ISO8859-1'b'nn'u'nn'b'nn_no'u'nn_no'b'no_NO.ISO8859-1'u'no_NO.ISO8859-1'b'no'u'no'b'ny_NO.ISO8859-1'u'ny_NO.ISO8859-1'b'no@nynorsk'u'no@nynorsk'b'no_no'u'no_no'b'no_no.iso88591@bokmal'u'no_no.iso88591@bokmal'b'no_no.iso88591@nynorsk'u'no_no.iso88591@nynorsk'b'norwegian'u'norwegian'b'nr_ZA.ISO8859-1'u'nr_ZA.ISO8859-1'b'nr'u'nr'b'nr_za'u'nr_za'b'nso_ZA.ISO8859-15'u'nso_ZA.ISO8859-15'b'nso'u'nso'b'nso_za'u'nso_za'b'ny'u'ny'b'ny_no'u'ny_no'b'nynorsk'u'nynorsk'b'oc_FR.ISO8859-1'u'oc_FR.ISO8859-1'b'oc'u'oc'b'oc_fr'u'oc_fr'b'om_ET.UTF-8'u'om_ET.UTF-8'b'om_et'u'om_et'b'om_KE.ISO8859-1'u'om_KE.ISO8859-1'b'om_ke'u'om_ke'b'or_IN.UTF-8'u'or_IN.UTF-8'b'or_in'u'or_in'b'os_RU.UTF-8'u'os_RU.UTF-8'b'os_ru'u'os_ru'b'pa_IN.UTF-8'u'pa_IN.UTF-8'b'pa'u'pa'b'pa_in'u'pa_in'b'pa_PK.UTF-8'u'pa_PK.UTF-8'b'pa_pk'u'pa_pk'b'pap_AN.UTF-8'u'pap_AN.UTF-8'b'pap_an'u'pap_an'b'pap_AW.UTF-8'u'pap_AW.UTF-8'b'pap_aw'u'pap_aw'b'pap_CW.UTF-8'u'pap_CW.UTF-8'b'pap_cw'u'pap_cw'b'pd_US.ISO8859-1'u'pd_US.ISO8859-1'b'pd'u'pd'b'pd_DE.ISO8859-1'u'pd_DE.ISO8859-1'b'pd_de'u'pd_de'b'pd_us'u'pd_us'b'ph_PH.ISO8859-1'u'ph_PH.ISO8859-1'b'ph'u'ph'b'ph_ph'u'ph_ph'b'pl_PL.ISO8859-2'u'pl_PL.ISO8859-2'b'pl'u'pl'b'pl_pl'u'pl_pl'b'polish'u'polish'b'pt_PT.ISO8859-1'u'pt_PT.ISO8859-1'b'portuguese'u'portuguese'b'pt_BR.ISO8859-1'u'pt_BR.ISO8859-1'b'portuguese_brazil'u'portuguese_brazil'b'posix-utf2'u'posix-utf2'b'pp_AN.ISO8859-1'u'pp_AN.ISO8859-1'b'pp'u'pp'b'pp_an'u'pp_an'b'ps_AF.UTF-8'u'ps_AF.UTF-8'b'ps_af'u'ps_af'b'pt'u'pt'b'pt_br'u'pt_br'b'pt_pt'u'pt_pt'b'quz_PE.UTF-8'u'quz_PE.UTF-8'b'quz_pe'u'quz_pe'b'raj_IN.UTF-8'u'raj_IN.UTF-8'b'raj_in'u'raj_in'b'ro_RO.ISO8859-2'u'ro_RO.ISO8859-2'b'ro'u'ro'b'ro_ro'u'ro_ro'b'romanian'u'romanian'b'ru_RU.UTF-8'u'ru_RU.UTF-8'b'ru'u'ru'b'ru_ru'u'ru_ru'b'ru_UA.KOI8-U'u'ru_UA.KOI8-U'b'ru_ua'u'ru_ua'b'rumanian'u'rumanian'b'ru_RU.KOI8-R'u'ru_RU.KOI8-R'b'russian'u'russian'b'rw_RW.ISO8859-1'u'rw_RW.ISO8859-1'b'rw'u'rw'b'rw_rw'u'rw_rw'b'sa_IN.UTF-8'u'sa_IN.UTF-8'b'sa_in'u'sa_in'b'sat_IN.UTF-8'u'sat_IN.UTF-8'b'sat_in'u'sat_in'b'sc_IT.UTF-8'u'sc_IT.UTF-8'b'sc_it'u'sc_it'b'sd_IN.UTF-8'u'sd_IN.UTF-8'b'sd'u'sd'b'sd_in'u'sd_in'b'sd_IN.UTF-8@devanagari'u'sd_IN.UTF-8@devanagari'b'sd_in@devanagari.utf8'u'sd_in@devanagari.utf8'b'sd_PK.UTF-8'u'sd_PK.UTF-8'b'sd_pk'u'sd_pk'b'se_NO.UTF-8'u'se_NO.UTF-8'b'se_no'u'se_no'b'sr_RS.UTF-8@latin'u'sr_RS.UTF-8@latin'b'serbocroatian'u'serbocroatian'b'sgs_LT.UTF-8'u'sgs_LT.UTF-8'b'sgs_lt'u'sgs_lt'b'sh'u'sh'b'sr_CS.ISO8859-2'u'sr_CS.ISO8859-2'b'sh_ba.iso88592@bosnia'u'sh_ba.iso88592@bosnia'b'sh_HR.ISO8859-2'u'sh_HR.ISO8859-2'b'sh_hr'u'sh_hr'b'sh_hr.iso88592'u'sh_hr.iso88592'b'sh_sp'u'sh_sp'b'sh_yu'u'sh_yu'b'shn_MM.UTF-8'u'shn_MM.UTF-8'b'shn_mm'u'shn_mm'b'shs_CA.UTF-8'u'shs_CA.UTF-8'b'shs_ca'u'shs_ca'b'si_LK.UTF-8'u'si_LK.UTF-8'b'si'u'si'b'si_lk'u'si_lk'b'sid_ET.UTF-8'u'sid_ET.UTF-8'b'sid_et'u'sid_et'b'sinhala'u'sinhala'b'sk_SK.ISO8859-2'u'sk_SK.ISO8859-2'b'sk'u'sk'b'sk_sk'u'sk_sk'b'sl_SI.ISO8859-2'u'sl_SI.ISO8859-2'b'sl'u'sl'b'sl_CS.ISO8859-2'u'sl_CS.ISO8859-2'b'sl_cs'u'sl_cs'b'sl_si'u'sl_si'b'slovak'u'slovak'b'slovene'u'slovene'b'slovenian'u'slovenian'b'sm_WS.UTF-8'u'sm_WS.UTF-8'b'sm_ws'u'sm_ws'b'so_DJ.ISO8859-1'u'so_DJ.ISO8859-1'b'so_dj'u'so_dj'b'so_ET.UTF-8'u'so_ET.UTF-8'b'so_et'u'so_et'b'so_KE.ISO8859-1'u'so_KE.ISO8859-1'b'so_ke'u'so_ke'b'so_SO.ISO8859-1'u'so_SO.ISO8859-1'b'so_so'u'so_so'b'sr_CS.ISO8859-5'u'sr_CS.ISO8859-5'b'sp'u'sp'b'sp_yu'u'sp_yu'b'spanish'u'spanish'b'spanish_spain'u'spanish_spain'b'sq_AL.ISO8859-2'u'sq_AL.ISO8859-2'b'sq'u'sq'b'sq_al'u'sq_al'b'sq_MK.UTF-8'u'sq_MK.UTF-8'b'sq_mk'u'sq_mk'b'sr_RS.UTF-8'u'sr_RS.UTF-8'b'sr'u'sr'b'sr@cyrillic'u'sr@cyrillic'b'sr_CS.UTF-8@latin'u'sr_CS.UTF-8@latin'b'sr@latn'u'sr@latn'b'sr_CS.UTF-8'u'sr_CS.UTF-8'b'sr_cs'u'sr_cs'b'sr_cs.iso88592@latn'u'sr_cs.iso88592@latn'b'sr_cs@latn'u'sr_cs@latn'b'sr_ME.UTF-8'u'sr_ME.UTF-8'b'sr_me'u'sr_me'b'sr_rs'u'sr_rs'b'sr_rs@latn'u'sr_rs@latn'b'sr_sp'u'sr_sp'b'sr_yu'u'sr_yu'b'sr_CS.CP1251'u'sr_CS.CP1251'b'sr_yu.cp1251@cyrillic'u'sr_yu.cp1251@cyrillic'b'sr_yu.iso88592'u'sr_yu.iso88592'b'sr_yu.iso88595'u'sr_yu.iso88595'b'sr_yu.iso88595@cyrillic'u'sr_yu.iso88595@cyrillic'b'sr_yu.microsoftcp1251@cyrillic'u'sr_yu.microsoftcp1251@cyrillic'b'sr_yu.utf8'u'sr_yu.utf8'b'sr_yu.utf8@cyrillic'u'sr_yu.utf8@cyrillic'b'sr_yu@cyrillic'u'sr_yu@cyrillic'b'ss_ZA.ISO8859-1'u'ss_ZA.ISO8859-1'b'ss'u'ss'b'ss_za'u'ss_za'b'st_ZA.ISO8859-1'u'st_ZA.ISO8859-1'b'st'u'st'b'st_za'u'st_za'b'sv_SE.ISO8859-1'u'sv_SE.ISO8859-1'b'sv'u'sv'b'sv_FI.ISO8859-1'u'sv_FI.ISO8859-1'b'sv_fi'u'sv_fi'b'sv_se'u'sv_se'b'sw_KE.UTF-8'u'sw_KE.UTF-8'b'sw_ke'u'sw_ke'b'sw_TZ.UTF-8'u'sw_TZ.UTF-8'b'sw_tz'u'sw_tz'b'swedish'u'swedish'b'szl_PL.UTF-8'u'szl_PL.UTF-8'b'szl_pl'u'szl_pl'b'ta_IN.TSCII-0'u'ta_IN.TSCII-0'b'ta'u'ta'b'ta_in'u'ta_in'b'ta_in.tscii'u'ta_in.tscii'b'ta_in.tscii0'u'ta_in.tscii0'b'ta_LK.UTF-8'u'ta_LK.UTF-8'b'ta_lk'u'ta_lk'b'tcy_IN.UTF-8'u'tcy_IN.UTF-8'b'tcy_in.utf8'u'tcy_in.utf8'b'te_IN.UTF-8'u'te_IN.UTF-8'b'te'u'te'b'te_in'u'te_in'b'tg_TJ.KOI8-C'u'tg_TJ.KOI8-C'b'tg'u'tg'b'tg_tj'u'tg_tj'b'th_TH.ISO8859-11'u'th_TH.ISO8859-11'b'th'u'th'b'th_th'u'th_th'b'th_TH.TIS620'u'th_TH.TIS620'b'th_th.tactis'u'th_th.tactis'b'th_th.tis620'u'th_th.tis620'b'the_NP.UTF-8'u'the_NP.UTF-8'b'the_np'u'the_np'b'ti_ER.UTF-8'u'ti_ER.UTF-8'b'ti_er'u'ti_er'b'ti_ET.UTF-8'u'ti_ET.UTF-8'b'ti_et'u'ti_et'b'tig_ER.UTF-8'u'tig_ER.UTF-8'b'tig_er'u'tig_er'b'tk_TM.UTF-8'u'tk_TM.UTF-8'b'tk_tm'u'tk_tm'b'tl_PH.ISO8859-1'u'tl_PH.ISO8859-1'b'tl'u'tl'b'tl_ph'u'tl_ph'b'tn_ZA.ISO8859-15'u'tn_ZA.ISO8859-15'b'tn'u'tn'b'tn_za'u'tn_za'b'to_TO.UTF-8'u'to_TO.UTF-8'b'to_to'u'to_to'b'tpi_PG.UTF-8'u'tpi_PG.UTF-8'b'tpi_pg'u'tpi_pg'b'tr_TR.ISO8859-9'u'tr_TR.ISO8859-9'b'tr'u'tr'b'tr_CY.ISO8859-9'u'tr_CY.ISO8859-9'b'tr_cy'u'tr_cy'b'tr_tr'u'tr_tr'b'ts_ZA.ISO8859-1'u'ts_ZA.ISO8859-1'b'ts'u'ts'b'ts_za'u'ts_za'b'tt_RU.TATAR-CYR'u'tt_RU.TATAR-CYR'b'tt'u'tt'b'tt_ru'u'tt_ru'b'tt_ru.tatarcyr'u'tt_ru.tatarcyr'b'tt_RU.UTF-8@iqtelif'u'tt_RU.UTF-8@iqtelif'b'tt_ru@iqtelif'u'tt_ru@iqtelif'b'turkish'u'turkish'b'ug_CN.UTF-8'u'ug_CN.UTF-8'b'ug_cn'u'ug_cn'b'uk_UA.KOI8-U'u'uk_UA.KOI8-U'b'uk'u'uk'b'uk_ua'u'uk_ua'b'en_US.utf'u'en_US.utf'b'univ'u'univ'b'en_US.UTF-8'u'en_US.UTF-8'b'universal.utf8@ucs4'u'universal.utf8@ucs4'b'unm_US.UTF-8'u'unm_US.UTF-8'b'unm_us'u'unm_us'b'ur_PK.CP1256'u'ur_PK.CP1256'b'ur'u'ur'b'ur_IN.UTF-8'u'ur_IN.UTF-8'b'ur_in'u'ur_in'b'ur_pk'u'ur_pk'b'uz_UZ.UTF-8'u'uz_UZ.UTF-8'b'uz'u'uz'b'uz_uz'u'uz_uz'b'uz_uz@cyrillic'u'uz_uz@cyrillic'b've_ZA.UTF-8'u've_ZA.UTF-8'b've'u've'b've_za'u've_za'b'vi_VN.TCVN'u'vi_VN.TCVN'b'vi'u'vi'b'vi_vn'u'vi_vn'b'vi_vn.tcvn'u'vi_vn.tcvn'b'vi_vn.tcvn5712'u'vi_vn.tcvn5712'b'vi_VN.VISCII'u'vi_VN.VISCII'b'vi_vn.viscii'u'vi_vn.viscii'b'vi_vn.viscii111'u'vi_vn.viscii111'b'wa_BE.ISO8859-1'u'wa_BE.ISO8859-1'b'wa'u'wa'b'wa_be'u'wa_be'b'wae_CH.UTF-8'u'wae_CH.UTF-8'b'wae_ch'u'wae_ch'b'wal_ET.UTF-8'u'wal_ET.UTF-8'b'wal_et'u'wal_et'b'wo_SN.UTF-8'u'wo_SN.UTF-8'b'wo_sn'u'wo_sn'b'xh_ZA.ISO8859-1'u'xh_ZA.ISO8859-1'b'xh'u'xh'b'xh_za'u'xh_za'b'yi_US.CP1255'u'yi_US.CP1255'b'yi'u'yi'b'yi_us'u'yi_us'b'yo_NG.UTF-8'u'yo_NG.UTF-8'b'yo_ng'u'yo_ng'b'yue_HK.UTF-8'u'yue_HK.UTF-8'b'yue_hk'u'yue_hk'b'yuw_PG.UTF-8'u'yuw_PG.UTF-8'b'yuw_pg'u'yuw_pg'b'zh'u'zh'b'zh_CN.gb2312'u'zh_CN.gb2312'b'zh_cn'u'zh_cn'b'zh_TW.big5'u'zh_TW.big5'b'zh_cn.big5'u'zh_cn.big5'b'zh_cn.euc'u'zh_cn.euc'b'zh_HK.big5hkscs'u'zh_HK.big5hkscs'b'zh_hk'u'zh_hk'b'zh_hk.big5hk'u'zh_hk.big5hk'b'zh_SG.GB2312'u'zh_SG.GB2312'b'zh_sg'u'zh_sg'b'zh_SG.GBK'u'zh_SG.GBK'b'zh_sg.gbk'u'zh_sg.gbk'b'zh_tw'u'zh_tw'b'zh_tw.euc'u'zh_tw.euc'b'zh_tw.euctw'u'zh_tw.euctw'b'zu_ZA.ISO8859-1'u'zu_ZA.ISO8859-1'b'zu'u'zu'b'zu_za'u'zu_za'b'af_ZA'u'af_ZA'b'sq_AL'u'sq_AL'b'gsw_FR'u'gsw_FR'b'am_ET'u'am_ET'b'ar_SA'u'ar_SA'b'ar_IQ'u'ar_IQ'b'ar_EG'u'ar_EG'b'ar_LY'u'ar_LY'b'ar_DZ'u'ar_DZ'b'ar_MA'u'ar_MA'b'ar_TN'u'ar_TN'b'ar_OM'u'ar_OM'b'ar_YE'u'ar_YE'b'ar_SY'u'ar_SY'b'ar_JO'u'ar_JO'b'ar_LB'u'ar_LB'b'ar_KW'u'ar_KW'b'ar_AE'u'ar_AE'b'ar_BH'u'ar_BH'b'ar_QA'u'ar_QA'b'hy_AM'u'hy_AM'b'as_IN'u'as_IN'b'az_AZ'u'az_AZ'b'ba_RU'u'ba_RU'b'eu_ES'u'eu_ES'b'be_BY'u'be_BY'b'bn_IN'u'bn_IN'b'bs_BA'u'bs_BA'b'br_FR'u'br_FR'b'bg_BG'u'bg_BG'b'ca_ES'u'ca_ES'b'zh_CHS'u'zh_CHS'b'zh_TW'u'zh_TW'b'zh_CN'u'zh_CN'b'zh_HK'u'zh_HK'b'zh_SG'u'zh_SG'b'zh_MO'u'zh_MO'b'zh_CHT'u'zh_CHT'b'co_FR'u'co_FR'b'hr_HR'u'hr_HR'b'hr_BA'u'hr_BA'b'cs_CZ'u'cs_CZ'b'da_DK'u'da_DK'b'gbz_AF'u'gbz_AF'b'div_MV'u'div_MV'b'nl_NL'u'nl_NL'b'nl_BE'u'nl_BE'b'en_US'u'en_US'b'en_GB'u'en_GB'b'en_AU'u'en_AU'b'en_CA'u'en_CA'b'en_NZ'u'en_NZ'b'en_IE'u'en_IE'b'en_ZA'u'en_ZA'b'en_JA'u'en_JA'b'en_CB'u'en_CB'b'en_BZ'u'en_BZ'b'en_TT'u'en_TT'b'en_ZW'u'en_ZW'b'en_PH'u'en_PH'b'en_IN'u'en_IN'b'en_MY'u'en_MY'b'et_EE'u'et_EE'b'fo_FO'u'fo_FO'b'fil_PH'u'fil_PH'b'fi_FI'u'fi_FI'b'fr_FR'u'fr_FR'b'fr_BE'u'fr_BE'b'fr_CA'u'fr_CA'b'fr_CH'u'fr_CH'b'fr_LU'u'fr_LU'b'fr_MC'u'fr_MC'b'fy_NL'u'fy_NL'b'gl_ES'u'gl_ES'b'ka_GE'u'ka_GE'b'de_DE'u'de_DE'b'de_CH'u'de_CH'b'de_AT'u'de_AT'b'de_LU'u'de_LU'b'de_LI'u'de_LI'b'el_GR'u'el_GR'b'kl_GL'u'kl_GL'b'gu_IN'u'gu_IN'b'ha_NG'u'ha_NG'b'he_IL'u'he_IL'b'hi_IN'u'hi_IN'b'hu_HU'u'hu_HU'b'is_IS'u'is_IS'b'id_ID'u'id_ID'b'iu_CA'u'iu_CA'b'ga_IE'u'ga_IE'b'it_IT'u'it_IT'b'it_CH'u'it_CH'b'ja_JP'u'ja_JP'b'kn_IN'u'kn_IN'b'kk_KZ'u'kk_KZ'b'kh_KH'u'kh_KH'b'qut_GT'u'qut_GT'b'rw_RW'u'rw_RW'b'kok_IN'u'kok_IN'b'ko_KR'u'ko_KR'b'ky_KG'u'ky_KG'b'lo_LA'u'lo_LA'b'lv_LV'u'lv_LV'b'lt_LT'u'lt_LT'b'dsb_DE'u'dsb_DE'b'lb_LU'u'lb_LU'b'mk_MK'u'mk_MK'b'ms_MY'u'ms_MY'b'ms_BN'u'ms_BN'b'ml_IN'u'ml_IN'b'mt_MT'u'mt_MT'b'mi_NZ'u'mi_NZ'b'arn_CL'u'arn_CL'b'mr_IN'u'mr_IN'b'moh_CA'u'moh_CA'b'mn_MN'u'mn_MN'b'mn_CN'u'mn_CN'b'ne_NP'u'ne_NP'b'nb_NO'u'nb_NO'b'nn_NO'u'nn_NO'b'oc_FR'u'oc_FR'b'or_IN'u'or_IN'b'ps_AF'u'ps_AF'b'fa_IR'u'fa_IR'b'pl_PL'u'pl_PL'b'pt_BR'u'pt_BR'b'pt_PT'u'pt_PT'b'pa_IN'u'pa_IN'b'quz_BO'u'quz_BO'b'quz_EC'u'quz_EC'b'quz_PE'u'quz_PE'b'ro_RO'u'ro_RO'b'rm_CH'u'rm_CH'b'ru_RU'u'ru_RU'b'smn_FI'u'smn_FI'b'smj_NO'u'smj_NO'b'smj_SE'u'smj_SE'b'se_NO'u'se_NO'b'se_SE'u'se_SE'b'se_FI'u'se_FI'b'sms_FI'u'sms_FI'b'sma_NO'u'sma_NO'b'sma_SE'u'sma_SE'b'sa_IN'u'sa_IN'b'sr_SP'u'sr_SP'b'sr_BA'u'sr_BA'b'si_LK'u'si_LK'b'ns_ZA'u'ns_ZA'b'tn_ZA'u'tn_ZA'b'sk_SK'u'sk_SK'b'sl_SI'u'sl_SI'b'es_ES'u'es_ES'b'es_MX'u'es_MX'b'es_GT'u'es_GT'b'es_CR'u'es_CR'b'es_PA'u'es_PA'b'es_DO'u'es_DO'b'es_VE'u'es_VE'b'es_CO'u'es_CO'b'es_PE'u'es_PE'b'es_AR'u'es_AR'b'es_EC'u'es_EC'b'es_CL'u'es_CL'b'es_UR'u'es_UR'b'es_PY'u'es_PY'b'es_BO'u'es_BO'b'es_SV'u'es_SV'b'es_HN'u'es_HN'b'es_NI'u'es_NI'b'es_PR'u'es_PR'b'es_US'u'es_US'b'sw_KE'u'sw_KE'b'sv_SE'u'sv_SE'b'sv_FI'u'sv_FI'b'syr_SY'u'syr_SY'b'tg_TJ'u'tg_TJ'b'tmz_DZ'u'tmz_DZ'b'ta_IN'u'ta_IN'b'tt_RU'u'tt_RU'b'te_IN'u'te_IN'b'th_TH'u'th_TH'b'bo_BT'u'bo_BT'b'bo_CN'u'bo_CN'b'tr_TR'u'tr_TR'b'tk_TM'u'tk_TM'b'ug_CN'u'ug_CN'b'uk_UA'u'uk_UA'b'wen_DE'u'wen_DE'b'ur_PK'u'ur_PK'b'ur_IN'u'ur_IN'b'uz_UZ'u'uz_UZ'b'vi_VN'u'vi_VN'b'cy_GB'u'cy_GB'b'wo_SN'u'wo_SN'b'xh_ZA'u'xh_ZA'b'sah_RU'u'sah_RU'b'ii_CN'u'ii_CN'b'yo_NG'u'yo_NG'b'zu_ZA'u'zu_ZA'b' Test function.
    'u' Test function.
    'b'LC_'u'LC_'b'Locale defaults as determined by getdefaultlocale():'u'Locale defaults as determined by getdefaultlocale():'b'Language: 'u'Language: 'b'(undefined)'u'(undefined)'b'Encoding: 'u'Encoding: 'b'Locale settings on startup:'u'Locale settings on startup:'b'   Language: 'u'   Language: 'b'   Encoding: 'u'   Encoding: 'b'Locale settings after calling resetlocale():'u'Locale settings after calling resetlocale():'b'Locale settings after calling setlocale(LC_ALL, ""):'u'Locale settings after calling setlocale(LC_ALL, ""):'b'NOTE:'u'NOTE:'b'setlocale(LC_ALL, "") does not support the default locale'u'setlocale(LC_ALL, "") does not support the default locale'b'given in the OS environment variables.'u'given in the OS environment variables.'b'Locale aliasing:'u'Locale aliasing:'b'Number formatting:'u'Number formatting:'u'Lib.locale'Synchronization primitives.mixins_ContextManagerMixin_LoopBoundMixinPrimitive lock objects.

    A primitive lock is a synchronization primitive that is not owned
    by a particular coroutine when locked.  A primitive lock is in one
    of two states, 'locked' or 'unlocked'.

    It is created in the unlocked state.  It has two basic methods,
    acquire() and release().  When the state is unlocked, acquire()
    changes the state to locked and returns immediately.  When the
    state is locked, acquire() blocks until a call to release() in
    another coroutine changes it to unlocked, then the acquire() call
    resets it to locked and returns.  The release() method should only
    be called in the locked state; it changes the state to unlocked
    and returns immediately.  If an attempt is made to release an
    unlocked lock, a RuntimeError will be raised.

    When more than one coroutine is blocked in acquire() waiting for
    the state to turn to unlocked, only one coroutine proceeds when a
    release() call resets the state to unlocked; first coroutine which
    is blocked in acquire() is being processed.

    acquire() is a coroutine and should be called with 'await'.

    Locks also support the asynchronous context management protocol.
    'async with lock' statement should be used.

    Usage:

        lock = Lock()
        ...
        await lock.acquire()
        try:
            ...
        finally:
            lock.release()

    Context manager usage:

        lock = Lock()
        ...
        async with lock:
             ...

    Lock objects can be tested for locking state:

        if not lock.locked():
           await lock.acquire()
        else:
           # lock is acquired
           ...

    _lockedunlocked, waiters:]>Return True if lock is acquired.Acquire a lock.

        This method blocks until the lock is unlocked, then sets it to
        locked and returns True.
        _wake_up_firstRelease a lock.

        When the lock is locked, reset it to unlocked, and return.
        If any other coroutines are blocked waiting for the lock to become
        unlocked, allow exactly one of them to proceed.

        When invoked on an unlocked lock, a RuntimeError is raised.

        There is no return value.
        Lock is not acquired.Wake up the first waiter if it isn't done.Asynchronous equivalent to threading.Event.

    Class implementing event objects. An event manages a flag that can be set
    to true with the set() method and reset to false with the clear() method.
    The wait() method blocks until the flag is true. The flag is initially
    false.
    unsetis_setReturn True if and only if the internal flag is true.Set the internal flag to true. All coroutines waiting for it to
        become true are awakened. Coroutine that call wait() once the flag is
        true will not block at all.
        Reset the internal flag to false. Subsequently, coroutines calling
        wait() will block until set() is called to set the internal flag
        to true again.Block until the internal flag is true.

        If the internal flag is true on entry, return True
        immediately.  Otherwise, block until another coroutine calls
        set() to set the flag to true, then return True.
        Asynchronous equivalent to threading.Condition.

    This class implements condition variable objects. A condition variable
    allows one or more coroutines to wait until they are notified by another
    coroutine.

    A new Lock object is created and used as the underlying lock.
    Wait until notified.

        If the calling coroutine has not acquired the lock when this
        method is called, a RuntimeError is raised.

        This method releases the underlying lock, and then blocks
        until it is awakened by a notify() or notify_all() call for
        the same condition variable in another coroutine.  Once
        awakened, it re-acquires the lock and returns True.
        cannot wait on un-acquired lockwait_forWait until a predicate becomes true.

        The predicate should be a callable which result will be
        interpreted as a boolean value.  The final predicate value is
        the return value.
        notifyBy default, wake up one coroutine waiting on this condition, if any.
        If the calling coroutine has not acquired the lock when this method
        is called, a RuntimeError is raised.

        This method wakes up at most n of the coroutines waiting for the
        condition variable; it is a no-op if no coroutines are waiting.

        Note: an awakened coroutine does not actually return from its
        wait() call until it can reacquire the lock. Since notify() does
        not release the lock, its caller should.
        cannot notify on un-acquired lockWake up all threads waiting on this condition. This method acts
        like notify(), but wakes up all waiting threads instead of one. If the
        calling thread has not acquired the lock when this method is called,
        a RuntimeError is raised.
        A Semaphore implementation.

    A semaphore manages an internal counter which is decremented by each
    acquire() call and incremented by each release() call. The counter
    can never go below zero; when acquire() finds that it is zero, it blocks,
    waiting until some other thread calls release().

    Semaphores also support the context management protocol.

    The optional argument gives the initial value for the internal
    counter; it defaults to 1. If the value given is less than 0,
    ValueError is raised.
    Semaphore initial value must be >= 0unlocked, value:Returns True if semaphore cannot be acquired immediately.Acquire a semaphore.

        If the internal counter is larger than zero on entry,
        decrement it by one and return True immediately.  If it is
        zero on entry, block, waiting until some other coroutine has
        called release() to make it larger than 0, and then return
        True.
        _wake_up_nextRelease a semaphore, incrementing the internal counter by one.

        When it was zero on entry and another coroutine is waiting for it to
        become larger than zero again, wake up that coroutine.
        Wake up the first waiter that isn't done.A bounded semaphore implementation.

    This raises ValueError in release() if it would increase the value
    above the initial value.
    _bound_valueBoundedSemaphore released too many times_BarrierStatefillingFILLINGdrainingDRAININGresettingRESETTINGbrokenBROKENAsyncio equivalent to threading.Barrier

    Implements a Barrier primitive.
    Useful for synchronizing a fixed number of tasks at known synchronization
    points. Tasks block on 'wait()' and are simultaneously awoken once they
    have all made their call.
    Create a barrier, initialised to 'parties' tasks.parties must be > 0_cond_partiesn_waitingWait for the barrier.

        When the specified number of tasks have started waiting, they are all
        simultaneously awoken.
        Returns an unique and individual index number from 0 to 'parties-1'.
        _block_releaseBarrier abortedAbort or reset of barrierReset the barrier to the initial state.

        Any tasks currently waiting will get the BrokenBarrier exception
        raised.
        abortPlace the barrier into a 'broken' state.

        Useful in case of error.  Any currently waiting tasks and tasks
        attempting to 'wait()' will have BrokenBarrierError raised.
        Return the number of tasks required to trip the barrier.Return the number of tasks currently waiting at the barrier.Return True if the barrier is in a broken state.# We have no use for the "as ..."  clause in the with# statement for locks.# Finally block should be called before the CancelledError# handling as we don't want CancelledError to call# _wake_up_first() and attempt to wake up itself.# .done() necessarily means that a waiter will wake up later on and# either take the lock, or, if it was cancelled and lock wasn't# taken already, will hit this again and wake up a new waiter.# Export the lock's locked(), acquire() and release() methods.# Must reacquire lock even if wait is cancelled# notify all tasks when state changes# count tasks in Barrier# wait for the barrier reaches the parties number# when start draining release and return index of waited task# Block while the barrier drains or resets.# We release the barrier# Wake up any tasks waiting for barrier to drain.# Block until the barrier is ready for us,# or raise an exception if it is broken.# It is draining or resetting, wait until done# unless a CancelledError occurs# see if the barrier is in a broken state# Release the tasks waiting in the barrier.# Enter draining state.# Next waiting tasks will be blocked until the end of draining.# Wait in the barrier until we are released. Raise an exception# if the barrier is reset or broken.# wait for end of filling# If we are the last tasks to exit the barrier, signal any tasks# waiting for the barrier to drain.#reset the barrier, waking up tasksb'Synchronization primitives.'u'Synchronization primitives.'b'Lock'u'Lock'b'Event'u'Event'b'Condition'u'Condition'b'Semaphore'u'Semaphore'b'BoundedSemaphore'u'BoundedSemaphore'b'Barrier'u'Barrier'b'Primitive lock objects.

    A primitive lock is a synchronization primitive that is not owned
    by a particular coroutine when locked.  A primitive lock is in one
    of two states, 'locked' or 'unlocked'.

    It is created in the unlocked state.  It has two basic methods,
    acquire() and release().  When the state is unlocked, acquire()
    changes the state to locked and returns immediately.  When the
    state is locked, acquire() blocks until a call to release() in
    another coroutine changes it to unlocked, then the acquire() call
    resets it to locked and returns.  The release() method should only
    be called in the locked state; it changes the state to unlocked
    and returns immediately.  If an attempt is made to release an
    unlocked lock, a RuntimeError will be raised.

    When more than one coroutine is blocked in acquire() waiting for
    the state to turn to unlocked, only one coroutine proceeds when a
    release() call resets the state to unlocked; first coroutine which
    is blocked in acquire() is being processed.

    acquire() is a coroutine and should be called with 'await'.

    Locks also support the asynchronous context management protocol.
    'async with lock' statement should be used.

    Usage:

        lock = Lock()
        ...
        await lock.acquire()
        try:
            ...
        finally:
            lock.release()

    Context manager usage:

        lock = Lock()
        ...
        async with lock:
             ...

    Lock objects can be tested for locking state:

        if not lock.locked():
           await lock.acquire()
        else:
           # lock is acquired
           ...

    'u'Primitive lock objects.

    A primitive lock is a synchronization primitive that is not owned
    by a particular coroutine when locked.  A primitive lock is in one
    of two states, 'locked' or 'unlocked'.

    It is created in the unlocked state.  It has two basic methods,
    acquire() and release().  When the state is unlocked, acquire()
    changes the state to locked and returns immediately.  When the
    state is locked, acquire() blocks until a call to release() in
    another coroutine changes it to unlocked, then the acquire() call
    resets it to locked and returns.  The release() method should only
    be called in the locked state; it changes the state to unlocked
    and returns immediately.  If an attempt is made to release an
    unlocked lock, a RuntimeError will be raised.

    When more than one coroutine is blocked in acquire() waiting for
    the state to turn to unlocked, only one coroutine proceeds when a
    release() call resets the state to unlocked; first coroutine which
    is blocked in acquire() is being processed.

    acquire() is a coroutine and should be called with 'await'.

    Locks also support the asynchronous context management protocol.
    'async with lock' statement should be used.

    Usage:

        lock = Lock()
        ...
        await lock.acquire()
        try:
            ...
        finally:
            lock.release()

    Context manager usage:

        lock = Lock()
        ...
        async with lock:
             ...

    Lock objects can be tested for locking state:

        if not lock.locked():
           await lock.acquire()
        else:
           # lock is acquired
           ...

    'b'locked'u'locked'b'unlocked'u'unlocked'b', waiters:'u', waiters:'b']>'u']>'b'Return True if lock is acquired.'u'Return True if lock is acquired.'b'Acquire a lock.

        This method blocks until the lock is unlocked, then sets it to
        locked and returns True.
        'u'Acquire a lock.

        This method blocks until the lock is unlocked, then sets it to
        locked and returns True.
        'b'Release a lock.

        When the lock is locked, reset it to unlocked, and return.
        If any other coroutines are blocked waiting for the lock to become
        unlocked, allow exactly one of them to proceed.

        When invoked on an unlocked lock, a RuntimeError is raised.

        There is no return value.
        'u'Release a lock.

        When the lock is locked, reset it to unlocked, and return.
        If any other coroutines are blocked waiting for the lock to become
        unlocked, allow exactly one of them to proceed.

        When invoked on an unlocked lock, a RuntimeError is raised.

        There is no return value.
        'b'Lock is not acquired.'u'Lock is not acquired.'b'Wake up the first waiter if it isn't done.'u'Wake up the first waiter if it isn't done.'b'Asynchronous equivalent to threading.Event.

    Class implementing event objects. An event manages a flag that can be set
    to true with the set() method and reset to false with the clear() method.
    The wait() method blocks until the flag is true. The flag is initially
    false.
    'u'Asynchronous equivalent to threading.Event.

    Class implementing event objects. An event manages a flag that can be set
    to true with the set() method and reset to false with the clear() method.
    The wait() method blocks until the flag is true. The flag is initially
    false.
    'b'unset'u'unset'b'Return True if and only if the internal flag is true.'u'Return True if and only if the internal flag is true.'b'Set the internal flag to true. All coroutines waiting for it to
        become true are awakened. Coroutine that call wait() once the flag is
        true will not block at all.
        'u'Set the internal flag to true. All coroutines waiting for it to
        become true are awakened. Coroutine that call wait() once the flag is
        true will not block at all.
        'b'Reset the internal flag to false. Subsequently, coroutines calling
        wait() will block until set() is called to set the internal flag
        to true again.'u'Reset the internal flag to false. Subsequently, coroutines calling
        wait() will block until set() is called to set the internal flag
        to true again.'b'Block until the internal flag is true.

        If the internal flag is true on entry, return True
        immediately.  Otherwise, block until another coroutine calls
        set() to set the flag to true, then return True.
        'u'Block until the internal flag is true.

        If the internal flag is true on entry, return True
        immediately.  Otherwise, block until another coroutine calls
        set() to set the flag to true, then return True.
        'b'Asynchronous equivalent to threading.Condition.

    This class implements condition variable objects. A condition variable
    allows one or more coroutines to wait until they are notified by another
    coroutine.

    A new Lock object is created and used as the underlying lock.
    'u'Asynchronous equivalent to threading.Condition.

    This class implements condition variable objects. A condition variable
    allows one or more coroutines to wait until they are notified by another
    coroutine.

    A new Lock object is created and used as the underlying lock.
    'b'Wait until notified.

        If the calling coroutine has not acquired the lock when this
        method is called, a RuntimeError is raised.

        This method releases the underlying lock, and then blocks
        until it is awakened by a notify() or notify_all() call for
        the same condition variable in another coroutine.  Once
        awakened, it re-acquires the lock and returns True.
        'u'Wait until notified.

        If the calling coroutine has not acquired the lock when this
        method is called, a RuntimeError is raised.

        This method releases the underlying lock, and then blocks
        until it is awakened by a notify() or notify_all() call for
        the same condition variable in another coroutine.  Once
        awakened, it re-acquires the lock and returns True.
        'b'cannot wait on un-acquired lock'u'cannot wait on un-acquired lock'b'Wait until a predicate becomes true.

        The predicate should be a callable which result will be
        interpreted as a boolean value.  The final predicate value is
        the return value.
        'u'Wait until a predicate becomes true.

        The predicate should be a callable which result will be
        interpreted as a boolean value.  The final predicate value is
        the return value.
        'b'By default, wake up one coroutine waiting on this condition, if any.
        If the calling coroutine has not acquired the lock when this method
        is called, a RuntimeError is raised.

        This method wakes up at most n of the coroutines waiting for the
        condition variable; it is a no-op if no coroutines are waiting.

        Note: an awakened coroutine does not actually return from its
        wait() call until it can reacquire the lock. Since notify() does
        not release the lock, its caller should.
        'u'By default, wake up one coroutine waiting on this condition, if any.
        If the calling coroutine has not acquired the lock when this method
        is called, a RuntimeError is raised.

        This method wakes up at most n of the coroutines waiting for the
        condition variable; it is a no-op if no coroutines are waiting.

        Note: an awakened coroutine does not actually return from its
        wait() call until it can reacquire the lock. Since notify() does
        not release the lock, its caller should.
        'b'cannot notify on un-acquired lock'u'cannot notify on un-acquired lock'b'Wake up all threads waiting on this condition. This method acts
        like notify(), but wakes up all waiting threads instead of one. If the
        calling thread has not acquired the lock when this method is called,
        a RuntimeError is raised.
        'u'Wake up all threads waiting on this condition. This method acts
        like notify(), but wakes up all waiting threads instead of one. If the
        calling thread has not acquired the lock when this method is called,
        a RuntimeError is raised.
        'b'A Semaphore implementation.

    A semaphore manages an internal counter which is decremented by each
    acquire() call and incremented by each release() call. The counter
    can never go below zero; when acquire() finds that it is zero, it blocks,
    waiting until some other thread calls release().

    Semaphores also support the context management protocol.

    The optional argument gives the initial value for the internal
    counter; it defaults to 1. If the value given is less than 0,
    ValueError is raised.
    'u'A Semaphore implementation.

    A semaphore manages an internal counter which is decremented by each
    acquire() call and incremented by each release() call. The counter
    can never go below zero; when acquire() finds that it is zero, it blocks,
    waiting until some other thread calls release().

    Semaphores also support the context management protocol.

    The optional argument gives the initial value for the internal
    counter; it defaults to 1. If the value given is less than 0,
    ValueError is raised.
    'b'Semaphore initial value must be >= 0'u'Semaphore initial value must be >= 0'b'unlocked, value:'u'unlocked, value:'b'Returns True if semaphore cannot be acquired immediately.'u'Returns True if semaphore cannot be acquired immediately.'b'Acquire a semaphore.

        If the internal counter is larger than zero on entry,
        decrement it by one and return True immediately.  If it is
        zero on entry, block, waiting until some other coroutine has
        called release() to make it larger than 0, and then return
        True.
        'u'Acquire a semaphore.

        If the internal counter is larger than zero on entry,
        decrement it by one and return True immediately.  If it is
        zero on entry, block, waiting until some other coroutine has
        called release() to make it larger than 0, and then return
        True.
        'b'Release a semaphore, incrementing the internal counter by one.

        When it was zero on entry and another coroutine is waiting for it to
        become larger than zero again, wake up that coroutine.
        'u'Release a semaphore, incrementing the internal counter by one.

        When it was zero on entry and another coroutine is waiting for it to
        become larger than zero again, wake up that coroutine.
        'b'Wake up the first waiter that isn't done.'u'Wake up the first waiter that isn't done.'b'A bounded semaphore implementation.

    This raises ValueError in release() if it would increase the value
    above the initial value.
    'u'A bounded semaphore implementation.

    This raises ValueError in release() if it would increase the value
    above the initial value.
    'b'BoundedSemaphore released too many times'u'BoundedSemaphore released too many times'b'filling'u'filling'b'draining'u'draining'b'resetting'u'resetting'b'broken'u'broken'b'Asyncio equivalent to threading.Barrier

    Implements a Barrier primitive.
    Useful for synchronizing a fixed number of tasks at known synchronization
    points. Tasks block on 'wait()' and are simultaneously awoken once they
    have all made their call.
    'u'Asyncio equivalent to threading.Barrier

    Implements a Barrier primitive.
    Useful for synchronizing a fixed number of tasks at known synchronization
    points. Tasks block on 'wait()' and are simultaneously awoken once they
    have all made their call.
    'b'Create a barrier, initialised to 'parties' tasks.'u'Create a barrier, initialised to 'parties' tasks.'b'parties must be > 0'u'parties must be > 0'b'Wait for the barrier.

        When the specified number of tasks have started waiting, they are all
        simultaneously awoken.
        Returns an unique and individual index number from 0 to 'parties-1'.
        'u'Wait for the barrier.

        When the specified number of tasks have started waiting, they are all
        simultaneously awoken.
        Returns an unique and individual index number from 0 to 'parties-1'.
        'b'Barrier aborted'u'Barrier aborted'b'Abort or reset of barrier'u'Abort or reset of barrier'b'Reset the barrier to the initial state.

        Any tasks currently waiting will get the BrokenBarrier exception
        raised.
        'u'Reset the barrier to the initial state.

        Any tasks currently waiting will get the BrokenBarrier exception
        raised.
        'b'Place the barrier into a 'broken' state.

        Useful in case of error.  Any currently waiting tasks and tasks
        attempting to 'wait()' will have BrokenBarrierError raised.
        'u'Place the barrier into a 'broken' state.

        Useful in case of error.  Any currently waiting tasks and tasks
        attempting to 'wait()' will have BrokenBarrierError raised.
        'b'Return the number of tasks required to trip the barrier.'u'Return the number of tasks required to trip the barrier.'b'Return the number of tasks currently waiting at the barrier.'u'Return the number of tasks currently waiting at the barrier.'b'Return True if the barrier is in a broken state.'u'Return True if the barrier is in a broken state.'u'Lib.asyncio.locks'u'asyncio.locks'u'locks'Logging configuration.# Name the logger after the package.b'Logging configuration.'u'Logging configuration.'u'Lib.asyncio.log'u'asyncio.log'Interface to the liblzma compression library.

This module provides a class for reading and writing compressed files,
classes for incremental (de)compression, and convenience functions for
one-shot (de)compression.

These classes and functions support both the XZ and legacy LZMA
container formats, as well as raw compressed data streams.
CHECK_NONECHECK_CRC32CHECK_CRC64CHECK_SHA256CHECK_ID_MAXCHECK_UNKNOWNFILTER_LZMA2FILTER_DELTAFILTER_X86FILTER_IA64FILTER_ARMFILTER_ARMTHUMBFILTER_POWERPCFILTER_SPARCFORMAT_AUTOFORMAT_XZFORMAT_ALONEMF_HC3MF_HC4MF_BT2MF_BT3MF_BT4MODE_FASTMODE_NORMALPRESET_DEFAULTPRESET_EXTREMELZMAFileLZMAErroris_check_supported_lzmaA file object providing transparent LZMA (de)compression.

    An LZMAFile can act as a wrapper for an existing file object, or
    refer directly to a named file on disk.

    Note that LZMAFile provides a *binary* file interface - data read
    is returned as bytes, and data to be written must be given as bytes.
    presetOpen an LZMA-compressed file in binary mode.

        filename can be either an actual file name (given as a str,
        bytes, or PathLike object), in which case the named file is
        opened, or it can be an existing file object to read from or
        write to.

        mode can be "r" for reading (default), "w" for (over)writing,
        "x" for creating exclusively, or "a" for appending. These can
        equivalently be given as "rb", "wb", "xb" and "ab" respectively.

        format specifies the container format to use for the file.
        If mode is "r", this defaults to FORMAT_AUTO. Otherwise, the
        default is FORMAT_XZ.

        check specifies the integrity check to use. This argument can
        only be used when opening a file for writing. For FORMAT_XZ,
        the default is CHECK_CRC64. FORMAT_ALONE and FORMAT_RAW do not
        support integrity checks - for these formats, check must be
        omitted, or be CHECK_NONE.

        When opening a file for reading, the *preset* argument is not
        meaningful, and should be omitted. The *filters* argument should
        also be omitted, except when format is FORMAT_RAW (in which case
        it is required).

        When opening a file for writing, the settings used by the
        compressor can be specified either as a preset compression
        level (with the *preset* argument), or in detail as a custom
        filter chain (with the *filters* argument). For FORMAT_XZ and
        FORMAT_ALONE, the default is to use the PRESET_DEFAULT preset
        level. For FORMAT_RAW, the caller must always specify a filter
        chain; the raw compressor does not support preset compression
        levels.

        preset (if provided) should be an integer in the range 0-9,
        optionally OR-ed with the constant PRESET_EXTREME.

        filters (if provided) should be a sequence of dicts. Each dict
        should have an entry for "id" indicating ID of the filter, plus
        additional entries for options to the filter.
        Cannot specify an integrity check when opening a file for reading"Cannot specify an integrity check ""when opening a file for reading"Cannot specify a preset compression level when opening a file for reading"Cannot specify a preset compression ""level when opening a file for reading"Read up to size uncompressed bytes from the file.

        If size is negative or omitted, read until EOF is reached.
        Returns b"" if the file is already at EOF.
        Read up to size uncompressed bytes, while trying to avoid
        making multiple reads from the underlying stream. Reads up to a
        buffer's worth of data if size is negative.

        Returns b"" if the file is at EOF.
        Write a bytes object to the file.

        Returns the number of uncompressed bytes written, which is
        always the length of data in bytes. Note that due to buffering,
        the file on disk may not reflect the data written until close()
        is called.
        Change the file position.

        The new position is specified by offset, relative to the
        position indicated by whence. Possible values for whence are:

            0: start of stream (default): offset must not be negative
            1: current stream position
            2: end of stream; offset must not be positive

        Returns the new file position.

        Note that seeking is emulated, so depending on the parameters,
        this operation may be extremely slow.
        Open an LZMA-compressed file in binary or text mode.

    filename can be either an actual file name (given as a str, bytes,
    or PathLike object), in which case the named file is opened, or it
    can be an existing file object to read from or write to.

    The mode argument can be "r", "rb" (default), "w", "wb", "x", "xb",
    "a", or "ab" for binary mode, or "rt", "wt", "xt", or "at" for text
    mode.

    The format, check, preset and filters arguments specify the
    compression settings, as for LZMACompressor, LZMADecompressor and
    LZMAFile.

    For binary mode, this function is equivalent to the LZMAFile
    constructor: LZMAFile(filename, mode, ...). In this case, the
    encoding, errors and newline arguments must not be provided.

    For text mode, an LZMAFile object is created, and wrapped in an
    io.TextIOWrapper instance with the specified encoding, error
    handling behavior, and line ending(s).

    lz_modeCompress a block of data.

    Refer to LZMACompressor's docstring for a description of the
    optional arguments *format*, *check*, *preset* and *filters*.

    For incremental compression, use an LZMACompressor instead.
    memlimitDecompress a block of data.

    Refer to LZMADecompressor's docstring for a description of the
    optional arguments *format*, *check* and *filters*.

    For incremental decompression, use an LZMADecompressor instead.
    # Relies on the undocumented fact that BufferedReader.peek() always# returns at least one byte (except at EOF)# Leftover data is not a valid LZMA/XZ stream; ignore it.b'Interface to the liblzma compression library.

This module provides a class for reading and writing compressed files,
classes for incremental (de)compression, and convenience functions for
one-shot (de)compression.

These classes and functions support both the XZ and legacy LZMA
container formats, as well as raw compressed data streams.
'u'Interface to the liblzma compression library.

This module provides a class for reading and writing compressed files,
classes for incremental (de)compression, and convenience functions for
one-shot (de)compression.

These classes and functions support both the XZ and legacy LZMA
container formats, as well as raw compressed data streams.
'b'CHECK_NONE'u'CHECK_NONE'b'CHECK_CRC32'u'CHECK_CRC32'b'CHECK_CRC64'u'CHECK_CRC64'b'CHECK_SHA256'u'CHECK_SHA256'b'CHECK_ID_MAX'u'CHECK_ID_MAX'b'CHECK_UNKNOWN'u'CHECK_UNKNOWN'b'FILTER_LZMA1'u'FILTER_LZMA1'b'FILTER_LZMA2'u'FILTER_LZMA2'b'FILTER_DELTA'u'FILTER_DELTA'b'FILTER_X86'u'FILTER_X86'b'FILTER_IA64'u'FILTER_IA64'b'FILTER_ARM'u'FILTER_ARM'b'FILTER_ARMTHUMB'u'FILTER_ARMTHUMB'b'FILTER_POWERPC'u'FILTER_POWERPC'b'FILTER_SPARC'u'FILTER_SPARC'b'FORMAT_AUTO'u'FORMAT_AUTO'b'FORMAT_XZ'u'FORMAT_XZ'b'FORMAT_ALONE'u'FORMAT_ALONE'b'FORMAT_RAW'u'FORMAT_RAW'b'MF_HC3'u'MF_HC3'b'MF_HC4'u'MF_HC4'b'MF_BT2'u'MF_BT2'b'MF_BT3'u'MF_BT3'b'MF_BT4'u'MF_BT4'b'MODE_FAST'u'MODE_FAST'b'MODE_NORMAL'u'MODE_NORMAL'b'PRESET_DEFAULT'u'PRESET_DEFAULT'b'PRESET_EXTREME'u'PRESET_EXTREME'b'LZMACompressor'u'LZMACompressor'b'LZMADecompressor'u'LZMADecompressor'b'LZMAFile'u'LZMAFile'b'LZMAError'u'LZMAError'b'is_check_supported'u'is_check_supported'b'A file object providing transparent LZMA (de)compression.

    An LZMAFile can act as a wrapper for an existing file object, or
    refer directly to a named file on disk.

    Note that LZMAFile provides a *binary* file interface - data read
    is returned as bytes, and data to be written must be given as bytes.
    'u'A file object providing transparent LZMA (de)compression.

    An LZMAFile can act as a wrapper for an existing file object, or
    refer directly to a named file on disk.

    Note that LZMAFile provides a *binary* file interface - data read
    is returned as bytes, and data to be written must be given as bytes.
    'b'Open an LZMA-compressed file in binary mode.

        filename can be either an actual file name (given as a str,
        bytes, or PathLike object), in which case the named file is
        opened, or it can be an existing file object to read from or
        write to.

        mode can be "r" for reading (default), "w" for (over)writing,
        "x" for creating exclusively, or "a" for appending. These can
        equivalently be given as "rb", "wb", "xb" and "ab" respectively.

        format specifies the container format to use for the file.
        If mode is "r", this defaults to FORMAT_AUTO. Otherwise, the
        default is FORMAT_XZ.

        check specifies the integrity check to use. This argument can
        only be used when opening a file for writing. For FORMAT_XZ,
        the default is CHECK_CRC64. FORMAT_ALONE and FORMAT_RAW do not
        support integrity checks - for these formats, check must be
        omitted, or be CHECK_NONE.

        When opening a file for reading, the *preset* argument is not
        meaningful, and should be omitted. The *filters* argument should
        also be omitted, except when format is FORMAT_RAW (in which case
        it is required).

        When opening a file for writing, the settings used by the
        compressor can be specified either as a preset compression
        level (with the *preset* argument), or in detail as a custom
        filter chain (with the *filters* argument). For FORMAT_XZ and
        FORMAT_ALONE, the default is to use the PRESET_DEFAULT preset
        level. For FORMAT_RAW, the caller must always specify a filter
        chain; the raw compressor does not support preset compression
        levels.

        preset (if provided) should be an integer in the range 0-9,
        optionally OR-ed with the constant PRESET_EXTREME.

        filters (if provided) should be a sequence of dicts. Each dict
        should have an entry for "id" indicating ID of the filter, plus
        additional entries for options to the filter.
        'u'Open an LZMA-compressed file in binary mode.

        filename can be either an actual file name (given as a str,
        bytes, or PathLike object), in which case the named file is
        opened, or it can be an existing file object to read from or
        write to.

        mode can be "r" for reading (default), "w" for (over)writing,
        "x" for creating exclusively, or "a" for appending. These can
        equivalently be given as "rb", "wb", "xb" and "ab" respectively.

        format specifies the container format to use for the file.
        If mode is "r", this defaults to FORMAT_AUTO. Otherwise, the
        default is FORMAT_XZ.

        check specifies the integrity check to use. This argument can
        only be used when opening a file for writing. For FORMAT_XZ,
        the default is CHECK_CRC64. FORMAT_ALONE and FORMAT_RAW do not
        support integrity checks - for these formats, check must be
        omitted, or be CHECK_NONE.

        When opening a file for reading, the *preset* argument is not
        meaningful, and should be omitted. The *filters* argument should
        also be omitted, except when format is FORMAT_RAW (in which case
        it is required).

        When opening a file for writing, the settings used by the
        compressor can be specified either as a preset compression
        level (with the *preset* argument), or in detail as a custom
        filter chain (with the *filters* argument). For FORMAT_XZ and
        FORMAT_ALONE, the default is to use the PRESET_DEFAULT preset
        level. For FORMAT_RAW, the caller must always specify a filter
        chain; the raw compressor does not support preset compression
        levels.

        preset (if provided) should be an integer in the range 0-9,
        optionally OR-ed with the constant PRESET_EXTREME.

        filters (if provided) should be a sequence of dicts. Each dict
        should have an entry for "id" indicating ID of the filter, plus
        additional entries for options to the filter.
        'b'Cannot specify an integrity check when opening a file for reading'u'Cannot specify an integrity check when opening a file for reading'b'Cannot specify a preset compression level when opening a file for reading'u'Cannot specify a preset compression level when opening a file for reading'b'Read up to size uncompressed bytes from the file.

        If size is negative or omitted, read until EOF is reached.
        Returns b"" if the file is already at EOF.
        'u'Read up to size uncompressed bytes from the file.

        If size is negative or omitted, read until EOF is reached.
        Returns b"" if the file is already at EOF.
        'b'Read up to size uncompressed bytes, while trying to avoid
        making multiple reads from the underlying stream. Reads up to a
        buffer's worth of data if size is negative.

        Returns b"" if the file is at EOF.
        'u'Read up to size uncompressed bytes, while trying to avoid
        making multiple reads from the underlying stream. Reads up to a
        buffer's worth of data if size is negative.

        Returns b"" if the file is at EOF.
        'b'Write a bytes object to the file.

        Returns the number of uncompressed bytes written, which is
        always the length of data in bytes. Note that due to buffering,
        the file on disk may not reflect the data written until close()
        is called.
        'u'Write a bytes object to the file.

        Returns the number of uncompressed bytes written, which is
        always the length of data in bytes. Note that due to buffering,
        the file on disk may not reflect the data written until close()
        is called.
        'b'Change the file position.

        The new position is specified by offset, relative to the
        position indicated by whence. Possible values for whence are:

            0: start of stream (default): offset must not be negative
            1: current stream position
            2: end of stream; offset must not be positive

        Returns the new file position.

        Note that seeking is emulated, so depending on the parameters,
        this operation may be extremely slow.
        'u'Change the file position.

        The new position is specified by offset, relative to the
        position indicated by whence. Possible values for whence are:

            0: start of stream (default): offset must not be negative
            1: current stream position
            2: end of stream; offset must not be positive

        Returns the new file position.

        Note that seeking is emulated, so depending on the parameters,
        this operation may be extremely slow.
        'b'Open an LZMA-compressed file in binary or text mode.

    filename can be either an actual file name (given as a str, bytes,
    or PathLike object), in which case the named file is opened, or it
    can be an existing file object to read from or write to.

    The mode argument can be "r", "rb" (default), "w", "wb", "x", "xb",
    "a", or "ab" for binary mode, or "rt", "wt", "xt", or "at" for text
    mode.

    The format, check, preset and filters arguments specify the
    compression settings, as for LZMACompressor, LZMADecompressor and
    LZMAFile.

    For binary mode, this function is equivalent to the LZMAFile
    constructor: LZMAFile(filename, mode, ...). In this case, the
    encoding, errors and newline arguments must not be provided.

    For text mode, an LZMAFile object is created, and wrapped in an
    io.TextIOWrapper instance with the specified encoding, error
    handling behavior, and line ending(s).

    'u'Open an LZMA-compressed file in binary or text mode.

    filename can be either an actual file name (given as a str, bytes,
    or PathLike object), in which case the named file is opened, or it
    can be an existing file object to read from or write to.

    The mode argument can be "r", "rb" (default), "w", "wb", "x", "xb",
    "a", or "ab" for binary mode, or "rt", "wt", "xt", or "at" for text
    mode.

    The format, check, preset and filters arguments specify the
    compression settings, as for LZMACompressor, LZMADecompressor and
    LZMAFile.

    For binary mode, this function is equivalent to the LZMAFile
    constructor: LZMAFile(filename, mode, ...). In this case, the
    encoding, errors and newline arguments must not be provided.

    For text mode, an LZMAFile object is created, and wrapped in an
    io.TextIOWrapper instance with the specified encoding, error
    handling behavior, and line ending(s).

    'b'Compress a block of data.

    Refer to LZMACompressor's docstring for a description of the
    optional arguments *format*, *check*, *preset* and *filters*.

    For incremental compression, use an LZMACompressor instead.
    'u'Compress a block of data.

    Refer to LZMACompressor's docstring for a description of the
    optional arguments *format*, *check*, *preset* and *filters*.

    For incremental compression, use an LZMACompressor instead.
    'b'Decompress a block of data.

    Refer to LZMADecompressor's docstring for a description of the
    optional arguments *format*, *check* and *filters*.

    For incremental decompression, use an LZMADecompressor instead.
    'u'Decompress a block of data.

    Refer to LZMADecompressor's docstring for a description of the
    optional arguments *format*, *check* and *filters*.

    For incremental decompression, use an LZMADecompressor instead.
    'u'Lib.lzma'The machinery of importlib: finders, loaders, hooks, etc.Returns a list of all recognized module suffixes for this processb'The machinery of importlib: finders, loaders, hooks, etc.'u'The machinery of importlib: finders, loaders, hooks, etc.'b'Returns a list of all recognized module suffixes for this process'u'Returns a list of all recognized module suffixes for this process'u'Lib.importlib.machinery'u'importlib.machinery'u'machinery'Unittest main program_NO_TESTS_EXITCODEExamples:
  %(prog)s test_module               - run tests from test_module
  %(prog)s module.TestClass          - run tests from module.TestClass
  %(prog)s module.Class.test_method  - run specified test method
  %(prog)s path/to/test_file.py      - run tests from test_file.py
MAIN_EXAMPLESExamples:
  %(prog)s                           - run default set of tests
  %(prog)s MyTestSuite               - run suite 'MyTestSuite'
  %(prog)s MyTestCase.testSomething  - run MyTestCase.testSomething
  %(prog)s MyTestCase                - run all 'test*' test methods
                                       in MyTestCase
MODULE_EXAMPLES_convert_namerel_path_convert_names_convert_select_pattern*%s*A command-line program that runs a set of tests; this is primarily
       for making test modules conveniently executable.
    catchbreakprogName_discovery_parserdefaultTesttestRunnertestLoadertb_localsdurationsparseArgsrunTestsusageExitTestProgram.usageExit() is deprecated and will be removed in Python 3.13"TestProgram.usageExit() is deprecated and will be"" removed in Python 3.13"_initArgParsers_print_help_main_parser_do_discoverytestNamescreateTestsfrom_discovery_getParentArgParserparent_parser_getMainArgParser_getDiscoveryArgParserVerbose output--quietQuiet output--localsShow local variables in tracebacks--durationsShow the N slowest test cases (N=0 for all)--failfastStop on first fail or error--catchCatch Ctrl-C and display results so far-b--bufferBuffer stdout and stderr during tests-kOnly run tests which match the given substringa list of any number of test modules, classes and test methods.'a list of any number of test modules, ''classes and test methods.'%s discoverFor test discovery all test modules must be importable from the top level directory of the project.'For test discovery all test modules must be ''importable from the top level directory of the ''project.'--start-directoryDirectory to start discovery ('.' default)-p--patternPattern to match tests ('test*.py' default)--top-level-directoryTop level directory of project (defaults to start directory)'Top level directory of project (defaults to ''start directory)'testsRunskippedwasSuccessful# on Linux / Mac OS X 'foo.PY' is not importable, but on# Windows it is. Simpler to do a case insensitive match# a better check would be to check that the name is a# valid Python module name.# on Windows both '\' and '/' are used as path# separators. Better to replace both than rely on os.path.sep# defaults for testing# even if DeprecationWarnings are ignored by default# print them anyway unless other warnings settings are# specified by the warnings arg or the -W python flag# here self.warnings is set either to the value passed# to the warnings args or to None.# If the user didn't pass a value self.warnings will# be None. This means that the behavior is unchanged# and depends on the values passed to -W.# this allows "python -m unittest -v" to still work for# test discovery.# to support python -m unittest ...# createTests will load tests from self.module# handle command line args for test discovery# for testing# didn't accept the tb_locals or durations argument# didn't accept the verbosity, buffer or failfast arguments# it is assumed to be a TestRunner instanceb'Unittest main program'u'Unittest main program'b'Examples:
  %(prog)s test_module               - run tests from test_module
  %(prog)s module.TestClass          - run tests from module.TestClass
  %(prog)s module.Class.test_method  - run specified test method
  %(prog)s path/to/test_file.py      - run tests from test_file.py
'u'Examples:
  %(prog)s test_module               - run tests from test_module
  %(prog)s module.TestClass          - run tests from module.TestClass
  %(prog)s module.Class.test_method  - run specified test method
  %(prog)s path/to/test_file.py      - run tests from test_file.py
'b'Examples:
  %(prog)s                           - run default set of tests
  %(prog)s MyTestSuite               - run suite 'MyTestSuite'
  %(prog)s MyTestCase.testSomething  - run MyTestCase.testSomething
  %(prog)s MyTestCase                - run all 'test*' test methods
                                       in MyTestCase
'u'Examples:
  %(prog)s                           - run default set of tests
  %(prog)s MyTestSuite               - run suite 'MyTestSuite'
  %(prog)s MyTestCase.testSomething  - run MyTestCase.testSomething
  %(prog)s MyTestCase                - run all 'test*' test methods
                                       in MyTestCase
'b'*%s*'u'*%s*'b'A command-line program that runs a set of tests; this is primarily
       for making test modules conveniently executable.
    'u'A command-line program that runs a set of tests; this is primarily
       for making test modules conveniently executable.
    'b'TestProgram.usageExit() is deprecated and will be removed in Python 3.13'u'TestProgram.usageExit() is deprecated and will be removed in Python 3.13'b'discover'u'discover'b'verbosity'u'verbosity'b'Verbose output'u'Verbose output'b'--quiet'u'--quiet'b'Quiet output'u'Quiet output'b'--locals'u'--locals'b'tb_locals'u'tb_locals'b'Show local variables in tracebacks'u'Show local variables in tracebacks'b'--durations'u'--durations'b'durations'u'durations'b'Show the N slowest test cases (N=0 for all)'u'Show the N slowest test cases (N=0 for all)'b'--failfast'u'--failfast'b'failfast'u'failfast'b'Stop on first fail or error'u'Stop on first fail or error'b'--catch'u'--catch'b'catchbreak'u'catchbreak'b'Catch Ctrl-C and display results so far'u'Catch Ctrl-C and display results so far'b'-b'u'-b'b'--buffer'u'--buffer'b'buffer'u'buffer'b'Buffer stdout and stderr during tests'u'Buffer stdout and stderr during tests'b'-k'u'-k'b'testNamePatterns'u'testNamePatterns'b'Only run tests which match the given substring'u'Only run tests which match the given substring'b'tests'u'tests'b'a list of any number of test modules, classes and test methods.'u'a list of any number of test modules, classes and test methods.'b'%s discover'u'%s discover'b'For test discovery all test modules must be importable from the top level directory of the project.'u'For test discovery all test modules must be importable from the top level directory of the project.'b'--start-directory'u'--start-directory'b'start'u'start'b'Directory to start discovery ('.' default)'u'Directory to start discovery ('.' default)'b'-p'u'-p'b'--pattern'u'--pattern'b'pattern'b'Pattern to match tests ('test*.py' default)'u'Pattern to match tests ('test*.py' default)'b'--top-level-directory'u'--top-level-directory'b'top'u'top'b'Top level directory of project (defaults to start directory)'u'Top level directory of project (defaults to start directory)'u'Lib.unittest.main'u'unittest.main'u'This module contains functions that can read and write Python values in
a binary format. The format is specific to Python, but independent of
machine architecture issues.

Not all Python object types are supported; in general, only objects
whose value is independent from a particular invocation of Python can be
written and read by this module. The following types are supported:
None, integers, floating point numbers, strings, bytes, bytearrays,
tuples, lists, sets, dictionaries, and code objects, where it
should be understood that tuples, lists and dictionaries are only
supported as long as the values contained therein are themselves
supported; and recursive lists and dictionaries should not be written
(they will cause infinite loops).

Variables:

version -- indicates the format that the module uses. Version 0 is the
    historical format, version 1 shares interned strings and version 2
    uses a binary format for floating point numbers.
    Version 3 shares common object references (New in version 3.4).

Functions:

dump() -- write value to a file
load() -- read value from a file
dumps() -- marshal value as a bytes object
loads() -- read value from a bytes-like object'u'This module provides access to the mathematical functions
defined by the C standard.'acosacoshasinasinhatanatan2atanhcbrtceilcombcoscoshdegreesdist2.718281828459045erferfcexp2expm1fabsfactorialfmodfrexpfsumhypotiscloseisfiniteisqrtlcmldexplgammalog1plog2nextafterperm3.141592653589793radianssinsinhsumprodtantanh6.283185307179586trunculp Python 'mbcs' Codec for Windows


Cloned by Mark Hammond (mhammond@skippinet.com.au) from ascii.py,
which was written by Marc-Andre Lemburg (mal@lemburg.com).

(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.

# Import them explicitly to cause an ImportError# on non-Windows systems# for IncrementalDecoder, IncrementalEncoder, ...### Codec APIs### encodings module APIb' Python 'mbcs' Codec for Windows


Cloned by Mark Hammond (mhammond@skippinet.com.au) from ascii.py,
which was written by Marc-Andre Lemburg (mal@lemburg.com).

(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.

'u' Python 'mbcs' Codec for Windows


Cloned by Mark Hammond (mhammond@skippinet.com.au) from ascii.py,
which was written by Marc-Andre Lemburg (mal@lemburg.com).

(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.

'u'Lib.encodings.mbcs'u'encodings.mbcs'Basic message object for the email package object model.EmailMessageemail._encoded_wordsSEMISPACE[ \(\)<>@,;:\\"/\[\]\?=]tspecials_splitparam_formatparamConvenience function to format and return a key=value pair.

    This will quote the value if needed or if quote is true.  If value is a
    three tuple (charset, language, value), it will be encoded according
    to RFC2231 rules.  If it contains non-ascii characters it will likewise
    be encoded according to RFC2231 rules, using the utf-8 charset and
    a null language.
    encode_rfc2231%s="%s"_parseparam_unquotevalue_decode_uuDecode uuencoded data.decoded_linesencoded_lines_iterbegin `begin` line not foundTruncated input 	
decoded_lineBasic message object.

    A message object is defined as something that has a bunch of RFC 2822
    headers and a payload.  It may optionally have an envelope header
    (a.k.a. Unix-From or From_ header).  If the message is a container (i.e. a
    multipart or a message/rfc822), then the payload is a list of Message
    objects, otherwise it is a string.

    Message objects implement part of the `mapping' interface, which assumes
    there is exactly one occurrence of the header per message.  Some headers
    do in fact appear multiple times (e.g. Received) and for those headers,
    you must use the explicit API to set or get all the headers.  Not all of
    the mapping methods are implemented.
    _unixfromtext/plain_default_typeReturn the entire formatted message as a string.
        as_stringunixfrommaxheaderlenReturn the entire formatted message as a string.

        Optional 'unixfrom', when true, means include the Unix From_ envelope
        header.  For backward compatibility reasons, if maxheaderlen is
        not specified it defaults to 0, so you must override it explicitly
        if you want a different maxheaderlen.  'policy' is passed to the
        Generator instance used to serialize the message; if it is not
        specified the policy associated with the message instance is used.

        If the message object contains binary data that is not encoded
        according to RFC standards, the non-compliant data will be replaced by
        unicode "unknown character" code points.
        email.generatorflattenReturn the entire formatted message as a bytes object.
        as_bytesReturn the entire formatted message as a bytes object.

        Optional 'unixfrom', when true, means include the Unix From_ envelope
        header.  'policy' is passed to the BytesGenerator instance used to
        serialize the message; if not specified the policy associated with
        the message instance is used.
        BytesGeneratorReturn True if the message consists of multiple parts.get_unixfromAdd the given payload to the current payload.

        The current payload will always be a list of objects after this method
        is called.  If you want to set the payload to a scalar object, use
        set_payload() instead.
        Attach is not valid on a message with a non-multipart payload"Attach is not valid on a message with a"" non-multipart payload"Return a reference to the payload.

        The payload will either be a list object or a string.  If you mutate
        the list object, you modify the message's payload in place.  Optional
        i returns that index into the payload.

        Optional decode is a flag indicating whether the payload should be
        decoded or not, according to the Content-Transfer-Encoding header
        (default is False).

        When True and the message is not a multipart, the payload will be
        decoded if this header's value is `quoted-printable' or `base64'.  If
        some other encoding is used, or the header is missing, or if the
        payload has bogus data (i.e. bogus base64 or uuencoded data), the
        payload is returned as-is.

        If the message is a multipart and the decode flag is True, then None
        is returned.
        Expected list, got %sbpayloadget_content_charsetx-uuencodeuuencodeuuex-uueSet the payload to the given value.

        Optional charset sets the message's default character set.  See
        set_charset() for details.
        set_charsetSet the charset of the payload to a given character set.

        charset can be a Charset instance, a string naming a character set, or
        None.  If it is a string it will be converted to a Charset instance.
        If charset is None, the charset parameter will be removed from the
        Content-Type field.  Anything else will generate a TypeError.

        The message will be assumed to be of type text/* encoded with
        charset.input_charset.  It will be converted to charset.output_charset
        and encoded properly, if needed, when generating the plain text
        representation of the message.  MIME headers (MIME-Version,
        Content-Type, Content-Transfer-Encoding) will be added as needed.
        del_paramMIME-Versionadd_headerset_paramget_charsetReturn the Charset instance associated with the message's payload.
        Return the total number of headers, including duplicates.Get a header value.

        Return None if the header is missing instead of raising an exception.

        Note that if the header appeared multiple times, exactly which
        occurrence gets returned is undefined.  Use get_all() to get all
        the values matching a header field name.
        Set the value of a header.

        Note: this does not overwrite an existing header with the same field
        name.  Use __delitem__() first to delete any existing headers.
        max_countThere may be at most {} {} headers in a message"There may be at most {} {} headers ""in a message"Delete all occurrences of a header, if present.

        Does not raise an exception if the header is missing.
        newheadersname_lowerReturn a list of all the message's header field names.

        These will be sorted in the order they appeared in the original
        message, or were added to the message, and may contain duplicates.
        Any fields deleted and re-inserted are always appended to the header
        list.
        Return a list of all the message's header values.

        These will be sorted in the order they appeared in the original
        message, or were added to the message, and may contain duplicates.
        Any fields deleted and re-inserted are always appended to the header
        list.
        Get all the message's header fields and values.

        These will be sorted in the order they appeared in the original
        message, or were added to the message, and may contain duplicates.
        Any fields deleted and re-inserted are always appended to the header
        list.
        failobjGet a header value.

        Like __getitem__() but return failobj instead of None when the field
        is missing.
        Store name and value in the model without modification.

        This is an "internal" API, intended only for use by a parser.
        raw_itemsReturn the (name, value) header pairs without modification.

        This is an "internal" API, intended only for use by a generator.
        Return a list of all the values for the named field.

        These will be sorted in the order they appeared in the original
        message, and may contain duplicates.  Any fields deleted and
        re-inserted are always appended to the header list.

        If no such fields exist, failobj is returned (defaults to None).
        _paramsExtended header setting.

        name is the header field to add.  keyword arguments can be used to set
        additional parameters for the header field, with underscores converted
        to dashes.  Normally the parameter will be added as key="value" unless
        value is None, in which case only the key will be added.  If a
        parameter value contains non-ASCII characters it can be specified as a
        three-tuple of (charset, language, value), in which case it will be
        encoded according to RFC2231 rules.  Otherwise it will be encoded using
        the utf-8 charset and a language of ''.

        Examples:

        msg.add_header('content-disposition', 'attachment', filename='bud.gif')
        msg.add_header('content-disposition', 'attachment',
                       filename=('utf-8', '', Fuballer.ppt'))
        msg.add_header('content-disposition', 'attachment',
                       filename='Fuballer.ppt'))
        replace_headerReplace a header.

        Replace the first matching header found in the message, retaining
        header order and case.  If no matching header was found, a KeyError is
        raised.
        Return the message's content type.

        The returned string is coerced to lower case of the form
        `maintype/subtype'.  If there was no Content-Type header in the
        message, the default type as given by get_default_type() will be
        returned.  Since according to RFC 2045, messages always have a default
        type this will always return a value.

        RFC 2045 defines a message's default type to be text/plain unless it
        appears inside a multipart/digest container, in which case it would be
        message/rfc822.
        get_default_typectypeReturn the message's main content type.

        This is the `maintype' part of the string returned by
        get_content_type().
        get_content_subtypeReturns the message's sub-content type.

        This is the `subtype' part of the string returned by
        get_content_type().
        Return the `default' content type.

        Most messages have a default content type of text/plain, except for
        messages that are subparts of multipart/digest containers.  Such
        subparts have a default content type of message/rfc822.
        Set the `default' content type.

        ctype should be either "text/plain" or "message/rfc822", although this
        is not enforced.  The default content type is not stored in the
        Content-Type header.
        _get_params_preservedecode_paramsget_paramsReturn the message's Content-Type parameters, as a list.

        The elements of the returned list are 2-tuples of key/value pairs, as
        split on the `=' sign.  The left hand side of the `=' is the key,
        while the right hand side is the value.  If there is no `=' sign in
        the parameter the value is the empty string.  The value is as
        described in the get_param() method.

        Optional failobj is the object to return if there is no Content-Type
        header.  Optional header is the header to search instead of
        Content-Type.  If unquote is True, the value is unquoted.
        get_paramReturn the parameter value if found in the Content-Type header.

        Optional failobj is the object to return if there is no Content-Type
        header, or the Content-Type header has no such parameter.  Optional
        header is the header to search instead of Content-Type.

        Parameter keys are always compared case insensitively.  The return
        value can either be a string, or a 3-tuple if the parameter was RFC
        2231 encoded.  When it's a 3-tuple, the elements of the value are of
        the form (CHARSET, LANGUAGE, VALUE).  Note that both CHARSET and
        LANGUAGE can be None, in which case you should consider VALUE to be
        encoded in the us-ascii charset.  You can usually ignore LANGUAGE.
        The parameter value (either the returned string, or the VALUE item in
        the 3-tuple) is always unquoted, unless unquote is set to False.

        If your application doesn't care whether the parameter was RFC 2231
        encoded, it can turn the return value into a string as follows:

            rawparam = msg.get_param('foo')
            param = email.utils.collapse_rfc2231_value(rawparam)

        requoteSet a parameter in the Content-Type header.

        If the parameter already exists in the header, its value will be
        replaced with the new value.

        If header is Content-Type and has not yet been defined for this
        message, it will be set to "text/plain" and the new parameter and
        value will be appended as per RFC 2045.

        An alternate header can be specified in the header argument, and all
        parameters will be quoted as necessary unless requote is False.

        If charset is specified, the parameter will be encoded according to RFC
        2231.  Optional language specifies the RFC 2231 language, defaulting
        to the empty string.  Both charset and language should be strings.
        old_paramappend_paramRemove the given parameter completely from the Content-Type header.

        The header will be re-written in place without the parameter or its
        value. All values will be quoted as necessary unless requote is
        False.  Optional header specifies an alternative to the Content-Type
        header.
        new_ctypeset_typeSet the main type and subtype for the Content-Type header.

        type must be a string in the form "maintype/subtype", otherwise a
        ValueError is raised.

        This method replaces the Content-Type header, keeping all the
        parameters in place.  If requote is False, this leaves the existing
        header's quoting as is.  Otherwise, the parameters will be quoted (the
        default).

        An alternative header can be specified in the header argument.  When
        the Content-Type header is set, we'll always also add a MIME-Version
        header.
        mime-versionReturn the filename associated with the payload if present.

        The filename is extracted from the Content-Disposition header's
        `filename' parameter, and it is unquoted.  If that header is missing
        the `filename' parameter, this method falls back to looking for the
        `name' parameter.
        content-dispositioncollapse_rfc2231_valueReturn the boundary associated with the payload if present.

        The boundary is extracted from the Content-Type header's `boundary'
        parameter, and it is unquoted.
        set_boundarySet the boundary parameter in Content-Type to 'boundary'.

        This is subtly different than deleting the Content-Type header and
        adding a new one with a new boundary parameter via add_header().  The
        main difference is that using the set_boundary() method preserves the
        order of the Content-Type header in the original message.

        HeaderParseError is raised if the message has no Content-Type header.
        No Content-Type header foundnewparamsfoundppkpvReturn the charset parameter of the Content-Type header.

        The returned string is always coerced to lower case.  If there is no
        Content-Type header, or if that header has no charset parameter,
        failobj is returned.
        pcharsetget_charsetsReturn a list containing the charset(s) used in this message.

        The returned list of items describes the Content-Type headers'
        charset parameter for this message and all the subparts in its
        payload.

        Each item will either be a string (the value of the charset parameter
        in the Content-Type header of that part) or the value of the
        'failobj' parameter (defaults to None), if the part does not have a
        main MIME type of "text", or the charset is not defined.

        The list will contain one string for each part of the message, plus
        one for the container message (i.e. self), so that a non-multipart
        message will still return a list of length 1.
        get_content_dispositionReturn the message's content-disposition if it exists, or None.

        The return values can be either 'inline', 'attachment' or None
        according to the rfc2183.
        c_demail.iteratorsMIMEPartemail.policyReturn the entire formatted message as a string.

        Optional 'unixfrom', when true, means include the Unix From_ envelope
        header.  maxheaderlen is retained for backward compatibility with the
        base Message class, but defaults to None, meaning that the policy value
        for max_line_length controls the header maximum length.  'policy' is
        passed to the Generator instance used to serialize the message; if it
        is not specified the policy associated with the message instance is
        used.
        is_attachmentcontent_dispositionattachment_find_bodypreferencelistmaintyperelatedsubpartiter_partscontent-idsubpartsget_bodyplainReturn best candidate mime part for display as 'body' of message.

        Do a depth first search, starting with self, looking for the first part
        matching each of the items in preferencelist, and return the part
        corresponding to the first item that has a match, or None if no items
        have a match.  If 'related' is not included in preferencelist, consider
        the root part of any multipart/related encountered as a candidate
        match.  Ignore parts with 'Content-Disposition: attachment'.
        best_prioprioalternative_body_typesiter_attachmentsReturn an iterator over the non-main parts of a multipart.

        Skip the first of each occurrence of text/plain, text/html,
        multipart/related, or multipart/alternative in the multipart (unless
        they have a 'Content-Disposition: attachment' header) and include all
        remaining subparts in the returned iterator.  When applied to a
        multipart/related, return all parts except the root part.  Return an
        empty iterator when applied to a multipart/alternative or a
        non-multipart.
        attachmentsReturn an iterator over all immediate subparts of a multipart.

        Return an empty iterator for a non-multipart.
        get_contentcontent_managerset_content_make_multipartdisallowed_subtypesexisting_subtypeCannot convert {} to {}keep_headerspart_headerscontent-multipart/make_relatedmixedmake_alternativemake_mixed_add_multipart_subtype_dispmake_Content-Dispositionadd_relatedinlineadd_alternativeadd_attachmentclear_content# Intrapackage imports# Regular expression that matches `special' characters in parameters, the# existence of which force quoting of the parameter value.# Split header parameters.  BAW: this may be too simple.  It isn't# strictly RFC 2045 (section 5.1) compliant, but it catches most headers# found in the wild.  We may eventually need a full fledged parser.# RDM: we might have a Header here; for now just stringify it.# A tuple is used for RFC 2231 encoded parameter values where items# are (charset, language, value).  charset is a string, not a Charset# instance.  RFC 2231 encoded values are never quoted, per RFC.# Encode as per RFC 2231# BAW: Please check this.  I think that if quote is set it should# force quoting even if not necessary.# RDM This might be a Header, so for now stringify it.# This is different than utils.collapse_rfc2231_value() because it doesn't# try to convert the value to a unicode.  Message.get_param() and# Message.get_params() are both currently defined to return the tuple in# the face of RFC 2231 parameters.# Workaround for broken uuencoders by /Fredrik Lundh# Defaults for multipart messages# Default content type# Unix From_ line# Payload manipulation.# Here is the logic table for this code, based on the email5.0.0 code:#   i     decode  is_multipart  result# ------  ------  ------------  ------------------------------#  None   True    True          None#   i     True    True          None#  None   False   True          _payload (a list)#   i     False   True          _payload element i (a Message)#   i     False   False         error (not a list)#   i     True    False         error (not a list)#  None   False   False         _payload#  None   True    False         _payload decoded (bytes)# Note that Barry planned to factor out the 'decode' case, but that# isn't so easy now that we handle the 8 bit data, which needs to be# converted in both the decode and non-decode path.# For backward compatibility, Use isinstance and this error message# instead of the more logical is_multipart test.# cte might be a Header, so for now stringify it.# payload may be bytes here.# This won't happen for RFC compliant messages (messages# containing only ASCII code points in the unicode input).# If it does happen, turn the string into bytes in a way# guaranteed not to fail.# XXX: this is a bit of a hack; decode_b should probably be factored# out somewhere, but I haven't figured out where yet.# Some decoding problem.# This 'if' is for backward compatibility, it allows unicode# through even though that won't work correctly if the# message is serialized.# MAPPING INTERFACE (partial)# "Internal" methods (public API, but only intended for use by a parser# or generator, not normal application code.# Additional useful stuff# Use these three methods instead of the three above.# This should have no parameters# RFC 2045, section 5.2 says if its invalid, use text/plain# Like get_params() but preserves the quoting of values.  BAW:# should this be part of the public interface?# Must have been a bare attribute# BAW: should we be strict?# Set the Content-Type, you get a MIME-Version# Skip the first param; it's the old type.# RFC 2046 says that boundaries may begin but not end in w/s# There was no Content-Type header, and we don't know what type# to set it to, so raise an exception.# The original Content-Type header had no boundary attribute.# Tack one on the end.  BAW: should we raise an exception# instead???# Replace the existing Content-Type header with the new value# RFC 2231 encoded, so decode it, and it better end up as ascii.# LookupError will be raised if the charset isn't known to# Python.  UnicodeError will be raised if the encoded text# contains a character not in the charset.# charset characters must be in us-ascii range# RFC 2046, $4.1.2 says charsets are not case sensitive# I.e. def walk(self): ...# Certain malformed messages can have content type set to `multipart/*`# but still have single part body, in which case payload.copy() can# fail with AttributeError.# payload is not a list, it is most probably a string.# For related, we treat everything but the root as an attachment.# The root may be indicated by 'start'; if there's no start or we# can't find the named start, treat the first subpart as the root.# Otherwise we more or less invert the remaining logic in get_body.# This only really works in edge cases (ex: non-text related or# alternatives) if the sending agent sets content-disposition.# Only skip the first example of each candidate type.# There is existing content, move it to the first subpart.b'Basic message object for the email package object model.'u'Basic message object for the email package object model.'b'Message'u'Message'b'EmailMessage'u'EmailMessage'b'[ \(\)<>@,;:\\"/\[\]\?=]'u'[ \(\)<>@,;:\\"/\[\]\?=]'b'Convenience function to format and return a key=value pair.

    This will quote the value if needed or if quote is true.  If value is a
    three tuple (charset, language, value), it will be encoded according
    to RFC2231 rules.  If it contains non-ascii characters it will likewise
    be encoded according to RFC2231 rules, using the utf-8 charset and
    a null language.
    'u'Convenience function to format and return a key=value pair.

    This will quote the value if needed or if quote is true.  If value is a
    three tuple (charset, language, value), it will be encoded according
    to RFC2231 rules.  If it contains non-ascii characters it will likewise
    be encoded according to RFC2231 rules, using the utf-8 charset and
    a null language.
    'b'%s="%s"'u'%s="%s"'b'Decode uuencoded data.'u'Decode uuencoded data.'b'begin 'b'`begin` line not found'u'`begin` line not found'b'Truncated input'u'Truncated input'b' 	
'b'Basic message object.

    A message object is defined as something that has a bunch of RFC 2822
    headers and a payload.  It may optionally have an envelope header
    (a.k.a. Unix-From or From_ header).  If the message is a container (i.e. a
    multipart or a message/rfc822), then the payload is a list of Message
    objects, otherwise it is a string.

    Message objects implement part of the `mapping' interface, which assumes
    there is exactly one occurrence of the header per message.  Some headers
    do in fact appear multiple times (e.g. Received) and for those headers,
    you must use the explicit API to set or get all the headers.  Not all of
    the mapping methods are implemented.
    'u'Basic message object.

    A message object is defined as something that has a bunch of RFC 2822
    headers and a payload.  It may optionally have an envelope header
    (a.k.a. Unix-From or From_ header).  If the message is a container (i.e. a
    multipart or a message/rfc822), then the payload is a list of Message
    objects, otherwise it is a string.

    Message objects implement part of the `mapping' interface, which assumes
    there is exactly one occurrence of the header per message.  Some headers
    do in fact appear multiple times (e.g. Received) and for those headers,
    you must use the explicit API to set or get all the headers.  Not all of
    the mapping methods are implemented.
    'b'text/plain'u'text/plain'b'Return the entire formatted message as a string.
        'u'Return the entire formatted message as a string.
        'b'Return the entire formatted message as a string.

        Optional 'unixfrom', when true, means include the Unix From_ envelope
        header.  For backward compatibility reasons, if maxheaderlen is
        not specified it defaults to 0, so you must override it explicitly
        if you want a different maxheaderlen.  'policy' is passed to the
        Generator instance used to serialize the message; if it is not
        specified the policy associated with the message instance is used.

        If the message object contains binary data that is not encoded
        according to RFC standards, the non-compliant data will be replaced by
        unicode "unknown character" code points.
        'u'Return the entire formatted message as a string.

        Optional 'unixfrom', when true, means include the Unix From_ envelope
        header.  For backward compatibility reasons, if maxheaderlen is
        not specified it defaults to 0, so you must override it explicitly
        if you want a different maxheaderlen.  'policy' is passed to the
        Generator instance used to serialize the message; if it is not
        specified the policy associated with the message instance is used.

        If the message object contains binary data that is not encoded
        according to RFC standards, the non-compliant data will be replaced by
        unicode "unknown character" code points.
        'b'Return the entire formatted message as a bytes object.
        'u'Return the entire formatted message as a bytes object.
        'b'Return the entire formatted message as a bytes object.

        Optional 'unixfrom', when true, means include the Unix From_ envelope
        header.  'policy' is passed to the BytesGenerator instance used to
        serialize the message; if not specified the policy associated with
        the message instance is used.
        'u'Return the entire formatted message as a bytes object.

        Optional 'unixfrom', when true, means include the Unix From_ envelope
        header.  'policy' is passed to the BytesGenerator instance used to
        serialize the message; if not specified the policy associated with
        the message instance is used.
        'b'Return True if the message consists of multiple parts.'u'Return True if the message consists of multiple parts.'b'Add the given payload to the current payload.

        The current payload will always be a list of objects after this method
        is called.  If you want to set the payload to a scalar object, use
        set_payload() instead.
        'u'Add the given payload to the current payload.

        The current payload will always be a list of objects after this method
        is called.  If you want to set the payload to a scalar object, use
        set_payload() instead.
        'b'Attach is not valid on a message with a non-multipart payload'u'Attach is not valid on a message with a non-multipart payload'b'Return a reference to the payload.

        The payload will either be a list object or a string.  If you mutate
        the list object, you modify the message's payload in place.  Optional
        i returns that index into the payload.

        Optional decode is a flag indicating whether the payload should be
        decoded or not, according to the Content-Transfer-Encoding header
        (default is False).

        When True and the message is not a multipart, the payload will be
        decoded if this header's value is `quoted-printable' or `base64'.  If
        some other encoding is used, or the header is missing, or if the
        payload has bogus data (i.e. bogus base64 or uuencoded data), the
        payload is returned as-is.

        If the message is a multipart and the decode flag is True, then None
        is returned.
        'u'Return a reference to the payload.

        The payload will either be a list object or a string.  If you mutate
        the list object, you modify the message's payload in place.  Optional
        i returns that index into the payload.

        Optional decode is a flag indicating whether the payload should be
        decoded or not, according to the Content-Transfer-Encoding header
        (default is False).

        When True and the message is not a multipart, the payload will be
        decoded if this header's value is `quoted-printable' or `base64'.  If
        some other encoding is used, or the header is missing, or if the
        payload has bogus data (i.e. bogus base64 or uuencoded data), the
        payload is returned as-is.

        If the message is a multipart and the decode flag is True, then None
        is returned.
        'b'Expected list, got %s'u'Expected list, got %s'b'x-uuencode'u'x-uuencode'b'uuencode'u'uuencode'b'uue'u'uue'b'x-uue'u'x-uue'b'Set the payload to the given value.

        Optional charset sets the message's default character set.  See
        set_charset() for details.
        'u'Set the payload to the given value.

        Optional charset sets the message's default character set.  See
        set_charset() for details.
        'b'Set the charset of the payload to a given character set.

        charset can be a Charset instance, a string naming a character set, or
        None.  If it is a string it will be converted to a Charset instance.
        If charset is None, the charset parameter will be removed from the
        Content-Type field.  Anything else will generate a TypeError.

        The message will be assumed to be of type text/* encoded with
        charset.input_charset.  It will be converted to charset.output_charset
        and encoded properly, if needed, when generating the plain text
        representation of the message.  MIME headers (MIME-Version,
        Content-Type, Content-Transfer-Encoding) will be added as needed.
        'u'Set the charset of the payload to a given character set.

        charset can be a Charset instance, a string naming a character set, or
        None.  If it is a string it will be converted to a Charset instance.
        If charset is None, the charset parameter will be removed from the
        Content-Type field.  Anything else will generate a TypeError.

        The message will be assumed to be of type text/* encoded with
        charset.input_charset.  It will be converted to charset.output_charset
        and encoded properly, if needed, when generating the plain text
        representation of the message.  MIME headers (MIME-Version,
        Content-Type, Content-Transfer-Encoding) will be added as needed.
        'b'MIME-Version'u'MIME-Version'b'Return the Charset instance associated with the message's payload.
        'u'Return the Charset instance associated with the message's payload.
        'b'Return the total number of headers, including duplicates.'u'Return the total number of headers, including duplicates.'b'Get a header value.

        Return None if the header is missing instead of raising an exception.

        Note that if the header appeared multiple times, exactly which
        occurrence gets returned is undefined.  Use get_all() to get all
        the values matching a header field name.
        'u'Get a header value.

        Return None if the header is missing instead of raising an exception.

        Note that if the header appeared multiple times, exactly which
        occurrence gets returned is undefined.  Use get_all() to get all
        the values matching a header field name.
        'b'Set the value of a header.

        Note: this does not overwrite an existing header with the same field
        name.  Use __delitem__() first to delete any existing headers.
        'u'Set the value of a header.

        Note: this does not overwrite an existing header with the same field
        name.  Use __delitem__() first to delete any existing headers.
        'b'There may be at most {} {} headers in a message'u'There may be at most {} {} headers in a message'b'Delete all occurrences of a header, if present.

        Does not raise an exception if the header is missing.
        'u'Delete all occurrences of a header, if present.

        Does not raise an exception if the header is missing.
        'b'Return a list of all the message's header field names.

        These will be sorted in the order they appeared in the original
        message, or were added to the message, and may contain duplicates.
        Any fields deleted and re-inserted are always appended to the header
        list.
        'u'Return a list of all the message's header field names.

        These will be sorted in the order they appeared in the original
        message, or were added to the message, and may contain duplicates.
        Any fields deleted and re-inserted are always appended to the header
        list.
        'b'Return a list of all the message's header values.

        These will be sorted in the order they appeared in the original
        message, or were added to the message, and may contain duplicates.
        Any fields deleted and re-inserted are always appended to the header
        list.
        'u'Return a list of all the message's header values.

        These will be sorted in the order they appeared in the original
        message, or were added to the message, and may contain duplicates.
        Any fields deleted and re-inserted are always appended to the header
        list.
        'b'Get all the message's header fields and values.

        These will be sorted in the order they appeared in the original
        message, or were added to the message, and may contain duplicates.
        Any fields deleted and re-inserted are always appended to the header
        list.
        'u'Get all the message's header fields and values.

        These will be sorted in the order they appeared in the original
        message, or were added to the message, and may contain duplicates.
        Any fields deleted and re-inserted are always appended to the header
        list.
        'b'Get a header value.

        Like __getitem__() but return failobj instead of None when the field
        is missing.
        'u'Get a header value.

        Like __getitem__() but return failobj instead of None when the field
        is missing.
        'b'Store name and value in the model without modification.

        This is an "internal" API, intended only for use by a parser.
        'u'Store name and value in the model without modification.

        This is an "internal" API, intended only for use by a parser.
        'b'Return the (name, value) header pairs without modification.

        This is an "internal" API, intended only for use by a generator.
        'u'Return the (name, value) header pairs without modification.

        This is an "internal" API, intended only for use by a generator.
        'b'Return a list of all the values for the named field.

        These will be sorted in the order they appeared in the original
        message, and may contain duplicates.  Any fields deleted and
        re-inserted are always appended to the header list.

        If no such fields exist, failobj is returned (defaults to None).
        'u'Return a list of all the values for the named field.

        These will be sorted in the order they appeared in the original
        message, and may contain duplicates.  Any fields deleted and
        re-inserted are always appended to the header list.

        If no such fields exist, failobj is returned (defaults to None).
        'b'Extended header setting.

        name is the header field to add.  keyword arguments can be used to set
        additional parameters for the header field, with underscores converted
        to dashes.  Normally the parameter will be added as key="value" unless
        value is None, in which case only the key will be added.  If a
        parameter value contains non-ASCII characters it can be specified as a
        three-tuple of (charset, language, value), in which case it will be
        encoded according to RFC2231 rules.  Otherwise it will be encoded using
        the utf-8 charset and a language of ''.

        Examples:

        msg.add_header('content-disposition', 'attachment', filename='bud.gif')
        msg.add_header('content-disposition', 'attachment',
                       filename=('utf-8', '', Fuballer.ppt'))
        msg.add_header('content-disposition', 'attachment',
                       filename='Fuballer.ppt'))
        'u'Extended header setting.

        name is the header field to add.  keyword arguments can be used to set
        additional parameters for the header field, with underscores converted
        to dashes.  Normally the parameter will be added as key="value" unless
        value is None, in which case only the key will be added.  If a
        parameter value contains non-ASCII characters it can be specified as a
        three-tuple of (charset, language, value), in which case it will be
        encoded according to RFC2231 rules.  Otherwise it will be encoded using
        the utf-8 charset and a language of ''.

        Examples:

        msg.add_header('content-disposition', 'attachment', filename='bud.gif')
        msg.add_header('content-disposition', 'attachment',
                       filename=('utf-8', '', Fuballer.ppt'))
        msg.add_header('content-disposition', 'attachment',
                       filename='Fuballer.ppt'))
        'b'Replace a header.

        Replace the first matching header found in the message, retaining
        header order and case.  If no matching header was found, a KeyError is
        raised.
        'u'Replace a header.

        Replace the first matching header found in the message, retaining
        header order and case.  If no matching header was found, a KeyError is
        raised.
        'b'Return the message's content type.

        The returned string is coerced to lower case of the form
        `maintype/subtype'.  If there was no Content-Type header in the
        message, the default type as given by get_default_type() will be
        returned.  Since according to RFC 2045, messages always have a default
        type this will always return a value.

        RFC 2045 defines a message's default type to be text/plain unless it
        appears inside a multipart/digest container, in which case it would be
        message/rfc822.
        'u'Return the message's content type.

        The returned string is coerced to lower case of the form
        `maintype/subtype'.  If there was no Content-Type header in the
        message, the default type as given by get_default_type() will be
        returned.  Since according to RFC 2045, messages always have a default
        type this will always return a value.

        RFC 2045 defines a message's default type to be text/plain unless it
        appears inside a multipart/digest container, in which case it would be
        message/rfc822.
        'b'Return the message's main content type.

        This is the `maintype' part of the string returned by
        get_content_type().
        'u'Return the message's main content type.

        This is the `maintype' part of the string returned by
        get_content_type().
        'b'Returns the message's sub-content type.

        This is the `subtype' part of the string returned by
        get_content_type().
        'u'Returns the message's sub-content type.

        This is the `subtype' part of the string returned by
        get_content_type().
        'b'Return the `default' content type.

        Most messages have a default content type of text/plain, except for
        messages that are subparts of multipart/digest containers.  Such
        subparts have a default content type of message/rfc822.
        'u'Return the `default' content type.

        Most messages have a default content type of text/plain, except for
        messages that are subparts of multipart/digest containers.  Such
        subparts have a default content type of message/rfc822.
        'b'Set the `default' content type.

        ctype should be either "text/plain" or "message/rfc822", although this
        is not enforced.  The default content type is not stored in the
        Content-Type header.
        'u'Set the `default' content type.

        ctype should be either "text/plain" or "message/rfc822", although this
        is not enforced.  The default content type is not stored in the
        Content-Type header.
        'b'Return the message's Content-Type parameters, as a list.

        The elements of the returned list are 2-tuples of key/value pairs, as
        split on the `=' sign.  The left hand side of the `=' is the key,
        while the right hand side is the value.  If there is no `=' sign in
        the parameter the value is the empty string.  The value is as
        described in the get_param() method.

        Optional failobj is the object to return if there is no Content-Type
        header.  Optional header is the header to search instead of
        Content-Type.  If unquote is True, the value is unquoted.
        'u'Return the message's Content-Type parameters, as a list.

        The elements of the returned list are 2-tuples of key/value pairs, as
        split on the `=' sign.  The left hand side of the `=' is the key,
        while the right hand side is the value.  If there is no `=' sign in
        the parameter the value is the empty string.  The value is as
        described in the get_param() method.

        Optional failobj is the object to return if there is no Content-Type
        header.  Optional header is the header to search instead of
        Content-Type.  If unquote is True, the value is unquoted.
        'b'Return the parameter value if found in the Content-Type header.

        Optional failobj is the object to return if there is no Content-Type
        header, or the Content-Type header has no such parameter.  Optional
        header is the header to search instead of Content-Type.

        Parameter keys are always compared case insensitively.  The return
        value can either be a string, or a 3-tuple if the parameter was RFC
        2231 encoded.  When it's a 3-tuple, the elements of the value are of
        the form (CHARSET, LANGUAGE, VALUE).  Note that both CHARSET and
        LANGUAGE can be None, in which case you should consider VALUE to be
        encoded in the us-ascii charset.  You can usually ignore LANGUAGE.
        The parameter value (either the returned string, or the VALUE item in
        the 3-tuple) is always unquoted, unless unquote is set to False.

        If your application doesn't care whether the parameter was RFC 2231
        encoded, it can turn the return value into a string as follows:

            rawparam = msg.get_param('foo')
            param = email.utils.collapse_rfc2231_value(rawparam)

        'u'Return the parameter value if found in the Content-Type header.

        Optional failobj is the object to return if there is no Content-Type
        header, or the Content-Type header has no such parameter.  Optional
        header is the header to search instead of Content-Type.

        Parameter keys are always compared case insensitively.  The return
        value can either be a string, or a 3-tuple if the parameter was RFC
        2231 encoded.  When it's a 3-tuple, the elements of the value are of
        the form (CHARSET, LANGUAGE, VALUE).  Note that both CHARSET and
        LANGUAGE can be None, in which case you should consider VALUE to be
        encoded in the us-ascii charset.  You can usually ignore LANGUAGE.
        The parameter value (either the returned string, or the VALUE item in
        the 3-tuple) is always unquoted, unless unquote is set to False.

        If your application doesn't care whether the parameter was RFC 2231
        encoded, it can turn the return value into a string as follows:

            rawparam = msg.get_param('foo')
            param = email.utils.collapse_rfc2231_value(rawparam)

        'b'Set a parameter in the Content-Type header.

        If the parameter already exists in the header, its value will be
        replaced with the new value.

        If header is Content-Type and has not yet been defined for this
        message, it will be set to "text/plain" and the new parameter and
        value will be appended as per RFC 2045.

        An alternate header can be specified in the header argument, and all
        parameters will be quoted as necessary unless requote is False.

        If charset is specified, the parameter will be encoded according to RFC
        2231.  Optional language specifies the RFC 2231 language, defaulting
        to the empty string.  Both charset and language should be strings.
        'u'Set a parameter in the Content-Type header.

        If the parameter already exists in the header, its value will be
        replaced with the new value.

        If header is Content-Type and has not yet been defined for this
        message, it will be set to "text/plain" and the new parameter and
        value will be appended as per RFC 2045.

        An alternate header can be specified in the header argument, and all
        parameters will be quoted as necessary unless requote is False.

        If charset is specified, the parameter will be encoded according to RFC
        2231.  Optional language specifies the RFC 2231 language, defaulting
        to the empty string.  Both charset and language should be strings.
        'b'Remove the given parameter completely from the Content-Type header.

        The header will be re-written in place without the parameter or its
        value. All values will be quoted as necessary unless requote is
        False.  Optional header specifies an alternative to the Content-Type
        header.
        'u'Remove the given parameter completely from the Content-Type header.

        The header will be re-written in place without the parameter or its
        value. All values will be quoted as necessary unless requote is
        False.  Optional header specifies an alternative to the Content-Type
        header.
        'b'Set the main type and subtype for the Content-Type header.

        type must be a string in the form "maintype/subtype", otherwise a
        ValueError is raised.

        This method replaces the Content-Type header, keeping all the
        parameters in place.  If requote is False, this leaves the existing
        header's quoting as is.  Otherwise, the parameters will be quoted (the
        default).

        An alternative header can be specified in the header argument.  When
        the Content-Type header is set, we'll always also add a MIME-Version
        header.
        'u'Set the main type and subtype for the Content-Type header.

        type must be a string in the form "maintype/subtype", otherwise a
        ValueError is raised.

        This method replaces the Content-Type header, keeping all the
        parameters in place.  If requote is False, this leaves the existing
        header's quoting as is.  Otherwise, the parameters will be quoted (the
        default).

        An alternative header can be specified in the header argument.  When
        the Content-Type header is set, we'll always also add a MIME-Version
        header.
        'b'mime-version'u'mime-version'b'Return the filename associated with the payload if present.

        The filename is extracted from the Content-Disposition header's
        `filename' parameter, and it is unquoted.  If that header is missing
        the `filename' parameter, this method falls back to looking for the
        `name' parameter.
        'u'Return the filename associated with the payload if present.

        The filename is extracted from the Content-Disposition header's
        `filename' parameter, and it is unquoted.  If that header is missing
        the `filename' parameter, this method falls back to looking for the
        `name' parameter.
        'b'content-disposition'u'content-disposition'b'Return the boundary associated with the payload if present.

        The boundary is extracted from the Content-Type header's `boundary'
        parameter, and it is unquoted.
        'u'Return the boundary associated with the payload if present.

        The boundary is extracted from the Content-Type header's `boundary'
        parameter, and it is unquoted.
        'b'boundary'u'boundary'b'Set the boundary parameter in Content-Type to 'boundary'.

        This is subtly different than deleting the Content-Type header and
        adding a new one with a new boundary parameter via add_header().  The
        main difference is that using the set_boundary() method preserves the
        order of the Content-Type header in the original message.

        HeaderParseError is raised if the message has no Content-Type header.
        'u'Set the boundary parameter in Content-Type to 'boundary'.

        This is subtly different than deleting the Content-Type header and
        adding a new one with a new boundary parameter via add_header().  The
        main difference is that using the set_boundary() method preserves the
        order of the Content-Type header in the original message.

        HeaderParseError is raised if the message has no Content-Type header.
        'b'No Content-Type header found'u'No Content-Type header found'b'Return the charset parameter of the Content-Type header.

        The returned string is always coerced to lower case.  If there is no
        Content-Type header, or if that header has no charset parameter,
        failobj is returned.
        'u'Return the charset parameter of the Content-Type header.

        The returned string is always coerced to lower case.  If there is no
        Content-Type header, or if that header has no charset parameter,
        failobj is returned.
        'b'Return a list containing the charset(s) used in this message.

        The returned list of items describes the Content-Type headers'
        charset parameter for this message and all the subparts in its
        payload.

        Each item will either be a string (the value of the charset parameter
        in the Content-Type header of that part) or the value of the
        'failobj' parameter (defaults to None), if the part does not have a
        main MIME type of "text", or the charset is not defined.

        The list will contain one string for each part of the message, plus
        one for the container message (i.e. self), so that a non-multipart
        message will still return a list of length 1.
        'u'Return a list containing the charset(s) used in this message.

        The returned list of items describes the Content-Type headers'
        charset parameter for this message and all the subparts in its
        payload.

        Each item will either be a string (the value of the charset parameter
        in the Content-Type header of that part) or the value of the
        'failobj' parameter (defaults to None), if the part does not have a
        main MIME type of "text", or the charset is not defined.

        The list will contain one string for each part of the message, plus
        one for the container message (i.e. self), so that a non-multipart
        message will still return a list of length 1.
        'b'Return the message's content-disposition if it exists, or None.

        The return values can be either 'inline', 'attachment' or None
        according to the rfc2183.
        'u'Return the message's content-disposition if it exists, or None.

        The return values can be either 'inline', 'attachment' or None
        according to the rfc2183.
        'b'Return the entire formatted message as a string.

        Optional 'unixfrom', when true, means include the Unix From_ envelope
        header.  maxheaderlen is retained for backward compatibility with the
        base Message class, but defaults to None, meaning that the policy value
        for max_line_length controls the header maximum length.  'policy' is
        passed to the Generator instance used to serialize the message; if it
        is not specified the policy associated with the message instance is
        used.
        'u'Return the entire formatted message as a string.

        Optional 'unixfrom', when true, means include the Unix From_ envelope
        header.  maxheaderlen is retained for backward compatibility with the
        base Message class, but defaults to None, meaning that the policy value
        for max_line_length controls the header maximum length.  'policy' is
        passed to the Generator instance used to serialize the message; if it
        is not specified the policy associated with the message instance is
        used.
        'b'attachment'u'attachment'b'related'u'related'b'content-id'u'content-id'b'plain'u'plain'b'Return best candidate mime part for display as 'body' of message.

        Do a depth first search, starting with self, looking for the first part
        matching each of the items in preferencelist, and return the part
        corresponding to the first item that has a match, or None if no items
        have a match.  If 'related' is not included in preferencelist, consider
        the root part of any multipart/related encountered as a candidate
        match.  Ignore parts with 'Content-Disposition: attachment'.
        'u'Return best candidate mime part for display as 'body' of message.

        Do a depth first search, starting with self, looking for the first part
        matching each of the items in preferencelist, and return the part
        corresponding to the first item that has a match, or None if no items
        have a match.  If 'related' is not included in preferencelist, consider
        the root part of any multipart/related encountered as a candidate
        match.  Ignore parts with 'Content-Disposition: attachment'.
        'b'alternative'u'alternative'b'Return an iterator over the non-main parts of a multipart.

        Skip the first of each occurrence of text/plain, text/html,
        multipart/related, or multipart/alternative in the multipart (unless
        they have a 'Content-Disposition: attachment' header) and include all
        remaining subparts in the returned iterator.  When applied to a
        multipart/related, return all parts except the root part.  Return an
        empty iterator when applied to a multipart/alternative or a
        non-multipart.
        'u'Return an iterator over the non-main parts of a multipart.

        Skip the first of each occurrence of text/plain, text/html,
        multipart/related, or multipart/alternative in the multipart (unless
        they have a 'Content-Disposition: attachment' header) and include all
        remaining subparts in the returned iterator.  When applied to a
        multipart/related, return all parts except the root part.  Return an
        empty iterator when applied to a multipart/alternative or a
        non-multipart.
        'b'Return an iterator over all immediate subparts of a multipart.

        Return an empty iterator for a non-multipart.
        'u'Return an iterator over all immediate subparts of a multipart.

        Return an empty iterator for a non-multipart.
        'b'Cannot convert {} to {}'u'Cannot convert {} to {}'b'content-'u'content-'b'multipart/'u'multipart/'b'mixed'u'mixed'b'make_'u'make_'b'Content-Disposition'u'Content-Disposition'b'inline'u'inline'u'Lib.email.message'u'email.message'Guess the MIME type of a file.

This module defines two useful functions:

guess_type(url, strict=True) -- guess the MIME type and encoding of a URL.

guess_extension(type, strict=True) -- guess the extension for a given MIME type.

It also contains the following, for tuning the behavior:

Data:

knownfiles -- list of files to parse
inited -- flag set when init() has been called
suffix_map -- dictionary mapping suffixes to suffixes
encodings_map -- dictionary mapping suffixes to encodings
types_map -- dictionary mapping suffixes to types

Functions:

init([files]) -- parse a list of files, default knownfiles (on Windows, the
  default values are taken from the registry)
read_mime_types(file) -- parse one file, return a dictionary or None
knownfilesinitedMimeTypesguess_typeguess_all_extensionsguess_extensionadd_typeread_mime_typessuffix_mapencodings_maptypes_mapcommon_types/etc/mime.types/etc/httpd/mime.types/etc/httpd/conf/mime.types/etc/apache/mime.types/etc/apache2/mime.types/usr/local/etc/httpd/conf/mime.types/usr/local/lib/netscape/mime.types/usr/local/etc/mime.types_dbMIME-types datastore.

    This datastore can handle information from mime.types-style files
    and supports basic determination of MIME type from a filename or
    URL, and can guess a reasonable extension given a MIME type.
    _encodings_map_default_suffix_map_defaulttypes_map_inv_types_map_default_common_types_defaultAdd a mapping between a type and an extension.

        When the extension is already known, the new
        type will replace the old one. When the type
        is already known the extension will be added
        to the list of known extensions.

        If strict is true, information will be added to
        list of standard types, else to the list of non-standard
        types.
        extsGuess the type of a file which is either a URL or a path-like object.

        Return value is a tuple (type, encoding) where type is None if
        the type can't be guessed (no or unknown suffix) or a string
        of the form type/subtype, usable for a MIME Content-type
        header; and encoding is None for no encoding or the name of
        the program used to encode (e.g. compress or gzip).  The
        mappings are table driven.  Encoding suffixes are case
        sensitive; type suffixes are first tried case sensitive, then
        case insensitive.

        The suffixes .tgz, .taz and .tz (case sensitive!) are all
        mapped to '.tar.gz'.  (This is table-driven too, using the
        dictionary suffix_map.)

        Optional `strict' argument when False adds a bunch of commonly found,
        but non-standard types.
        semiext_lowerGuess the extensions for a file based on its MIME type.

        Return value is a list of strings giving the possible filename
        extensions, including the leading dot ('.').  The extension is not
        guaranteed to have been associated with any particular data stream,
        but would be mapped to the MIME type `type' by guess_type().

        Optional `strict' argument when false adds a bunch of commonly found,
        but non-standard types.
        Guess the extension for a file based on its MIME type.

        Return value is a string giving a filename extension,
        including the leading dot ('.').  The extension is not
        guaranteed to have been associated with any particular data
        stream, but would be mapped to the MIME type `type' by
        guess_type().  If no extension can be guessed for `type', None
        is returned.

        Optional `strict' argument when false adds a bunch of commonly found,
        but non-standard types.
        
        Read a single mime.types-format file, specified by pathname.

        If strict is true, information will be added to
        list of standard types, else to the list of non-standard
        types.
        readfp
        Read a single mime.types-format file.

        If strict is true, information will be added to
        list of standard types, else to the list of non-standard
        types.
        suffread_windows_registry
        Load the MIME types database from Windows registry.

        If strict is true, information will be added to
        list of standard types, else to the list of non-standard
        types.
        _read_windows_registryenum_typesmimedbEnumKeyHKEY_CLASSES_ROOThkcrsubkeynamesubkeyQueryValueExContent TypemimetypedatatypeREG_SZGuess the type of a file based on its URL.

    Return value is a tuple (type, encoding) where type is None if the
    type can't be guessed (no or unknown suffix) or a string of the
    form type/subtype, usable for a MIME Content-type header; and
    encoding is None for no encoding or the name of the program used
    to encode (e.g. compress or gzip).  The mappings are table
    driven.  Encoding suffixes are case sensitive; type suffixes are
    first tried case sensitive, then case insensitive.

    The suffixes .tgz, .taz and .tz (case sensitive!) are all mapped
    to ".tar.gz".  (This is table-driven too, using the dictionary
    suffix_map).

    Optional `strict' argument when false adds a bunch of commonly found, but
    non-standard types.
    Guess the extensions for a file based on its MIME type.

    Return value is a list of strings giving the possible filename
    extensions, including the leading dot ('.').  The extension is not
    guaranteed to have been associated with any particular data
    stream, but would be mapped to the MIME type `type' by
    guess_type().  If no extension can be guessed for `type', None
    is returned.

    Optional `strict' argument when false adds a bunch of commonly found,
    but non-standard types.
    Guess the extension for a file based on its MIME type.

    Return value is a string giving a filename extension, including the
    leading dot ('.').  The extension is not guaranteed to have been
    associated with any particular data stream, but would be mapped to the
    MIME type `type' by guess_type().  If no extension can be guessed for
    `type', None is returned.

    Optional `strict' argument when false adds a bunch of commonly found,
    but non-standard types.
    Add a mapping between a type and an extension.

    When the extension is already known, the new
    type will replace the old one. When the type
    is already known the extension will be added
    to the list of known extensions.

    If strict is true, information will be added to
    list of standard types, else to the list of non-standard
    types.
    _default_mime_types.svg.gz.svgz.tar.gz.tgz.taz.tz.tar.bz2.tbz2.tar.xz.txz.Z.bz2xz.xz.brtext/javascript.js.mjsapplication/json.jsonapplication/manifest+json.webmanifestapplication/msword.doc.dot.wizapplication/n-quads.nqapplication/n-triples.ntapplication/octet-stream.bin.a.dll.o.obj.soapplication/oda.odaapplication/pdf.pdfapplication/pkcs7-mime.p7capplication/postscript.ps.ai.epsapplication/trig.trigapplication/vnd.apple.mpegurl.m3u.m3u8application/vnd.ms-excel.xls.xlbapplication/vnd.ms-powerpoint.ppt.pot.ppa.pps.pwzapplication/wasm.wasmapplication/x-bcpio.bcpioapplication/x-cpio.cpioapplication/x-csh.cshapplication/x-dvi.dviapplication/x-gtar.gtarapplication/x-hdf.hdfapplication/x-hdf5.h5application/x-latex.latexapplication/x-mif.mifapplication/x-netcdf.cdf.ncapplication/x-pkcs12.p12.pfxapplication/x-pn-realaudio.ramapplication/x-python-code.pyoapplication/x-sh.shapplication/x-shar.sharapplication/x-shockwave-flash.swfapplication/x-sv4cpio.sv4cpioapplication/x-sv4crc.sv4crcapplication/x-tar.tarapplication/x-tcl.tclapplication/x-tex.texapplication/x-texinfo.texi.texinfoapplication/x-troff.roff.t.trapplication/x-troff-man.manapplication/x-troff-me.meapplication/x-troff-ms.msapplication/x-ustar.ustarapplication/x-wais-source.srcapplication/xml.xsl.rdf.wsdl.xpdlapplication/zip.zipaudio/3gpp.3gp.3gppaudio/3gpp2.3g2.3gpp2audio/aac.aac.adts.loas.assaudio/basic.au.sndaudio/mpeg.mp3.mp2audio/opus.opusaudio/x-aiff.aif.aifc.aiffaudio/x-pn-realaudio.raaudio/x-wav.wavimage/avif.avifimage/bmp.bmpimage/gif.gifimage/ief.iefimage/jpeg.jpg.jpe.jpegimage/heic.heicimage/heif.heifimage/png.pngimage/svg+xml.svgimage/tiff.tiff.tifimage/vnd.microsoft.icon.icoimage/x-cmu-raster.rasimage/x-portable-anymap.pnmimage/x-portable-bitmap.pbmimage/x-portable-graymap.pgmimage/x-portable-pixmap.ppmimage/x-rgb.rgbimage/x-xbitmap.xbmimage/x-xpixmap.xpmimage/x-xwindowdump.xwd.eml.mht.mhtml.nwstext/css.csstext/csv.csvtext/html.html.htmtext/n3.n3.txt.bat.c.h.ksh.pl.srttext/richtext.rtxtext/tab-separated-values.tsvtext/vtt.vtttext/x-pythontext/x-setext.etxtext/x-sgml.sgm.sgmltext/x-vcard.vcf.xmlvideo/mp4.mp4video/mpeg.mpeg.m1v.mpa.mpe.mpgvideo/quicktime.mov.qtvideo/webm.webmvideo/x-msvideo.avivideo/x-sgi-movie.movieapplication/rtf.rtfaudio/midi.midi.midimage/jpgimage/pict.pict.pct.picimage/webp.webptext/xul.xulUsage: mimetypes.py [options] type

Options:
    --help / -h       -- print this message and exit
    --lenient / -l    -- additionally search of some common, but non-standard
                         types.
    --extension / -e  -- guess extension instead of type

More than one type argument may be given.
USAGEhlelenient--help--lenient--extensiongtypeguessI don't know anything about typetype:encoding:# Apache# Apache 1# Apache 2# Apache 1.2# Apache 1.3# dict for (non-strict, strict)# syntax of data URLs:# dataurl   := "data:" [ mediatype ] [ ";base64" ] "," data# mediatype := [ type "/" subtype ] *( ";" parameter )# data      := *urlchar# parameter := attribute "=" value# type/subtype defaults to "text/plain"# bad data URL# never compressed, so encoding is None# encodings_map is case sensitive# Accelerated function if it is available# Only check file extensions# raises OSError if no 'Content Type' value# so that MimeTypes.__init__() doesn't call us again# Quick return if not supported# Make the DB a global variable now that it is fully initialized# Before adding new types, make sure they are either registered with IANA,# at http://www.iana.org/assignments/media-types# or extensions, i.e. using the x- prefix# If you add to these, please keep them sorted by mime type.# Make sure the entry with the preferred file extension for a particular mime type# appears before any others of the same mimetype.# These are non-standard types, commonly found in the wild.  They will# only match if strict=0 flag is given to the API methods.# Please sort these toob'Guess the MIME type of a file.

This module defines two useful functions:

guess_type(url, strict=True) -- guess the MIME type and encoding of a URL.

guess_extension(type, strict=True) -- guess the extension for a given MIME type.

It also contains the following, for tuning the behavior:

Data:

knownfiles -- list of files to parse
inited -- flag set when init() has been called
suffix_map -- dictionary mapping suffixes to suffixes
encodings_map -- dictionary mapping suffixes to encodings
types_map -- dictionary mapping suffixes to types

Functions:

init([files]) -- parse a list of files, default knownfiles (on Windows, the
  default values are taken from the registry)
read_mime_types(file) -- parse one file, return a dictionary or None
'u'Guess the MIME type of a file.

This module defines two useful functions:

guess_type(url, strict=True) -- guess the MIME type and encoding of a URL.

guess_extension(type, strict=True) -- guess the extension for a given MIME type.

It also contains the following, for tuning the behavior:

Data:

knownfiles -- list of files to parse
inited -- flag set when init() has been called
suffix_map -- dictionary mapping suffixes to suffixes
encodings_map -- dictionary mapping suffixes to encodings
types_map -- dictionary mapping suffixes to types

Functions:

init([files]) -- parse a list of files, default knownfiles (on Windows, the
  default values are taken from the registry)
read_mime_types(file) -- parse one file, return a dictionary or None
'b'knownfiles'u'knownfiles'b'inited'u'inited'b'MimeTypes'u'MimeTypes'b'guess_type'u'guess_type'b'guess_all_extensions'u'guess_all_extensions'b'guess_extension'u'guess_extension'b'add_type'u'add_type'b'read_mime_types'u'read_mime_types'b'suffix_map'u'suffix_map'b'encodings_map'u'encodings_map'b'types_map'u'types_map'b'common_types'u'common_types'b'/etc/mime.types'u'/etc/mime.types'b'/etc/httpd/mime.types'u'/etc/httpd/mime.types'b'/etc/httpd/conf/mime.types'u'/etc/httpd/conf/mime.types'b'/etc/apache/mime.types'u'/etc/apache/mime.types'b'/etc/apache2/mime.types'u'/etc/apache2/mime.types'b'/usr/local/etc/httpd/conf/mime.types'u'/usr/local/etc/httpd/conf/mime.types'b'/usr/local/lib/netscape/mime.types'u'/usr/local/lib/netscape/mime.types'b'/usr/local/etc/mime.types'u'/usr/local/etc/mime.types'b'MIME-types datastore.

    This datastore can handle information from mime.types-style files
    and supports basic determination of MIME type from a filename or
    URL, and can guess a reasonable extension given a MIME type.
    'u'MIME-types datastore.

    This datastore can handle information from mime.types-style files
    and supports basic determination of MIME type from a filename or
    URL, and can guess a reasonable extension given a MIME type.
    'b'Add a mapping between a type and an extension.

        When the extension is already known, the new
        type will replace the old one. When the type
        is already known the extension will be added
        to the list of known extensions.

        If strict is true, information will be added to
        list of standard types, else to the list of non-standard
        types.
        'u'Add a mapping between a type and an extension.

        When the extension is already known, the new
        type will replace the old one. When the type
        is already known the extension will be added
        to the list of known extensions.

        If strict is true, information will be added to
        list of standard types, else to the list of non-standard
        types.
        'b'Guess the type of a file which is either a URL or a path-like object.

        Return value is a tuple (type, encoding) where type is None if
        the type can't be guessed (no or unknown suffix) or a string
        of the form type/subtype, usable for a MIME Content-type
        header; and encoding is None for no encoding or the name of
        the program used to encode (e.g. compress or gzip).  The
        mappings are table driven.  Encoding suffixes are case
        sensitive; type suffixes are first tried case sensitive, then
        case insensitive.

        The suffixes .tgz, .taz and .tz (case sensitive!) are all
        mapped to '.tar.gz'.  (This is table-driven too, using the
        dictionary suffix_map.)

        Optional `strict' argument when False adds a bunch of commonly found,
        but non-standard types.
        'u'Guess the type of a file which is either a URL or a path-like object.

        Return value is a tuple (type, encoding) where type is None if
        the type can't be guessed (no or unknown suffix) or a string
        of the form type/subtype, usable for a MIME Content-type
        header; and encoding is None for no encoding or the name of
        the program used to encode (e.g. compress or gzip).  The
        mappings are table driven.  Encoding suffixes are case
        sensitive; type suffixes are first tried case sensitive, then
        case insensitive.

        The suffixes .tgz, .taz and .tz (case sensitive!) are all
        mapped to '.tar.gz'.  (This is table-driven too, using the
        dictionary suffix_map.)

        Optional `strict' argument when False adds a bunch of commonly found,
        but non-standard types.
        'b'Guess the extensions for a file based on its MIME type.

        Return value is a list of strings giving the possible filename
        extensions, including the leading dot ('.').  The extension is not
        guaranteed to have been associated with any particular data stream,
        but would be mapped to the MIME type `type' by guess_type().

        Optional `strict' argument when false adds a bunch of commonly found,
        but non-standard types.
        'u'Guess the extensions for a file based on its MIME type.

        Return value is a list of strings giving the possible filename
        extensions, including the leading dot ('.').  The extension is not
        guaranteed to have been associated with any particular data stream,
        but would be mapped to the MIME type `type' by guess_type().

        Optional `strict' argument when false adds a bunch of commonly found,
        but non-standard types.
        'b'Guess the extension for a file based on its MIME type.

        Return value is a string giving a filename extension,
        including the leading dot ('.').  The extension is not
        guaranteed to have been associated with any particular data
        stream, but would be mapped to the MIME type `type' by
        guess_type().  If no extension can be guessed for `type', None
        is returned.

        Optional `strict' argument when false adds a bunch of commonly found,
        but non-standard types.
        'u'Guess the extension for a file based on its MIME type.

        Return value is a string giving a filename extension,
        including the leading dot ('.').  The extension is not
        guaranteed to have been associated with any particular data
        stream, but would be mapped to the MIME type `type' by
        guess_type().  If no extension can be guessed for `type', None
        is returned.

        Optional `strict' argument when false adds a bunch of commonly found,
        but non-standard types.
        'b'
        Read a single mime.types-format file, specified by pathname.

        If strict is true, information will be added to
        list of standard types, else to the list of non-standard
        types.
        'u'
        Read a single mime.types-format file, specified by pathname.

        If strict is true, information will be added to
        list of standard types, else to the list of non-standard
        types.
        'b'
        Read a single mime.types-format file.

        If strict is true, information will be added to
        list of standard types, else to the list of non-standard
        types.
        'u'
        Read a single mime.types-format file.

        If strict is true, information will be added to
        list of standard types, else to the list of non-standard
        types.
        'b'
        Load the MIME types database from Windows registry.

        If strict is true, information will be added to
        list of standard types, else to the list of non-standard
        types.
        'u'
        Load the MIME types database from Windows registry.

        If strict is true, information will be added to
        list of standard types, else to the list of non-standard
        types.
        'b'Content Type'u'Content Type'b'Guess the type of a file based on its URL.

    Return value is a tuple (type, encoding) where type is None if the
    type can't be guessed (no or unknown suffix) or a string of the
    form type/subtype, usable for a MIME Content-type header; and
    encoding is None for no encoding or the name of the program used
    to encode (e.g. compress or gzip).  The mappings are table
    driven.  Encoding suffixes are case sensitive; type suffixes are
    first tried case sensitive, then case insensitive.

    The suffixes .tgz, .taz and .tz (case sensitive!) are all mapped
    to ".tar.gz".  (This is table-driven too, using the dictionary
    suffix_map).

    Optional `strict' argument when false adds a bunch of commonly found, but
    non-standard types.
    'u'Guess the type of a file based on its URL.

    Return value is a tuple (type, encoding) where type is None if the
    type can't be guessed (no or unknown suffix) or a string of the
    form type/subtype, usable for a MIME Content-type header; and
    encoding is None for no encoding or the name of the program used
    to encode (e.g. compress or gzip).  The mappings are table
    driven.  Encoding suffixes are case sensitive; type suffixes are
    first tried case sensitive, then case insensitive.

    The suffixes .tgz, .taz and .tz (case sensitive!) are all mapped
    to ".tar.gz".  (This is table-driven too, using the dictionary
    suffix_map).

    Optional `strict' argument when false adds a bunch of commonly found, but
    non-standard types.
    'b'Guess the extensions for a file based on its MIME type.

    Return value is a list of strings giving the possible filename
    extensions, including the leading dot ('.').  The extension is not
    guaranteed to have been associated with any particular data
    stream, but would be mapped to the MIME type `type' by
    guess_type().  If no extension can be guessed for `type', None
    is returned.

    Optional `strict' argument when false adds a bunch of commonly found,
    but non-standard types.
    'u'Guess the extensions for a file based on its MIME type.

    Return value is a list of strings giving the possible filename
    extensions, including the leading dot ('.').  The extension is not
    guaranteed to have been associated with any particular data
    stream, but would be mapped to the MIME type `type' by
    guess_type().  If no extension can be guessed for `type', None
    is returned.

    Optional `strict' argument when false adds a bunch of commonly found,
    but non-standard types.
    'b'Guess the extension for a file based on its MIME type.

    Return value is a string giving a filename extension, including the
    leading dot ('.').  The extension is not guaranteed to have been
    associated with any particular data stream, but would be mapped to the
    MIME type `type' by guess_type().  If no extension can be guessed for
    `type', None is returned.

    Optional `strict' argument when false adds a bunch of commonly found,
    but non-standard types.
    'u'Guess the extension for a file based on its MIME type.

    Return value is a string giving a filename extension, including the
    leading dot ('.').  The extension is not guaranteed to have been
    associated with any particular data stream, but would be mapped to the
    MIME type `type' by guess_type().  If no extension can be guessed for
    `type', None is returned.

    Optional `strict' argument when false adds a bunch of commonly found,
    but non-standard types.
    'b'Add a mapping between a type and an extension.

    When the extension is already known, the new
    type will replace the old one. When the type
    is already known the extension will be added
    to the list of known extensions.

    If strict is true, information will be added to
    list of standard types, else to the list of non-standard
    types.
    'u'Add a mapping between a type and an extension.

    When the extension is already known, the new
    type will replace the old one. When the type
    is already known the extension will be added
    to the list of known extensions.

    If strict is true, information will be added to
    list of standard types, else to the list of non-standard
    types.
    'b'.svg.gz'u'.svg.gz'b'.svgz'u'.svgz'b'.tar.gz'u'.tar.gz'b'.tgz'u'.tgz'b'.taz'u'.taz'b'.tz'u'.tz'b'.tar.bz2'u'.tar.bz2'b'.tbz2'u'.tbz2'b'.tar.xz'u'.tar.xz'b'.txz'u'.txz'b'.Z'u'.Z'b'.bz2'u'.bz2'b'xz'u'xz'b'.xz'u'.xz'b'.br'u'.br'b'text/javascript'u'text/javascript'b'.js'u'.js'b'.mjs'u'.mjs'b'application/json'u'application/json'b'.json'u'.json'b'application/manifest+json'u'application/manifest+json'b'.webmanifest'u'.webmanifest'b'application/msword'u'application/msword'b'.doc'u'.doc'b'.dot'u'.dot'b'.wiz'u'.wiz'b'application/n-quads'u'application/n-quads'b'.nq'u'.nq'b'application/n-triples'u'application/n-triples'b'.nt'u'.nt'b'application/octet-stream'u'application/octet-stream'b'.bin'u'.bin'b'.a'u'.a'b'.dll'u'.dll'b'.o'u'.o'b'.obj'u'.obj'b'.so'u'.so'b'application/oda'u'application/oda'b'.oda'u'.oda'b'application/pdf'u'application/pdf'b'.pdf'u'.pdf'b'application/pkcs7-mime'u'application/pkcs7-mime'b'.p7c'u'.p7c'b'application/postscript'u'application/postscript'b'.ps'u'.ps'b'.ai'u'.ai'b'.eps'u'.eps'b'application/trig'u'application/trig'b'.trig'u'.trig'b'application/vnd.apple.mpegurl'u'application/vnd.apple.mpegurl'b'.m3u'u'.m3u'b'.m3u8'u'.m3u8'b'application/vnd.ms-excel'u'application/vnd.ms-excel'b'.xls'u'.xls'b'.xlb'u'.xlb'b'application/vnd.ms-powerpoint'u'application/vnd.ms-powerpoint'b'.ppt'u'.ppt'b'.pot'u'.pot'b'.ppa'u'.ppa'b'.pps'u'.pps'b'.pwz'u'.pwz'b'application/wasm'u'application/wasm'b'.wasm'u'.wasm'b'application/x-bcpio'u'application/x-bcpio'b'.bcpio'u'.bcpio'b'application/x-cpio'u'application/x-cpio'b'.cpio'u'.cpio'b'application/x-csh'u'application/x-csh'b'.csh'u'.csh'b'application/x-dvi'u'application/x-dvi'b'.dvi'u'.dvi'b'application/x-gtar'u'application/x-gtar'b'.gtar'u'.gtar'b'application/x-hdf'u'application/x-hdf'b'.hdf'u'.hdf'b'application/x-hdf5'u'application/x-hdf5'b'.h5'u'.h5'b'application/x-latex'u'application/x-latex'b'.latex'u'.latex'b'application/x-mif'u'application/x-mif'b'.mif'u'.mif'b'application/x-netcdf'u'application/x-netcdf'b'.cdf'u'.cdf'b'.nc'u'.nc'b'application/x-pkcs12'u'application/x-pkcs12'b'.p12'u'.p12'b'.pfx'u'.pfx'b'application/x-pn-realaudio'u'application/x-pn-realaudio'b'.ram'u'.ram'b'application/x-python-code'u'application/x-python-code'b'.pyo'u'.pyo'b'application/x-sh'u'application/x-sh'b'.sh'u'.sh'b'application/x-shar'u'application/x-shar'b'.shar'u'.shar'b'application/x-shockwave-flash'u'application/x-shockwave-flash'b'.swf'u'.swf'b'application/x-sv4cpio'u'application/x-sv4cpio'b'.sv4cpio'u'.sv4cpio'b'application/x-sv4crc'u'application/x-sv4crc'b'.sv4crc'u'.sv4crc'b'application/x-tar'u'application/x-tar'b'.tar'u'.tar'b'application/x-tcl'u'application/x-tcl'b'.tcl'u'.tcl'b'application/x-tex'u'application/x-tex'b'.tex'u'.tex'b'application/x-texinfo'u'application/x-texinfo'b'.texi'u'.texi'b'.texinfo'u'.texinfo'b'application/x-troff'u'application/x-troff'b'.roff'u'.roff'b'.t'u'.t'b'.tr'u'.tr'b'application/x-troff-man'u'application/x-troff-man'b'.man'u'.man'b'application/x-troff-me'u'application/x-troff-me'b'.me'u'.me'b'application/x-troff-ms'u'application/x-troff-ms'b'.ms'u'.ms'b'application/x-ustar'u'application/x-ustar'b'.ustar'u'.ustar'b'application/x-wais-source'u'application/x-wais-source'b'.src'u'.src'b'application/xml'u'application/xml'b'.xsl'u'.xsl'b'.rdf'u'.rdf'b'.wsdl'u'.wsdl'b'.xpdl'u'.xpdl'b'application/zip'u'application/zip'b'.zip'u'.zip'b'audio/3gpp'u'audio/3gpp'b'.3gp'u'.3gp'b'.3gpp'u'.3gpp'b'audio/3gpp2'u'audio/3gpp2'b'.3g2'u'.3g2'b'.3gpp2'u'.3gpp2'b'audio/aac'u'audio/aac'b'.aac'u'.aac'b'.adts'u'.adts'b'.loas'u'.loas'b'.ass'u'.ass'b'audio/basic'u'audio/basic'b'.au'u'.au'b'.snd'u'.snd'b'audio/mpeg'u'audio/mpeg'b'.mp3'u'.mp3'b'.mp2'u'.mp2'b'audio/opus'u'audio/opus'b'.opus'u'.opus'b'audio/x-aiff'u'audio/x-aiff'b'.aif'u'.aif'b'.aifc'u'.aifc'b'.aiff'u'.aiff'b'audio/x-pn-realaudio'u'audio/x-pn-realaudio'b'.ra'u'.ra'b'audio/x-wav'u'audio/x-wav'b'.wav'u'.wav'b'image/avif'u'image/avif'b'.avif'u'.avif'b'image/bmp'u'image/bmp'b'.bmp'u'.bmp'b'image/gif'u'image/gif'b'.gif'u'.gif'b'image/ief'u'image/ief'b'.ief'u'.ief'b'image/jpeg'u'image/jpeg'b'.jpg'u'.jpg'b'.jpe'u'.jpe'b'.jpeg'u'.jpeg'b'image/heic'u'image/heic'b'.heic'u'.heic'b'image/heif'u'image/heif'b'.heif'u'.heif'b'image/png'u'image/png'b'.png'u'.png'b'image/svg+xml'u'image/svg+xml'b'.svg'u'.svg'b'image/tiff'u'image/tiff'b'.tiff'u'.tiff'b'.tif'u'.tif'b'image/vnd.microsoft.icon'u'image/vnd.microsoft.icon'b'.ico'u'.ico'b'image/x-cmu-raster'u'image/x-cmu-raster'b'.ras'u'.ras'b'image/x-portable-anymap'u'image/x-portable-anymap'b'.pnm'u'.pnm'b'image/x-portable-bitmap'u'image/x-portable-bitmap'b'.pbm'u'.pbm'b'image/x-portable-graymap'u'image/x-portable-graymap'b'.pgm'u'.pgm'b'image/x-portable-pixmap'u'image/x-portable-pixmap'b'.ppm'u'.ppm'b'image/x-rgb'u'image/x-rgb'b'.rgb'u'.rgb'b'image/x-xbitmap'u'image/x-xbitmap'b'.xbm'u'.xbm'b'image/x-xpixmap'u'image/x-xpixmap'b'.xpm'u'.xpm'b'image/x-xwindowdump'u'image/x-xwindowdump'b'.xwd'u'.xwd'b'.eml'u'.eml'b'.mht'u'.mht'b'.mhtml'u'.mhtml'b'.nws'u'.nws'b'text/css'u'text/css'b'.css'u'.css'b'text/csv'u'text/csv'b'.csv'u'.csv'b'text/html'u'text/html'b'.html'u'.html'b'.htm'u'.htm'b'text/n3'u'text/n3'b'.n3'u'.n3'b'.txt'u'.txt'b'.bat'u'.bat'b'.c'u'.c'b'.h'u'.h'b'.ksh'u'.ksh'b'.pl'u'.pl'b'.srt'u'.srt'b'text/richtext'u'text/richtext'b'.rtx'u'.rtx'b'text/tab-separated-values'u'text/tab-separated-values'b'.tsv'u'.tsv'b'text/vtt'u'text/vtt'b'.vtt'u'.vtt'b'text/x-python'u'text/x-python'b'text/x-setext'u'text/x-setext'b'.etx'u'.etx'b'text/x-sgml'u'text/x-sgml'b'.sgm'u'.sgm'b'.sgml'u'.sgml'b'text/x-vcard'u'text/x-vcard'b'.vcf'u'.vcf'b'.xml'u'.xml'b'video/mp4'u'video/mp4'b'.mp4'u'.mp4'b'video/mpeg'u'video/mpeg'b'.mpeg'u'.mpeg'b'.m1v'u'.m1v'b'.mpa'u'.mpa'b'.mpe'u'.mpe'b'.mpg'u'.mpg'b'video/quicktime'u'video/quicktime'b'.mov'u'.mov'b'.qt'u'.qt'b'video/webm'u'video/webm'b'.webm'u'.webm'b'video/x-msvideo'u'video/x-msvideo'b'.avi'u'.avi'b'video/x-sgi-movie'u'video/x-sgi-movie'b'.movie'u'.movie'b'application/rtf'u'application/rtf'b'.rtf'u'.rtf'b'audio/midi'u'audio/midi'b'.midi'u'.midi'b'.mid'u'.mid'b'image/jpg'u'image/jpg'b'image/pict'u'image/pict'b'.pict'u'.pict'b'.pct'u'.pct'b'.pic'u'.pic'b'image/webp'u'image/webp'b'.webp'u'.webp'b'text/xul'u'text/xul'b'.xul'u'.xul'b'Usage: mimetypes.py [options] type

Options:
    --help / -h       -- print this message and exit
    --lenient / -l    -- additionally search of some common, but non-standard
                         types.
    --extension / -e  -- guess extension instead of type

More than one type argument may be given.
'u'Usage: mimetypes.py [options] type

Options:
    --help / -h       -- print this message and exit
    --lenient / -l    -- additionally search of some common, but non-standard
                         types.
    --extension / -e  -- guess extension instead of type

More than one type argument may be given.
'b'hle'u'hle'b'lenient'u'lenient'b'extension'u'extension'b'--help'u'--help'b'--lenient'u'--lenient'b'--extension'u'--extension'b'I don't know anything about type'u'I don't know anything about type'b'type:'u'type:'b'encoding:'u'encoding:'u'Lib.mimetypes'u'mimetypes'Event loop mixins._global_lock is bound to a different event loopb'Event loop mixins.'u'Event loop mixins.'b' is bound to a different event loop'u' is bound to a different event loop'u'Lib.asyncio.mixins'u'asyncio.mixins'u'mixins'u'14.40.33807.0'CRT_ASSEMBLY_VERSIONGetErrorModeLK_LOCKLK_NBLCKLK_NBRLCKLK_RLCKLK_UNLCKSEM_FAILCRITICALERRORSSEM_NOALIGNMENTFAULTEXCEPTSEM_NOGPFAULTERRORBOXSEM_NOOPENFILEERRORBOXSetErrorModeget_osfhandlegetchgetchegetwchgetwcheheapminkbhitlockingopen_osfhandleputchputwchsetmodeungetchungetwchmsvcrtbenchmark_multiple_nows_0benchmark_multiple_nows_1benchmark_multiple_nows_2total_timerun_benchmarks_multiple_nows# leap seconds# division by 0u'Temp.date_time.benchmarks.multiple_nows'u'date_time.benchmarks.multiple_nows'u'benchmarks.multiple_nows'u'multiple_nows'benchmark_naive_utc_local_02024naivebenchmark_naive_utc_local_1benchmark_naive_utc_local_2benchmark_naive_utc_local_3zerobenchmark_naive_utc_local_4benchmark_naive_utc_local_5benchmark_naive_utc_local_6benchmark_naive_utc_local_7benchmark_naive_utc_local_8# naive# UTC# local# note that this actually passesu'Temp.date_time.benchmarks.naive_utc_local'u'date_time.benchmarks.naive_utc_local'u'benchmarks.naive_utc_local'u'naive_utc_local'__fspath__inodeis_junctionnt.DirEntryDirEntryEX_OKF_OKO_APPENDO_BINARYO_NOINHERITO_RANDOMO_RDWRO_SEQUENTIALO_SHORT_LIVEDO_TEMPORARYO_TEXTO_TRUNCP_DETACHP_NOWAITP_NOWAITOP_OVERLAYP_WAITR_OKTMP_MAXW_OKX_OK_LOAD_LIBRARY_SEARCH_APPLICATION_DIR_LOAD_LIBRARY_SEARCH_DEFAULT_DIRS_LOAD_LIBRARY_SEARCH_DLL_LOAD_DIR_LOAD_LIBRARY_SEARCH_SYSTEM32_LOAD_LIBRARY_SEARCH_USER_DIRSu'This module provides access to operating system functionality that is
standardized by the C Standard and the POSIX standard (a thinly
disguised Unix interface).  Refer to the library manual and
corresponding Unix manual entries for more information on calls.'_add_dll_directory_getdiskusage_getfinalpathname_getfullpathname_getvolumepathnameu'HAVE_FTRUNCATE'u'MS_WINDOWS'_have_functions_path_exists_path_isdevdrive_path_islink_path_normpath_remove_dll_directorycloserangedevice_encodingdup2execvexecvefsyncftruncateget_blockingget_handle_inheritableget_inheritablegetcwdbgetlogingetppidlistdriveslistmountslistvolumeslseekputenvreadlinkrmdirset_handle_inheritableset_inheritablespawnvspawnvestartfileu'stat_result: Result from stat, fstat, or lstat.

This object may be accessed either as a tuple of
  (mode, ino, dev, nlink, uid, gid, size, atime, mtime, ctime)
or via the attributes st_mode, st_ino, st_dev, st_nlink, st_uid, and so on.

Posix/windows: If your platform supports st_blksize, st_blocks, st_rdev,
or st_flags, they are available as attributes only.

See os.stat for more information.'u'st_mode'u'st_ino'u'st_dev'u'st_nlink'u'st_uid'u'st_gid'u'st_size'u'os'st_atime_nsst_birthtimest_birthtime_nsst_ctime_nsst_file_attributesst_gidst_mtime_nsst_nlinkst_reparse_tagst_uidos.stat_resultstat_resultu'statvfs_result: Result from statvfs or fstatvfs.

This object may be accessed either as a tuple of
  (bsize, frsize, blocks, bfree, bavail, files, ffree, favail, flag, namemax),
or via the attributes f_bsize, f_frsize, f_blocks, f_bfree, and so on.

See os.statvfs for more information.'u'f_bsize'u'f_frsize'u'f_blocks'u'f_bfree'u'f_bavail'u'f_files'u'f_ffree'u'f_favail'u'f_flag'u'f_namemax'f_bavailf_bfreef_blocksf_bsizef_favailf_ffreef_filesf_flagf_frsizef_fsidf_namemaxos.statvfs_resultstatvfs_resultsymlinku'A tuple of (columns, lines) for holding terminal window size'u'columns'u'lines'os.terminal_sizeterminal_sizeu'times_result: Result from os.times().

This object may be accessed either as a tuple of
  (user, system, children_user, children_system, elapsed),
or via the attributes user, system, children_user, children_system,
and elapsed.

See os.times for more information.'u'user'u'system'u'children_user'u'children_system'u'elapsed'children_systemchildren_userusernt.times_resulttimes_resultumasku'uname_result: Result from os.uname().

This object may be accessed either as a tuple of
  (sysname, nodename, release, version, machine),
or via the attributes sysname, nodename, release, version, and machine.

See os.uname for more information.'u'sysname'u'nodename'u'release'u'machine'nodenamesysnament.uname_resultuname_resultunsetenvutimeCommon pathname manipulations, WindowsNT/95 version.

Instead of importing this module directly, import os and refer to this
module as os.path.
.;C:\bindefpathnuldevnullgenericpathsplitrootismountexpanduserexpandvarssupports_unicode_filenamescommonpathisjunction_get_bothseps\/_LCMapStringEx_LOCALE_NAME_INVARIANT_LCMAP_LOWERCASENormalize case of pathname.

        Makes all characters lowercase and all slashes into backslashes.
        fsdecodeTest whether a path is absolute:\colon_sepcolonresult_driveresult_rootresult_pathp_drivep_rootp_pathSplit a pathname into drive/UNC sharepoint and relative path specifiers.
    Returns a 2-tuple (drive_or_unc, path); either part may be empty.

    If you assign
        result = splitdrive(p)
    It is always true that:
        result[0] + result[1] == p

    If the path contained a drive letter, drive_or_unc will contain everything
    up to and including the colon.  e.g. splitdrive("c:/dir") returns ("c:", "/dir")

    If the path contained a UNC path, the drive_or_unc will contain the host name
    and share up to but not including the fourth directory separator character.
    e.g. splitdrive("//host/computer/dir") returns ("//host/computer", "/dir")

    Paths cannot contain both a drive letter and a UNC path.

    Split a pathname into drive, root and tail. The drive is defined
    exactly as in splitdrive(). On Windows, the root may be a single path
    separator or an empty string. The tail contains anything after the root.
    For example:

        splitroot('//server/share/') == ('//server/share', '/', '')
        splitroot('C:/Users/Barney') == ('C:', '/', 'Users/Barney')
        splitroot('C:///spam///ham') == ('C:', '/', '//spam///ham')
        splitroot('Windows/notepad') == ('', '', 'Windows/notepad')
    \\?\UNC\unc_prefixnormpindex2Split a pathname.

    Return tuple (head, tail) where tail is everything after the final slash.
    Either part may be empty.Returns the final component of a pathnameReturns the directory component of a pathnameTest whether a path is a junctionTest whether a path exists.  Returns True for broken symbolic linksTest whether a path is a mount point (a drive root, the root of a
    share, or a mounted volume)Expand ~ and ~user constructs.

    If user or $HOME is unknown, do nothing.USERPROFILEuserhomeHOMEPATHHOMEDRIVEtarget_userUSERNAMEcurrent_userExpand shell variables of the forms $var, ${var} and %var%.

    Unknown variables are left unchanged._-varcharsbracerbracedollarenvironbpathlenNormalize path, eliminating double slashes, etc._abspath_fallbackReturn the absolute version of a path as a fallback function in case
    `nt._getfullpathname` is not available or raises OSError. See bpo-31047 for
    more.

    cwdReturn the absolute version of a path._nt_readlink_readlink_deep6787439043924393allowed_winerrorold_path_getfinalpathname_nonstrict12319201921new_path\\?\new_unc_prefix\\.\NULhad_prefixinitial_winerrorspathReturn a relative version of a pathno path specifiedstart_abspath_absstart_drivestart_restpath_drivepath_restpath is on mount %r, start on mount %rstart_listpath_liste1e2rel_listGiven a sequence of path names, returns the longest common sub-path.commonpath() arg is an empty sequencedrivesplitssplit_pathsCan't mix absolute and relative pathsPaths don't have the same drivecommonisdevdriveDetermines whether the specified path is on a Windows Dev Drive.# Module 'ntpath' -- common operations on WinNT/Win95 pathnames# strings representing various path-related bits and pieces# These are primarily for export; internally, they are hardcoded.# Should be set before imports for resolving cyclic dependency.# Normalize the case of a pathname and map slashes to backslashes.# Other normalizations (such as optimizing '../' away) are not done# (this is done by normpath).# Return whether a path is absolute.# Trivial in Posix, harder on Windows.# For Windows it is absolute if it starts with a slash or backslash (current# volume), or if a pathname after the volume-letter-and-colon or UNC-resource# starts with a slash or backslash.# Absolute: UNC, device, and paths with a drive and root.# LEGACY BUG: isabs("/x") should be false since the path has no drive.# Join two (or more) paths.#23780: Ensure compatible data type even if p is null.# Second path is absolute# Different drives => ignore the first path entirely# Same drive in different case# Second path is relative to the first## add separator between UNC and non-absolute path# Split a path in a drive specification (a drive letter followed by a# colon) and the path specification.# It is always true that drivespec + pathspec == p# UNC drives, e.g. \\server\share or \\?\UNC\server\share# Device drives, e.g. \\.\device or \\?\device# Relative path with root, e.g. \Windows# Absolute drive-letter path, e.g. X:\Windows# Relative path with drive, e.g. X:Windows# Relative path, e.g. Windows# Split a path in head (everything up to the last '/') and tail (the# rest).  After the trailing '/' is stripped, the invariant# join(head, tail) == p holds.# The resulting head won't end in '/' unless it is the root.# set i to index beyond p's last slash# now tail has no slashes# Return the tail (basename) part of a path.# Return the head (dirname) part of a path.# Is a path a junction?# Being true for dangling symbolic links is also useful.# Is a path a mount point?# Any drive letter root (eg c:\)# Any share UNC (eg \\server\share)# Any volume mounted on a filesystem folder# No one method detects all three situations. Historically we've lexically# detected drive letter roots and share UNCs. The canonical approach to# detecting mounted volumes (querying the reparse tag) fails for the most# common case: drive letter roots. The alternative which uses GetVolumePathName# fails if the drive letter is the result of a SUBST.# Expand paths beginning with '~' or '~user'.# '~' means $HOME; '~user' means that user's home directory.# If the path doesn't begin with '~', or if the user or $HOME is unknown,# the path is returned unchanged (leaving error reporting to whatever# function is called with the expanded path as argument).# See also module 'glob' for expansion of *, ? and [...] in pathnames.# (A function should also be defined to do full *sh-style environment# variable expansion.)#~user# Try to guess user home directory.  By default all user# profile directories are located in the same place and are# named by corresponding usernames.  If userhome isn't a# normal profile directory, this guess is likely wrong,# so we bail out.# Expand paths containing shell variable substitutions.# The following rules apply:#       - no expansion within single quotes#       - '$$' is translated into '$'#       - '%%' is translated into '%' if '%%' are not seen in %var1%%var2%#       - ${varname} is accepted.#       - $varname is accepted.#       - %varname% is accepted.#       - varnames can be made out of letters, digits and the characters '_-'#         (though is not verified in the ${varname} and %varname% cases)# XXX With COMMAND.COM you can use any characters in a variable name,# XXX except '^|<>='.# no expansion within single quotes# variable or '%'# variable or '$$'# Normalize a path, e.g. A//B, A/./B and A/foo/../B all become A\B.# Previously, this function also truncated pathnames to 8+3 format,# but as this module is called "ntpath", that's obviously wrong!# If the path is now empty, substitute '.'# Return an absolute path.# not running on Windows - mock up something sensible# use native Windows method on Windows# realpath is a no-op on systems without _getfinalpathname support.# These error codes indicate that we should stop reading links and# return the path we currently have.# 1: ERROR_INVALID_FUNCTION# 2: ERROR_FILE_NOT_FOUND# 3: ERROR_DIRECTORY_NOT_FOUND# 5: ERROR_ACCESS_DENIED# 21: ERROR_NOT_READY (implies drive with no media)# 32: ERROR_SHARING_VIOLATION (probably an NTFS paging file)# 50: ERROR_NOT_SUPPORTED (implies no support for reparse points)# 67: ERROR_BAD_NET_NAME (implies remote server unavailable)# 87: ERROR_INVALID_PARAMETER# 4390: ERROR_NOT_A_REPARSE_POINT# 4392: ERROR_INVALID_REPARSE_DATA# 4393: ERROR_REPARSE_TAG_INVALID# Links may be relative, so resolve them against their# own location# If it's something other than a symlink, we don't know# what it's actually going to be resolved against, so# just return the old path.# Stop on reparse points that are not symlinks# These error codes indicate that we should stop resolving the path# and return the value we currently have.# 50: ERROR_NOT_SUPPORTED# 53: ERROR_BAD_NETPATH# 65: ERROR_NETWORK_ACCESS_DENIED# 123: ERROR_INVALID_NAME# 161: ERROR_BAD_PATHNAME# 1920: ERROR_CANT_ACCESS_FILE# 1921: ERROR_CANT_RESOLVE_FILENAME (implies unfollowable symlink)# Non-strict algorithm is to find as much of the target directory# as we can and join the rest.# The OS could not resolve this path fully, so we attempt# to follow the link ourselves. If we succeed, join the tail# If we fail to readlink(), let's keep traversing# TODO (bpo-38186): Request the real file name from the directory# entry using FindFirstFileW. For now, we will return the path# as best we have it# bpo-38081: Special case for realpath(b'nul')# bpo-38081: Special case for realpath('nul')# gh-106242: Raised for embedded null characters# In strict mode, we convert into an OSError.# Non-strict mode returns the path as-is, since we've already# made it absolute.# The path returned by _getfinalpathname will always start with \\?\ -# strip off that prefix unless it was already provided on the original# path.# For UNC paths, the prefix will actually be \\?\UNC\# Handle that case as well.# Ensure that the non-prefixed path resolves to the same path# Unexpected, as an invalid path should not have gained a prefix# at any point, but we ignore this error just in case.# If the path does not exist and originally did not exist, then# strip the prefix anyway.# All supported version have Unicode filename support.# Work out how much of the filepath is shared by start and path.# Return the longest common sub-path of the sequence of paths given as input.# The function is case-insensitive and 'separator-insensitive', i.e. if the# only difference between two paths is the use of '\' versus '/' as separator,# they are deemed to be equal.# However, the returned path will have the standard '\' separator (even if the# given paths had the alternative '/' separator) and will have the case of the# first path given in the sequence. Additionally, any trailing separator is# stripped from the returned path.# Check that all drive letters or UNC paths match. The check is made only# now otherwise type errors for mixing strings and bytes would not be# caught.# The isdir(), isfile(), islink() and exists() implementations in# genericpath use os.stat(). This is overkill on Windows. Use simpler# builtin functions if they are available.# Use genericpath.* as imported above# Never a Dev Driveb'Common pathname manipulations, WindowsNT/95 version.

Instead of importing this module directly, import os and refer to this
module as os.path.
'u'Common pathname manipulations, WindowsNT/95 version.

Instead of importing this module directly, import os and refer to this
module as os.path.
'b'.;C:\bin'u'.;C:\bin'b'nul'u'nul'b'normcase'u'normcase'b'isabs'u'isabs'b'join'u'join'b'splitdrive'u'splitdrive'b'splitroot'u'splitroot'b'splitext'u'splitext'b'basename'u'basename'b'dirname'u'dirname'b'lexists'u'lexists'b'ismount'u'ismount'b'expanduser'u'expanduser'b'expandvars'u'expandvars'b'normpath'u'normpath'b'abspath'u'abspath'b'curdir'u'curdir'b'pardir'u'pardir'b'pathsep'u'pathsep'b'defpath'u'defpath'b'altsep'u'altsep'b'extsep'u'extsep'b'devnull'u'devnull'b'realpath'u'realpath'b'supports_unicode_filenames'u'supports_unicode_filenames'b'relpath'u'relpath'b'commonpath'u'commonpath'b'isjunction'u'isjunction'b'\/'u'\/'b'Normalize case of pathname.

        Makes all characters lowercase and all slashes into backslashes.
        'u'Normalize case of pathname.

        Makes all characters lowercase and all slashes into backslashes.
        'b'Test whether a path is absolute'u'Test whether a path is absolute'b':\'u':\'b'Split a pathname into drive/UNC sharepoint and relative path specifiers.
    Returns a 2-tuple (drive_or_unc, path); either part may be empty.

    If you assign
        result = splitdrive(p)
    It is always true that:
        result[0] + result[1] == p

    If the path contained a drive letter, drive_or_unc will contain everything
    up to and including the colon.  e.g. splitdrive("c:/dir") returns ("c:", "/dir")

    If the path contained a UNC path, the drive_or_unc will contain the host name
    and share up to but not including the fourth directory separator character.
    e.g. splitdrive("//host/computer/dir") returns ("//host/computer", "/dir")

    Paths cannot contain both a drive letter and a UNC path.

    'u'Split a pathname into drive/UNC sharepoint and relative path specifiers.
    Returns a 2-tuple (drive_or_unc, path); either part may be empty.

    If you assign
        result = splitdrive(p)
    It is always true that:
        result[0] + result[1] == p

    If the path contained a drive letter, drive_or_unc will contain everything
    up to and including the colon.  e.g. splitdrive("c:/dir") returns ("c:", "/dir")

    If the path contained a UNC path, the drive_or_unc will contain the host name
    and share up to but not including the fourth directory separator character.
    e.g. splitdrive("//host/computer/dir") returns ("//host/computer", "/dir")

    Paths cannot contain both a drive letter and a UNC path.

    'b'Split a pathname into drive, root and tail. The drive is defined
    exactly as in splitdrive(). On Windows, the root may be a single path
    separator or an empty string. The tail contains anything after the root.
    For example:

        splitroot('//server/share/') == ('//server/share', '/', '')
        splitroot('C:/Users/Barney') == ('C:', '/', 'Users/Barney')
        splitroot('C:///spam///ham') == ('C:', '/', '//spam///ham')
        splitroot('Windows/notepad') == ('', '', 'Windows/notepad')
    'u'Split a pathname into drive, root and tail. The drive is defined
    exactly as in splitdrive(). On Windows, the root may be a single path
    separator or an empty string. The tail contains anything after the root.
    For example:

        splitroot('//server/share/') == ('//server/share', '/', '')
        splitroot('C:/Users/Barney') == ('C:', '/', 'Users/Barney')
        splitroot('C:///spam///ham') == ('C:', '/', '//spam///ham')
        splitroot('Windows/notepad') == ('', '', 'Windows/notepad')
    'b'\\?\UNC\'u'\\?\UNC\'b'Split a pathname.

    Return tuple (head, tail) where tail is everything after the final slash.
    Either part may be empty.'u'Split a pathname.

    Return tuple (head, tail) where tail is everything after the final slash.
    Either part may be empty.'b'Returns the final component of a pathname'u'Returns the final component of a pathname'b'Returns the directory component of a pathname'u'Returns the directory component of a pathname'b'st_reparse_tag'u'st_reparse_tag'b'Test whether a path is a junction'u'Test whether a path is a junction'b'Test whether a path exists.  Returns True for broken symbolic links'u'Test whether a path exists.  Returns True for broken symbolic links'b'Test whether a path is a mount point (a drive root, the root of a
    share, or a mounted volume)'u'Test whether a path is a mount point (a drive root, the root of a
    share, or a mounted volume)'b'Expand ~ and ~user constructs.

    If user or $HOME is unknown, do nothing.'u'Expand ~ and ~user constructs.

    If user or $HOME is unknown, do nothing.'b'USERPROFILE'u'USERPROFILE'b'HOMEPATH'u'HOMEPATH'b'HOMEDRIVE'u'HOMEDRIVE'b'USERNAME'u'USERNAME'b'Expand shell variables of the forms $var, ${var} and %var%.

    Unknown variables are left unchanged.'u'Expand shell variables of the forms $var, ${var} and %var%.

    Unknown variables are left unchanged.'b'_-'u'_-'b'environb'u'environb'b'Normalize path, eliminating double slashes, etc.'u'Normalize path, eliminating double slashes, etc.'b'Return the absolute version of a path as a fallback function in case
    `nt._getfullpathname` is not available or raises OSError. See bpo-31047 for
    more.

    'u'Return the absolute version of a path as a fallback function in case
    `nt._getfullpathname` is not available or raises OSError. See bpo-31047 for
    more.

    'b'Return the absolute version of a path.'u'Return the absolute version of a path.'b'\\?\'b'\\.\NUL'u'\\?\'u'\\.\NUL'b'Return a relative version of a path'u'Return a relative version of a path'b'no path specified'u'no path specified'b'path is on mount %r, start on mount %r'u'path is on mount %r, start on mount %r'b'Given a sequence of path names, returns the longest common sub-path.'u'Given a sequence of path names, returns the longest common sub-path.'b'commonpath() arg is an empty sequence'u'commonpath() arg is an empty sequence'b'Can't mix absolute and relative paths'u'Can't mix absolute and relative paths'b'Paths don't have the same drive'u'Paths don't have the same drive'b'Determines whether the specified path is on a Windows Dev Drive.'u'Determines whether the specified path is on a Windows Dev Drive.'u'Lib.ntpath'u'ntpath'Abstract Base Classes (ABCs) for numbers, according to PEP 3141.

TODO: Fill out more detailed documentation on the operators.All numbers inherit from this class.

    If you just want to check if an argument x is a number, without
    caring what kind, use isinstance(x, Number).
    Complex defines the operations that work on the builtin complex type.

    In short, those are: a conversion to complex, .real, .imag, +, -,
    *, /, **, abs(), .conjugate, ==, and !=.

    If it is given heterogeneous arguments, and doesn't have special
    knowledge about them, it should fall back to the builtin complex
    type as described below.
    Return a builtin complex instance. Called for complex(self).True if self != 0. Called for bool(self).Retrieve the real component of this number.

        This should subclass Real.
        Retrieve the imaginary component of this number.

        This should subclass Real.
        self + otherother + self-self+selfself - otherother - selfself * otherother * selfself / other: Should promote to float when necessary.other / selfself ** exponent; should promote to float or complex when necessary.base ** selfReturns the Real distance from 0. Called for abs(self).(x+y*i).conjugate() returns (x-y*i).self == otherTo Complex, Real adds the operations that work on real numbers.

    In short, those are: a conversion to float, trunc(), divmod,
    %, <, <=, >, and >=.

    Real also provides defaults for the derived operations.
    Any Real can be converted to a native float object.

        Called for float(self).trunc(self): Truncates self to an Integral.

        Returns an Integral i such that:
          * i > 0 iff self > 0;
          * abs(i) <= abs(self);
          * for any Integral j satisfying the first two conditions,
            abs(i) >= abs(j) [i.e. i has "maximal" abs among those].
        i.e. "truncate towards 0".
        Finds the greatest Integral <= self.Finds the least Integral >= self.Rounds self to ndigits decimal places, defaulting to 0.

        If ndigits is omitted or None, returns an Integral, otherwise
        returns a Real. Rounds half toward even.
        divmod(self, other): The pair (self // other, self % other).

        Sometimes this can be computed faster than the pair of
        operations.
        divmod(other, self): The pair (other // self, other % self).

        Sometimes this can be computed faster than the pair of
        operations.
        self // other: The floor() of self/other.other // self: The floor() of other/self.self % otherother % selfself < other

        < on Reals defines a total ordering, except perhaps for NaN.self <= othercomplex(self) == complex(float(self), 0)Real numbers are their real component.Real numbers have no imaginary component.Conjugate is a no-op for Reals..numerator and .denominator should be in lowest terms.float(self) = self.numerator / self.denominator

        It's important that this conversion use the integer's "true"
        division rather than casting one side to float before dividing
        so that ratios of huge integers convert without overflowing.

        Integral adds methods that work on integral numbers.

    In short, these are conversion to int, pow with modulus, and the
    bit-string operations.
    int(self)Called whenever an index is needed, such as in slicingself ** exponent % modulus, but maybe faster.

        Accept the modulus argument if you want to support the
        3-argument version of pow(). Raise a TypeError if exponent < 0
        or any argument isn't Integral. Otherwise, just implement the
        2-argument version described in Complex.
        self << otherother << selfself >> otherother >> selfself & otherother & selfself ^ otherother ^ selfself | otherother | self~selffloat(self) == float(int(self))Integers are their own numerators.Integers have a denominator of 1.# ABC.# or changing parameter names.  This is still a bit dubious but at# Concrete numeric types must provide their own hash implementation## Notes on Decimal## ----------------## Decimal has all of the methods specified by the Real abc, but it should## not be registered as a Real because decimals do not interoperate with## binary floats (i.e.  Decimal('3.14') + 2.71828 is undefined).  But,## abstract reals are expected to interoperate (i.e. R1 + R2 should be## expected to work if R1 and R2 are both Reals).# Concrete implementations of Complex abstract methods.# Concrete implementation of Real's conversion to float.# Concrete implementations of Rational and Real abstract methods.b'Abstract Base Classes (ABCs) for numbers, according to PEP 3141.

TODO: Fill out more detailed documentation on the operators.'u'Abstract Base Classes (ABCs) for numbers, according to PEP 3141.

TODO: Fill out more detailed documentation on the operators.'b'Number'u'Number'b'Complex'u'Complex'b'Real'u'Real'b'Rational'u'Rational'b'Integral'u'Integral'b'All numbers inherit from this class.

    If you just want to check if an argument x is a number, without
    caring what kind, use isinstance(x, Number).
    'u'All numbers inherit from this class.

    If you just want to check if an argument x is a number, without
    caring what kind, use isinstance(x, Number).
    'b'Complex defines the operations that work on the builtin complex type.

    In short, those are: a conversion to complex, .real, .imag, +, -,
    *, /, **, abs(), .conjugate, ==, and !=.

    If it is given heterogeneous arguments, and doesn't have special
    knowledge about them, it should fall back to the builtin complex
    type as described below.
    'u'Complex defines the operations that work on the builtin complex type.

    In short, those are: a conversion to complex, .real, .imag, +, -,
    *, /, **, abs(), .conjugate, ==, and !=.

    If it is given heterogeneous arguments, and doesn't have special
    knowledge about them, it should fall back to the builtin complex
    type as described below.
    'b'Return a builtin complex instance. Called for complex(self).'u'Return a builtin complex instance. Called for complex(self).'b'True if self != 0. Called for bool(self).'u'True if self != 0. Called for bool(self).'b'Retrieve the real component of this number.

        This should subclass Real.
        'u'Retrieve the real component of this number.

        This should subclass Real.
        'b'Retrieve the imaginary component of this number.

        This should subclass Real.
        'u'Retrieve the imaginary component of this number.

        This should subclass Real.
        'b'self + other'u'self + other'b'other + self'u'other + self'b'-self'u'-self'b'+self'u'+self'b'self - other'u'self - other'b'other - self'u'other - self'b'self * other'u'self * other'b'other * self'u'other * self'b'self / other: Should promote to float when necessary.'u'self / other: Should promote to float when necessary.'b'other / self'u'other / self'b'self ** exponent; should promote to float or complex when necessary.'u'self ** exponent; should promote to float or complex when necessary.'b'base ** self'u'base ** self'b'Returns the Real distance from 0. Called for abs(self).'u'Returns the Real distance from 0. Called for abs(self).'b'(x+y*i).conjugate() returns (x-y*i).'u'(x+y*i).conjugate() returns (x-y*i).'b'self == other'u'self == other'b'To Complex, Real adds the operations that work on real numbers.

    In short, those are: a conversion to float, trunc(), divmod,
    %, <, <=, >, and >=.

    Real also provides defaults for the derived operations.
    'u'To Complex, Real adds the operations that work on real numbers.

    In short, those are: a conversion to float, trunc(), divmod,
    %, <, <=, >, and >=.

    Real also provides defaults for the derived operations.
    'b'Any Real can be converted to a native float object.

        Called for float(self).'u'Any Real can be converted to a native float object.

        Called for float(self).'b'trunc(self): Truncates self to an Integral.

        Returns an Integral i such that:
          * i > 0 iff self > 0;
          * abs(i) <= abs(self);
          * for any Integral j satisfying the first two conditions,
            abs(i) >= abs(j) [i.e. i has "maximal" abs among those].
        i.e. "truncate towards 0".
        'u'trunc(self): Truncates self to an Integral.

        Returns an Integral i such that:
          * i > 0 iff self > 0;
          * abs(i) <= abs(self);
          * for any Integral j satisfying the first two conditions,
            abs(i) >= abs(j) [i.e. i has "maximal" abs among those].
        i.e. "truncate towards 0".
        'b'Finds the greatest Integral <= self.'u'Finds the greatest Integral <= self.'b'Finds the least Integral >= self.'u'Finds the least Integral >= self.'b'Rounds self to ndigits decimal places, defaulting to 0.

        If ndigits is omitted or None, returns an Integral, otherwise
        returns a Real. Rounds half toward even.
        'u'Rounds self to ndigits decimal places, defaulting to 0.

        If ndigits is omitted or None, returns an Integral, otherwise
        returns a Real. Rounds half toward even.
        'b'divmod(self, other): The pair (self // other, self % other).

        Sometimes this can be computed faster than the pair of
        operations.
        'u'divmod(self, other): The pair (self // other, self % other).

        Sometimes this can be computed faster than the pair of
        operations.
        'b'divmod(other, self): The pair (other // self, other % self).

        Sometimes this can be computed faster than the pair of
        operations.
        'u'divmod(other, self): The pair (other // self, other % self).

        Sometimes this can be computed faster than the pair of
        operations.
        'b'self // other: The floor() of self/other.'u'self // other: The floor() of self/other.'b'other // self: The floor() of other/self.'u'other // self: The floor() of other/self.'b'self % other'u'self % other'b'other % self'u'other % self'b'self < other

        < on Reals defines a total ordering, except perhaps for NaN.'u'self < other

        < on Reals defines a total ordering, except perhaps for NaN.'b'self <= other'u'self <= other'b'complex(self) == complex(float(self), 0)'u'complex(self) == complex(float(self), 0)'b'Real numbers are their real component.'u'Real numbers are their real component.'b'Real numbers have no imaginary component.'u'Real numbers have no imaginary component.'b'Conjugate is a no-op for Reals.'u'Conjugate is a no-op for Reals.'b'.numerator and .denominator should be in lowest terms.'u'.numerator and .denominator should be in lowest terms.'b'float(self) = self.numerator / self.denominator

        It's important that this conversion use the integer's "true"
        division rather than casting one side to float before dividing
        so that ratios of huge integers convert without overflowing.

        'u'float(self) = self.numerator / self.denominator

        It's important that this conversion use the integer's "true"
        division rather than casting one side to float before dividing
        so that ratios of huge integers convert without overflowing.

        'b'Integral adds methods that work on integral numbers.

    In short, these are conversion to int, pow with modulus, and the
    bit-string operations.
    'u'Integral adds methods that work on integral numbers.

    In short, these are conversion to int, pow with modulus, and the
    bit-string operations.
    'b'int(self)'u'int(self)'b'Called whenever an index is needed, such as in slicing'u'Called whenever an index is needed, such as in slicing'b'self ** exponent % modulus, but maybe faster.

        Accept the modulus argument if you want to support the
        3-argument version of pow(). Raise a TypeError if exponent < 0
        or any argument isn't Integral. Otherwise, just implement the
        2-argument version described in Complex.
        'u'self ** exponent % modulus, but maybe faster.

        Accept the modulus argument if you want to support the
        3-argument version of pow(). Raise a TypeError if exponent < 0
        or any argument isn't Integral. Otherwise, just implement the
        2-argument version described in Complex.
        'b'self << other'u'self << other'b'other << self'u'other << self'b'self >> other'u'self >> other'b'other >> self'u'other >> self'b'self & other'u'self & other'b'other & self'u'other & self'b'self ^ other'u'self ^ other'b'other ^ self'u'other ^ self'b'self | other'u'self | other'b'other | self'u'other | self'b'~self'u'~self'b'float(self) == float(int(self))'u'float(self) == float(int(self))'b'Integers are their own numerators.'u'Integers are their own numerators.'b'Integers have a denominator of 1.'u'Integers have a denominator of 1.'u'Lib.numbers'u'numbers'
opcode module - potentially shared between dis and other modules which
operate on bytecodes (e.g. peephole optimizers).
hasexcHAVE_ARGUMENTENABLE_SPECIALIZATIONis_pseudoMIN_PSEUDO_OPCODEMAX_PSEUDO_OPCODEoplists_pseudo_opsdef_opname_opjrel_opjabs_oppseudo_opreal_opsoplistropPOP_TOPPUSH_NULLINTERPRETER_EXITEND_FOREND_SENDNOPUNARY_NEGATIVEUNARY_NOTUNARY_INVERTRESERVEDBINARY_SUBSCRBINARY_SLICESTORE_SLICEGET_LENMATCH_MAPPINGMATCH_SEQUENCEMATCH_KEYSPUSH_EXC_INFO35CHECK_EXC_MATCHCHECK_EG_MATCH37WITH_EXCEPT_START49GET_AITERGET_ANEXT51BEFORE_ASYNC_WITHBEFORE_WITHEND_ASYNC_FORCLEANUP_THROW55STORE_SUBSCRDELETE_SUBSCR61GET_ITERGET_YIELD_FROM_ITER69LOAD_BUILD_CLASS71LOAD_ASSERTION_ERROR74RETURN_GENERATOR75RETURN_VALUE83SETUP_ANNOTATIONSLOAD_LOCALSPOP_EXCEPT8990DELETE_NAME91UNPACK_SEQUENCEUNPACK_EX94STORE_ATTR95DELETE_ATTRDELETE_GLOBALSWAP99LOAD_NAMEBUILD_TUPLEBUILD_LISTBUILD_SETBUILD_MAP106COMPARE_OP107108IMPORT_FROMJUMP_FORWARD110POP_JUMP_IF_FALSE114POP_JUMP_IF_TRUE116IS_OP117CONTAINS_OPRERAISE119LOAD_FASTSTORE_FASTDELETE_FAST126LOAD_FAST_CHECKPOP_JUMP_IF_NOT_NONEPOP_JUMP_IF_NONERAISE_VARARGSGET_AWAITABLEBUILD_SLICEJUMP_BACKWARD_NO_INTERRUPTMAKE_CELLLOAD_CLOSURELOAD_DEREFSTORE_DEREFDELETE_DEREFCALL_FUNCTION_EXLOAD_FAST_AND_CLEARLIST_APPENDSET_ADDMAP_ADDCOPY_FREE_VARSYIELD_VALUERESUMEMATCH_CLASSBUILD_CONST_KEY_MAPBUILD_STRINGLIST_EXTENDSET_UPDATEDICT_MERGEDICT_UPDATECALLKW_NAMESLOAD_FROM_DICT_OR_GLOBALSLOAD_FROM_DICT_OR_DEREFMIN_INSTRUMENTED_OPCODEINSTRUMENTED_LOAD_SUPER_ATTRINSTRUMENTED_POP_JUMP_IF_NONEINSTRUMENTED_POP_JUMP_IF_NOT_NONEINSTRUMENTED_RESUMEINSTRUMENTED_CALLINSTRUMENTED_RETURN_VALUEINSTRUMENTED_YIELD_VALUEINSTRUMENTED_CALL_FUNCTION_EXINSTRUMENTED_JUMP_FORWARDINSTRUMENTED_JUMP_BACKWARDINSTRUMENTED_RETURN_CONSTINSTRUMENTED_FOR_ITERINSTRUMENTED_POP_JUMP_IF_FALSEINSTRUMENTED_POP_JUMP_IF_TRUEINSTRUMENTED_END_FORINSTRUMENTED_END_SENDINSTRUMENTED_INSTRUCTIONINSTRUMENTED_LINESETUP_FINALLYSETUP_CLEANUP257SETUP_WITHPOP_BLOCK260JUMP_NO_INTERRUPT261LOAD_METHOD262LOAD_SUPER_METHOD263LOAD_ZERO_SUPER_METHOD264LOAD_ZERO_SUPER_ATTR265STORE_FAST_MAYBE_NULL266<%r>NB_ADDNB_ANDNB_FLOOR_DIVIDENB_LSHIFTNB_MATRIX_MULTIPLYNB_MULTIPLYNB_REMAINDERNB_ORNB_POWERNB_RSHIFTNB_SUBTRACTNB_TRUE_DIVIDENB_XORNB_INPLACE_ADD+=NB_INPLACE_AND&=NB_INPLACE_FLOOR_DIVIDE//=NB_INPLACE_LSHIFT<<=NB_INPLACE_MATRIX_MULTIPLY@=NB_INPLACE_MULTIPLY*=NB_INPLACE_REMAINDER%=NB_INPLACE_OR|=NB_INPLACE_POWER**=NB_INPLACE_RSHIFT>>=NB_INPLACE_SUBTRACT-=NB_INPLACE_TRUE_DIVIDE/=NB_INPLACE_XOR^=INTRINSIC_1_INVALIDINTRINSIC_PRINTINTRINSIC_IMPORT_STARINTRINSIC_STOPITERATION_ERRORINTRINSIC_ASYNC_GEN_WRAPINTRINSIC_UNARY_POSITIVEINTRINSIC_LIST_TO_TUPLEINTRINSIC_TYPEVARINTRINSIC_PARAMSPECINTRINSIC_TYPEVARTUPLEINTRINSIC_SUBSCRIPT_GENERICINTRINSIC_TYPEALIASINTRINSIC_2_INVALIDINTRINSIC_PREP_RERAISE_STARINTRINSIC_TYPEVAR_WITH_BOUNDINTRINSIC_TYPEVAR_WITH_CONSTRAINTSINTRINSIC_SET_FUNCTION_TYPE_PARAMSBINARY_OP_ADD_FLOATBINARY_OP_ADD_INTBINARY_OP_ADD_UNICODEBINARY_OP_INPLACE_ADD_UNICODEBINARY_OP_MULTIPLY_FLOATBINARY_OP_MULTIPLY_INTBINARY_OP_SUBTRACT_FLOATBINARY_OP_SUBTRACT_INTBINARY_SUBSCR_DICTBINARY_SUBSCR_GETITEMBINARY_SUBSCR_LIST_INTBINARY_SUBSCR_TUPLE_INTCALL_PY_EXACT_ARGSCALL_PY_WITH_DEFAULTSCALL_BOUND_METHOD_EXACT_ARGSCALL_BUILTIN_CLASSCALL_BUILTIN_FAST_WITH_KEYWORDSCALL_METHOD_DESCRIPTOR_FAST_WITH_KEYWORDSCALL_NO_KW_BUILTIN_FASTCALL_NO_KW_BUILTIN_OCALL_NO_KW_ISINSTANCECALL_NO_KW_LENCALL_NO_KW_LIST_APPENDCALL_NO_KW_METHOD_DESCRIPTOR_FASTCALL_NO_KW_METHOD_DESCRIPTOR_NOARGSCALL_NO_KW_METHOD_DESCRIPTOR_OCALL_NO_KW_STR_1CALL_NO_KW_TUPLE_1CALL_NO_KW_TYPE_1COMPARE_OP_FLOATCOMPARE_OP_INTCOMPARE_OP_STRFOR_ITER_LISTFOR_ITER_TUPLEFOR_ITER_RANGEFOR_ITER_GENLOAD_SUPER_ATTR_ATTRLOAD_SUPER_ATTR_METHODLOAD_ATTR_CLASSLOAD_ATTR_GETATTRIBUTE_OVERRIDDENLOAD_ATTR_INSTANCE_VALUELOAD_ATTR_MODULELOAD_ATTR_PROPERTYLOAD_ATTR_SLOTLOAD_ATTR_WITH_HINTLOAD_ATTR_METHOD_LAZY_DICTLOAD_ATTR_METHOD_NO_DICTLOAD_ATTR_METHOD_WITH_VALUESLOAD_CONST__LOAD_FASTLOAD_FAST__LOAD_CONSTLOAD_FAST__LOAD_FASTLOAD_GLOBAL_BUILTINLOAD_GLOBAL_MODULESTORE_ATTR_INSTANCE_VALUESTORE_ATTR_SLOTSTORE_ATTR_WITH_HINTSTORE_FAST__LOAD_FASTSTORE_FAST__STORE_FASTSTORE_SUBSCR_DICTSTORE_SUBSCR_LIST_INTUNPACK_SEQUENCE_LISTUNPACK_SEQUENCE_TUPLEUNPACK_SEQUENCE_TWO_TUPLESEND_GENcountermodule_keys_versionbuiltin_keys_versionkeys_versionfunc_version# It's a chicken-and-egg I'm afraid:# We're imported before _opcode's made.# With exception unheeded# (stack_effect is not needed)# Both our chickens and eggs are allayed.#     --Larry Hastings, 2013/11/23## pseudo opcodes (used in the compiler) mapped to the values##they can become in the actual code.# add the pseudo opcode to the lists its targets are in# Instruction opcodes for compiled code# Blank lines correspond to available opcodes# We reserve 17 as it is the initial value for the specializing counter# This helps us catch cases where we attempt to execute a cache.# real opcodes from here have an argument:# Index in name list# ""# Number of tuple items# Index in const list# Number of list items# Number of set items# Number of dict entries# Comparison operator# Number of words to skip# Local variable number, no null check# Local variable number# Number of raise arguments (1, 2, or 3)# Flags# Number of items# Number of words to skip (backwards)# This must be kept in sync with deepfreeze.py# Instrumented instructions# 255 is reserved# These potentially push [NULL, bound method] onto the stack.# These will always push [unbound method, self] onto the stack.b'
opcode module - potentially shared between dis and other modules which
operate on bytecodes (e.g. peephole optimizers).
'u'
opcode module - potentially shared between dis and other modules which
operate on bytecodes (e.g. peephole optimizers).
'b'cmp_op'u'cmp_op'b'hasarg'u'hasarg'b'hasconst'u'hasconst'b'hasname'u'hasname'b'hasjrel'u'hasjrel'b'hasjabs'u'hasjabs'b'haslocal'u'haslocal'b'hascompare'u'hascompare'b'hasfree'u'hasfree'b'hasexc'u'hasexc'b'opmap'u'opmap'b'HAVE_ARGUMENT'u'HAVE_ARGUMENT'b'EXTENDED_ARG'u'EXTENDED_ARG'b'stack_effect'u'stack_effect'b'POP_TOP'u'POP_TOP'b'PUSH_NULL'u'PUSH_NULL'b'INTERPRETER_EXIT'u'INTERPRETER_EXIT'b'END_FOR'u'END_FOR'b'END_SEND'u'END_SEND'b'NOP'u'NOP'b'UNARY_NEGATIVE'u'UNARY_NEGATIVE'b'UNARY_NOT'u'UNARY_NOT'b'UNARY_INVERT'u'UNARY_INVERT'b'RESERVED'u'RESERVED'b'BINARY_SUBSCR'u'BINARY_SUBSCR'b'BINARY_SLICE'u'BINARY_SLICE'b'STORE_SLICE'u'STORE_SLICE'b'GET_LEN'u'GET_LEN'b'MATCH_MAPPING'u'MATCH_MAPPING'b'MATCH_SEQUENCE'u'MATCH_SEQUENCE'b'MATCH_KEYS'u'MATCH_KEYS'b'PUSH_EXC_INFO'u'PUSH_EXC_INFO'b'CHECK_EXC_MATCH'u'CHECK_EXC_MATCH'b'CHECK_EG_MATCH'u'CHECK_EG_MATCH'b'WITH_EXCEPT_START'u'WITH_EXCEPT_START'b'GET_AITER'u'GET_AITER'b'GET_ANEXT'u'GET_ANEXT'b'BEFORE_ASYNC_WITH'u'BEFORE_ASYNC_WITH'b'BEFORE_WITH'u'BEFORE_WITH'b'END_ASYNC_FOR'u'END_ASYNC_FOR'b'CLEANUP_THROW'u'CLEANUP_THROW'b'STORE_SUBSCR'u'STORE_SUBSCR'b'DELETE_SUBSCR'u'DELETE_SUBSCR'b'GET_ITER'u'GET_ITER'b'GET_YIELD_FROM_ITER'u'GET_YIELD_FROM_ITER'b'LOAD_BUILD_CLASS'u'LOAD_BUILD_CLASS'b'LOAD_ASSERTION_ERROR'u'LOAD_ASSERTION_ERROR'b'RETURN_GENERATOR'u'RETURN_GENERATOR'b'RETURN_VALUE'u'RETURN_VALUE'b'SETUP_ANNOTATIONS'u'SETUP_ANNOTATIONS'b'LOAD_LOCALS'u'LOAD_LOCALS'b'POP_EXCEPT'u'POP_EXCEPT'b'DELETE_NAME'u'DELETE_NAME'b'UNPACK_SEQUENCE'u'UNPACK_SEQUENCE'b'UNPACK_EX'u'UNPACK_EX'b'STORE_ATTR'u'STORE_ATTR'b'DELETE_ATTR'u'DELETE_ATTR'b'DELETE_GLOBAL'u'DELETE_GLOBAL'b'SWAP'u'SWAP'b'LOAD_NAME'u'LOAD_NAME'b'BUILD_TUPLE'u'BUILD_TUPLE'b'BUILD_LIST'u'BUILD_LIST'b'BUILD_SET'u'BUILD_SET'b'BUILD_MAP'u'BUILD_MAP'b'COMPARE_OP'u'COMPARE_OP'b'IMPORT_FROM'u'IMPORT_FROM'b'JUMP_FORWARD'u'JUMP_FORWARD'b'POP_JUMP_IF_FALSE'u'POP_JUMP_IF_FALSE'b'POP_JUMP_IF_TRUE'u'POP_JUMP_IF_TRUE'b'IS_OP'u'IS_OP'b'CONTAINS_OP'u'CONTAINS_OP'b'RERAISE'u'RERAISE'b'LOAD_FAST'u'LOAD_FAST'b'STORE_FAST'u'STORE_FAST'b'DELETE_FAST'u'DELETE_FAST'b'LOAD_FAST_CHECK'u'LOAD_FAST_CHECK'b'POP_JUMP_IF_NOT_NONE'u'POP_JUMP_IF_NOT_NONE'b'POP_JUMP_IF_NONE'u'POP_JUMP_IF_NONE'b'RAISE_VARARGS'u'RAISE_VARARGS'b'GET_AWAITABLE'u'GET_AWAITABLE'b'BUILD_SLICE'u'BUILD_SLICE'b'JUMP_BACKWARD_NO_INTERRUPT'u'JUMP_BACKWARD_NO_INTERRUPT'b'MAKE_CELL'u'MAKE_CELL'b'LOAD_CLOSURE'u'LOAD_CLOSURE'b'LOAD_DEREF'u'LOAD_DEREF'b'STORE_DEREF'u'STORE_DEREF'b'DELETE_DEREF'u'DELETE_DEREF'b'CALL_FUNCTION_EX'u'CALL_FUNCTION_EX'b'LOAD_FAST_AND_CLEAR'u'LOAD_FAST_AND_CLEAR'b'LIST_APPEND'u'LIST_APPEND'b'SET_ADD'u'SET_ADD'b'MAP_ADD'u'MAP_ADD'b'COPY_FREE_VARS'u'COPY_FREE_VARS'b'YIELD_VALUE'u'YIELD_VALUE'b'RESUME'u'RESUME'b'MATCH_CLASS'u'MATCH_CLASS'b'BUILD_CONST_KEY_MAP'u'BUILD_CONST_KEY_MAP'b'BUILD_STRING'u'BUILD_STRING'b'LIST_EXTEND'u'LIST_EXTEND'b'SET_UPDATE'u'SET_UPDATE'b'DICT_MERGE'u'DICT_MERGE'b'DICT_UPDATE'u'DICT_UPDATE'b'CALL'u'CALL'b'KW_NAMES'u'KW_NAMES'b'LOAD_FROM_DICT_OR_GLOBALS'u'LOAD_FROM_DICT_OR_GLOBALS'b'LOAD_FROM_DICT_OR_DEREF'u'LOAD_FROM_DICT_OR_DEREF'b'INSTRUMENTED_LOAD_SUPER_ATTR'u'INSTRUMENTED_LOAD_SUPER_ATTR'b'INSTRUMENTED_POP_JUMP_IF_NONE'u'INSTRUMENTED_POP_JUMP_IF_NONE'b'INSTRUMENTED_POP_JUMP_IF_NOT_NONE'u'INSTRUMENTED_POP_JUMP_IF_NOT_NONE'b'INSTRUMENTED_RESUME'u'INSTRUMENTED_RESUME'b'INSTRUMENTED_CALL'u'INSTRUMENTED_CALL'b'INSTRUMENTED_RETURN_VALUE'u'INSTRUMENTED_RETURN_VALUE'b'INSTRUMENTED_YIELD_VALUE'u'INSTRUMENTED_YIELD_VALUE'b'INSTRUMENTED_CALL_FUNCTION_EX'u'INSTRUMENTED_CALL_FUNCTION_EX'b'INSTRUMENTED_JUMP_FORWARD'u'INSTRUMENTED_JUMP_FORWARD'b'INSTRUMENTED_JUMP_BACKWARD'u'INSTRUMENTED_JUMP_BACKWARD'b'INSTRUMENTED_RETURN_CONST'u'INSTRUMENTED_RETURN_CONST'b'INSTRUMENTED_FOR_ITER'u'INSTRUMENTED_FOR_ITER'b'INSTRUMENTED_POP_JUMP_IF_FALSE'u'INSTRUMENTED_POP_JUMP_IF_FALSE'b'INSTRUMENTED_POP_JUMP_IF_TRUE'u'INSTRUMENTED_POP_JUMP_IF_TRUE'b'INSTRUMENTED_END_FOR'u'INSTRUMENTED_END_FOR'b'INSTRUMENTED_END_SEND'u'INSTRUMENTED_END_SEND'b'INSTRUMENTED_INSTRUCTION'u'INSTRUMENTED_INSTRUCTION'b'INSTRUMENTED_LINE'u'INSTRUMENTED_LINE'b'SETUP_FINALLY'u'SETUP_FINALLY'b'SETUP_CLEANUP'u'SETUP_CLEANUP'b'SETUP_WITH'u'SETUP_WITH'b'POP_BLOCK'u'POP_BLOCK'b'JUMP_NO_INTERRUPT'u'JUMP_NO_INTERRUPT'b'LOAD_METHOD'u'LOAD_METHOD'b'LOAD_SUPER_METHOD'u'LOAD_SUPER_METHOD'b'LOAD_ZERO_SUPER_METHOD'u'LOAD_ZERO_SUPER_METHOD'b'LOAD_ZERO_SUPER_ATTR'u'LOAD_ZERO_SUPER_ATTR'b'STORE_FAST_MAYBE_NULL'u'STORE_FAST_MAYBE_NULL'b'<%r>'u'<%r>'b'NB_ADD'u'NB_ADD'b'NB_AND'u'NB_AND'b'NB_FLOOR_DIVIDE'u'NB_FLOOR_DIVIDE'b'NB_LSHIFT'u'NB_LSHIFT'b'NB_MATRIX_MULTIPLY'u'NB_MATRIX_MULTIPLY'b'NB_MULTIPLY'u'NB_MULTIPLY'b'NB_REMAINDER'u'NB_REMAINDER'b'NB_OR'u'NB_OR'b'NB_POWER'u'NB_POWER'b'NB_RSHIFT'u'NB_RSHIFT'b'NB_SUBTRACT'u'NB_SUBTRACT'b'NB_TRUE_DIVIDE'u'NB_TRUE_DIVIDE'b'NB_XOR'u'NB_XOR'b'NB_INPLACE_ADD'u'NB_INPLACE_ADD'b'+='u'+='b'NB_INPLACE_AND'u'NB_INPLACE_AND'b'&='u'&='b'NB_INPLACE_FLOOR_DIVIDE'u'NB_INPLACE_FLOOR_DIVIDE'b'//='u'//='b'NB_INPLACE_LSHIFT'u'NB_INPLACE_LSHIFT'b'<<='u'<<='b'NB_INPLACE_MATRIX_MULTIPLY'u'NB_INPLACE_MATRIX_MULTIPLY'b'@='u'@='b'NB_INPLACE_MULTIPLY'u'NB_INPLACE_MULTIPLY'b'*='u'*='b'NB_INPLACE_REMAINDER'u'NB_INPLACE_REMAINDER'b'%='u'%='b'NB_INPLACE_OR'u'NB_INPLACE_OR'b'|='u'|='b'NB_INPLACE_POWER'u'NB_INPLACE_POWER'b'**='u'**='b'NB_INPLACE_RSHIFT'u'NB_INPLACE_RSHIFT'b'>>='u'>>='b'NB_INPLACE_SUBTRACT'u'NB_INPLACE_SUBTRACT'b'-='u'-='b'NB_INPLACE_TRUE_DIVIDE'u'NB_INPLACE_TRUE_DIVIDE'b'/='u'/='b'NB_INPLACE_XOR'u'NB_INPLACE_XOR'b'^='u'^='b'INTRINSIC_1_INVALID'u'INTRINSIC_1_INVALID'b'INTRINSIC_PRINT'u'INTRINSIC_PRINT'b'INTRINSIC_IMPORT_STAR'u'INTRINSIC_IMPORT_STAR'b'INTRINSIC_STOPITERATION_ERROR'u'INTRINSIC_STOPITERATION_ERROR'b'INTRINSIC_ASYNC_GEN_WRAP'u'INTRINSIC_ASYNC_GEN_WRAP'b'INTRINSIC_UNARY_POSITIVE'u'INTRINSIC_UNARY_POSITIVE'b'INTRINSIC_LIST_TO_TUPLE'u'INTRINSIC_LIST_TO_TUPLE'b'INTRINSIC_TYPEVAR'u'INTRINSIC_TYPEVAR'b'INTRINSIC_PARAMSPEC'u'INTRINSIC_PARAMSPEC'b'INTRINSIC_TYPEVARTUPLE'u'INTRINSIC_TYPEVARTUPLE'b'INTRINSIC_SUBSCRIPT_GENERIC'u'INTRINSIC_SUBSCRIPT_GENERIC'b'INTRINSIC_TYPEALIAS'u'INTRINSIC_TYPEALIAS'b'INTRINSIC_2_INVALID'u'INTRINSIC_2_INVALID'b'INTRINSIC_PREP_RERAISE_STAR'u'INTRINSIC_PREP_RERAISE_STAR'b'INTRINSIC_TYPEVAR_WITH_BOUND'u'INTRINSIC_TYPEVAR_WITH_BOUND'b'INTRINSIC_TYPEVAR_WITH_CONSTRAINTS'u'INTRINSIC_TYPEVAR_WITH_CONSTRAINTS'b'INTRINSIC_SET_FUNCTION_TYPE_PARAMS'u'INTRINSIC_SET_FUNCTION_TYPE_PARAMS'b'BINARY_OP_ADD_FLOAT'u'BINARY_OP_ADD_FLOAT'b'BINARY_OP_ADD_INT'u'BINARY_OP_ADD_INT'b'BINARY_OP_ADD_UNICODE'u'BINARY_OP_ADD_UNICODE'b'BINARY_OP_INPLACE_ADD_UNICODE'u'BINARY_OP_INPLACE_ADD_UNICODE'b'BINARY_OP_MULTIPLY_FLOAT'u'BINARY_OP_MULTIPLY_FLOAT'b'BINARY_OP_MULTIPLY_INT'u'BINARY_OP_MULTIPLY_INT'b'BINARY_OP_SUBTRACT_FLOAT'u'BINARY_OP_SUBTRACT_FLOAT'b'BINARY_OP_SUBTRACT_INT'u'BINARY_OP_SUBTRACT_INT'b'BINARY_SUBSCR_DICT'u'BINARY_SUBSCR_DICT'b'BINARY_SUBSCR_GETITEM'u'BINARY_SUBSCR_GETITEM'b'BINARY_SUBSCR_LIST_INT'u'BINARY_SUBSCR_LIST_INT'b'BINARY_SUBSCR_TUPLE_INT'u'BINARY_SUBSCR_TUPLE_INT'b'CALL_PY_EXACT_ARGS'u'CALL_PY_EXACT_ARGS'b'CALL_PY_WITH_DEFAULTS'u'CALL_PY_WITH_DEFAULTS'b'CALL_BOUND_METHOD_EXACT_ARGS'u'CALL_BOUND_METHOD_EXACT_ARGS'b'CALL_BUILTIN_CLASS'u'CALL_BUILTIN_CLASS'b'CALL_BUILTIN_FAST_WITH_KEYWORDS'u'CALL_BUILTIN_FAST_WITH_KEYWORDS'b'CALL_METHOD_DESCRIPTOR_FAST_WITH_KEYWORDS'u'CALL_METHOD_DESCRIPTOR_FAST_WITH_KEYWORDS'b'CALL_NO_KW_BUILTIN_FAST'u'CALL_NO_KW_BUILTIN_FAST'b'CALL_NO_KW_BUILTIN_O'u'CALL_NO_KW_BUILTIN_O'b'CALL_NO_KW_ISINSTANCE'u'CALL_NO_KW_ISINSTANCE'b'CALL_NO_KW_LEN'u'CALL_NO_KW_LEN'b'CALL_NO_KW_LIST_APPEND'u'CALL_NO_KW_LIST_APPEND'b'CALL_NO_KW_METHOD_DESCRIPTOR_FAST'u'CALL_NO_KW_METHOD_DESCRIPTOR_FAST'b'CALL_NO_KW_METHOD_DESCRIPTOR_NOARGS'u'CALL_NO_KW_METHOD_DESCRIPTOR_NOARGS'b'CALL_NO_KW_METHOD_DESCRIPTOR_O'u'CALL_NO_KW_METHOD_DESCRIPTOR_O'b'CALL_NO_KW_STR_1'u'CALL_NO_KW_STR_1'b'CALL_NO_KW_TUPLE_1'u'CALL_NO_KW_TUPLE_1'b'CALL_NO_KW_TYPE_1'u'CALL_NO_KW_TYPE_1'b'COMPARE_OP_FLOAT'u'COMPARE_OP_FLOAT'b'COMPARE_OP_INT'u'COMPARE_OP_INT'b'COMPARE_OP_STR'u'COMPARE_OP_STR'b'FOR_ITER_LIST'u'FOR_ITER_LIST'b'FOR_ITER_TUPLE'u'FOR_ITER_TUPLE'b'FOR_ITER_RANGE'u'FOR_ITER_RANGE'b'FOR_ITER_GEN'u'FOR_ITER_GEN'b'LOAD_SUPER_ATTR_ATTR'u'LOAD_SUPER_ATTR_ATTR'b'LOAD_SUPER_ATTR_METHOD'u'LOAD_SUPER_ATTR_METHOD'b'LOAD_ATTR_CLASS'u'LOAD_ATTR_CLASS'b'LOAD_ATTR_GETATTRIBUTE_OVERRIDDEN'u'LOAD_ATTR_GETATTRIBUTE_OVERRIDDEN'b'LOAD_ATTR_INSTANCE_VALUE'u'LOAD_ATTR_INSTANCE_VALUE'b'LOAD_ATTR_MODULE'u'LOAD_ATTR_MODULE'b'LOAD_ATTR_PROPERTY'u'LOAD_ATTR_PROPERTY'b'LOAD_ATTR_SLOT'u'LOAD_ATTR_SLOT'b'LOAD_ATTR_WITH_HINT'u'LOAD_ATTR_WITH_HINT'b'LOAD_ATTR_METHOD_LAZY_DICT'u'LOAD_ATTR_METHOD_LAZY_DICT'b'LOAD_ATTR_METHOD_NO_DICT'u'LOAD_ATTR_METHOD_NO_DICT'b'LOAD_ATTR_METHOD_WITH_VALUES'u'LOAD_ATTR_METHOD_WITH_VALUES'b'LOAD_CONST__LOAD_FAST'u'LOAD_CONST__LOAD_FAST'b'LOAD_FAST__LOAD_CONST'u'LOAD_FAST__LOAD_CONST'b'LOAD_FAST__LOAD_FAST'u'LOAD_FAST__LOAD_FAST'b'LOAD_GLOBAL_BUILTIN'u'LOAD_GLOBAL_BUILTIN'b'LOAD_GLOBAL_MODULE'u'LOAD_GLOBAL_MODULE'b'STORE_ATTR_INSTANCE_VALUE'u'STORE_ATTR_INSTANCE_VALUE'b'STORE_ATTR_SLOT'u'STORE_ATTR_SLOT'b'STORE_ATTR_WITH_HINT'u'STORE_ATTR_WITH_HINT'b'STORE_FAST__LOAD_FAST'u'STORE_FAST__LOAD_FAST'b'STORE_FAST__STORE_FAST'u'STORE_FAST__STORE_FAST'b'STORE_SUBSCR_DICT'u'STORE_SUBSCR_DICT'b'STORE_SUBSCR_LIST_INT'u'STORE_SUBSCR_LIST_INT'b'UNPACK_SEQUENCE_LIST'u'UNPACK_SEQUENCE_LIST'b'UNPACK_SEQUENCE_TUPLE'u'UNPACK_SEQUENCE_TUPLE'b'UNPACK_SEQUENCE_TWO_TUPLE'u'UNPACK_SEQUENCE_TWO_TUPLE'b'SEND_GEN'u'SEND_GEN'b'counter'u'counter'b'index'u'index'b'module_keys_version'u'module_keys_version'b'builtin_keys_version'u'builtin_keys_version'b'keys_version'u'keys_version'b'descr'u'descr'b'func_version'u'func_version'u'Lib.opcode'
Operator Interface

This module exports a set of functions corresponding to the intrinsic
operators of Python.  For example, operator.add(x, y) is equivalent
to the expression x+y.  The function names are those used for special
methods; variants without leading and trailing '__' are also provided
for convenience.

This is the pure Python implementation of the module.
_absSame as a < b.Same as a <= b.Same as a == b.Same as a != b.Same as a >= b.Same as a > b.Same as not a.Return True if a is true, False otherwise.Same as a is b.Same as a is not b.Same as abs(a).Same as a + b.Same as a & b.Same as a // b.Same as a.__index__().Same as ~a.Same as a << b.Same as a % b.Same as a * b.Same as a @ b.Same as -a.Same as a | b.Same as +a.Same as a ** b.Same as a >> b.Same as a - b.Same as a / b.Same as a ^ b.Same as a + b, for a and b sequences.'%s' object can't be concatenatedSame as b in a (note reversed operands).Return the number of items in a which are, or which equal, b.Same as del a[b].Same as a[b].Return the first index of b in a.sequence.index(x): x not in sequenceSame as a[b] = c.
    Return an estimate of the number of items in obj.
    This is useful for presizing containers when building from an iterable.

    If the object supports len(), the result will be exact. Otherwise, it may
    over- or under-estimate by an arbitrary amount. The result will be an
    integer >= 0.
    '%s' object cannot be interpreted as an integerhint__length_hint__ must be integer, not %s__length_hint__() should return >= 0Same as obj(*args, **kwargs).
    Return a callable object that fetches the given attribute(s) from its operand.
    After f = attrgetter('name'), the call f(r) returns r.name.
    After g = attrgetter('name', 'date'), the call g(r) returns (r.name, r.date).
    After h = attrgetter('name.first', 'name.last'), the call h(r) returns
    (r.name.first, r.name.last).
    _attrsattribute name must be a stringgetters
    Return a callable object that fetches the given item(s) from its operand.
    After f = itemgetter(2), the call f(r) returns r[2].
    After g = itemgetter(2, 5, 3), the call g(r) returns (r[2], r[5], r[3])
    _items
    Return a callable object that calls the given method on its operand.
    After f = methodcaller('name'), the call f(r) returns r.name().
    After g = methodcaller('name', 'date', foo=1), the call g(r) returns
    r.name('date', foo=1).
    _kwargsmethod name must be a stringSame as a += b.Same as a &= b.Same as a += b, for a and b sequences.Same as a //= b.Same as a <<= b.Same as a %= b.Same as a *= b.Same as a @= b.Same as a |= b.Same as a **= b.Same as a >>= b.Same as a -= b.Same as a /= b.Same as a ^= b.__not____inv____concat____iconcat__# Comparison Operations *******************************************************## Logical Operations **********************************************************## Mathematical/Bitwise Operations *********************************************## Sequence Operations *********************************************************## Other Operations ************************************************************## Generalized Lookup Objects **************************************************## In-place Operations *********************************************************## All of these "__func__ = func" assignments have to happen after importing# from _operator to make sure they're set to the right functionb'
Operator Interface

This module exports a set of functions corresponding to the intrinsic
operators of Python.  For example, operator.add(x, y) is equivalent
to the expression x+y.  The function names are those used for special
methods; variants without leading and trailing '__' are also provided
for convenience.

This is the pure Python implementation of the module.
'u'
Operator Interface

This module exports a set of functions corresponding to the intrinsic
operators of Python.  For example, operator.add(x, y) is equivalent
to the expression x+y.  The function names are those used for special
methods; variants without leading and trailing '__' are also provided
for convenience.

This is the pure Python implementation of the module.
'b'abs'u'abs'b'add'u'add'b'and_'u'and_'b'attrgetter'u'attrgetter'b'concat'u'concat'b'contains'u'contains'b'countOf'u'countOf'b'delitem'u'delitem'b'floordiv'u'floordiv'b'getitem'u'getitem'b'iadd'u'iadd'b'iand'u'iand'b'iconcat'u'iconcat'b'ifloordiv'u'ifloordiv'b'ilshift'u'ilshift'b'imatmul'u'imatmul'b'imod'u'imod'b'imul'u'imul'b'indexOf'u'indexOf'b'inv'u'inv'b'invert'u'invert'b'ior'u'ior'b'ipow'u'ipow'b'irshift'u'irshift'b'is_'u'is_'b'is_not'u'is_not'b'isub'u'isub'b'itemgetter'u'itemgetter'b'itruediv'u'itruediv'b'ixor'u'ixor'b'length_hint'u'length_hint'b'lshift'u'lshift'b'matmul'u'matmul'b'methodcaller'u'methodcaller'b'mod'u'mod'b'mul'u'mul'b'neg'u'neg'b'not_'u'not_'b'or_'u'or_'b'pos'u'pos'b'pow'u'pow'b'rshift'u'rshift'b'setitem'u'setitem'b'truediv'u'truediv'b'truth'u'truth'b'xor'u'xor'b'Same as a < b.'u'Same as a < b.'b'Same as a <= b.'u'Same as a <= b.'b'Same as a == b.'u'Same as a == b.'b'Same as a != b.'u'Same as a != b.'b'Same as a >= b.'u'Same as a >= b.'b'Same as a > b.'u'Same as a > b.'b'Same as not a.'u'Same as not a.'b'Return True if a is true, False otherwise.'u'Return True if a is true, False otherwise.'b'Same as a is b.'u'Same as a is b.'b'Same as a is not b.'u'Same as a is not b.'b'Same as abs(a).'u'Same as abs(a).'b'Same as a + b.'u'Same as a + b.'b'Same as a & b.'u'Same as a & b.'b'Same as a // b.'u'Same as a // b.'b'Same as a.__index__().'u'Same as a.__index__().'b'Same as ~a.'u'Same as ~a.'b'Same as a << b.'u'Same as a << b.'b'Same as a % b.'u'Same as a % b.'b'Same as a * b.'u'Same as a * b.'b'Same as a @ b.'u'Same as a @ b.'b'Same as -a.'u'Same as -a.'b'Same as a | b.'u'Same as a | b.'b'Same as +a.'u'Same as +a.'b'Same as a ** b.'u'Same as a ** b.'b'Same as a >> b.'u'Same as a >> b.'b'Same as a - b.'u'Same as a - b.'b'Same as a / b.'u'Same as a / b.'b'Same as a ^ b.'u'Same as a ^ b.'b'Same as a + b, for a and b sequences.'u'Same as a + b, for a and b sequences.'b''%s' object can't be concatenated'u''%s' object can't be concatenated'b'Same as b in a (note reversed operands).'u'Same as b in a (note reversed operands).'b'Return the number of items in a which are, or which equal, b.'u'Return the number of items in a which are, or which equal, b.'b'Same as del a[b].'u'Same as del a[b].'b'Same as a[b].'u'Same as a[b].'b'Return the first index of b in a.'u'Return the first index of b in a.'b'sequence.index(x): x not in sequence'u'sequence.index(x): x not in sequence'b'Same as a[b] = c.'u'Same as a[b] = c.'b'
    Return an estimate of the number of items in obj.
    This is useful for presizing containers when building from an iterable.

    If the object supports len(), the result will be exact. Otherwise, it may
    over- or under-estimate by an arbitrary amount. The result will be an
    integer >= 0.
    'u'
    Return an estimate of the number of items in obj.
    This is useful for presizing containers when building from an iterable.

    If the object supports len(), the result will be exact. Otherwise, it may
    over- or under-estimate by an arbitrary amount. The result will be an
    integer >= 0.
    'b''%s' object cannot be interpreted as an integer'u''%s' object cannot be interpreted as an integer'b'__length_hint__ must be integer, not %s'u'__length_hint__ must be integer, not %s'b'__length_hint__() should return >= 0'u'__length_hint__() should return >= 0'b'Same as obj(*args, **kwargs).'u'Same as obj(*args, **kwargs).'b'
    Return a callable object that fetches the given attribute(s) from its operand.
    After f = attrgetter('name'), the call f(r) returns r.name.
    After g = attrgetter('name', 'date'), the call g(r) returns (r.name, r.date).
    After h = attrgetter('name.first', 'name.last'), the call h(r) returns
    (r.name.first, r.name.last).
    'u'
    Return a callable object that fetches the given attribute(s) from its operand.
    After f = attrgetter('name'), the call f(r) returns r.name.
    After g = attrgetter('name', 'date'), the call g(r) returns (r.name, r.date).
    After h = attrgetter('name.first', 'name.last'), the call h(r) returns
    (r.name.first, r.name.last).
    'b'_attrs'u'_attrs'b'_call'u'_call'b'attribute name must be a string'u'attribute name must be a string'b'
    Return a callable object that fetches the given item(s) from its operand.
    After f = itemgetter(2), the call f(r) returns r[2].
    After g = itemgetter(2, 5, 3), the call g(r) returns (r[2], r[5], r[3])
    'u'
    Return a callable object that fetches the given item(s) from its operand.
    After f = itemgetter(2), the call f(r) returns r[2].
    After g = itemgetter(2, 5, 3), the call g(r) returns (r[2], r[5], r[3])
    'b'_items'u'_items'b'
    Return a callable object that calls the given method on its operand.
    After f = methodcaller('name'), the call f(r) returns r.name().
    After g = methodcaller('name', 'date', foo=1), the call g(r) returns
    r.name('date', foo=1).
    'u'
    Return a callable object that calls the given method on its operand.
    After f = methodcaller('name'), the call f(r) returns r.name().
    After g = methodcaller('name', 'date', foo=1), the call g(r) returns
    r.name('date', foo=1).
    'b'_kwargs'u'_kwargs'b'method name must be a string'u'method name must be a string'b'Same as a += b.'u'Same as a += b.'b'Same as a &= b.'u'Same as a &= b.'b'Same as a += b, for a and b sequences.'u'Same as a += b, for a and b sequences.'b'Same as a //= b.'u'Same as a //= b.'b'Same as a <<= b.'u'Same as a <<= b.'b'Same as a %= b.'u'Same as a %= b.'b'Same as a *= b.'u'Same as a *= b.'b'Same as a @= b.'u'Same as a @= b.'b'Same as a |= b.'u'Same as a |= b.'b'Same as a **= b.'u'Same as a **= b.'b'Same as a >>= b.'u'Same as a >>= b.'b'Same as a -= b.'u'Same as a -= b.'b'Same as a /= b.'u'Same as a /= b.'b'Same as a ^= b.'u'Same as a ^= b.'u'Lib.operator'OS routines for NT or Posix depending on what system we're on.

This exports:
  - all functions from posix or nt, e.g. unlink, stat, etc.
  - os.path is either posixpath or ntpath
  - os.name is either 'posix' or 'nt'
  - os.curdir is a string representing the current directory (always '.')
  - os.pardir is a string representing the parent directory (always '..')
  - os.sep is the (or a most common) pathname separator ('/' or '\\')
  - os.extsep is the extension separator (always '.')
  - os.altsep is the alternate pathname separator (None or '/')
  - os.pathsep is the component separator used in $PATH etc
  - os.linesep is the line separator in text files ('\r' or '\n' or '\r\n')
  - os.defpath is the default search path for executables
  - os.devnull is the file path of the null device ('/dev/null', etc.)

Programs that import and use 'os' stand a better chance of being
portable between different platforms.  Of course, they must then
only use functions that are defined by all platforms (e.g., unlink
and opendir), and leave all pathname manipulation to os.path
(e.g., split and join).
_namesget_exec_pathfdopen_exists_get_exports_listntpathno os specific module foundos.path_globalsHAVE_FACCESSATHAVE_FCHMODATHAVE_FCHOWNATchownHAVE_FSTATATHAVE_FUTIMESATHAVE_LINKATHAVE_MKDIRATHAVE_MKFIFOATmkfifoHAVE_MKNODATmknodHAVE_OPENATHAVE_READLINKATHAVE_RENAMEATHAVE_SYMLINKATHAVE_UNLINKATHAVE_UTIMENSATsupports_dir_fdsupports_effective_idsHAVE_FCHDIRHAVE_FCHMODHAVE_FCHOWNHAVE_FDOPENDIRHAVE_FEXECVEHAVE_FTRUNCATEHAVE_FUTIMENSHAVE_FUTIMESHAVE_FPATHCONFpathconfstatvfsfstatvfsHAVE_FSTATVFSsupports_fdHAVE_LCHFLAGSchflagsHAVE_LCHMODlchownHAVE_LCHOWNHAVE_LUTIMESHAVE_LSTATMS_WINDOWSsupports_follow_symlinks0o777exist_okmakedirs(name [, mode=0o777][, exist_ok=False])

    Super-mkdir; create a leaf directory and all intermediate ones.  Works like
    mkdir, except that any intermediate path segment (not just the rightmost)
    will be created if it does not exist. If the target directory already
    exists, raise an OSError if exist_ok is False. Otherwise no exception is
    raised.  This is recursive.

    cdirremovedirsremovedirs(name)

    Super-rmdir; remove a leaf directory and all empty intermediate
    ones.  Works like rmdir except that, if the leaf directory is
    successfully removed, directories corresponding to rightmost path
    segments will be pruned away until either the whole path is
    consumed or an error occurs.  Errors during this latter phase are
    ignored -- they generally mean that a directory was not empty.

    renamesrenames(old, new)

    Super-rename; create directories as necessary and delete any left
    empty.  Works like rename, except creation of any intermediate
    directories needed to make the new pathname good is attempted
    first.  After the rename, directories corresponding to rightmost
    path segments of the old name will be pruned until either the
    whole path is consumed or a nonempty directory is found.

    Note: this function can fail with the new directory structure made
    if you lack permissions needed to unlink the leaf directory or
    file.

    _walk_symlinks_as_filestopdownonerrorfollowlinksDirectory tree generator.

    For each directory in the directory tree rooted at top (including top
    itself, but excluding '.' and '..'), yields a 3-tuple

        dirpath, dirnames, filenames

    dirpath is a string, the path to the directory.  dirnames is a list of
    the names of the subdirectories in dirpath (including symlinks to directories,
    and excluding '.' and '..').
    filenames is a list of the names of the non-directory files in dirpath.
    Note that the names in the lists are just names, with no path components.
    To get a full path (which begins with top) to a file or directory in
    dirpath, do os.path.join(dirpath, name).

    If optional arg 'topdown' is true or not specified, the triple for a
    directory is generated before the triples for any of its subdirectories
    (directories are generated top down).  If topdown is false, the triple
    for a directory is generated after the triples for all of its
    subdirectories (directories are generated bottom up).

    When topdown is true, the caller can modify the dirnames list in-place
    (e.g., via del or slice assignment), and walk will only recurse into the
    subdirectories whose names remain in dirnames; this can be used to prune the
    search, or to impose a specific order of visiting.  Modifying dirnames when
    topdown is false has no effect on the behavior of os.walk(), since the
    directories in dirnames have already been generated by the time dirnames
    itself is generated. No matter the value of topdown, the list of
    subdirectories is retrieved before the tuples for the directory and its
    subdirectories are generated.

    By default errors from the os.scandir() call are ignored.  If
    optional arg 'onerror' is specified, it should be a function; it
    will be called with one argument, an OSError instance.  It can
    report the error to continue with the walk, or raise the exception
    to abort the walk.  Note that the filename is available as the
    filename attribute of the exception object.

    By default, os.walk does not follow symbolic links to subdirectories on
    systems that support them.  In order to get this functionality, set the
    optional argument 'followlinks' to true.

    Caution:  if you pass a relative pathname for top, don't change the
    current working directory between resumptions of walk.  walk never
    changes the current directory, and assumes that the client doesn't
    either.

    Example:

    import os
    from os.path import join, getsize
    for root, dirs, files in os.walk('python/Lib/email'):
        print(root, "consumes ")
        print(sum(getsize(join(root, name)) for name in files), end=" ")
        print("bytes in", len(files), "non-directory files")
        if 'CVS' in dirs:
            dirs.remove('CVS')  # don't visit CVS directories

    os.walknondirswalk_dirsscandir_itcontfollow_symlinkswalk_intofwalkDirectory tree generator.

        This behaves exactly like walk(), except that it yields a 4-tuple

            dirpath, dirnames, filenames, dirfd

        `dirpath`, `dirnames` and `filenames` are identical to walk() output,
        and `dirfd` is a file descriptor referring to the directory `dirpath`.

        The advantage of fwalk() over walk() is that it's safe against symlink
        races (when follow_symlinks is False).

        If dir_fd is not None, it should be a file descriptor open to a directory,
          and top should be relative; top will then be relative to that directory.
          (dir_fd is always supported for fwalk.)

        Caution:
        Since fwalk() yields file descriptors, those are only valid until the
        next iteration step, so you should dup() them if you want to keep them
        for a longer period.

        Example:

        import os
        for root, dirs, files, rootfd in os.fwalk('python/Lib/email'):
            print(root, "consumes", end="")
            print(sum(os.stat(name, dir_fd=rootfd).st_size for name in files),
                  end="")
            print("bytes in", len(files), "non-directory files")
            if 'CVS' in dirs:
                dirs.remove('CVS')  # don't visit CVS directories
        os.fwalk_fwalk_walkisbytes_fwalk_fwalk_close_fwalk_yieldisrootdirfdtoppathtopnameorig_stO_NONBLOCKtopfdexeclexecl(file, *args)

    Execute the executable file with argument list args, replacing the
    current process. execleexecle(file, *args, env)

    Execute the executable file with argument list args and
    environment env, replacing the current process. envexeclpexeclp(file, *args)

    Execute the executable file (which is searched for along $PATH)
    with argument list args, replacing the current process. execvpexeclpeexeclpe(file, *args, env)

    Execute the executable file (which is searched for along $PATH)
    with argument list args and environment env, replacing the current
    process. execvpeexecvp(file, args)

    Execute the executable file (which is searched for along $PATH)
    with argument list args, replacing the current process.
    args may be a list or tuple of strings. _execvpeexecvpe(file, args, env)

    Execute the executable file (which is searched for along $PATH)
    with argument list args and environment env, replacing the
    current process.
    args may be a list or tuple of strings. exec_funcargrestsaved_excReturns the sequence of directories that will be searched for the
    named executable (similar to a shell) when launching a process.

    *env* must be an environment variable dict or None.  If *env* is None,
    os.environ will be used.
    supports_bytes_environpath_listbenv cannot contain 'PATH' and b'PATH' keys_Environencodekeydecodekeyencodevaluedecodevalueencodedkeyformatted_itemsenviron({{}})_createenvironcheck_strstr expected, not %sgetenvGet an environment variable, return None if it doesn't exist.
    The optional second argument can specify an alternate default.
    key, default and the result are str._check_bytesbytes expected, not %sgetenvbGet an environment variable, return None if it doesn't exist.
        The optional second argument can specify an alternate default.
        key, default and the result are bytes._fscodecEncode filename (an os.PathLike, bytes, or str) to the filesystem
        encoding with 'surrogateescape' error handler, return bytes unchanged.
        On Windows, use 'strict' error handler if the file system encoding is
        'mbcs' (which is the default encoding).
        Decode filename (an os.PathLike, bytes, or str) from the filesystem
        encoding with 'surrogateescape' error handler, return str unchanged. On
        Windows, use 'strict' error handler if the file system encoding is
        'mbcs' (which is the default encoding).
        _spawnvefargv must be a tuple or a listargv first element cannot be emptywpidWIFSTOPPEDspawnv(mode, file, args) -> integer

Execute file with arguments from args in a subprocess.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. spawnve(mode, file, args, env) -> integer

Execute file with arguments from args in a subprocess with the
specified environment.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. spawnvpspawnvp(mode, file, args) -> integer

Execute file (which is looked for along $PATH) with arguments from
args in a subprocess.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. spawnvpespawnvpe(mode, file, args, env) -> integer

Execute file (which is looked for along $PATH) with arguments from
args in a subprocess with the supplied environment.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. spawnlspawnl(mode, file, *args) -> integer

Execute file with arguments from args in a subprocess.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. spawnlespawnle(mode, file, *args, env) -> integer

Execute file with arguments from args in a subprocess with the
supplied environment.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. spawnlpspawnlp(mode, file, *args) -> integer

Execute file (which is looked for along $PATH) with arguments from
args in a subprocess with the supplied environment.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. spawnlpespawnlpe(mode, file, *args, env) -> integer

Execute file (which is looked for along $PATH) with arguments from
args in a subprocess with the supplied environment.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. vxworksinvalid cmd type (%s, expected string)invalid mode %rpopen() does not support unbuffered streams_wrap_closeinvalid fd type (%s, expected integer)_fspathReturn the path representation of a path-like object.

    If str or bytes is passed in, it is returned unchanged. Otherwise the
    os.PathLike interface is used to get the path representation. If the
    path representation is not str or bytes, TypeError is raised. If the
    provided path is not str, bytes, or os.PathLike, TypeError is raised.
    path_typepath_reprexpected str, bytes or os.PathLike object, not "expected str, bytes or os.PathLike object, "expected {}.__fspath__() to return str or bytes, not {}"expected {}.__fspath__() to return str or bytes, ""not {}"Abstract base class for implementing the file system path protocol.Return the file system path representation of the object._AddedDllDirectorycookieremove_dll_directory_cookie<AddedDllDirectory({!r})><AddedDllDirectory()>add_dll_directoryAdd a path to the DLL search path.

        This search path is used when resolving dependencies for imported
        extension modules (the module itself is resolved through sys.path),
        and also by ctypes.

        Remove the directory by calling close() on the returned object or
        using it in a with statement.
        #'# Note:  more names are added to __all__ later.# Any new dependencies of the os module and/or changes in path separator# requires updating importlib as well.# fstat always works# mac os x10.3# Some platforms don't support lchmod().  Often the function exists# anyway, as a stub that always returns ENOSUP or perhaps EOPNOTSUPP.# (No, I don't know why that's a good design.)  ./configure will detect# this and reject it--so HAVE_LCHMOD still won't be defined on such# platforms.  This is Very Helpful.# However, sometimes platforms without a working lchmod() *do* have# fchmodat().  (Examples: Linux kernel 3.2 with glibc 2.15,# OpenIndiana 3.x.)  And fchmodat() has a flag that theoretically makes# it behave like lchmod().  So in theory it would be a suitable# replacement for lchmod().  But when lchmod() doesn't work, fchmodat()'s# flag doesn't work *either*.  Sadly ./configure isn't sophisticated# enough to detect this condition--it only determines whether or not# fchmodat() minimally works.# Therefore we simply ignore fchmodat() when deciding whether or not# os.chmod supports follow_symlinks.  Just checking lchmod() is# sufficient.  After all--if you have a working fchmodat(), your# lchmod() almost certainly works too.# _add("HAVE_FCHMODAT",   "chmod")# Python uses fixed values for the SEEK_ constants; they are mapped# to native constants if necessary in posixmodule.c# Other possible SEEK values are directly imported from posixmodule.c# Super directory utilities.# (Inspired by Eric Raymond; the doc strings are mostly his)# Defeats race condition when another thread created the path# xxx/newdir/. exists if xxx/newdir exists# Cannot rely on checking for EEXIST, since the operating system# could give priority to other errors like EACCES or EROFS# Private sentinel that makes walk() classify all symlinks and junctions as# regular files.# We may not have read permission for top, in which case we can't# get a list of the files the directory contains.# We suppress the exception here, rather than blow up for a# minor reason when (say) a thousand readable directories are still# left to visit.# If is_dir() raises an OSError, consider the entry not to# be a directory, same behaviour as os.path.isdir().# Bottom-up: traverse into sub-directory, but exclude# symlinks to directories if followlinks is False# If is_symlink() raises an OSError, consider the# entry not to be a symbolic link, same behaviour# as os.path.islink().# Yield before sub-directory traversal if going top down# Traverse into sub-directories# bpo-23605: os.path.islink() is used instead of caching# entry.is_symlink() result during the loop on os.scandir() because# the caller can replace the directory entry during the "yield"# Yield after sub-directory traversal if going bottom up# Close any file descriptors still on the stack.# Each item in the _fwalk() stack is a pair (action, args).# args: (isroot, dirfd, toppath, topname, entry)# args: (toppath, dirnames, filenames, topfd)# args: dirfd# Note: This uses O(depth of the directory tree) file descriptors: if# necessary, it can be adapted to only require O(1) FDs, see issue# #13734.# Note: To guard against symlink races, we use the standard# lstat()/open()/fstat() trick.# Add dangling symlinks, ignore disappeared files# Add trailing slash.# Use a local import instead of a global import to limit the number of# modules loaded at startup: the os module is always loaded at startup by# Python. It may also avoid a bootstrap issue.# {b'PATH': ...}.get('PATH') and {'PATH': ...}.get(b'PATH') emit a# BytesWarning when using python -b or python -bb: ignore the warning# Change environ to automatically call putenv() and unsetenv()# raise KeyError with the original key value# list() from dict object is an atomic operation# Where Env Var Names Must Be UPPERCASE# Where Env Var Names Can Be Mixed Case# unicode environ# bytes environ# Does type-checking of `filename`.# Supply spawn*() (probably only for Unix)# XXX Should we support P_DETACH?  I suppose it could fork()**2# and close the std I/O streams.  Also, P_OVERLAY is the same# as execv*()?# Internal helper; func is the exec*() function to use# Parent# Caller is responsible for waiting!# Note: spawnvp[e] isn't currently supported on Windows# These aren't supplied by the basic Windows code# but can be easily implemented in Python# At the moment, Windows doesn't implement spawnvp[e],# so it won't have spawnlp[e] either.# VxWorks has no user space shell provided. As a result, running# command in a shell can't be supported.# Supply os.popen()# Helper for popen() -- a proxy for a file whose close waits for the process# Shift left to match old behavior# Supply os.fdopen()# For testing purposes, make sure the function is available when the C# implementation exists.# Work from the object's type to match method resolution of other magic# methods.# If there is no C implementation, make the pure Python version the# implementation as transparently as possible.b'OS routines for NT or Posix depending on what system we're on.

This exports:
  - all functions from posix or nt, e.g. unlink, stat, etc.
  - os.path is either posixpath or ntpath
  - os.name is either 'posix' or 'nt'
  - os.curdir is a string representing the current directory (always '.')
  - os.pardir is a string representing the parent directory (always '..')
  - os.sep is the (or a most common) pathname separator ('/' or '\\')
  - os.extsep is the extension separator (always '.')
  - os.altsep is the alternate pathname separator (None or '/')
  - os.pathsep is the component separator used in $PATH etc
  - os.linesep is the line separator in text files ('\r' or '\n' or '\r\n')
  - os.defpath is the default search path for executables
  - os.devnull is the file path of the null device ('/dev/null', etc.)

Programs that import and use 'os' stand a better chance of being
portable between different platforms.  Of course, they must then
only use functions that are defined by all platforms (e.g., unlink
and opendir), and leave all pathname manipulation to os.path
(e.g., split and join).
'u'OS routines for NT or Posix depending on what system we're on.

This exports:
  - all functions from posix or nt, e.g. unlink, stat, etc.
  - os.path is either posixpath or ntpath
  - os.name is either 'posix' or 'nt'
  - os.curdir is a string representing the current directory (always '.')
  - os.pardir is a string representing the parent directory (always '..')
  - os.sep is the (or a most common) pathname separator ('/' or '\\')
  - os.extsep is the extension separator (always '.')
  - os.altsep is the alternate pathname separator (None or '/')
  - os.pathsep is the component separator used in $PATH etc
  - os.linesep is the line separator in text files ('\r' or '\n' or '\r\n')
  - os.defpath is the default search path for executables
  - os.devnull is the file path of the null device ('/dev/null', etc.)

Programs that import and use 'os' stand a better chance of being
portable between different platforms.  Of course, they must then
only use functions that are defined by all platforms (e.g., unlink
and opendir), and leave all pathname manipulation to os.path
(e.g., split and join).
'b'fsencode'u'fsencode'b'fsdecode'u'fsdecode'b'get_exec_path'u'get_exec_path'b'fdopen'u'fdopen'b'_exit'u'_exit'b'nt'b'no os specific module found'u'no os specific module found'b'os.path'u'os.path'b'_have_functions'u'_have_functions'b'HAVE_FACCESSAT'u'HAVE_FACCESSAT'b'access'u'access'b'HAVE_FCHMODAT'u'HAVE_FCHMODAT'b'chmod'u'chmod'b'HAVE_FCHOWNAT'u'HAVE_FCHOWNAT'b'chown'u'chown'b'HAVE_FSTATAT'u'HAVE_FSTATAT'b'stat'u'stat'b'HAVE_FUTIMESAT'u'HAVE_FUTIMESAT'b'utime'u'utime'b'HAVE_LINKAT'u'HAVE_LINKAT'b'link'u'link'b'HAVE_MKDIRAT'u'HAVE_MKDIRAT'b'mkdir'u'mkdir'b'HAVE_MKFIFOAT'u'HAVE_MKFIFOAT'b'mkfifo'u'mkfifo'b'HAVE_MKNODAT'u'HAVE_MKNODAT'b'mknod'u'mknod'b'HAVE_OPENAT'u'HAVE_OPENAT'b'HAVE_READLINKAT'u'HAVE_READLINKAT'b'readlink'u'readlink'b'HAVE_RENAMEAT'u'HAVE_RENAMEAT'b'rename'u'rename'b'HAVE_SYMLINKAT'u'HAVE_SYMLINKAT'b'symlink'u'symlink'b'HAVE_UNLINKAT'u'HAVE_UNLINKAT'b'unlink'u'unlink'b'rmdir'u'rmdir'b'HAVE_UTIMENSAT'u'HAVE_UTIMENSAT'b'HAVE_FCHDIR'u'HAVE_FCHDIR'b'HAVE_FCHMOD'u'HAVE_FCHMOD'b'HAVE_FCHOWN'u'HAVE_FCHOWN'b'HAVE_FDOPENDIR'u'HAVE_FDOPENDIR'b'listdir'u'listdir'b'scandir'u'scandir'b'HAVE_FEXECVE'u'HAVE_FEXECVE'b'execve'u'execve'b'HAVE_FTRUNCATE'b'truncate'u'truncate'b'HAVE_FUTIMENS'u'HAVE_FUTIMENS'b'HAVE_FUTIMES'u'HAVE_FUTIMES'b'HAVE_FPATHCONF'u'HAVE_FPATHCONF'b'pathconf'u'pathconf'b'statvfs'u'statvfs'b'fstatvfs'u'fstatvfs'b'HAVE_FSTATVFS'u'HAVE_FSTATVFS'b'HAVE_LCHFLAGS'u'HAVE_LCHFLAGS'b'chflags'u'chflags'b'HAVE_LCHMOD'u'HAVE_LCHMOD'b'lchown'u'lchown'b'HAVE_LCHOWN'u'HAVE_LCHOWN'b'HAVE_LUTIMES'u'HAVE_LUTIMES'b'HAVE_LSTAT'u'HAVE_LSTAT'b'MS_WINDOWS'b'makedirs(name [, mode=0o777][, exist_ok=False])

    Super-mkdir; create a leaf directory and all intermediate ones.  Works like
    mkdir, except that any intermediate path segment (not just the rightmost)
    will be created if it does not exist. If the target directory already
    exists, raise an OSError if exist_ok is False. Otherwise no exception is
    raised.  This is recursive.

    'u'makedirs(name [, mode=0o777][, exist_ok=False])

    Super-mkdir; create a leaf directory and all intermediate ones.  Works like
    mkdir, except that any intermediate path segment (not just the rightmost)
    will be created if it does not exist. If the target directory already
    exists, raise an OSError if exist_ok is False. Otherwise no exception is
    raised.  This is recursive.

    'b'removedirs(name)

    Super-rmdir; remove a leaf directory and all empty intermediate
    ones.  Works like rmdir except that, if the leaf directory is
    successfully removed, directories corresponding to rightmost path
    segments will be pruned away until either the whole path is
    consumed or an error occurs.  Errors during this latter phase are
    ignored -- they generally mean that a directory was not empty.

    'u'removedirs(name)

    Super-rmdir; remove a leaf directory and all empty intermediate
    ones.  Works like rmdir except that, if the leaf directory is
    successfully removed, directories corresponding to rightmost path
    segments will be pruned away until either the whole path is
    consumed or an error occurs.  Errors during this latter phase are
    ignored -- they generally mean that a directory was not empty.

    'b'renames(old, new)

    Super-rename; create directories as necessary and delete any left
    empty.  Works like rename, except creation of any intermediate
    directories needed to make the new pathname good is attempted
    first.  After the rename, directories corresponding to rightmost
    path segments of the old name will be pruned until either the
    whole path is consumed or a nonempty directory is found.

    Note: this function can fail with the new directory structure made
    if you lack permissions needed to unlink the leaf directory or
    file.

    'u'renames(old, new)

    Super-rename; create directories as necessary and delete any left
    empty.  Works like rename, except creation of any intermediate
    directories needed to make the new pathname good is attempted
    first.  After the rename, directories corresponding to rightmost
    path segments of the old name will be pruned until either the
    whole path is consumed or a nonempty directory is found.

    Note: this function can fail with the new directory structure made
    if you lack permissions needed to unlink the leaf directory or
    file.

    'b'makedirs'u'makedirs'b'removedirs'u'removedirs'b'renames'u'renames'b'Directory tree generator.

    For each directory in the directory tree rooted at top (including top
    itself, but excluding '.' and '..'), yields a 3-tuple

        dirpath, dirnames, filenames

    dirpath is a string, the path to the directory.  dirnames is a list of
    the names of the subdirectories in dirpath (including symlinks to directories,
    and excluding '.' and '..').
    filenames is a list of the names of the non-directory files in dirpath.
    Note that the names in the lists are just names, with no path components.
    To get a full path (which begins with top) to a file or directory in
    dirpath, do os.path.join(dirpath, name).

    If optional arg 'topdown' is true or not specified, the triple for a
    directory is generated before the triples for any of its subdirectories
    (directories are generated top down).  If topdown is false, the triple
    for a directory is generated after the triples for all of its
    subdirectories (directories are generated bottom up).

    When topdown is true, the caller can modify the dirnames list in-place
    (e.g., via del or slice assignment), and walk will only recurse into the
    subdirectories whose names remain in dirnames; this can be used to prune the
    search, or to impose a specific order of visiting.  Modifying dirnames when
    topdown is false has no effect on the behavior of os.walk(), since the
    directories in dirnames have already been generated by the time dirnames
    itself is generated. No matter the value of topdown, the list of
    subdirectories is retrieved before the tuples for the directory and its
    subdirectories are generated.

    By default errors from the os.scandir() call are ignored.  If
    optional arg 'onerror' is specified, it should be a function; it
    will be called with one argument, an OSError instance.  It can
    report the error to continue with the walk, or raise the exception
    to abort the walk.  Note that the filename is available as the
    filename attribute of the exception object.

    By default, os.walk does not follow symbolic links to subdirectories on
    systems that support them.  In order to get this functionality, set the
    optional argument 'followlinks' to true.

    Caution:  if you pass a relative pathname for top, don't change the
    current working directory between resumptions of walk.  walk never
    changes the current directory, and assumes that the client doesn't
    either.

    Example:

    import os
    from os.path import join, getsize
    for root, dirs, files in os.walk('python/Lib/email'):
        print(root, "consumes ")
        print(sum(getsize(join(root, name)) for name in files), end=" ")
        print("bytes in", len(files), "non-directory files")
        if 'CVS' in dirs:
            dirs.remove('CVS')  # don't visit CVS directories

    'u'Directory tree generator.

    For each directory in the directory tree rooted at top (including top
    itself, but excluding '.' and '..'), yields a 3-tuple

        dirpath, dirnames, filenames

    dirpath is a string, the path to the directory.  dirnames is a list of
    the names of the subdirectories in dirpath (including symlinks to directories,
    and excluding '.' and '..').
    filenames is a list of the names of the non-directory files in dirpath.
    Note that the names in the lists are just names, with no path components.
    To get a full path (which begins with top) to a file or directory in
    dirpath, do os.path.join(dirpath, name).

    If optional arg 'topdown' is true or not specified, the triple for a
    directory is generated before the triples for any of its subdirectories
    (directories are generated top down).  If topdown is false, the triple
    for a directory is generated after the triples for all of its
    subdirectories (directories are generated bottom up).

    When topdown is true, the caller can modify the dirnames list in-place
    (e.g., via del or slice assignment), and walk will only recurse into the
    subdirectories whose names remain in dirnames; this can be used to prune the
    search, or to impose a specific order of visiting.  Modifying dirnames when
    topdown is false has no effect on the behavior of os.walk(), since the
    directories in dirnames have already been generated by the time dirnames
    itself is generated. No matter the value of topdown, the list of
    subdirectories is retrieved before the tuples for the directory and its
    subdirectories are generated.

    By default errors from the os.scandir() call are ignored.  If
    optional arg 'onerror' is specified, it should be a function; it
    will be called with one argument, an OSError instance.  It can
    report the error to continue with the walk, or raise the exception
    to abort the walk.  Note that the filename is available as the
    filename attribute of the exception object.

    By default, os.walk does not follow symbolic links to subdirectories on
    systems that support them.  In order to get this functionality, set the
    optional argument 'followlinks' to true.

    Caution:  if you pass a relative pathname for top, don't change the
    current working directory between resumptions of walk.  walk never
    changes the current directory, and assumes that the client doesn't
    either.

    Example:

    import os
    from os.path import join, getsize
    for root, dirs, files in os.walk('python/Lib/email'):
        print(root, "consumes ")
        print(sum(getsize(join(root, name)) for name in files), end=" ")
        print("bytes in", len(files), "non-directory files")
        if 'CVS' in dirs:
            dirs.remove('CVS')  # don't visit CVS directories

    'b'os.walk'u'os.walk'b'walk'u'walk'b'Directory tree generator.

        This behaves exactly like walk(), except that it yields a 4-tuple

            dirpath, dirnames, filenames, dirfd

        `dirpath`, `dirnames` and `filenames` are identical to walk() output,
        and `dirfd` is a file descriptor referring to the directory `dirpath`.

        The advantage of fwalk() over walk() is that it's safe against symlink
        races (when follow_symlinks is False).

        If dir_fd is not None, it should be a file descriptor open to a directory,
          and top should be relative; top will then be relative to that directory.
          (dir_fd is always supported for fwalk.)

        Caution:
        Since fwalk() yields file descriptors, those are only valid until the
        next iteration step, so you should dup() them if you want to keep them
        for a longer period.

        Example:

        import os
        for root, dirs, files, rootfd in os.fwalk('python/Lib/email'):
            print(root, "consumes", end="")
            print(sum(os.stat(name, dir_fd=rootfd).st_size for name in files),
                  end="")
            print("bytes in", len(files), "non-directory files")
            if 'CVS' in dirs:
                dirs.remove('CVS')  # don't visit CVS directories
        'u'Directory tree generator.

        This behaves exactly like walk(), except that it yields a 4-tuple

            dirpath, dirnames, filenames, dirfd

        `dirpath`, `dirnames` and `filenames` are identical to walk() output,
        and `dirfd` is a file descriptor referring to the directory `dirpath`.

        The advantage of fwalk() over walk() is that it's safe against symlink
        races (when follow_symlinks is False).

        If dir_fd is not None, it should be a file descriptor open to a directory,
          and top should be relative; top will then be relative to that directory.
          (dir_fd is always supported for fwalk.)

        Caution:
        Since fwalk() yields file descriptors, those are only valid until the
        next iteration step, so you should dup() them if you want to keep them
        for a longer period.

        Example:

        import os
        for root, dirs, files, rootfd in os.fwalk('python/Lib/email'):
            print(root, "consumes", end="")
            print(sum(os.stat(name, dir_fd=rootfd).st_size for name in files),
                  end="")
            print("bytes in", len(files), "non-directory files")
            if 'CVS' in dirs:
                dirs.remove('CVS')  # don't visit CVS directories
        'b'os.fwalk'u'os.fwalk'b'fwalk'u'fwalk'b'execl(file, *args)

    Execute the executable file with argument list args, replacing the
    current process. 'u'execl(file, *args)

    Execute the executable file with argument list args, replacing the
    current process. 'b'execle(file, *args, env)

    Execute the executable file with argument list args and
    environment env, replacing the current process. 'u'execle(file, *args, env)

    Execute the executable file with argument list args and
    environment env, replacing the current process. 'b'execlp(file, *args)

    Execute the executable file (which is searched for along $PATH)
    with argument list args, replacing the current process. 'u'execlp(file, *args)

    Execute the executable file (which is searched for along $PATH)
    with argument list args, replacing the current process. 'b'execlpe(file, *args, env)

    Execute the executable file (which is searched for along $PATH)
    with argument list args and environment env, replacing the current
    process. 'u'execlpe(file, *args, env)

    Execute the executable file (which is searched for along $PATH)
    with argument list args and environment env, replacing the current
    process. 'b'execvp(file, args)

    Execute the executable file (which is searched for along $PATH)
    with argument list args, replacing the current process.
    args may be a list or tuple of strings. 'u'execvp(file, args)

    Execute the executable file (which is searched for along $PATH)
    with argument list args, replacing the current process.
    args may be a list or tuple of strings. 'b'execvpe(file, args, env)

    Execute the executable file (which is searched for along $PATH)
    with argument list args and environment env, replacing the
    current process.
    args may be a list or tuple of strings. 'u'execvpe(file, args, env)

    Execute the executable file (which is searched for along $PATH)
    with argument list args and environment env, replacing the
    current process.
    args may be a list or tuple of strings. 'b'execl'u'execl'b'execle'u'execle'b'execlp'u'execlp'b'execlpe'u'execlpe'b'execvp'u'execvp'b'execvpe'u'execvpe'b'Returns the sequence of directories that will be searched for the
    named executable (similar to a shell) when launching a process.

    *env* must be an environment variable dict or None.  If *env* is None,
    os.environ will be used.
    'u'Returns the sequence of directories that will be searched for the
    named executable (similar to a shell) when launching a process.

    *env* must be an environment variable dict or None.  If *env* is None,
    os.environ will be used.
    'b'env cannot contain 'PATH' and b'PATH' keys'u'env cannot contain 'PATH' and b'PATH' keys'b'environ({{'u'environ({{'b'}})'u'}})'b'str expected, not %s'u'str expected, not %s'b'Get an environment variable, return None if it doesn't exist.
    The optional second argument can specify an alternate default.
    key, default and the result are str.'u'Get an environment variable, return None if it doesn't exist.
    The optional second argument can specify an alternate default.
    key, default and the result are str.'b'getenv'u'getenv'b'supports_bytes_environ'u'supports_bytes_environ'b'bytes expected, not %s'u'bytes expected, not %s'b'Get an environment variable, return None if it doesn't exist.
        The optional second argument can specify an alternate default.
        key, default and the result are bytes.'u'Get an environment variable, return None if it doesn't exist.
        The optional second argument can specify an alternate default.
        key, default and the result are bytes.'b'getenvb'u'getenvb'b'Encode filename (an os.PathLike, bytes, or str) to the filesystem
        encoding with 'surrogateescape' error handler, return bytes unchanged.
        On Windows, use 'strict' error handler if the file system encoding is
        'mbcs' (which is the default encoding).
        'u'Encode filename (an os.PathLike, bytes, or str) to the filesystem
        encoding with 'surrogateescape' error handler, return bytes unchanged.
        On Windows, use 'strict' error handler if the file system encoding is
        'mbcs' (which is the default encoding).
        'b'Decode filename (an os.PathLike, bytes, or str) from the filesystem
        encoding with 'surrogateescape' error handler, return str unchanged. On
        Windows, use 'strict' error handler if the file system encoding is
        'mbcs' (which is the default encoding).
        'u'Decode filename (an os.PathLike, bytes, or str) from the filesystem
        encoding with 'surrogateescape' error handler, return str unchanged. On
        Windows, use 'strict' error handler if the file system encoding is
        'mbcs' (which is the default encoding).
        'b'spawnv'u'spawnv'b'execv'u'execv'b'P_WAIT'u'P_WAIT'b'P_NOWAIT'u'P_NOWAIT'b'P_NOWAITO'u'P_NOWAITO'b'argv must be a tuple or a list'u'argv must be a tuple or a list'b'argv first element cannot be empty'u'argv first element cannot be empty'b'spawnv(mode, file, args) -> integer

Execute file with arguments from args in a subprocess.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. 'u'spawnv(mode, file, args) -> integer

Execute file with arguments from args in a subprocess.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. 'b'spawnve(mode, file, args, env) -> integer

Execute file with arguments from args in a subprocess with the
specified environment.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. 'u'spawnve(mode, file, args, env) -> integer

Execute file with arguments from args in a subprocess with the
specified environment.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. 'b'spawnvp(mode, file, args) -> integer

Execute file (which is looked for along $PATH) with arguments from
args in a subprocess.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. 'u'spawnvp(mode, file, args) -> integer

Execute file (which is looked for along $PATH) with arguments from
args in a subprocess.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. 'b'spawnvpe(mode, file, args, env) -> integer

Execute file (which is looked for along $PATH) with arguments from
args in a subprocess with the supplied environment.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. 'u'spawnvpe(mode, file, args, env) -> integer

Execute file (which is looked for along $PATH) with arguments from
args in a subprocess with the supplied environment.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. 'b'spawnve'u'spawnve'b'spawnvp'u'spawnvp'b'spawnvpe'u'spawnvpe'b'spawnl(mode, file, *args) -> integer

Execute file with arguments from args in a subprocess.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. 'u'spawnl(mode, file, *args) -> integer

Execute file with arguments from args in a subprocess.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. 'b'spawnle(mode, file, *args, env) -> integer

Execute file with arguments from args in a subprocess with the
supplied environment.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. 'u'spawnle(mode, file, *args, env) -> integer

Execute file with arguments from args in a subprocess with the
supplied environment.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. 'b'spawnl'u'spawnl'b'spawnle'u'spawnle'b'spawnlp(mode, file, *args) -> integer

Execute file (which is looked for along $PATH) with arguments from
args in a subprocess with the supplied environment.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. 'u'spawnlp(mode, file, *args) -> integer

Execute file (which is looked for along $PATH) with arguments from
args in a subprocess with the supplied environment.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. 'b'spawnlpe(mode, file, *args, env) -> integer

Execute file (which is looked for along $PATH) with arguments from
args in a subprocess with the supplied environment.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. 'u'spawnlpe(mode, file, *args, env) -> integer

Execute file (which is looked for along $PATH) with arguments from
args in a subprocess with the supplied environment.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. 'b'spawnlp'u'spawnlp'b'spawnlpe'u'spawnlpe'b'vxworks'u'vxworks'b'invalid cmd type (%s, expected string)'u'invalid cmd type (%s, expected string)'b'invalid mode %r'u'invalid mode %r'b'popen() does not support unbuffered streams'u'popen() does not support unbuffered streams'b'popen'u'popen'b'invalid fd type (%s, expected integer)'u'invalid fd type (%s, expected integer)'b'Return the path representation of a path-like object.

    If str or bytes is passed in, it is returned unchanged. Otherwise the
    os.PathLike interface is used to get the path representation. If the
    path representation is not str or bytes, TypeError is raised. If the
    provided path is not str, bytes, or os.PathLike, TypeError is raised.
    'u'Return the path representation of a path-like object.

    If str or bytes is passed in, it is returned unchanged. Otherwise the
    os.PathLike interface is used to get the path representation. If the
    path representation is not str or bytes, TypeError is raised. If the
    provided path is not str, bytes, or os.PathLike, TypeError is raised.
    'b'__fspath__'u'__fspath__'b'expected str, bytes or os.PathLike object, not 'u'expected str, bytes or os.PathLike object, not 'b'expected {}.__fspath__() to return str or bytes, not {}'u'expected {}.__fspath__() to return str or bytes, not {}'b'fspath'u'fspath'b'Abstract base class for implementing the file system path protocol.'u'Abstract base class for implementing the file system path protocol.'b'Return the file system path representation of the object.'u'Return the file system path representation of the object.'b'<AddedDllDirectory({!r})>'u'<AddedDllDirectory({!r})>'b'<AddedDllDirectory()>'u'<AddedDllDirectory()>'b'Add a path to the DLL search path.

        This search path is used when resolving dependencies for imported
        extension modules (the module itself is resolved through sys.path),
        and also by ctypes.

        Remove the directory by calling close() on the returned object or
        using it in a with statement.
        'u'Add a path to the DLL search path.

        This search path is used when resolving dependencies for imported
        extension modules (the module itself is resolved through sys.path),
        and also by ctypes.

        Remove the directory by calling close() on the returned object or
        using it in a with statement.
        'u'Lib.os'Parse (absolute and relative) URLs.

urlparse module is based upon the following RFC specifications.

RFC 3986 (STD66): "Uniform Resource Identifiers" by T. Berners-Lee, R. Fielding
and L.  Masinter, January 2005.

RFC 2732 : "Format for Literal IPv6 Addresses in URL's by R.Hinden, B.Carpenter
and L.Masinter, December 1999.

RFC 2396:  "Uniform Resource Identifiers (URI)": Generic Syntax by T.
Berners-Lee, R. Fielding, and L. Masinter, August 1998.

RFC 2368: "The mailto URL scheme", by P.Hoffman , L Masinter, J. Zawinski, July 1998.

RFC 1808: "Relative Uniform Resource Locators", by R. Fielding, UC Irvine, June
1995.

RFC 1738: "Uniform Resource Locators (URL)" by T. Berners-Lee, L. Masinter, M.
McCahill, December 1994

RFC 3986 is considered the current standard and any future changes to
urlparse module should conform with it.  The urlparse module is
currently not entirely compliant with this RFC due to defacto
scenarios for parsing, and for backward compatibility purposes, some
parsing quirks from older RFCs are retained. The testcases in
test_urlparse.py provides a good indicator of parsing behavior.

The WHATWG URL Parser spec should also be considered.  We are not compliant with
it either due to existing user code API behavior expectations (Hyrum's Law).
It serves as a useful guide when making changes.
ipaddressurlunparseurljoinurldefragparse_qsparse_qslquote_from_bytesDefragResultParseResultSplitResultDefragResultBytesParseResultBytesSplitResultBytesftpgophernntpwaisshttpmmsprosperortsprtspsrtspusftpsvnsvn+sshwssuses_relativetelnetsnewsrsyncnfsgitgit+sshitms-servicesuses_netlochdlsipsipsteluses_paramsmailtonewsnon_hierarchicaluses_queryuses_fragmentabcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789+-.'abcdefghijklmnopqrstuvwxyz''ABCDEFGHIJKLMNOPQRSTUVWXYZ''0123456789''+-.'scheme_chars 	
 _WHATWG_C0_CONTROL_OR_SPACE_UNSAFE_URL_BYTES_TO_REMOVEclear_cacheClear internal performance caches. Undocumented; some tests want it._byte_quoter_factory_implicit_encoding_implicit_errors_noop_encode_result_decode_args_coerce_argsstr_inputCannot mix str and non-str arguments_ResultMixinStrStandard approach to encoding parsed results from str to bytes_encoded_counterpart_ResultMixinBytesStandard approach to decoding parsed results from bytes to str_decoded_counterpart_NetlocResultMixinBaseShared methods for the parsed result objects containing a netloc elementusername_userinfopasswordhostname_hostinfoPort could not be cast to integer value as Port out of range 0-65535_NetlocResultMixinStruserinfohave_infohostinfohave_passwordhave_open_brbracketed_NetlocResultMixinBytesurl fragment_DefragResultBasescheme netloc path query fragment_SplitResultBasescheme netloc path params query fragment_ParseResultBase
DefragResult(url, fragment)

A 2-tuple that contains the url without fragment identifier and the fragment
identifier as a separate argument.
The URL with no fragment identifier.
Fragment identifier separated from URL, that allows indirect identification of a
secondary resource by reference to a primary resource and additional identifying
information.
fragment
SplitResult(scheme, netloc, path, query, fragment)

A 5-tuple that contains the different components of a URL. Similar to
ParseResult, but does not split params.
Specifies URL scheme for the request.
Network location where the request is made to.

The hierarchical path, such as the path to a file to download.

The query component, that contains non-hierarchical data, that along with data
in path component, identifies a resource in the scope of URI's scheme and
network location.
query
Fragment identifier, that allows indirect identification of a secondary resource
by reference to a primary resource and additional identifying information.

ParseResult(scheme, netloc, path, params, query, fragment)

A 6-tuple that contains components of a parsed URL.

Parameters for last path element used to dereference the URI in order to provide
access to perform some operation on the resource.
ResultBase_fix_result_transcoding_result_pairs_decoded_encodedallow_fragmentsParse a URL into 6 components:
    <scheme>://<netloc>/<path>;<params>?<query>#<fragment>

    The result is a named 6-tuple with fields corresponding to the
    above. It is either a ParseResult or ParseResultBytes object,
    depending on the type of the url parameter.

    The username, password, hostname, and port sub-components of netloc
    can also be accessed as attributes of the returned object.

    The scheme argument provides the default value of the scheme
    component when no scheme is found in url.

    If allow_fragments is False, no attempt is made to separate the
    fragment component from the previous component, which can be either
    path or query.

    Note that % escapes are not expanded.
    _coerce_resultsplitresult_splitparams_splitnetlocdelim/?#wdelim_checknetlocNFKCnetloc2/?#@:netloc '' contains invalid characters under NFKC normalization_check_bracketed_host\Av[a-fA-F0-9]+\..+\ZIPvFuture address is invalidAn IPv4 address cannot be in bracketsParse a URL into 5 components:
    <scheme>://<netloc>/<path>?<query>#<fragment>

    The result is a named 5-tuple with fields corresponding to the
    above. It is either a SplitResult or SplitResultBytes object,
    depending on the type of the url parameter.

    The username, password, hostname, and port sub-components of netloc
    can also be accessed as attributes of the returned object.

    The scheme argument provides the default value of the scheme
    component when no scheme is found in url.

    If allow_fragments is False, no attempt is made to separate the
    fragment component from the previous component, which can be either
    path or query.

    Note that % escapes are not expanded.
    Invalid IPv6 URLbracketed_hostcomponentsPut a parsed URL back together again.  This may result in a
    slightly different, but equivalent URL, if the URL that was parsed
    originally had redundant delimiters, e.g. a ? with an empty query
    (the draft states that these are equivalent).%s;%sCombine the elements of a tuple as returned by urlsplit() into a
    complete URL as a string. The data argument can be any five-item iterable.
    This may result in a slightly different, but equivalent URL, if the URL that
    was parsed originally had unnecessary delimiters (for example, a ? with an
    empty query; the RFC states that these are equivalent).Join a base URL and a possibly relative URL to form an absolute
    interpretation of the latter.bschemebnetlocbpathbparamsbquerybfragmentbase_partssegmentsresolved_pathsegRemoves any existing fragment from URL.

    Returns a tuple of the defragmented URL and the fragment.  If
    the URL contained no fragments, the second element is the
    empty string.
    fragdefrag_hexdig_hextobyteunquote_to_bytes('abc%20def') -> b'abc def'._unquote_impl([ -]+)_asciire_generate_unquoted_partsprevious_match_endascii_matchReplace %xx escapes by their single-character equivalent. The optional
    encoding and errors parameters specify how to decode percent-encoded
    sequences into Unicode characters, as accepted by the bytes.decode()
    method.
    By default, percent-encoded sequences are decoded with UTF-8, and invalid
    sequences are replaced by a placeholder character.

    unquote('abc%20def') -> 'abc def'.
    qskeep_blank_valuesstrict_parsingmax_num_fieldsParse a query given as a string argument.

        Arguments:

        qs: percent-encoded query string to be parsed

        keep_blank_values: flag indicating whether blank values in
            percent-encoded queries should be treated as blank strings.
            A true value indicates that blanks should be retained as
            blank strings.  The default false value indicates that
            blank values are to be ignored and treated as if they were
            not included.

        strict_parsing: flag indicating what to do with parsing errors.
            If false (the default), errors are silently ignored.
            If true, errors raise a ValueError exception.

        encoding and errors: specify how to decode percent-encoded sequences
            into Unicode characters, as accepted by the bytes.decode() method.

        max_num_fields: int. If set, then throws a ValueError if there
            are more than n fields read by parse_qsl().

        separator: str. The symbol to use for separating the query arguments.
            Defaults to &.

        Returns a dictionary.
    parsed_resultpairsParse a query given as a string argument.

        Arguments:

        qs: percent-encoded query string to be parsed

        keep_blank_values: flag indicating whether blank values in
            percent-encoded queries should be treated as blank strings.
            A true value indicates that blanks should be retained as blank
            strings.  The default false value indicates that blank values
            are to be ignored and treated as if they were  not included.

        strict_parsing: flag indicating what to do with parsing errors. If
            false (the default), errors are silently ignored. If true,
            errors raise a ValueError exception.

        encoding and errors: specify how to decode percent-encoded sequences
            into Unicode characters, as accepted by the bytes.decode() method.

        max_num_fields: int. If set, then throws a ValueError
            if there are more than n fields read by parse_qsl().

        separator: str. The symbol to use for separating the query arguments.
            Defaults to &.

        Returns a list, as G-d intended.
    Separator must be of type string or bytes._unquoteMax number of fields exceededname_valuehas_eqbad query field: %rLike unquote(), but also replace plus signs by spaces, as required for
    unquoting HTML form values.

    unquote_plus('%7e/abc+def') -> '~/abc def'
    ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789_.-~b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'b'abcdefghijklmnopqrstuvwxyz'b'_.-~'_ALWAYS_SAFE_ALWAYS_SAFE_BYTESQuoterDeprecated in 3.11. urllib.parse.Quoter will be removed in Python 3.14. It was not intended to be a public API.'Deprecated in 3.11. ''urllib.parse.Quoter will be removed in Python 3.14. ''It was not intended to be a public API.'_QuoterA mapping from bytes numbers (in range(0,256)) to strings.

    String values are percent-encoded byte values, unless the key < 128, and
    in either of the specified safe set, or the always safe set.
    safe: bytes object.<Quoter %{:02X}quote('abc def') -> 'abc%20def'

    Each part of a URL, e.g. the path info, the query, etc., has a
    different set of reserved characters that must be quoted. The
    quote function offers a cautious (not minimal) way to quote a
    string for most of these parts.

    RFC 3986 Uniform Resource Identifier (URI): Generic Syntax lists
    the following (un)reserved characters.

    unreserved    = ALPHA / DIGIT / "-" / "." / "_" / "~"
    reserved      = gen-delims / sub-delims
    gen-delims    = ":" / "/" / "?" / "#" / "[" / "]" / "@"
    sub-delims    = "!" / "$" / "&" / "'" / "(" / ")"
                  / "*" / "+" / "," / ";" / "="

    Each of the reserved characters is reserved in some component of a URL,
    but not necessarily in all of them.

    The quote function %-escapes all characters that are neither in the
    unreserved chars ("always safe") nor the additional chars set via the
    safe arg.

    The default for the safe arg is '/'. The character is reserved, but in
    typical usage the quote function is being called on a path where the
    existing slash characters are to be preserved.

    Python 3.7 updates from using RFC 2396 to RFC 3986 to quote URL strings.
    Now, "~" is included in the set of unreserved characters.

    string and safe may be either str or bytes objects. encoding and errors
    must not be specified if string is a bytes object.

    The optional encoding and errors parameters specify how to deal with
    non-ASCII characters, as accepted by the str.encode method.
    By default, encoding='utf-8' (characters are encoded with UTF-8), and
    errors='strict' (unsupported characters raise a UnicodeEncodeError).
    quote() doesn't support 'encoding' for bytesquote() doesn't support 'errors' for bytesLike quote(), but also replace ' ' with '+', as required for quoting
    HTML form values. Plus signs in the original string are escaped unless
    they are included in safe. It also does not have safe default to '/'.
    spaceLike quote(), but accepts a bytes object rather than a str, and does
    not perform string-to-bytes encoding.  It always returns an ASCII string.
    quote_from_bytes(b'abc def?') -> 'abc%20def%3f'
    quote_from_bytes() expected bytesquoterbs_len200000200_000doseqquote_viaEncode a dict or sequence of two-element tuples into a URL query string.

    If any values in the query arg are sequences and doseq is true, each
    sequence element is converted to a separate parameter.

    If the query arg is a sequence of two-element tuples, the order of the
    parameters in the output will match the order of parameters in the
    input.

    The components of a query arg may each be either a string or a bytes type.

    The safe, encoding, and errors parameters are passed down to the function
    specified by quote_via (encoding and errors only if a component is a str).
    not a valid non-string sequence or mapping object"not a valid non-string sequence ""or mapping object"urllib.parse.to_bytes() is deprecated as of 3.8_to_bytesto_bytes(u"URL") --> 'URL'.URL  contains non-ASCII charactersTransform a string like '<URL:scheme://host/path>' into 'scheme://host/path'.

    The string is returned unchanged if it's not a wrapped URL.
    URL:splittypeurllib.parse.splittype() is deprecated as of 3.8, use urllib.parse.urlparse() instead"urllib.parse.splittype() is deprecated as of 3.8, ""use urllib.parse.urlparse() instead"_splittype_typeprogsplittype('type:opaquestring') --> 'type', 'opaquestring'.([^/:]+):(.*)splithosturllib.parse.splithost() is deprecated as of 3.8, use urllib.parse.urlparse() instead"urllib.parse.splithost() is deprecated as of 3.8, "_splithost_hostprogsplithost('//host[:port]/path') --> 'host[:port]', '/path'.//([^/#?]*)(.*)host_portsplituserurllib.parse.splituser() is deprecated as of 3.8, use urllib.parse.urlparse() instead"urllib.parse.splituser() is deprecated as of 3.8, "splituser('user[:passwd]@host[:port]') --> 'user[:passwd]', 'host[:port]'.splitpasswdurllib.parse.splitpasswd() is deprecated as of 3.8, use urllib.parse.urlparse() instead"urllib.parse.splitpasswd() is deprecated as of 3.8, "_splitpasswdsplitpasswd('user:passwd') -> 'user', 'passwd'.passwdsplitporturllib.parse.splitport() is deprecated as of 3.8, use urllib.parse.urlparse() instead"urllib.parse.splitport() is deprecated as of 3.8, "_splitport_portprogsplitport('host:port') --> 'host', 'port'.(.*):([0-9]*)splitnportdefporturllib.parse.splitnport() is deprecated as of 3.8, use urllib.parse.urlparse() instead"urllib.parse.splitnport() is deprecated as of 3.8, "_splitnportSplit host and port, returning numeric port.
    Return given default port if no ':' found; defaults to -1.
    Return numerical port if a valid number is found after ':'.
    Return None if ':' but not a valid number.nportsplitqueryurllib.parse.splitquery() is deprecated as of 3.8, use urllib.parse.urlparse() instead"urllib.parse.splitquery() is deprecated as of 3.8, "_splitquerysplitquery('/path?query') --> '/path', 'query'.splittagurllib.parse.splittag() is deprecated as of 3.8, use urllib.parse.urlparse() instead"urllib.parse.splittag() is deprecated as of 3.8, "_splittagsplittag('/path#tag') --> '/path', 'tag'.splitattrurllib.parse.splitattr() is deprecated as of 3.8, use urllib.parse.urlparse() instead"urllib.parse.splitattr() is deprecated as of 3.8, "_splitattrsplitattr('/path;attr1=value1;attr2=value2;...') ->
        '/path', ['attr1=value1', 'attr2=value2', ...].splitvalueurllib.parse.splitvalue() is deprecated as of 3.8, use urllib.parse.parse_qsl() instead"urllib.parse.splitvalue() is deprecated as of 3.8, ""use urllib.parse.parse_qsl() instead"_splitvaluesplitvalue('attr=value') --> 'attr', 'value'.# A classification of schemes.# The empty string classifies URLs with no scheme specified,# being the default value returned by urlsplit and urlparse.# These are not actually used anymore, but should stay for backwards# compatibility.  (They are undocumented, but have a public-looking name.)# Characters valid in scheme names# Leading and trailing C0 control and space to be stripped per WHATWG spec.# == "".join([chr(i) for i in range(0, 0x20 + 1)])# Unsafe bytes to be removed per WHATWG spec# Helpers for bytes handling# For 3.2, we deliberately require applications that# handle improperly quoted URLs to do their own# decoding and encoding. If valid use cases are# presented, we may relax this by using latin-1# decoding internally for 3.3# Invokes decode if necessary to create str args# and returns the coerced inputs along with# an appropriate result coercion function#   - noop for str inputs#   - encoding function otherwise# We special-case the empty string to support the# "scheme=''" default argument to some functions# Result objects are more helpful than simple tuples# Scoped IPv6 address may have zone info, which must not be lowercased# like http://[fe80::822a:a8ff:fe49:470c%tESt]:1234/keys# For backwards compatibility, alias _NetlocResultMixinStr# ResultBase is no longer part of the documented API, but it is# retained since deprecating it isn't worth the hassle# Structured result objects for string data# Structured result objects for bytes data# Set up the encode/decode result pairs# position of end of domain part of url, default is end# look for delimiters; the order is NOT important# find first of this delim# if found# use earliest delim position# return (domain, rest)# looking for characters like \u2100 that expand to 'a/c'# IDNA uses NFKC equivalence, so normalize for this check# ignore characters already included# but not the surrounding text# Valid bracketed hosts are defined in# https://www.rfc-editor.org/rfc/rfc3986#page-49 and https://url.spec.whatwg.org/# Throws Value Error if not IPv6 or IPv4# typed=True avoids BytesWarnings being emitted during cache key# comparison since this API supports both bytes and str input.# Only lstrip url as some applications rely on preserving trailing space.# (https://url.spec.whatwg.org/#concept-basic-url-parser would strip both)# the last item is not a directory, so will not be taken into account# in resolving the relative path# for rfc3986, ignore all base path should the first character be root.# filter out elements that would cause redundant slashes on re-joining# the resolved_path# ignore any .. segments that would otherwise cause an IndexError# when popped from resolved_path if resolving for rfc3986# do some post-processing here. if the last segment was a relative dir,# then we need to append the trailing '/'# Note: strings are encoded as UTF-8. This is only an issue if it contains# unescaped non-ASCII characters, which URIs should not.# Is it a string-like object?# Non-ASCII# The ascii_match[1] group == string[start:end].# Non-ASCII tail# Use memoryview() to reject integers and iterables,# acceptable by the bytes constructor.# If max_num_fields is defined then check that the number of fields# is less than max_num_fields. This prevents a memory exhaustion DOS# attack via post bodies with many fields.# Keeps a cache internally, via __missing__, for efficiency (lookups# of cached keys don't call Python code at all).# Handle a cache miss. Store quoted string in cache and return.# Check if ' ' in string, where string may either be a str or bytes.  If# there are no spaces, the regular quote will produce the right answer.# Expectation: A typical program is unlikely to create more than 5 of these.# Normalize 'safe' by converting to bytes and removing non-ASCII chars# List comprehensions are faster than generator expressions.# This saves memory - https://github.com/python/cpython/issues/95865# It's a bother at times that strings and string-like objects are# sequences.# non-sequence items should not work with len()# non-empty strings will fail this# Zero-length sequences of all types will get here and succeed,# but that's a minor nit.  Since the original implementation# allowed empty dicts that type of behavior probably should be# preserved for consistency# Is this a sufficient test for sequence-ness?# not a sequence# loop over the sequence# Most URL schemes require ASCII. If that changes, the conversion# can be relaxed.# XXX get rid of to_bytes()# splittag('/path#tag') --> '/path', 'tag'b'Parse (absolute and relative) URLs.

urlparse module is based upon the following RFC specifications.

RFC 3986 (STD66): "Uniform Resource Identifiers" by T. Berners-Lee, R. Fielding
and L.  Masinter, January 2005.

RFC 2732 : "Format for Literal IPv6 Addresses in URL's by R.Hinden, B.Carpenter
and L.Masinter, December 1999.

RFC 2396:  "Uniform Resource Identifiers (URI)": Generic Syntax by T.
Berners-Lee, R. Fielding, and L. Masinter, August 1998.

RFC 2368: "The mailto URL scheme", by P.Hoffman , L Masinter, J. Zawinski, July 1998.

RFC 1808: "Relative Uniform Resource Locators", by R. Fielding, UC Irvine, June
1995.

RFC 1738: "Uniform Resource Locators (URL)" by T. Berners-Lee, L. Masinter, M.
McCahill, December 1994

RFC 3986 is considered the current standard and any future changes to
urlparse module should conform with it.  The urlparse module is
currently not entirely compliant with this RFC due to defacto
scenarios for parsing, and for backward compatibility purposes, some
parsing quirks from older RFCs are retained. The testcases in
test_urlparse.py provides a good indicator of parsing behavior.

The WHATWG URL Parser spec should also be considered.  We are not compliant with
it either due to existing user code API behavior expectations (Hyrum's Law).
It serves as a useful guide when making changes.
'u'Parse (absolute and relative) URLs.

urlparse module is based upon the following RFC specifications.

RFC 3986 (STD66): "Uniform Resource Identifiers" by T. Berners-Lee, R. Fielding
and L.  Masinter, January 2005.

RFC 2732 : "Format for Literal IPv6 Addresses in URL's by R.Hinden, B.Carpenter
and L.Masinter, December 1999.

RFC 2396:  "Uniform Resource Identifiers (URI)": Generic Syntax by T.
Berners-Lee, R. Fielding, and L. Masinter, August 1998.

RFC 2368: "The mailto URL scheme", by P.Hoffman , L Masinter, J. Zawinski, July 1998.

RFC 1808: "Relative Uniform Resource Locators", by R. Fielding, UC Irvine, June
1995.

RFC 1738: "Uniform Resource Locators (URL)" by T. Berners-Lee, L. Masinter, M.
McCahill, December 1994

RFC 3986 is considered the current standard and any future changes to
urlparse module should conform with it.  The urlparse module is
currently not entirely compliant with this RFC due to defacto
scenarios for parsing, and for backward compatibility purposes, some
parsing quirks from older RFCs are retained. The testcases in
test_urlparse.py provides a good indicator of parsing behavior.

The WHATWG URL Parser spec should also be considered.  We are not compliant with
it either due to existing user code API behavior expectations (Hyrum's Law).
It serves as a useful guide when making changes.
'b'urlunparse'u'urlunparse'b'urljoin'u'urljoin'b'urldefrag'u'urldefrag'b'urlsplit'u'urlsplit'b'urlunsplit'u'urlunsplit'b'parse_qs'u'parse_qs'b'parse_qsl'u'parse_qsl'b'quote_from_bytes'u'quote_from_bytes'b'unquote_to_bytes'u'unquote_to_bytes'b'DefragResult'u'DefragResult'b'ParseResult'u'ParseResult'b'SplitResult'u'SplitResult'b'DefragResultBytes'u'DefragResultBytes'b'ParseResultBytes'u'ParseResultBytes'b'SplitResultBytes'u'SplitResultBytes'b'ftp'u'ftp'b'gopher'u'gopher'b'nntp'u'nntp'b'wais'u'wais'b'shttp'u'shttp'b'mms'u'mms'b'prospero'u'prospero'b'rtsp'u'rtsp'b'rtsps'u'rtsps'b'rtspu'u'rtspu'b'sftp'u'sftp'b'svn'u'svn'b'svn+ssh'u'svn+ssh'b'ws'u'ws'b'wss'u'wss'b'telnet'u'telnet'b'snews'u'snews'b'rsync'u'rsync'b'nfs'u'nfs'b'git'u'git'b'git+ssh'u'git+ssh'b'itms-services'u'itms-services'b'hdl'u'hdl'b'sip'u'sip'b'sips'u'sips'b'tel'u'tel'b'mailto'u'mailto'b'news'u'news'b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789+-.'u'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789+-.'b' 	
 'u' 	
 'b'Clear internal performance caches. Undocumented; some tests want it.'u'Clear internal performance caches. Undocumented; some tests want it.'b'Cannot mix str and non-str arguments'u'Cannot mix str and non-str arguments'b'Standard approach to encoding parsed results from str to bytes'u'Standard approach to encoding parsed results from str to bytes'b'Standard approach to decoding parsed results from bytes to str'u'Standard approach to decoding parsed results from bytes to str'b'Shared methods for the parsed result objects containing a netloc element'u'Shared methods for the parsed result objects containing a netloc element'b'Port could not be cast to integer value as 'u'Port could not be cast to integer value as 'b'Port out of range 0-65535'u'Port out of range 0-65535'b'url fragment'u'url fragment'b'scheme netloc path query fragment'u'scheme netloc path query fragment'b'scheme netloc path params query fragment'u'scheme netloc path params query fragment'b'
DefragResult(url, fragment)

A 2-tuple that contains the url without fragment identifier and the fragment
identifier as a separate argument.
'u'
DefragResult(url, fragment)

A 2-tuple that contains the url without fragment identifier and the fragment
identifier as a separate argument.
'b'The URL with no fragment identifier.'u'The URL with no fragment identifier.'b'
Fragment identifier separated from URL, that allows indirect identification of a
secondary resource by reference to a primary resource and additional identifying
information.
'u'
Fragment identifier separated from URL, that allows indirect identification of a
secondary resource by reference to a primary resource and additional identifying
information.
'b'
SplitResult(scheme, netloc, path, query, fragment)

A 5-tuple that contains the different components of a URL. Similar to
ParseResult, but does not split params.
'u'
SplitResult(scheme, netloc, path, query, fragment)

A 5-tuple that contains the different components of a URL. Similar to
ParseResult, but does not split params.
'b'Specifies URL scheme for the request.'u'Specifies URL scheme for the request.'b'
Network location where the request is made to.
'u'
Network location where the request is made to.
'b'
The hierarchical path, such as the path to a file to download.
'u'
The hierarchical path, such as the path to a file to download.
'b'
The query component, that contains non-hierarchical data, that along with data
in path component, identifies a resource in the scope of URI's scheme and
network location.
'u'
The query component, that contains non-hierarchical data, that along with data
in path component, identifies a resource in the scope of URI's scheme and
network location.
'b'
Fragment identifier, that allows indirect identification of a secondary resource
by reference to a primary resource and additional identifying information.
'u'
Fragment identifier, that allows indirect identification of a secondary resource
by reference to a primary resource and additional identifying information.
'b'
ParseResult(scheme, netloc, path, params, query, fragment)

A 6-tuple that contains components of a parsed URL.
'u'
ParseResult(scheme, netloc, path, params, query, fragment)

A 6-tuple that contains components of a parsed URL.
'b'
Parameters for last path element used to dereference the URI in order to provide
access to perform some operation on the resource.
'u'
Parameters for last path element used to dereference the URI in order to provide
access to perform some operation on the resource.
'b'Parse a URL into 6 components:
    <scheme>://<netloc>/<path>;<params>?<query>#<fragment>

    The result is a named 6-tuple with fields corresponding to the
    above. It is either a ParseResult or ParseResultBytes object,
    depending on the type of the url parameter.

    The username, password, hostname, and port sub-components of netloc
    can also be accessed as attributes of the returned object.

    The scheme argument provides the default value of the scheme
    component when no scheme is found in url.

    If allow_fragments is False, no attempt is made to separate the
    fragment component from the previous component, which can be either
    path or query.

    Note that % escapes are not expanded.
    'u'Parse a URL into 6 components:
    <scheme>://<netloc>/<path>;<params>?<query>#<fragment>

    The result is a named 6-tuple with fields corresponding to the
    above. It is either a ParseResult or ParseResultBytes object,
    depending on the type of the url parameter.

    The username, password, hostname, and port sub-components of netloc
    can also be accessed as attributes of the returned object.

    The scheme argument provides the default value of the scheme
    component when no scheme is found in url.

    If allow_fragments is False, no attempt is made to separate the
    fragment component from the previous component, which can be either
    path or query.

    Note that % escapes are not expanded.
    'b'/?#'u'/?#'b'NFKC'u'NFKC'b'/?#@:'u'/?#@:'b'netloc ''u'netloc ''b'' contains invalid 'u'' contains invalid 'b'characters under NFKC normalization'u'characters under NFKC normalization'b'v'u'v'b'\Av[a-fA-F0-9]+\..+\Z'u'\Av[a-fA-F0-9]+\..+\Z'b'IPvFuture address is invalid'u'IPvFuture address is invalid'b'An IPv4 address cannot be in brackets'u'An IPv4 address cannot be in brackets'b'Parse a URL into 5 components:
    <scheme>://<netloc>/<path>?<query>#<fragment>

    The result is a named 5-tuple with fields corresponding to the
    above. It is either a SplitResult or SplitResultBytes object,
    depending on the type of the url parameter.

    The username, password, hostname, and port sub-components of netloc
    can also be accessed as attributes of the returned object.

    The scheme argument provides the default value of the scheme
    component when no scheme is found in url.

    If allow_fragments is False, no attempt is made to separate the
    fragment component from the previous component, which can be either
    path or query.

    Note that % escapes are not expanded.
    'u'Parse a URL into 5 components:
    <scheme>://<netloc>/<path>?<query>#<fragment>

    The result is a named 5-tuple with fields corresponding to the
    above. It is either a SplitResult or SplitResultBytes object,
    depending on the type of the url parameter.

    The username, password, hostname, and port sub-components of netloc
    can also be accessed as attributes of the returned object.

    The scheme argument provides the default value of the scheme
    component when no scheme is found in url.

    If allow_fragments is False, no attempt is made to separate the
    fragment component from the previous component, which can be either
    path or query.

    Note that % escapes are not expanded.
    'b'Invalid IPv6 URL'u'Invalid IPv6 URL'b'Put a parsed URL back together again.  This may result in a
    slightly different, but equivalent URL, if the URL that was parsed
    originally had redundant delimiters, e.g. a ? with an empty query
    (the draft states that these are equivalent).'u'Put a parsed URL back together again.  This may result in a
    slightly different, but equivalent URL, if the URL that was parsed
    originally had redundant delimiters, e.g. a ? with an empty query
    (the draft states that these are equivalent).'b'%s;%s'u'%s;%s'b'Combine the elements of a tuple as returned by urlsplit() into a
    complete URL as a string. The data argument can be any five-item iterable.
    This may result in a slightly different, but equivalent URL, if the URL that
    was parsed originally had unnecessary delimiters (for example, a ? with an
    empty query; the RFC states that these are equivalent).'u'Combine the elements of a tuple as returned by urlsplit() into a
    complete URL as a string. The data argument can be any five-item iterable.
    This may result in a slightly different, but equivalent URL, if the URL that
    was parsed originally had unnecessary delimiters (for example, a ? with an
    empty query; the RFC states that these are equivalent).'b'Join a base URL and a possibly relative URL to form an absolute
    interpretation of the latter.'u'Join a base URL and a possibly relative URL to form an absolute
    interpretation of the latter.'b'Removes any existing fragment from URL.

    Returns a tuple of the defragmented URL and the fragment.  If
    the URL contained no fragments, the second element is the
    empty string.
    'u'Removes any existing fragment from URL.

    Returns a tuple of the defragmented URL and the fragment.  If
    the URL contained no fragments, the second element is the
    empty string.
    'b'unquote_to_bytes('abc%20def') -> b'abc def'.'u'unquote_to_bytes('abc%20def') -> b'abc def'.'b'([ -]+)'u'([ -]+)'b'Replace %xx escapes by their single-character equivalent. The optional
    encoding and errors parameters specify how to decode percent-encoded
    sequences into Unicode characters, as accepted by the bytes.decode()
    method.
    By default, percent-encoded sequences are decoded with UTF-8, and invalid
    sequences are replaced by a placeholder character.

    unquote('abc%20def') -> 'abc def'.
    'u'Replace %xx escapes by their single-character equivalent. The optional
    encoding and errors parameters specify how to decode percent-encoded
    sequences into Unicode characters, as accepted by the bytes.decode()
    method.
    By default, percent-encoded sequences are decoded with UTF-8, and invalid
    sequences are replaced by a placeholder character.

    unquote('abc%20def') -> 'abc def'.
    'b'Parse a query given as a string argument.

        Arguments:

        qs: percent-encoded query string to be parsed

        keep_blank_values: flag indicating whether blank values in
            percent-encoded queries should be treated as blank strings.
            A true value indicates that blanks should be retained as
            blank strings.  The default false value indicates that
            blank values are to be ignored and treated as if they were
            not included.

        strict_parsing: flag indicating what to do with parsing errors.
            If false (the default), errors are silently ignored.
            If true, errors raise a ValueError exception.

        encoding and errors: specify how to decode percent-encoded sequences
            into Unicode characters, as accepted by the bytes.decode() method.

        max_num_fields: int. If set, then throws a ValueError if there
            are more than n fields read by parse_qsl().

        separator: str. The symbol to use for separating the query arguments.
            Defaults to &.

        Returns a dictionary.
    'u'Parse a query given as a string argument.

        Arguments:

        qs: percent-encoded query string to be parsed

        keep_blank_values: flag indicating whether blank values in
            percent-encoded queries should be treated as blank strings.
            A true value indicates that blanks should be retained as
            blank strings.  The default false value indicates that
            blank values are to be ignored and treated as if they were
            not included.

        strict_parsing: flag indicating what to do with parsing errors.
            If false (the default), errors are silently ignored.
            If true, errors raise a ValueError exception.

        encoding and errors: specify how to decode percent-encoded sequences
            into Unicode characters, as accepted by the bytes.decode() method.

        max_num_fields: int. If set, then throws a ValueError if there
            are more than n fields read by parse_qsl().

        separator: str. The symbol to use for separating the query arguments.
            Defaults to &.

        Returns a dictionary.
    'b'Parse a query given as a string argument.

        Arguments:

        qs: percent-encoded query string to be parsed

        keep_blank_values: flag indicating whether blank values in
            percent-encoded queries should be treated as blank strings.
            A true value indicates that blanks should be retained as blank
            strings.  The default false value indicates that blank values
            are to be ignored and treated as if they were  not included.

        strict_parsing: flag indicating what to do with parsing errors. If
            false (the default), errors are silently ignored. If true,
            errors raise a ValueError exception.

        encoding and errors: specify how to decode percent-encoded sequences
            into Unicode characters, as accepted by the bytes.decode() method.

        max_num_fields: int. If set, then throws a ValueError
            if there are more than n fields read by parse_qsl().

        separator: str. The symbol to use for separating the query arguments.
            Defaults to &.

        Returns a list, as G-d intended.
    'u'Parse a query given as a string argument.

        Arguments:

        qs: percent-encoded query string to be parsed

        keep_blank_values: flag indicating whether blank values in
            percent-encoded queries should be treated as blank strings.
            A true value indicates that blanks should be retained as blank
            strings.  The default false value indicates that blank values
            are to be ignored and treated as if they were  not included.

        strict_parsing: flag indicating what to do with parsing errors. If
            false (the default), errors are silently ignored. If true,
            errors raise a ValueError exception.

        encoding and errors: specify how to decode percent-encoded sequences
            into Unicode characters, as accepted by the bytes.decode() method.

        max_num_fields: int. If set, then throws a ValueError
            if there are more than n fields read by parse_qsl().

        separator: str. The symbol to use for separating the query arguments.
            Defaults to &.

        Returns a list, as G-d intended.
    'b'Separator must be of type string or bytes.'u'Separator must be of type string or bytes.'b'Max number of fields exceeded'u'Max number of fields exceeded'b'bad query field: %r'u'bad query field: %r'b'Like unquote(), but also replace plus signs by spaces, as required for
    unquoting HTML form values.

    unquote_plus('%7e/abc+def') -> '~/abc def'
    'u'Like unquote(), but also replace plus signs by spaces, as required for
    unquoting HTML form values.

    unquote_plus('%7e/abc+def') -> '~/abc def'
    'b'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789_.-~'b'Quoter'u'Quoter'b'Deprecated in 3.11. urllib.parse.Quoter will be removed in Python 3.14. It was not intended to be a public API.'u'Deprecated in 3.11. urllib.parse.Quoter will be removed in Python 3.14. It was not intended to be a public API.'b'A mapping from bytes numbers (in range(0,256)) to strings.

    String values are percent-encoded byte values, unless the key < 128, and
    in either of the specified safe set, or the always safe set.
    'u'A mapping from bytes numbers (in range(0,256)) to strings.

    String values are percent-encoded byte values, unless the key < 128, and
    in either of the specified safe set, or the always safe set.
    'b'safe: bytes object.'u'safe: bytes object.'b'<Quoter 'u'<Quoter 'b'%{:02X}'u'%{:02X}'b'quote('abc def') -> 'abc%20def'

    Each part of a URL, e.g. the path info, the query, etc., has a
    different set of reserved characters that must be quoted. The
    quote function offers a cautious (not minimal) way to quote a
    string for most of these parts.

    RFC 3986 Uniform Resource Identifier (URI): Generic Syntax lists
    the following (un)reserved characters.

    unreserved    = ALPHA / DIGIT / "-" / "." / "_" / "~"
    reserved      = gen-delims / sub-delims
    gen-delims    = ":" / "/" / "?" / "#" / "[" / "]" / "@"
    sub-delims    = "!" / "$" / "&" / "'" / "(" / ")"
                  / "*" / "+" / "," / ";" / "="

    Each of the reserved characters is reserved in some component of a URL,
    but not necessarily in all of them.

    The quote function %-escapes all characters that are neither in the
    unreserved chars ("always safe") nor the additional chars set via the
    safe arg.

    The default for the safe arg is '/'. The character is reserved, but in
    typical usage the quote function is being called on a path where the
    existing slash characters are to be preserved.

    Python 3.7 updates from using RFC 2396 to RFC 3986 to quote URL strings.
    Now, "~" is included in the set of unreserved characters.

    string and safe may be either str or bytes objects. encoding and errors
    must not be specified if string is a bytes object.

    The optional encoding and errors parameters specify how to deal with
    non-ASCII characters, as accepted by the str.encode method.
    By default, encoding='utf-8' (characters are encoded with UTF-8), and
    errors='strict' (unsupported characters raise a UnicodeEncodeError).
    'u'quote('abc def') -> 'abc%20def'

    Each part of a URL, e.g. the path info, the query, etc., has a
    different set of reserved characters that must be quoted. The
    quote function offers a cautious (not minimal) way to quote a
    string for most of these parts.

    RFC 3986 Uniform Resource Identifier (URI): Generic Syntax lists
    the following (un)reserved characters.

    unreserved    = ALPHA / DIGIT / "-" / "." / "_" / "~"
    reserved      = gen-delims / sub-delims
    gen-delims    = ":" / "/" / "?" / "#" / "[" / "]" / "@"
    sub-delims    = "!" / "$" / "&" / "'" / "(" / ")"
                  / "*" / "+" / "," / ";" / "="

    Each of the reserved characters is reserved in some component of a URL,
    but not necessarily in all of them.

    The quote function %-escapes all characters that are neither in the
    unreserved chars ("always safe") nor the additional chars set via the
    safe arg.

    The default for the safe arg is '/'. The character is reserved, but in
    typical usage the quote function is being called on a path where the
    existing slash characters are to be preserved.

    Python 3.7 updates from using RFC 2396 to RFC 3986 to quote URL strings.
    Now, "~" is included in the set of unreserved characters.

    string and safe may be either str or bytes objects. encoding and errors
    must not be specified if string is a bytes object.

    The optional encoding and errors parameters specify how to deal with
    non-ASCII characters, as accepted by the str.encode method.
    By default, encoding='utf-8' (characters are encoded with UTF-8), and
    errors='strict' (unsupported characters raise a UnicodeEncodeError).
    'b'quote() doesn't support 'encoding' for bytes'u'quote() doesn't support 'encoding' for bytes'b'quote() doesn't support 'errors' for bytes'u'quote() doesn't support 'errors' for bytes'b'Like quote(), but also replace ' ' with '+', as required for quoting
    HTML form values. Plus signs in the original string are escaped unless
    they are included in safe. It also does not have safe default to '/'.
    'u'Like quote(), but also replace ' ' with '+', as required for quoting
    HTML form values. Plus signs in the original string are escaped unless
    they are included in safe. It also does not have safe default to '/'.
    'b'Like quote(), but accepts a bytes object rather than a str, and does
    not perform string-to-bytes encoding.  It always returns an ASCII string.
    quote_from_bytes(b'abc def?') -> 'abc%20def%3f'
    'u'Like quote(), but accepts a bytes object rather than a str, and does
    not perform string-to-bytes encoding.  It always returns an ASCII string.
    quote_from_bytes(b'abc def?') -> 'abc%20def%3f'
    'b'quote_from_bytes() expected bytes'u'quote_from_bytes() expected bytes'b'Encode a dict or sequence of two-element tuples into a URL query string.

    If any values in the query arg are sequences and doseq is true, each
    sequence element is converted to a separate parameter.

    If the query arg is a sequence of two-element tuples, the order of the
    parameters in the output will match the order of parameters in the
    input.

    The components of a query arg may each be either a string or a bytes type.

    The safe, encoding, and errors parameters are passed down to the function
    specified by quote_via (encoding and errors only if a component is a str).
    'u'Encode a dict or sequence of two-element tuples into a URL query string.

    If any values in the query arg are sequences and doseq is true, each
    sequence element is converted to a separate parameter.

    If the query arg is a sequence of two-element tuples, the order of the
    parameters in the output will match the order of parameters in the
    input.

    The components of a query arg may each be either a string or a bytes type.

    The safe, encoding, and errors parameters are passed down to the function
    specified by quote_via (encoding and errors only if a component is a str).
    'b'items'b'not a valid non-string sequence or mapping object'u'not a valid non-string sequence or mapping object'b'urllib.parse.to_bytes() is deprecated as of 3.8'u'urllib.parse.to_bytes() is deprecated as of 3.8'b'to_bytes(u"URL") --> 'URL'.'u'to_bytes(u"URL") --> 'URL'.'b'URL 'u'URL 'b' contains non-ASCII characters'u' contains non-ASCII characters'b'Transform a string like '<URL:scheme://host/path>' into 'scheme://host/path'.

    The string is returned unchanged if it's not a wrapped URL.
    'u'Transform a string like '<URL:scheme://host/path>' into 'scheme://host/path'.

    The string is returned unchanged if it's not a wrapped URL.
    'b'URL:'u'URL:'b'urllib.parse.splittype() is deprecated as of 3.8, use urllib.parse.urlparse() instead'u'urllib.parse.splittype() is deprecated as of 3.8, use urllib.parse.urlparse() instead'b'splittype('type:opaquestring') --> 'type', 'opaquestring'.'u'splittype('type:opaquestring') --> 'type', 'opaquestring'.'b'([^/:]+):(.*)'u'([^/:]+):(.*)'b'urllib.parse.splithost() is deprecated as of 3.8, use urllib.parse.urlparse() instead'u'urllib.parse.splithost() is deprecated as of 3.8, use urllib.parse.urlparse() instead'b'splithost('//host[:port]/path') --> 'host[:port]', '/path'.'u'splithost('//host[:port]/path') --> 'host[:port]', '/path'.'b'//([^/#?]*)(.*)'u'//([^/#?]*)(.*)'b'urllib.parse.splituser() is deprecated as of 3.8, use urllib.parse.urlparse() instead'u'urllib.parse.splituser() is deprecated as of 3.8, use urllib.parse.urlparse() instead'b'splituser('user[:passwd]@host[:port]') --> 'user[:passwd]', 'host[:port]'.'u'splituser('user[:passwd]@host[:port]') --> 'user[:passwd]', 'host[:port]'.'b'urllib.parse.splitpasswd() is deprecated as of 3.8, use urllib.parse.urlparse() instead'u'urllib.parse.splitpasswd() is deprecated as of 3.8, use urllib.parse.urlparse() instead'b'splitpasswd('user:passwd') -> 'user', 'passwd'.'u'splitpasswd('user:passwd') -> 'user', 'passwd'.'b'urllib.parse.splitport() is deprecated as of 3.8, use urllib.parse.urlparse() instead'u'urllib.parse.splitport() is deprecated as of 3.8, use urllib.parse.urlparse() instead'b'splitport('host:port') --> 'host', 'port'.'u'splitport('host:port') --> 'host', 'port'.'b'(.*):([0-9]*)'u'(.*):([0-9]*)'b'urllib.parse.splitnport() is deprecated as of 3.8, use urllib.parse.urlparse() instead'u'urllib.parse.splitnport() is deprecated as of 3.8, use urllib.parse.urlparse() instead'b'Split host and port, returning numeric port.
    Return given default port if no ':' found; defaults to -1.
    Return numerical port if a valid number is found after ':'.
    Return None if ':' but not a valid number.'u'Split host and port, returning numeric port.
    Return given default port if no ':' found; defaults to -1.
    Return numerical port if a valid number is found after ':'.
    Return None if ':' but not a valid number.'b'urllib.parse.splitquery() is deprecated as of 3.8, use urllib.parse.urlparse() instead'u'urllib.parse.splitquery() is deprecated as of 3.8, use urllib.parse.urlparse() instead'b'splitquery('/path?query') --> '/path', 'query'.'u'splitquery('/path?query') --> '/path', 'query'.'b'urllib.parse.splittag() is deprecated as of 3.8, use urllib.parse.urlparse() instead'u'urllib.parse.splittag() is deprecated as of 3.8, use urllib.parse.urlparse() instead'b'splittag('/path#tag') --> '/path', 'tag'.'u'splittag('/path#tag') --> '/path', 'tag'.'b'urllib.parse.splitattr() is deprecated as of 3.8, use urllib.parse.urlparse() instead'u'urllib.parse.splitattr() is deprecated as of 3.8, use urllib.parse.urlparse() instead'b'splitattr('/path;attr1=value1;attr2=value2;...') ->
        '/path', ['attr1=value1', 'attr2=value2', ...].'u'splitattr('/path;attr1=value1;attr2=value2;...') ->
        '/path', ['attr1=value1', 'attr2=value2', ...].'b'urllib.parse.splitvalue() is deprecated as of 3.8, use urllib.parse.parse_qsl() instead'u'urllib.parse.splitvalue() is deprecated as of 3.8, use urllib.parse.parse_qsl() instead'b'splitvalue('attr=value') --> 'attr', 'value'.'u'splitvalue('attr=value') --> 'attr', 'value'.'u'Lib.urllib.parse'u'parse'A parser of RFC 2822 and MIME email messages.HeaderParserBytesHeaderParseremail.feedparserParser of RFC 2822 and MIME email messages.

        Creates an in-memory object tree representing the email message, which
        can then be manipulated and turned over to a Generator to return the
        textual representation of the message.

        The string must be formatted as a block of RFC 2822 headers and header
        continuation lines, optionally preceded by a `Unix-from' header.  The
        header block is terminated either by the end of the string or by a
        blank line.

        _class is the class to instantiate for new message objects when they
        must be created.  This class must have a constructor that can take
        zero arguments.  Default is Message.Message.

        The policy keyword specifies a policy object that controls a number of
        aspects of the parser's operation.  The default policy maintains
        backward compatibility.

        headersonlyCreate a message structure from the data in a file.

        Reads all the data from the file and returns the root of the message
        structure.  Optional headersonly is a flag specifying whether to stop
        parsing after reading the headers or not.  The default is False,
        meaning it parses the entire contents of the file.
        Create a message structure from a string.

        Returns the root of the message structure.  Optional headersonly is a
        flag specifying whether to stop parsing after reading the headers or
        not.  The default is False, meaning it parses the entire contents of
        the file.
        Parser of binary RFC 2822 and MIME email messages.

        Creates an in-memory object tree representing the email message, which
        can then be manipulated and turned over to a Generator to return the
        textual representation of the message.

        The input must be formatted as a block of RFC 2822 headers and header
        continuation lines, optionally preceded by a `Unix-from' header.  The
        header block is terminated either by the end of the input or by a
        blank line.

        _class is the class to instantiate for new message objects when they
        must be created.  This class must have a constructor that can take
        zero arguments.  Default is Message.Message.
        Create a message structure from the data in a binary file.

        Reads all the data from the file and returns the root of the message
        structure.  Optional headersonly is a flag specifying whether to stop
        parsing after reading the headers or not.  The default is False,
        meaning it parses the entire contents of the file.
        Create a message structure from a byte string.

        Returns the root of the message structure.  Optional headersonly is a
        flag specifying whether to stop parsing after reading the headers or
        not.  The default is False, meaning it parses the entire contents of
        the file.
        # Author: Barry Warsaw, Thomas Wouters, Anthony Baxterb'A parser of RFC 2822 and MIME email messages.'u'A parser of RFC 2822 and MIME email messages.'b'Parser'u'Parser'b'HeaderParser'u'HeaderParser'b'BytesParser'u'BytesParser'b'BytesHeaderParser'u'BytesHeaderParser'b'Parser of RFC 2822 and MIME email messages.

        Creates an in-memory object tree representing the email message, which
        can then be manipulated and turned over to a Generator to return the
        textual representation of the message.

        The string must be formatted as a block of RFC 2822 headers and header
        continuation lines, optionally preceded by a `Unix-from' header.  The
        header block is terminated either by the end of the string or by a
        blank line.

        _class is the class to instantiate for new message objects when they
        must be created.  This class must have a constructor that can take
        zero arguments.  Default is Message.Message.

        The policy keyword specifies a policy object that controls a number of
        aspects of the parser's operation.  The default policy maintains
        backward compatibility.

        'u'Parser of RFC 2822 and MIME email messages.

        Creates an in-memory object tree representing the email message, which
        can then be manipulated and turned over to a Generator to return the
        textual representation of the message.

        The string must be formatted as a block of RFC 2822 headers and header
        continuation lines, optionally preceded by a `Unix-from' header.  The
        header block is terminated either by the end of the string or by a
        blank line.

        _class is the class to instantiate for new message objects when they
        must be created.  This class must have a constructor that can take
        zero arguments.  Default is Message.Message.

        The policy keyword specifies a policy object that controls a number of
        aspects of the parser's operation.  The default policy maintains
        backward compatibility.

        'b'Create a message structure from the data in a file.

        Reads all the data from the file and returns the root of the message
        structure.  Optional headersonly is a flag specifying whether to stop
        parsing after reading the headers or not.  The default is False,
        meaning it parses the entire contents of the file.
        'u'Create a message structure from the data in a file.

        Reads all the data from the file and returns the root of the message
        structure.  Optional headersonly is a flag specifying whether to stop
        parsing after reading the headers or not.  The default is False,
        meaning it parses the entire contents of the file.
        'b'Create a message structure from a string.

        Returns the root of the message structure.  Optional headersonly is a
        flag specifying whether to stop parsing after reading the headers or
        not.  The default is False, meaning it parses the entire contents of
        the file.
        'u'Create a message structure from a string.

        Returns the root of the message structure.  Optional headersonly is a
        flag specifying whether to stop parsing after reading the headers or
        not.  The default is False, meaning it parses the entire contents of
        the file.
        'b'Parser of binary RFC 2822 and MIME email messages.

        Creates an in-memory object tree representing the email message, which
        can then be manipulated and turned over to a Generator to return the
        textual representation of the message.

        The input must be formatted as a block of RFC 2822 headers and header
        continuation lines, optionally preceded by a `Unix-from' header.  The
        header block is terminated either by the end of the input or by a
        blank line.

        _class is the class to instantiate for new message objects when they
        must be created.  This class must have a constructor that can take
        zero arguments.  Default is Message.Message.
        'u'Parser of binary RFC 2822 and MIME email messages.

        Creates an in-memory object tree representing the email message, which
        can then be manipulated and turned over to a Generator to return the
        textual representation of the message.

        The input must be formatted as a block of RFC 2822 headers and header
        continuation lines, optionally preceded by a `Unix-from' header.  The
        header block is terminated either by the end of the input or by a
        blank line.

        _class is the class to instantiate for new message objects when they
        must be created.  This class must have a constructor that can take
        zero arguments.  Default is Message.Message.
        'b'Create a message structure from the data in a binary file.

        Reads all the data from the file and returns the root of the message
        structure.  Optional headersonly is a flag specifying whether to stop
        parsing after reading the headers or not.  The default is False,
        meaning it parses the entire contents of the file.
        'u'Create a message structure from the data in a binary file.

        Reads all the data from the file and returns the root of the message
        structure.  Optional headersonly is a flag specifying whether to stop
        parsing after reading the headers or not.  The default is False,
        meaning it parses the entire contents of the file.
        'b'Create a message structure from a byte string.

        Returns the root of the message structure.  Optional headersonly is a
        flag specifying whether to stop parsing after reading the headers or
        not.  The default is False, meaning it parses the entire contents of
        the file.
        'u'Create a message structure from a byte string.

        Returns the root of the message structure.  Optional headersonly is a
        flag specifying whether to stop parsing after reading the headers or
        not.  The default is False, meaning it parses the entire contents of
        the file.
        'u'Lib.email.parser'u'email.parser'Object-oriented filesystem paths.

This module provides classes to represent abstract paths and concrete
paths with operations that have semantics appropriate for different
operating systems.
urlquote_from_bytesPurePathPureWindowsPathPosixPathWindowsPathCONPRNAUXNULCONIN$CONOUT$COM123456789LPT_WIN_RESERVED_NAMES_WINERROR_NOT_READY_WINERROR_INVALID_NAME_WINERROR_CANT_RESOLVE_FILENAME_IGNORED_ERRNOS_IGNORED_WINERRORS_ignore_error_is_case_sensitiveflavourAa_FNMATCH_PREFIX_FNMATCH_SUFFIX_FNMATCH_SLICE_SWAP_SEP_AND_NEWLINE_make_selectorpattern_partscase_sensitive_TerminatingSelectorchild_parts_idxchild_parts_DoubleRecursiveWildcardSelector_RecursiveWildcardSelector_ParentSelectorInvalid pattern: '**' can only be an entire path component_WildcardSelector_compile_pattern_linespattern_linesCompile the given pattern lines to an `re.Pattern` object.

    The *pattern_lines* argument is a glob-style pattern (e.g. '*/*.py') with
    its path separators and newlines swapped (e.g. '*
*.py`). By using
    newlines to separate path components, and not setting `re.DOTALL`, we
    ensure that the `*` wildcard cannot match path separators.

    The returned `re.Pattern` object may have its `match()` method called to
    match a complete pattern, or `search()` to match from the right. The
    argument supplied to these methods must also have its path separators and
    newlines swapped.
    *
.+\n.+_SelectorA selector matches a specific glob pattern part against the children
    of a given path.successorselect_fromIterate over all child paths of `parent_path` matched by this
        selector.  This can contain parent_path itself.path_cls_scandir_select_from_make_child_relpath_iterate_directoriesdirpathdirnamessuccessor_selectstarting_point
    Like _RecursiveWildcardSelector, but also de-duplicates results from
    successive selectors. This is necessary if the pattern contains
    multiple non-adjacent '**' segments.
    yielded_PathParentsThis object provides sequence-like access to the logical ancestors
    of a path.  Don't try to construct it yourself._drv_root_tail_from_parsed_parts<{}.parents>Base class for manipulating paths without I/O.

    PurePath represents a filesystem path and offers operations which
    don't imply any actual filesystem I/O.  Depending on your system,
    instantiating a PurePath will return either a PurePosixPath or a
    PureWindowsPath object.  You can also instantiate either of these classes
    directly, regardless of your system.
    _raw_paths_tail_cached_str_normcase_cached_parts_normcase_cached_lines_cached_flavourConstruct a PurePath from one or several strings and or existing
        PurePath objects.  The strings and path objects are combined so as
        to yield a canonicalized path, which is incorporated into the
        new PurePath object.
        argument should be a str or an os.PathLike object where __fspath__ returns a str, not "argument should be a str or an os.PathLike ""object where __fspath__ returns a str, "with_segmentspathsegmentsConstruct a new path object from any number of path-like objects.
        Subclasses may override this method to customize how new path objects
        are created from methods like `iterdir()`.
        _parse_pathdrvreldrv_parts?.parsed_load_parts_format_parsed_partspath_strReturn the string representation of the path, suitable for
        passing to system calls.as_posixReturn the string representation of the path with forward (/)
        slashes.Return the bytes representation of the path.  This is only
        recommended to use under Unix.as_uriReturn the path as a 'file' URI.is_absoluterelative path can't be expressed as a file URIfile:///file:file://_str_normcase_parts_normcaseThe drive prefix (letter or UNC path), if any.The root of the path, if any.anchorThe concatenation of the drive and root, or ''.The final path component, if any.
        The final component's last suffix, if any.

        This includes the leading period. For example: '.txt'
        
        A list of the final component's suffixes, if any.

        These include the leading periods. For example: ['.tar', '.gz']
        The final path component, minus its last suffix.with_nameReturn a new path with the file name changed.%r has an empty nameInvalid name %rwith_stemReturn a new path with the stem changed.with_suffixReturn a new path with the file suffix changed.  If the path
        has no suffix, add given suffix.  If the given suffix is an empty
        string, remove the suffix from the path.
        Invalid suffix %rold_suffixwalk_upReturn the relative path to another path identified by the passed
        arguments.  If the operation is not possible (because this is not
        related to the other path), raise ValueError.

        The *walk_up* parameter controls whether `..` may be used to resolve
        the path.
        support for supplying more than one positional argument to pathlib.PurePath.relative_to() is deprecated and scheduled for removal in Python {remove}"support for supplying more than one positional argument ""to pathlib.PurePath.relative_to() is deprecated and ""scheduled for removal in Python {remove}"pathlib.PurePath.relative_to(*args)is_relative_to is not in the subpath of '..' segment in  cannot be walked have different anchorsReturn True if the path is relative to another path or False.
        support for supplying more than one argument to pathlib.PurePath.is_relative_to() is deprecated and scheduled for removal in Python {remove}"support for supplying more than one argument to ""pathlib.PurePath.is_relative_to() is deprecated and "pathlib.PurePath.is_relative_to(*args)An object providing sequence-like access to the
        components in the filesystem path.Combine this path with one or several arguments, and return a
        new path representing either a subpath (if all arguments are relative
        paths) or a totally different path (if one of the arguments is
        anchored).
        The logical parent of the path.A sequence of this path's logical parents.True if the path is absolute (has both a root and, if applicable,
        a drive).Return True if the path contains one of the special names reserved
        by the system, if any.
        Return True if this path matches the given pattern.
        empty patternPurePath subclass for non-Windows systems.

    On a POSIX system, instantiating a PurePath should return this object.
    However, you can also instantiate it directly on any system.
    PurePath subclass for Windows systems.

    On a Windows system, instantiating a PurePath should return this object.
    However, you can also instantiate it directly on any system.
    PurePath subclass that can make system calls.

    Path represents a filesystem path but unlike PurePath, also offers
    methods to do system calls on path objects. Depending on your system,
    instantiating a Path will return either a PosixPath or a WindowsPath
    object. You can also instantiate a PosixPath or WindowsPath directly,
    but cannot instantiate a WindowsPath on a POSIX system or vice versa.
    
        Return the result of the stat() system call on this path, like
        os.stat() does.
        
        Like stat(), except if the path points to a symlink, the symlink's
        status information is returned, rather than its target's.
        
        Whether this path exists.

        This method normally follows symlinks; to check whether a symlink exists,
        add the argument follow_symlinks=False.
        
        Whether this path is a directory.
        
        Whether this path is a regular file (also True for symlinks pointing
        to regular files).
        is_mount
        Check if this path is a mount point
        
        Whether this path is a symbolic link.
        
        Whether this path is a junction.
        is_block_device
        Whether this path is a block device.
        is_char_device
        Whether this path is a character device.
        is_fifo
        Whether this path is a FIFO.
        is_socket
        Whether this path is a socket.
        other_pathReturn whether other_path is the same or not as this file
        (as returned by os.path.samefile()).
        other_st
        Open the file pointed to by this path and return a file object, as
        the built-in open() function does.
        
        Open the file in bytes mode, read it, and close the file.
        
        Open the file in text mode, read it, and close the file.
        write_bytes
        Open the file in bytes mode, write to it, and close the file.
        write_text
        Open the file in text mode, write to it, and close the file.
        data must be str, not %sYield path objects of the directory contents.

        The children are yielded in arbitrary order, and the
        special entries '.' and '..' are not included.
        Iterate over this subtree and yield all existing files (of any
        kind, including directories) matching the given relative pattern.
        pathlib.Path.globUnacceptable pattern: {!r}Non-relative patterns are unsupportedRecursively yield all existing files (of any kind, including
        directories) matching the given relative pattern, anywhere in
        this subtree.
        pathlib.Path.rglobtop_downon_errorWalk the directory tree from this directory, similar to os.walk().pathlib.Path.walksupport for supplying keyword arguments to pathlib.PurePath is deprecated and scheduled for removal in Python {remove}"support for supplying keyword arguments to pathlib.PurePath ""is deprecated and scheduled for removal in Python {remove}"pathlib.PurePath(**kwargs)pathlib.Path.__enter__() is deprecated and scheduled for removal in Python 3.13; Path objects as a context manager is a no-op"pathlib.Path.__enter__() is deprecated and scheduled ""for removal in Python 3.13; Path objects as a context ""manager is a no-op"Return a new path pointing to the current working directory.absolutehomeReturn a new path pointing to the user's home directory (as
        returned by os.path.expanduser('~')).
        Return an absolute version of this path by prepending the current
        working directory. No normalization or symlink resolution is performed.

        Use resolve() to get the canonical path to a file.
        resolve
        Make the path absolute, resolving all symlinks on the way and also
        normalizing it.
        check_eloopSymlink loop from %r
        Return the login name of the file owner.
        getpwuidpw_namePath.owner() is unsupported on this system
        Return the group name of the file gid.
        grpgetgrgidgr_namePath.group() is unsupported on this system
        Return the path to which the symbolic link points.
        os.readlink() not available on this systemtouch
        Create this file with the given access mode, if it doesn't exist.
        
        Create a new directory at this given path.
        
        Change the permissions of the path, like os.chmod().
        lchmod
        Like chmod(), except if the path points to a symlink, the symlink's
        permissions are changed, rather than its target's.
        missing_ok
        Remove this file or link.
        If the path is a directory, use rmdir() instead.
        
        Remove this directory.  The directory must be empty.
        
        Rename this path to the target path.

        The target path may be absolute or relative. Relative paths are
        interpreted relative to the current working directory, *not* the
        directory of the Path object.

        Returns the new Path instance pointing to the target path.
        
        Rename this path to the target path, overwriting if that path exists.

        The target path may be absolute or relative. Relative paths are
        interpreted relative to the current working directory, *not* the
        directory of the Path object.

        Returns the new Path instance pointing to the target path.
        symlink_totarget_is_directory
        Make this path a symlink pointing to the target path.
        Note the order of arguments (link, target) is the reverse of os.symlink.
        os.symlink() not available on this systemhardlink_to
        Make this path a hard link pointing to the same file as *target*.

        Note the order of arguments (self, target) is the reverse of os.link's.
        os.link() not available on this system Return a new path with expanded ~ and ~user constructs
        (as returned by os.path.expanduser)
        homedirCould not determine home directory.Path subclass for non-Windows systems.

    On a POSIX system, instantiating a Path should return this object.
    cannot instantiate  on your systemPath subclass for Windows systems.

    On a Windows system, instantiating a Path should return this object.
    # Internals# Reference for Windows paths can be found at# https://learn.microsoft.com/en-gb/windows/win32/fileio/naming-a-file .# drive exists but is not accessible# fix for bpo-35306# broken symlink pointing to itself# EBADF - guard against macOS `stat` throwing EBADF# Globbing helpers# fnmatch.translate() returns a regular expression that includes a prefix and# a suffix, which enable matching newlines and ensure the end of the string is# matched, respectively. These features are undesirable for our implementation# of PurePatch.match(), which represents path separators as newlines and joins# pattern segments together. As a workaround, we define a slice object that# can remove the prefix and suffix from any translate() result. See the# _compile_pattern_lines() function for more details.# Match the start of the path, or just after a path separator# Any other component: pass to fnmatch.translate(). We slice off# the common prefix and suffix added by translate() to ensure that# re.DOTALL is not set, and the end of the string not matched,# respectively. With DOTALL not set, '*' wildcards will not match# path separators, because the '.' characters in the pattern will# not match newlines.# Match the end of the path, always.# TODO: evaluate case-sensitivity of each directory in _select_from()# We must close the scandir() object before proceeding to# avoid exhausting file descriptors when globbing deep trees.# Public API# The `_raw_paths` slot stores unnormalized string paths. This is set# in the `__init__()` method.# The `_drv`, `_root` and `_tail_cached` slots store parsed and# normalized parts of the path. They are set when any of the `drive`,# `root` or `_tail` properties are accessed for the first time. The# three-part division corresponds to the result of# `os.path.splitroot()`, except that the tail is further split on path# separators (i.e. it is a list of strings), and that the root and# tail are normalized.# The `_str` slot stores the string representation of the path,# computed from the drive, root and tail when `__str__()` is called# for the first time. It's used to implement `_str_normcase`# The `_str_normcase_cached` slot stores the string path with# normalized case. It is set when the `_str_normcase` property is# accessed for the first time. It's used to implement `__eq__()`# `__hash__()`, and `_parts_normcase`# The `_parts_normcase_cached` slot stores the case-normalized# string path after splitting on path separators. It's set when the# `_parts_normcase` property is accessed for the first time. It's used# to implement comparison methods like `__lt__()`.# The `_lines_cached` slot stores the string path with path separators# and newlines swapped. This is used to implement `match()`.# The `_hash` slot stores the hash of the case-normalized string# path. It's set when `__hash__()` is called for the first time.# Using the parts tuple helps share interned path parts# when pickling related paths.# GH-103631: Convert separators for backwards compatibility.# e.g. //server/share# e.g. //?/unc/server/share# It's a path on a local drive => 'file:///c:/a/b'# It's a path on a network drive => 'file://host/share/a/b'# It's a posix path => 'file:///etc/hosts'# String with normalized case, for hashing and equality checks# Cached parts with normalized case, for comparisons.# Path with separators and newlines swapped, for pattern matching.# The value of this property should not be cached on the path object,# as doing so would introduce a reference cycle.# ntpath.isabs() is defective - see GH-44626.# Optimization: work with raw paths on POSIX.# NOTE: the rules for reserved names seem somewhat complicated# (e.g. r"..\NUL" is reserved but not r"foo\NUL" if "foo" does not# exist). We err on the side of caution and return True for paths# which are not considered reserved by Windows.# UNC paths are never reserved.# Can't subclass os.PathLike from PurePath and keep the constructor# optimizations in PurePath.__slots__.# Filesystem-accessing classes# Convenience functions for querying the stat results# Non-encodable path# Path doesn't exist or is a broken symlink# (see http://web.archive.org/web/20200623061726/https://bitbucket.org/pitrou/pathlib/issues/12/ )# Path doesn't exist# type-check for the buffer interface before truncating the file# bpo-24132: a future version of pathlib will support subclassing of# pathlib.Path to customize how the filesystem is accessed. This# includes scandir(), which is used to implement glob().# We may not have read permission for self, in which case we can't# get a list of the files the directory contains. os.walk()# always suppressed the exception in that instance, rather than# blow up for a minor reason when (say) a thousand readable# directories are still left to visit. That logic is copied here.# Carried over from os.path.isdir().# In previous versions of pathlib, __exit__() marked this path as# closed; subsequent attempts to perform I/O would raise an IOError.# This functionality was never documented, and had the effect of# making Path objects mutable, contrary to PEP 428.# In Python 3.9 __exit__() was made a no-op.# In Python 3.11 __enter__() began emitting DeprecationWarning.# In Python 3.13 __enter__() and __exit__() should be removed.# We call 'absolute()' rather than using 'os.getcwd()' directly to# enable users to replace the implementation of 'absolute()' in a# subclass and benefit from the new behaviour here. This works because# os.path.abspath('.') == os.getcwd().# There is a CWD on each drive-letter drive.# Fast path for "empty" paths, e.g. Path("."), Path("") or Path().# We pass only one argument to with_segments() to avoid the cost# of joining, and we exploit the fact that getcwd() returns a# fully-normalized string by storing it in _str. This is used to# implement Path.cwd().# In non-strict mode, realpath() doesn't raise on symlink loops.# Ensure we get an exception by calling stat()# First try to bump modification time# Implementation note: GNU touch uses the UTIME_NOW option of# the utimensat() / futimens() functions.# Avoid exception chainingb'Object-oriented filesystem paths.

This module provides classes to represent abstract paths and concrete
paths with operations that have semantics appropriate for different
operating systems.
'u'Object-oriented filesystem paths.

This module provides classes to represent abstract paths and concrete
paths with operations that have semantics appropriate for different
operating systems.
'b'PurePath'u'PurePath'b'PurePosixPath'u'PurePosixPath'b'PureWindowsPath'u'PureWindowsPath'b'PosixPath'u'PosixPath'b'WindowsPath'u'WindowsPath'b'CON'u'CON'b'PRN'u'PRN'b'AUX'u'AUX'b'NUL'u'NUL'b'CONIN$'u'CONIN$'b'CONOUT$'u'CONOUT$'b'COM'u'COM'b'123456789'u'123456789'b'LPT'u'LPT'b'errno'b'winerror'u'winerror'b'Aa'u'Aa'b'Invalid pattern: '**' can only be an entire path component'u'Invalid pattern: '**' can only be an entire path component'b'Compile the given pattern lines to an `re.Pattern` object.

    The *pattern_lines* argument is a glob-style pattern (e.g. '*/*.py') with
    its path separators and newlines swapped (e.g. '*
*.py`). By using
    newlines to separate path components, and not setting `re.DOTALL`, we
    ensure that the `*` wildcard cannot match path separators.

    The returned `re.Pattern` object may have its `match()` method called to
    match a complete pattern, or `search()` to match from the right. The
    argument supplied to these methods must also have its path separators and
    newlines swapped.
    'u'Compile the given pattern lines to an `re.Pattern` object.

    The *pattern_lines* argument is a glob-style pattern (e.g. '*/*.py') with
    its path separators and newlines swapped (e.g. '*
*.py`). By using
    newlines to separate path components, and not setting `re.DOTALL`, we
    ensure that the `*` wildcard cannot match path separators.

    The returned `re.Pattern` object may have its `match()` method called to
    match a complete pattern, or `search()` to match from the right. The
    argument supplied to these methods must also have its path separators and
    newlines swapped.
    'b'*
'u'*
'b'.+\n'u'.+\n'b'.+'u'.+'b'A selector matches a specific glob pattern part against the children
    of a given path.'u'A selector matches a specific glob pattern part against the children
    of a given path.'b'Iterate over all child paths of `parent_path` matched by this
        selector.  This can contain parent_path itself.'u'Iterate over all child paths of `parent_path` matched by this
        selector.  This can contain parent_path itself.'b'
    Like _RecursiveWildcardSelector, but also de-duplicates results from
    successive selectors. This is necessary if the pattern contains
    multiple non-adjacent '**' segments.
    'u'
    Like _RecursiveWildcardSelector, but also de-duplicates results from
    successive selectors. This is necessary if the pattern contains
    multiple non-adjacent '**' segments.
    'b'This object provides sequence-like access to the logical ancestors
    of a path.  Don't try to construct it yourself.'u'This object provides sequence-like access to the logical ancestors
    of a path.  Don't try to construct it yourself.'b'_path'b'_drv'u'_drv'b'_root'u'_root'b'_tail'u'_tail'b'<{}.parents>'u'<{}.parents>'b'Base class for manipulating paths without I/O.

    PurePath represents a filesystem path and offers operations which
    don't imply any actual filesystem I/O.  Depending on your system,
    instantiating a PurePath will return either a PurePosixPath or a
    PureWindowsPath object.  You can also instantiate either of these classes
    directly, regardless of your system.
    'u'Base class for manipulating paths without I/O.

    PurePath represents a filesystem path and offers operations which
    don't imply any actual filesystem I/O.  Depending on your system,
    instantiating a PurePath will return either a PurePosixPath or a
    PureWindowsPath object.  You can also instantiate either of these classes
    directly, regardless of your system.
    'b'_raw_paths'u'_raw_paths'b'_tail_cached'u'_tail_cached'b'_str'u'_str'b'_str_normcase_cached'u'_str_normcase_cached'b'_parts_normcase_cached'u'_parts_normcase_cached'b'_lines_cached'u'_lines_cached'b'_hash'u'_hash'b'Construct a PurePath from one or several strings and or existing
        PurePath objects.  The strings and path objects are combined so as
        to yield a canonicalized path, which is incorporated into the
        new PurePath object.
        'u'Construct a PurePath from one or several strings and or existing
        PurePath objects.  The strings and path objects are combined so as
        to yield a canonicalized path, which is incorporated into the
        new PurePath object.
        'b'argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'u'argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'b'Construct a new path object from any number of path-like objects.
        Subclasses may override this method to customize how new path objects
        are created from methods like `iterdir()`.
        'u'Construct a new path object from any number of path-like objects.
        Subclasses may override this method to customize how new path objects
        are created from methods like `iterdir()`.
        'b'?.'u'?.'b'Return the string representation of the path, suitable for
        passing to system calls.'u'Return the string representation of the path, suitable for
        passing to system calls.'b'Return the string representation of the path with forward (/)
        slashes.'u'Return the string representation of the path with forward (/)
        slashes.'b'Return the bytes representation of the path.  This is only
        recommended to use under Unix.'u'Return the bytes representation of the path.  This is only
        recommended to use under Unix.'b'Return the path as a 'file' URI.'u'Return the path as a 'file' URI.'b'relative path can't be expressed as a file URI'u'relative path can't be expressed as a file URI'b'file:///'u'file:///'b'file:'u'file:'b'file://'u'file://'b'The drive prefix (letter or UNC path), if any.'u'The drive prefix (letter or UNC path), if any.'b'The root of the path, if any.'u'The root of the path, if any.'b'The concatenation of the drive and root, or ''.'u'The concatenation of the drive and root, or ''.'b'The final path component, if any.'u'The final path component, if any.'b'
        The final component's last suffix, if any.

        This includes the leading period. For example: '.txt'
        'u'
        The final component's last suffix, if any.

        This includes the leading period. For example: '.txt'
        'b'
        A list of the final component's suffixes, if any.

        These include the leading periods. For example: ['.tar', '.gz']
        'u'
        A list of the final component's suffixes, if any.

        These include the leading periods. For example: ['.tar', '.gz']
        'b'The final path component, minus its last suffix.'u'The final path component, minus its last suffix.'b'Return a new path with the file name changed.'u'Return a new path with the file name changed.'b'%r has an empty name'u'%r has an empty name'b'Invalid name %r'u'Invalid name %r'b'Return a new path with the stem changed.'u'Return a new path with the stem changed.'b'Return a new path with the file suffix changed.  If the path
        has no suffix, add given suffix.  If the given suffix is an empty
        string, remove the suffix from the path.
        'u'Return a new path with the file suffix changed.  If the path
        has no suffix, add given suffix.  If the given suffix is an empty
        string, remove the suffix from the path.
        'b'Invalid suffix %r'u'Invalid suffix %r'b'Return the relative path to another path identified by the passed
        arguments.  If the operation is not possible (because this is not
        related to the other path), raise ValueError.

        The *walk_up* parameter controls whether `..` may be used to resolve
        the path.
        'u'Return the relative path to another path identified by the passed
        arguments.  If the operation is not possible (because this is not
        related to the other path), raise ValueError.

        The *walk_up* parameter controls whether `..` may be used to resolve
        the path.
        'b'support for supplying more than one positional argument to pathlib.PurePath.relative_to() is deprecated and scheduled for removal in Python {remove}'u'support for supplying more than one positional argument to pathlib.PurePath.relative_to() is deprecated and scheduled for removal in Python {remove}'b'pathlib.PurePath.relative_to(*args)'u'pathlib.PurePath.relative_to(*args)'b' is not in the subpath of 'u' is not in the subpath of 'b''..' segment in 'u''..' segment in 'b' cannot be walked'u' cannot be walked'b' have different anchors'u' have different anchors'b'Return True if the path is relative to another path or False.
        'u'Return True if the path is relative to another path or False.
        'b'support for supplying more than one argument to pathlib.PurePath.is_relative_to() is deprecated and scheduled for removal in Python {remove}'u'support for supplying more than one argument to pathlib.PurePath.is_relative_to() is deprecated and scheduled for removal in Python {remove}'b'pathlib.PurePath.is_relative_to(*args)'u'pathlib.PurePath.is_relative_to(*args)'b'An object providing sequence-like access to the
        components in the filesystem path.'u'An object providing sequence-like access to the
        components in the filesystem path.'b'Combine this path with one or several arguments, and return a
        new path representing either a subpath (if all arguments are relative
        paths) or a totally different path (if one of the arguments is
        anchored).
        'u'Combine this path with one or several arguments, and return a
        new path representing either a subpath (if all arguments are relative
        paths) or a totally different path (if one of the arguments is
        anchored).
        'b'The logical parent of the path.'u'The logical parent of the path.'b'A sequence of this path's logical parents.'u'A sequence of this path's logical parents.'b'True if the path is absolute (has both a root and, if applicable,
        a drive).'u'True if the path is absolute (has both a root and, if applicable,
        a drive).'b'Return True if the path contains one of the special names reserved
        by the system, if any.'u'Return True if the path contains one of the special names reserved
        by the system, if any.'b'
        Return True if this path matches the given pattern.
        'u'
        Return True if this path matches the given pattern.
        'b'empty pattern'u'empty pattern'b'PurePath subclass for non-Windows systems.

    On a POSIX system, instantiating a PurePath should return this object.
    However, you can also instantiate it directly on any system.
    'u'PurePath subclass for non-Windows systems.

    On a POSIX system, instantiating a PurePath should return this object.
    However, you can also instantiate it directly on any system.
    'b'PurePath subclass for Windows systems.

    On a Windows system, instantiating a PurePath should return this object.
    However, you can also instantiate it directly on any system.
    'u'PurePath subclass for Windows systems.

    On a Windows system, instantiating a PurePath should return this object.
    However, you can also instantiate it directly on any system.
    'b'PurePath subclass that can make system calls.

    Path represents a filesystem path but unlike PurePath, also offers
    methods to do system calls on path objects. Depending on your system,
    instantiating a Path will return either a PosixPath or a WindowsPath
    object. You can also instantiate a PosixPath or WindowsPath directly,
    but cannot instantiate a WindowsPath on a POSIX system or vice versa.
    'u'PurePath subclass that can make system calls.

    Path represents a filesystem path but unlike PurePath, also offers
    methods to do system calls on path objects. Depending on your system,
    instantiating a Path will return either a PosixPath or a WindowsPath
    object. You can also instantiate a PosixPath or WindowsPath directly,
    but cannot instantiate a WindowsPath on a POSIX system or vice versa.
    'b'
        Return the result of the stat() system call on this path, like
        os.stat() does.
        'u'
        Return the result of the stat() system call on this path, like
        os.stat() does.
        'b'
        Like stat(), except if the path points to a symlink, the symlink's
        status information is returned, rather than its target's.
        'u'
        Like stat(), except if the path points to a symlink, the symlink's
        status information is returned, rather than its target's.
        'b'
        Whether this path exists.

        This method normally follows symlinks; to check whether a symlink exists,
        add the argument follow_symlinks=False.
        'u'
        Whether this path exists.

        This method normally follows symlinks; to check whether a symlink exists,
        add the argument follow_symlinks=False.
        'b'
        Whether this path is a directory.
        'u'
        Whether this path is a directory.
        'b'
        Whether this path is a regular file (also True for symlinks pointing
        to regular files).
        'u'
        Whether this path is a regular file (also True for symlinks pointing
        to regular files).
        'b'
        Check if this path is a mount point
        'u'
        Check if this path is a mount point
        'b'
        Whether this path is a symbolic link.
        'u'
        Whether this path is a symbolic link.
        'b'
        Whether this path is a junction.
        'u'
        Whether this path is a junction.
        'b'
        Whether this path is a block device.
        'u'
        Whether this path is a block device.
        'b'
        Whether this path is a character device.
        'u'
        Whether this path is a character device.
        'b'
        Whether this path is a FIFO.
        'u'
        Whether this path is a FIFO.
        'b'
        Whether this path is a socket.
        'u'
        Whether this path is a socket.
        'b'Return whether other_path is the same or not as this file
        (as returned by os.path.samefile()).
        'u'Return whether other_path is the same or not as this file
        (as returned by os.path.samefile()).
        'b'
        Open the file pointed to by this path and return a file object, as
        the built-in open() function does.
        'u'
        Open the file pointed to by this path and return a file object, as
        the built-in open() function does.
        'b'
        Open the file in bytes mode, read it, and close the file.
        'u'
        Open the file in bytes mode, read it, and close the file.
        'b'
        Open the file in text mode, read it, and close the file.
        'u'
        Open the file in text mode, read it, and close the file.
        'b'
        Open the file in bytes mode, write to it, and close the file.
        'u'
        Open the file in bytes mode, write to it, and close the file.
        'b'
        Open the file in text mode, write to it, and close the file.
        'u'
        Open the file in text mode, write to it, and close the file.
        'b'data must be str, not %s'u'data must be str, not %s'b'Yield path objects of the directory contents.

        The children are yielded in arbitrary order, and the
        special entries '.' and '..' are not included.
        'u'Yield path objects of the directory contents.

        The children are yielded in arbitrary order, and the
        special entries '.' and '..' are not included.
        'b'Iterate over this subtree and yield all existing files (of any
        kind, including directories) matching the given relative pattern.
        'u'Iterate over this subtree and yield all existing files (of any
        kind, including directories) matching the given relative pattern.
        'b'pathlib.Path.glob'u'pathlib.Path.glob'b'Unacceptable pattern: {!r}'u'Unacceptable pattern: {!r}'b'Non-relative patterns are unsupported'u'Non-relative patterns are unsupported'b'Recursively yield all existing files (of any kind, including
        directories) matching the given relative pattern, anywhere in
        this subtree.
        'u'Recursively yield all existing files (of any kind, including
        directories) matching the given relative pattern, anywhere in
        this subtree.
        'b'pathlib.Path.rglob'u'pathlib.Path.rglob'b'Walk the directory tree from this directory, similar to os.walk().'u'Walk the directory tree from this directory, similar to os.walk().'b'pathlib.Path.walk'u'pathlib.Path.walk'b'support for supplying keyword arguments to pathlib.PurePath is deprecated and scheduled for removal in Python {remove}'u'support for supplying keyword arguments to pathlib.PurePath is deprecated and scheduled for removal in Python {remove}'b'pathlib.PurePath(**kwargs)'u'pathlib.PurePath(**kwargs)'b'pathlib.Path.__enter__() is deprecated and scheduled for removal in Python 3.13; Path objects as a context manager is a no-op'u'pathlib.Path.__enter__() is deprecated and scheduled for removal in Python 3.13; Path objects as a context manager is a no-op'b'Return a new path pointing to the current working directory.'u'Return a new path pointing to the current working directory.'b'Return a new path pointing to the user's home directory (as
        returned by os.path.expanduser('~')).
        'u'Return a new path pointing to the user's home directory (as
        returned by os.path.expanduser('~')).
        'b'Return an absolute version of this path by prepending the current
        working directory. No normalization or symlink resolution is performed.

        Use resolve() to get the canonical path to a file.
        'u'Return an absolute version of this path by prepending the current
        working directory. No normalization or symlink resolution is performed.

        Use resolve() to get the canonical path to a file.
        'b'
        Make the path absolute, resolving all symlinks on the way and also
        normalizing it.
        'u'
        Make the path absolute, resolving all symlinks on the way and also
        normalizing it.
        'b'Symlink loop from %r'u'Symlink loop from %r'b'
        Return the login name of the file owner.
        'u'
        Return the login name of the file owner.
        'b'Path.owner() is unsupported on this system'u'Path.owner() is unsupported on this system'b'
        Return the group name of the file gid.
        'u'
        Return the group name of the file gid.
        'b'Path.group() is unsupported on this system'u'Path.group() is unsupported on this system'b'
        Return the path to which the symbolic link points.
        'u'
        Return the path to which the symbolic link points.
        'b'os.readlink() not available on this system'u'os.readlink() not available on this system'b'
        Create this file with the given access mode, if it doesn't exist.
        'u'
        Create this file with the given access mode, if it doesn't exist.
        'b'
        Create a new directory at this given path.
        'u'
        Create a new directory at this given path.
        'b'
        Change the permissions of the path, like os.chmod().
        'u'
        Change the permissions of the path, like os.chmod().
        'b'
        Like chmod(), except if the path points to a symlink, the symlink's
        permissions are changed, rather than its target's.
        'u'
        Like chmod(), except if the path points to a symlink, the symlink's
        permissions are changed, rather than its target's.
        'b'
        Remove this file or link.
        If the path is a directory, use rmdir() instead.
        'u'
        Remove this file or link.
        If the path is a directory, use rmdir() instead.
        'b'
        Remove this directory.  The directory must be empty.
        'u'
        Remove this directory.  The directory must be empty.
        'b'
        Rename this path to the target path.

        The target path may be absolute or relative. Relative paths are
        interpreted relative to the current working directory, *not* the
        directory of the Path object.

        Returns the new Path instance pointing to the target path.
        'u'
        Rename this path to the target path.

        The target path may be absolute or relative. Relative paths are
        interpreted relative to the current working directory, *not* the
        directory of the Path object.

        Returns the new Path instance pointing to the target path.
        'b'
        Rename this path to the target path, overwriting if that path exists.

        The target path may be absolute or relative. Relative paths are
        interpreted relative to the current working directory, *not* the
        directory of the Path object.

        Returns the new Path instance pointing to the target path.
        'u'
        Rename this path to the target path, overwriting if that path exists.

        The target path may be absolute or relative. Relative paths are
        interpreted relative to the current working directory, *not* the
        directory of the Path object.

        Returns the new Path instance pointing to the target path.
        'b'
        Make this path a symlink pointing to the target path.
        Note the order of arguments (link, target) is the reverse of os.symlink.
        'u'
        Make this path a symlink pointing to the target path.
        Note the order of arguments (link, target) is the reverse of os.symlink.
        'b'os.symlink() not available on this system'u'os.symlink() not available on this system'b'
        Make this path a hard link pointing to the same file as *target*.

        Note the order of arguments (self, target) is the reverse of os.link's.
        'u'
        Make this path a hard link pointing to the same file as *target*.

        Note the order of arguments (self, target) is the reverse of os.link's.
        'b'os.link() not available on this system'u'os.link() not available on this system'b' Return a new path with expanded ~ and ~user constructs
        (as returned by os.path.expanduser)
        'u' Return a new path with expanded ~ and ~user constructs
        (as returned by os.path.expanduser)
        'b'Could not determine home directory.'u'Could not determine home directory.'b'Path subclass for non-Windows systems.

    On a POSIX system, instantiating a Path should return this object.
    'u'Path subclass for non-Windows systems.

    On a POSIX system, instantiating a Path should return this object.
    'b'cannot instantiate 'u'cannot instantiate 'b' on your system'u' on your system'b'Path subclass for Windows systems.

    On a Windows system, instantiating a Path should return this object.
    'u'Path subclass for Windows systems.

    On a Windows system, instantiating a Path should return this object.
    'u'Lib.pathlib'u'pathlib'
The Python Debugger Pdb
=======================

To use the debugger in its simplest form:

        >>> import pdb
        >>> pdb.run('<a statement>')

The debugger's prompt is '(Pdb) '.  This will stop in the first
function call in <a statement>.

Alternatively, if a statement terminated with an unhandled exception,
you can use pdb's post-mortem facility to inspect the contents of the
traceback:

        >>> <a statement>
        <exception traceback>
        >>> import pdb
        >>> pdb.pm()

The commands recognized by the debugger are listed in the next
section.  Most can be abbreviated as indicated; e.g., h(elp) means
that 'help' can be typed as 'h' or 'help' (but not as 'he' or 'hel',
nor as 'H' or 'Help' or 'HELP').  Optional arguments are enclosed in
square brackets.  Alternatives in the command syntax are separated
by a vertical bar (|).

A blank line repeats the previous command literally, except for
'list', where it lists the next 11 lines.

Commands that the debugger doesn't recognize are assumed to be Python
statements and are executed in the context of the program being
debugged.  Python statements can also be prefixed with an exclamation
point ('!').  This is a powerful way to inspect the program being
debugged; it is even possible to change variables or call functions.
When an exception occurs in such a statement, the exception name is
printed but the debugger's state is not changed.

The debugger supports aliases, which can save typing.  And aliases can
have parameters (see the alias help entry) which allows one a certain
level of adaptability to the context under examination.

Multiple commands may be entered on a single line, separated by the
pair ';;'.  No intelligence is applied to separating the commands; the
input is split at the first ';;', even if it is in the middle of a
quoted string.

If a file ".pdbrc" exists in your home directory or in the current
directory, it is read in and executed as if it had been typed at the
debugger prompt.  This is particularly useful for aliases.  If both
files exist, the one in the home directory is read first and aliases
defined there can be overridden by the local file.  This behavior can be
disabled by passing the "readrc=False" argument to the Pdb constructor.

Aside from aliases, the debugger is not directly programmable; but it
is implemented as a class from which you can derive your own debugger
class, which you can make as fancy as you like.


Debugger commands
=================

bdbRestartCauses a debugger to be restarted for the debugged python program.post_mortemfind_functiondef\s+%s\s*[(]crelasti2lineno_rstrString that doesn't quote its repr._ScriptTargetError:does not existis a directoryexec(compile(, 'exec'))_ModuleTarget_detailsImportError: print_excrunpy_get_module_details_spec
-> line_prefix_previous_sigint_handlerreadrcpdb.Pdb(Pdb) displayingmainpyfile_wait_for_mainpyfileset_completer_delims 	
`@#$%^&*()=+[{]}\|;:'",<>?allow_kbdintrcLines~/.pdbrcrcFile.pdbrccommands_dopromptcommands_silentcommands_definingcommands_bnumsigint_handlersignum
Program interrupted. (Use 'cont' to resume).forgetcurindexcurframe__pdb_convenience_variablessetupcurframe_localsset_convenience_variable_frameThis method is called when there is the remote possibility
        that we ever need to stop in this function.--Call--This function is called when we stop or break at this line.bp_commandsCall every command that was set for the current active breakpoint
        (if there is one).

        Returns True if the normal interaction function must be called,
        False otherwise.lastcmd_backprint_stack_entry_cmdloopThis function is called when a return trap is set here._retval--Return--This function is called if an exception occurs,
        but only if we are to stop at or just below this level.__exception__Internal _format_exc--KeyboardInterrupt--_getval_exceptdisplay %s: %s  [old: %s]_safe_reprCustom displayhook for the exec in default(), which prevents
        assignment of the _ variable in the builtins.
        <stdin>save_stdin_error_exc_replace_convenience_variablesReplace the convenience variables in 'line' with their values.
           e.g. $foo is replaced by __pdb_convenience_variables["foo"].
           Note: such pattern in string literals will be skippeddollar_startdollar_endreplace_variablestoken_typetoken_stringNAMETokenErrorlast_endline_pieces__pdb_convenience_variables[""]Handle alias expansion and ';;' separator.tmpArg%*;;Interpret the argument as though it had been typed in response
        to the prompt.

        Checks whether this line is typed at the normal prompt or in
        a breakpoint command list definition.
        handle_command_defHandles one command line during command list definition.silentcmdlistcommands_resuming***_complete_location_complete_expression_complete_bpnumberdotteddo_commands(Pdb) commands [bpnumber]
        (com) ...
        (com) end
        (Pdb)

        Specify a list of commands for breakpoint number bpnumber.
        The commands themselves are entered on the following lines.
        Type a line containing just 'end' to terminate the commands.
        The commands are executed when the breakpoint is hit.

        To remove all commands from a breakpoint, type commands and
        follow it immediately with end; that is, give no commands.

        With no bpnumber argument, commands refers to the last
        breakpoint set.

        You can use breakpoint commands to start your program up
        again.  Simply use the continue command, or step, or any other
        command that resumes execution.

        Specifying any command resuming execution (currently continue,
        step, next, return, jump, quit and their abbreviations)
        terminates the command list (as if that command was
        immediately followed by end).  This is because any time you
        resume execution (even with a simple next or step), you may
        encounter another breakpoint -- which could have its own
        command list, leading to ambiguities about which list to
        execute.

        If you use the 'silent' command in the command list, the usual
        message about stopping at a breakpoint is not printed.  This
        may be desirable for breakpoints that are to print a specific
        message and then continue.  If none of the other commands
        print anything, you will see no sign that the breakpoint was
        reached.
        bnumUsage: commands [bnum]
        ...
        endcannot set commands: %sold_command_defsprompt_back(com) command definition aborted, old commands restoredcomplete_commandsdo_breakb(reak) [ ([filename:]lineno | function) [, condition] ]

        Without argument, list all breaks.

        With a line number argument, set a break at this line in the
        current file.  With a function name, set a break at the first
        executable line of that function.  If a second argument is
        present, it is a string specifying an expression which must
        evaluate to true before the breakpoint is honored.

        The line number may be prefixed with a filename and a colon,
        to specify a breakpoint in another file (probably one that
        hasn't been loaded yet).  The file is searched for on
        sys.path; the .py suffix may be omitted.
        Num Type         Disp Enb   Where_compile_error_messageInvalid condition %s: %rlookupmodule%r not found from sys.pathBad lineno: %slineinfoThe specified object %r is not a function or was not found along sys.path.'The specified object %r is not a function ''or was not found along sys.path.'defaultFilechecklineBreakpoint %d at %s:%dProduce a reasonable default.do_bcomplete_breakcomplete_bdo_tbreaktbreak [ ([filename:]lineno | function) [, condition] ]

        Same arguments as break, but sets a temporary breakpoint: it
        is automatically deleted when first hit.
        complete_tbreakidentifieridstringCheck whether specified line seems to be executable.

        Return `lineno` if it is, 0 if not (e.g. a docstring, comment, blank
        line or EOF). Warning: testing is not comprehensive.
        End of fileBlank or commentdo_enableenable bpnumber [bpnumber ...]

        Enables the breakpoints given as a space separated list of
        breakpoint numbers.
        Enabled %scomplete_enabledo_disabledisable bpnumber [bpnumber ...]

        Disables the breakpoints given as a space separated list of
        breakpoint numbers.  Disabling a breakpoint means it cannot
        cause the program to stop execution, but unlike clearing a
        breakpoint, it remains in the list of breakpoints and can be
        (re-)enabled.
        Disabled %scomplete_disabledo_conditioncondition bpnumber [condition]

        Set a new condition for the breakpoint, an expression which
        must evaluate to true before the breakpoint is honored.  If
        condition is absent, any existing condition is removed; i.e.,
        the breakpoint is made unconditional.
        Breakpoint %d is now unconditional.New condition set for breakpoint %d.complete_conditiondo_ignoreignore bpnumber [count]

        Set the ignore count for the given breakpoint number.  If
        count is omitted, the ignore count is set to 0.  A breakpoint
        becomes active when the ignore count is zero.  When non-zero,
        the count is decremented each time the breakpoint is reached
        and the breakpoint is not disabled and any associated
        condition evaluates to true.
        %d crossingscountstr1 crossingWill ignore next %s of breakpoint %d.Will stop next time breakpoint %d is reached.complete_ignorecl(ear) [filename:lineno | bpnumber ...]

        With a space separated list of breakpoint numbers, clear
        those breakpoints.  Without argument, clear all breaks (but
        first ask confirmation).  With a filename:lineno argument,
        clear all breaks at that line in that file.
        Clear all breaks? replyyesDeleted %sInvalid line number (%s)numberlistdo_clcomplete_clearcomplete_cldo_wherew(here)

        Print a stack trace, with the most recent frame at the bottom.
        An arrow indicates the "current frame", which determines the
        context of most commands.  'bt' is an alias for this command.
        print_stack_tracedo_wdo_bt_select_framedo_upu(p) [count]

        Move the current frame count (default one) levels up in the
        stack trace (to an older frame).
        Oldest frameInvalid frame count (%s)newframedo_udo_downd(own) [count]

        Move the current frame count (default one) levels down in the
        stack trace (to a newer frame).
        Newest framedo_ddo_untilunt(il) [lineno]

        Without argument, continue execution until the line with a
        number greater than the current one is reached.  With a line
        number, continue execution until a line with a number greater
        or equal to that is reached.  In both cases, also stop when
        the current frame returns.
        Error in argument: %r"until" line number is smaller than current line number'"until" line number is smaller than current ''line number'do_untdo_steps(tep)

        Execute the current line, stop at the first possible occasion
        (either in a function that is called or in the current
        function).
        do_sdo_nextn(ext)

        Continue execution until the next line in the current function
        is reached or it returns.
        do_ndo_runrun [args...]

        Restart the debugged python program. If a string is supplied
        it is split with "shlex", and the result is used as the new
        sys.argv.  History, breakpoints, actions and debugger options
        are preserved.  "restart" is an alias for "run".
        shlexargv0Cannot run %s: %sdo_restartdo_returnr(eturn)

        Continue execution until the current function returns.
        do_rdo_continuec(ont(inue))

        Continue execution, only stop when a breakpoint is encountered.
        do_cdo_contdo_jumpj(ump) lineno

        Set the next line that will be executed.  Only available in
        the bottom-most frame.  This lets you jump back and execute
        code again, or jump forward to skip code that you don't want
        to run.

        It should be noted that not all jumps are allowed -- for
        instance it is not possible to jump into the middle of a
        for loop or out of a finally clause.
        You can only jump within the bottom frameJump failed: %sThe 'jump' command requires a line numberdo_jdo_debugdebug code

        Enter a recursive debugger that steps through the code
        argument (which is an arbitrary expression or statement to be
        executed in the current environment).
        ENTERING RECURSIVE DEBUGGERLEAVING RECURSIVE DEBUGGERcomplete_debugdo_quitq(uit) | exit

        Quit from the debugger. The program being executed is aborted.
        _user_requested_quitdo_qdo_exitdo_EOFEOF

        Handles the receipt of EOF as a command.
        do_argsa(rgs)

        Print the argument list of the current function.
        %s = %s%s = *** undefined ***do_ado_retvalretval

        Print the return value for the last return of a function.
        Not yet returned!do_rv_getval** raised %s **_msg_val_func*** repr() failed:  ***do_pp expression

        Print the value of the expression.
        do_pppp expression

        Pretty-print the value of the expression.
        complete_printcomplete_pcomplete_ppdo_listl(ist) [first[, last] | .]

        List source code for the current file.  Without arguments,
        list 11 lines around the current line or continue the previous
        listing.  With . as argument, list 11 lines around the current
        line.  With one argument, list 11 lines starting at that line.
        With two arguments, list the given range; if the second
        argument is less than the first, it is a count.

        The current line in the current frame is indicated by "->".
        If an exception is being debugged, the line where the
        exception was originally raised or propagated is indicated by
        ">>", if it differs from the current line.
        <frozenbreaklist_print_lines[EOF]do_ldo_longlistll | longlist

        List the whole source code for the current function or frame.
        _getsourcelinesdo_lldo_sourcesource expression

        Try to get source code for the given object and display it.
        complete_sourcePrint a range of lines.current_linenoexc_linenodo_whatiswhatis expression

        Print the type of the argument.
        Method %sFunction %sClass %s.%scomplete_whatisdo_displaydisplay [expression]

        Display the value of the expression if it changed, each time execution
        stops in the current frame.

        Without expression, list all display expressions for the current frame.
        Currently displaying:%s: %sNo expression is being displayedUnable to display %s: %rdisplay %s: %scomplete_displaydo_undisplayundisplay [expression]

        Do not display the expression any more in the current frame.

        Without expression, clear all display expressions for the current frame.
        not displaying %scomplete_undisplaydo_interactinteract

        Start an interactive interpreter whose global namespace
        contains all the (global and local) names found in the current scope.
        *interactive*do_aliasalias [name [command]]

        Create an alias called 'name' that executes 'command'.  The
        command must *not* be enclosed in quotes.  Replaceable
        parameters can be indicated by %1, %2, and so on, while %* is
        replaced by all the parameters.  If no command is given, the
        current alias for name is shown. If no name is given, all
        aliases are listed.

        Aliases may be nested and can contain anything that can be
        legally typed at the pdb prompt.  Note!  You *can* override
        internal pdb commands with aliases!  Those internal commands
        are then hidden until the alias is removed.  Aliasing is
        recursively applied to the first word of the command line; all
        other words in the line are left alone.

        As an example, here are two useful aliases (especially when
        placed in the .pdbrc file):

        # Print instance variables (usage "pi classInst")
        alias pi for k in %1.__dict__.keys(): print("%1.",k,"=",%1.__dict__[k])
        # Print instance variables in self
        alias ps pi self
        Unknown alias 'do_unaliasunalias name

        Delete the specified alias.
        complete_unaliasprompt_prefix> h(elp)

        Without argument, print the list of available commands.
        With a command name as argument, print help about that command.
        "help pdb" shows the full pdb documentation.
        "help exec" gives help on the ! command.
        topiccommandNo help for %r; please do not run Python with -OO if you need command help'No help for %r; please do not run Python with -OO ''if you need command help'No help for %r; __doc__ string missing_help_message_from_docNo help for %rdo_hhelp_exec(!) statement

        Execute the (one-line) statement in the context of the current
        stack frame.  The exclamation point can be omitted unless the
        first word of the statement resembles a debugger command, e.g.:
        (Pdb) ! n=42
        (Pdb)

        To assign to a global variable you must always prefix the command with
        a 'global' command, e.g.:
        (Pdb) global list_options; list_options = ['-l']
        (Pdb)
        help_pdbHelper function for break/clear parsing -- may be overridden.

        lookupmodule() translates (possibly incomplete) file or module name
        into an absolute file name.
        Return the error message as string if compiling `expr` fails.No help message found.usage_endUsage:        downuptbreakuntiljumplonglistwhatisdisplayundisplayunaliasquit_help_order_commandstatementExecute the *statement* (given as a string or a code object)
    under debugger control.

    The debugger prompt appears before any code is executed; you can set
    breakpoints and type continue, or you can step through the statement
    using step or next.

    The optional *globals* and *locals* arguments specify the
    environment in which the code is executed; by default the
    dictionary of the module __main__ is used (see the explanation of
    the built-in exec() or eval() functions.).
    expressionEvaluate the *expression* (given as a string or a code object)
    under debugger control.

    When runeval() returns, it returns the value of the expression.
    Otherwise this function is similar to run().
    Call the function (a function or method object, not a string)
    with the given arguments.

    When runcall() returns, it returns whatever the function call
    returned. The debugger prompt appears as soon as the function is
    entered.
    Enter the debugger at the calling stack frame.

    This is useful to hard-code a breakpoint at a given point in a
    program, even if the code is not otherwise being debugged (e.g. when
    an assertion fails). If given, *header* is printed to the console
    just before debugging begins.
    Enter post-mortem debugging of the given *traceback* object.

    If no traceback is given, it uses the one of the exception that is
    currently being handled (an exception must be being handled if the
    default is to be used).
    A valid traceback must be passed if no exception is being handled"A valid traceback must be passed if no ""exception is being handled"Enter post-mortem debugging of the traceback found in sys.last_traceback.import x; x.main()TESTCMDpydocpagerusage: pdb.py [-c command] ... [-m module | pyfile] [arg] ...

Debug the Python program given by pyfile. Alternatively,
an executable module or package to debug can be specified using
the -m switch.

Initial commands are read from .pdbrc files in your home directory
and in the current directory, if they exist.  Commands supplied with
-c are executed after commands from .pdbrc files.

To let the script run until an exception occurs, use "-c continue".
To let the script run up to a given line X in the debugged file, use
"-c 'until X'"._usagemhc:command=--commandmodule_indicatedThe program finished and will be restartedRestartingwith arguments:The program exited via sys.exit(). Exit status:Uncaught exception. Entering post mortem debuggingRunning 'cont' or 'step' will restart the programPost mortem debugger finished. The  will be restarted# NOTE: the actual command documentation is collected from docstrings of the# commands and is appended to __doc__ after the class has been defined.# consumer of this info expects the first line to be 1# Mutate self to be the "real path".# Store the original path for error reporting.# Replace pdb's dir with script's dir in front of module search path.# Interaction prompt line will separate file and call info from code# text using value of line_prefix string.  A newline and arrow may# be to your liking.  You can set it once pdb is imported using the# command "pdb.line_prefix = '\n% '".# line_prefix = ': '    # Use this to get the old situation back# Probably a better default# Try to load readline if it exists# remove some common file name delimiters# Read ~/.pdbrc and ./.pdbrc# associates a command list to breakpoint numbers# for each bp num, tells if the prompt# must be disp. after execing the cmd list# for each bp num, tells if the stack trace# True while in the process of defining# a command list# The breakpoint number for which we are# defining a list# when setting up post-mortem debugging with a traceback, save all# the original line numbers to be displayed along the current line# numbers (which can be different, e.g. due to finally clauses)# The f_locals dictionary is updated from the actual frame# locals whenever the .f_locals accessor is called, so we# cache it here to ensure that modifications are not overwritten.# Override Bdb methods# self.currentbp is set in bdb in Bdb.break_here if a breakpoint was hit# An 'Internal StopIteration' exception is an exception debug event# issued by the interpreter when handling a subgenerator run with# 'yield from' or a generator controlled by a for loop. No exception has# actually occurred in this case. The debugger uses this debug event to# stop when the debuggee is returning from such generators.# General interaction function# keyboard interrupts allow for an easy way to cancel# the current command, so allow them during interactive input# Called before loop, handles display expressions# Set up convenience variable containers# check for identity first; this prevents custom __eq__ to# be called at every loop, and also prevents instances whose# fields are changed to be displayed# Restore the previous signal handler at the Pdb prompt.# ValueError: signal only works in main thread# if we have more commands to process, do not show the stack entry# reproduce the behavior of the standard displayhook, not printing None# line is a one-line command so we only care about column# split into ';;' separated commands# unless it's an alias command# queue up everything after marker# Replace all the convenience variables# continue to handle other cmd def in the cmd list# end of cmd list# Determine if we must stop# one of the resuming commands# interface abstraction functions# convenience variables# Generic completion functions.  Individual complete_foo methods can be# assigned below to one of these functions.# Complete a file/module/function location for break/tbreak/clear.# Here comes a line number or a condition which we can't complete.# First, try to find matching functions (i.e. expressions).# Then, try to complete file names as well.# Complete a breakpoint number.  (This would be more helpful if we could# display additional info along with the completions, such as file/line# of the breakpoint.)# Complete an arbitrary expression.# Collect globals and locals.  It is usually not really sensible to also# complete builtins, and they clutter the namespace quite heavily, so we# leave them out.# Walk an attribute chain up to the last part, similar to what# rlcompleter does.  This will bail if any of the parts are not# simple attribute access, which is what we want.# Complete a simple name.# Command definitions, called by cmdloop()# The argument is the remaining string on the command line# Return true to exit from the command loop# Save old definitions for the case of a keyboard interrupt.# Restore old definitions.# There's at least one# parse arguments; comma has lowest precedence# and cannot occur in filename# parse stuff after comma: "condition"# parse stuff before comma: [filename:]lineno | function# no colon; can be lineno or function#use co_name to identify the bkpt (function names#could be aliased, but co_name is invariant)# last thing to try# ok contains a function name# Check for reasonable breakpoint# now set the break point# To be overridden in derived debuggers# Input is identifier, may be in single quotes# not in single quotes# quoted# Protection for derived debuggers# Best first guess at file to look at# More than one part.# First is module, second is method/class# this method should be callable before starting debugging, so default# to "no globals" if there is no current frame# Don't allow setting breakpoint at a blank line# Make sure it works for "clear C:\foo\bar.py:12"# 'c' is already an abbreviation for 'continue'# this is caught in the main debugger loop# ValueError happens when do_continue() is invoked from# a non-main thread in which case we just continue without# SIGINT set. Would printing a message here (once) make# sense?# Do the jump, fix up our copy of the stack, and display the# new position# _getval() has displayed the error# assume it's a count# gh-93696: stdlib frozen modules provide a useful __file__# this workaround can be removed with the closure of gh-89815# _getval() already printed the error# Is it an instance method?# Is it a function?# Is it a class?# None of the above...# List of all the commands making the program resume execution.# Print a traceback starting at the top stack frame.# The most recently entered frame is printed last;# this is different from dbx and gdb, but consistent with# the Python interpreter's stack trace.# It is also consistent with the up/down commands (which are# compatible with dbx and gdb: up moves towards 'main()'# and down moves towards the most recent stack frame).# Provide help# other helper functions# When bdb sets tracing, a number of call and line events happen# BEFORE debugger even reaches user's code (and the exact sequence of# events depends on python version). Take special measures to# avoid stopping before reaching the main script (see user_line and# user_call for details).# The target has to run in __main__ namespace (or imports from# __main__ will break). Clear __main__ and replace with# the target namespace.# GH-103319# inspect.getsourcelines() returns lineno = 0 for# module-level frame which breaks our code print line number# This method should be replaced by inspect.getsourcelines(obj)# once this bug is fixed in inspect# Collect all command help into docstring, if not run with -OO# unfortunately we can't guess this order from the class definition# Simplified interface# Post-Mortem interface# handling the default# Main program for testing# print help# Hide "pdb.py" and pdb options from argument list# Note on saving/restoring sys.argv: it's a good idea when sys.argv was# modified by the script being debugged. It's a bad idea when it was# changed by the user from the command line. There is a "restart" command# which allows explicit specification of command line arguments.# In most cases SystemExit does not warrant a post-mortem session.# When invoked as main program, invoke the debugger on a scriptb'
The Python Debugger Pdb
=======================

To use the debugger in its simplest form:

        >>> import pdb
        >>> pdb.run('<a statement>')

The debugger's prompt is '(Pdb) '.  This will stop in the first
function call in <a statement>.

Alternatively, if a statement terminated with an unhandled exception,
you can use pdb's post-mortem facility to inspect the contents of the
traceback:

        >>> <a statement>
        <exception traceback>
        >>> import pdb
        >>> pdb.pm()

The commands recognized by the debugger are listed in the next
section.  Most can be abbreviated as indicated; e.g., h(elp) means
that 'help' can be typed as 'h' or 'help' (but not as 'he' or 'hel',
nor as 'H' or 'Help' or 'HELP').  Optional arguments are enclosed in
square brackets.  Alternatives in the command syntax are separated
by a vertical bar (|).

A blank line repeats the previous command literally, except for
'list', where it lists the next 11 lines.

Commands that the debugger doesn't recognize are assumed to be Python
statements and are executed in the context of the program being
debugged.  Python statements can also be prefixed with an exclamation
point ('!').  This is a powerful way to inspect the program being
debugged; it is even possible to change variables or call functions.
When an exception occurs in such a statement, the exception name is
printed but the debugger's state is not changed.

The debugger supports aliases, which can save typing.  And aliases can
have parameters (see the alias help entry) which allows one a certain
level of adaptability to the context under examination.

Multiple commands may be entered on a single line, separated by the
pair ';;'.  No intelligence is applied to separating the commands; the
input is split at the first ';;', even if it is in the middle of a
quoted string.

If a file ".pdbrc" exists in your home directory or in the current
directory, it is read in and executed as if it had been typed at the
debugger prompt.  This is particularly useful for aliases.  If both
files exist, the one in the home directory is read first and aliases
defined there can be overridden by the local file.  This behavior can be
disabled by passing the "readrc=False" argument to the Pdb constructor.

Aside from aliases, the debugger is not directly programmable; but it
is implemented as a class from which you can derive your own debugger
class, which you can make as fancy as you like.


Debugger commands
=================

'u'
The Python Debugger Pdb
=======================

To use the debugger in its simplest form:

        >>> import pdb
        >>> pdb.run('<a statement>')

The debugger's prompt is '(Pdb) '.  This will stop in the first
function call in <a statement>.

Alternatively, if a statement terminated with an unhandled exception,
you can use pdb's post-mortem facility to inspect the contents of the
traceback:

        >>> <a statement>
        <exception traceback>
        >>> import pdb
        >>> pdb.pm()

The commands recognized by the debugger are listed in the next
section.  Most can be abbreviated as indicated; e.g., h(elp) means
that 'help' can be typed as 'h' or 'help' (but not as 'he' or 'hel',
nor as 'H' or 'Help' or 'HELP').  Optional arguments are enclosed in
square brackets.  Alternatives in the command syntax are separated
by a vertical bar (|).

A blank line repeats the previous command literally, except for
'list', where it lists the next 11 lines.

Commands that the debugger doesn't recognize are assumed to be Python
statements and are executed in the context of the program being
debugged.  Python statements can also be prefixed with an exclamation
point ('!').  This is a powerful way to inspect the program being
debugged; it is even possible to change variables or call functions.
When an exception occurs in such a statement, the exception name is
printed but the debugger's state is not changed.

The debugger supports aliases, which can save typing.  And aliases can
have parameters (see the alias help entry) which allows one a certain
level of adaptability to the context under examination.

Multiple commands may be entered on a single line, separated by the
pair ';;'.  No intelligence is applied to separating the commands; the
input is split at the first ';;', even if it is in the middle of a
quoted string.

If a file ".pdbrc" exists in your home directory or in the current
directory, it is read in and executed as if it had been typed at the
debugger prompt.  This is particularly useful for aliases.  If both
files exist, the one in the home directory is read first and aliases
defined there can be overridden by the local file.  This behavior can be
disabled by passing the "readrc=False" argument to the Pdb constructor.

Aside from aliases, the debugger is not directly programmable; but it
is implemented as a class from which you can derive your own debugger
class, which you can make as fancy as you like.


Debugger commands
=================

'b'Causes a debugger to be restarted for the debugged python program.'u'Causes a debugger to be restarted for the debugged python program.'b'pm'u'pm'b'Pdb'u'Pdb'b'runeval'u'runeval'b'runctx'u'runctx'b'runcall'u'runcall'b'set_trace'u'set_trace'b'post_mortem'u'post_mortem'b'def\s+%s\s*[(]'u'def\s+%s\s*[(]'b'String that doesn't quote its repr.'u'String that doesn't quote its repr.'b'Error:'u'Error:'b'does not exist'u'does not exist'b'is a directory'u'is a directory'b'exec(compile('u'exec(compile('b', 'exec'))'u', 'exec'))'b'ImportError: 'u'ImportError: 'b'
-> 'u'
-> 'b'pdb.Pdb'u'pdb.Pdb'b'(Pdb) 'u'(Pdb) 'b' 	
`@#$%^&*()=+[{]}\|;:'",<>?'u' 	
`@#$%^&*()=+[{]}\|;:'",<>?'b'~/.pdbrc'u'~/.pdbrc'b'.pdbrc'u'.pdbrc'b'
Program interrupted. (Use 'cont' to resume).'u'
Program interrupted. (Use 'cont' to resume).'b'curframe'u'curframe'b'__pdb_convenience_variables'u'__pdb_convenience_variables'b'_frame'u'_frame'b'This method is called when there is the remote possibility
        that we ever need to stop in this function.'u'This method is called when there is the remote possibility
        that we ever need to stop in this function.'b'--Call--'u'--Call--'b'This function is called when we stop or break at this line.'u'This function is called when we stop or break at this line.'b'Call every command that was set for the current active breakpoint
        (if there is one).

        Returns True if the normal interaction function must be called,
        False otherwise.'u'Call every command that was set for the current active breakpoint
        (if there is one).

        Returns True if the normal interaction function must be called,
        False otherwise.'b'currentbp'u'currentbp'b'This function is called when a return trap is set here.'u'This function is called when a return trap is set here.'b'_retval'u'_retval'b'--Return--'u'--Return--'b'This function is called if an exception occurs,
        but only if we are to stop at or just below this level.'u'This function is called if an exception occurs,
        but only if we are to stop at or just below this level.'b'__exception__'u'__exception__'b'_exception'u'_exception'b'Internal 'u'Internal 'b'--KeyboardInterrupt--'u'--KeyboardInterrupt--'b'display %s: %s  [old: %s]'u'display %s: %s  [old: %s]'b'Custom displayhook for the exec in default(), which prevents
        assignment of the _ variable in the builtins.
        'u'Custom displayhook for the exec in default(), which prevents
        assignment of the _ variable in the builtins.
        'b'<stdin>'u'<stdin>'b'Replace the convenience variables in 'line' with their values.
           e.g. $foo is replaced by __pdb_convenience_variables["foo"].
           Note: such pattern in string literals will be skipped'u'Replace the convenience variables in 'line' with their values.
           e.g. $foo is replaced by __pdb_convenience_variables["foo"].
           Note: such pattern in string literals will be skipped'b'__pdb_convenience_variables["'u'__pdb_convenience_variables["'b'"]'u'"]'b'Handle alias expansion and ';;' separator.'u'Handle alias expansion and ';;' separator.'b'%*'u'%*'b'alias'u'alias'b';;'u';;'b'Interpret the argument as though it had been typed in response
        to the prompt.

        Checks whether this line is typed at the normal prompt or in
        a breakpoint command list definition.
        'u'Interpret the argument as though it had been typed in response
        to the prompt.

        Checks whether this line is typed at the normal prompt or in
        a breakpoint command list definition.
        'b'Handles one command line during command list definition.'u'Handles one command line during command list definition.'b'silent'u'silent'b'***'u'***'b'(Pdb) commands [bpnumber]
        (com) ...
        (com) end
        (Pdb)

        Specify a list of commands for breakpoint number bpnumber.
        The commands themselves are entered on the following lines.
        Type a line containing just 'end' to terminate the commands.
        The commands are executed when the breakpoint is hit.

        To remove all commands from a breakpoint, type commands and
        follow it immediately with end; that is, give no commands.

        With no bpnumber argument, commands refers to the last
        breakpoint set.

        You can use breakpoint commands to start your program up
        again.  Simply use the continue command, or step, or any other
        command that resumes execution.

        Specifying any command resuming execution (currently continue,
        step, next, return, jump, quit and their abbreviations)
        terminates the command list (as if that command was
        immediately followed by end).  This is because any time you
        resume execution (even with a simple next or step), you may
        encounter another breakpoint -- which could have its own
        command list, leading to ambiguities about which list to
        execute.

        If you use the 'silent' command in the command list, the usual
        message about stopping at a breakpoint is not printed.  This
        may be desirable for breakpoints that are to print a specific
        message and then continue.  If none of the other commands
        print anything, you will see no sign that the breakpoint was
        reached.
        'u'(Pdb) commands [bpnumber]
        (com) ...
        (com) end
        (Pdb)

        Specify a list of commands for breakpoint number bpnumber.
        The commands themselves are entered on the following lines.
        Type a line containing just 'end' to terminate the commands.
        The commands are executed when the breakpoint is hit.

        To remove all commands from a breakpoint, type commands and
        follow it immediately with end; that is, give no commands.

        With no bpnumber argument, commands refers to the last
        breakpoint set.

        You can use breakpoint commands to start your program up
        again.  Simply use the continue command, or step, or any other
        command that resumes execution.

        Specifying any command resuming execution (currently continue,
        step, next, return, jump, quit and their abbreviations)
        terminates the command list (as if that command was
        immediately followed by end).  This is because any time you
        resume execution (even with a simple next or step), you may
        encounter another breakpoint -- which could have its own
        command list, leading to ambiguities about which list to
        execute.

        If you use the 'silent' command in the command list, the usual
        message about stopping at a breakpoint is not printed.  This
        may be desirable for breakpoints that are to print a specific
        message and then continue.  If none of the other commands
        print anything, you will see no sign that the breakpoint was
        reached.
        'b'Usage: commands [bnum]
        ...
        end'u'Usage: commands [bnum]
        ...
        end'b'cannot set commands: %s'u'cannot set commands: %s'b'(com) 'u'(com) 'b'command definition aborted, old commands restored'u'command definition aborted, old commands restored'b'b(reak) [ ([filename:]lineno | function) [, condition] ]

        Without argument, list all breaks.

        With a line number argument, set a break at this line in the
        current file.  With a function name, set a break at the first
        executable line of that function.  If a second argument is
        present, it is a string specifying an expression which must
        evaluate to true before the breakpoint is honored.

        The line number may be prefixed with a filename and a colon,
        to specify a breakpoint in another file (probably one that
        hasn't been loaded yet).  The file is searched for on
        sys.path; the .py suffix may be omitted.
        'u'b(reak) [ ([filename:]lineno | function) [, condition] ]

        Without argument, list all breaks.

        With a line number argument, set a break at this line in the
        current file.  With a function name, set a break at the first
        executable line of that function.  If a second argument is
        present, it is a string specifying an expression which must
        evaluate to true before the breakpoint is honored.

        The line number may be prefixed with a filename and a colon,
        to specify a breakpoint in another file (probably one that
        hasn't been loaded yet).  The file is searched for on
        sys.path; the .py suffix may be omitted.
        'b'Num Type         Disp Enb   Where'u'Num Type         Disp Enb   Where'b'Invalid condition %s: %r'u'Invalid condition %s: %r'b'%r not found from sys.path'u'%r not found from sys.path'b'Bad lineno: %s'u'Bad lineno: %s'b'The specified object %r is not a function or was not found along sys.path.'u'The specified object %r is not a function or was not found along sys.path.'b'Breakpoint %d at %s:%d'u'Breakpoint %d at %s:%d'b'Produce a reasonable default.'u'Produce a reasonable default.'b'tbreak [ ([filename:]lineno | function) [, condition] ]

        Same arguments as break, but sets a temporary breakpoint: it
        is automatically deleted when first hit.
        'u'tbreak [ ([filename:]lineno | function) [, condition] ]

        Same arguments as break, but sets a temporary breakpoint: it
        is automatically deleted when first hit.
        'b'Check whether specified line seems to be executable.

        Return `lineno` if it is, 0 if not (e.g. a docstring, comment, blank
        line or EOF). Warning: testing is not comprehensive.
        'u'Check whether specified line seems to be executable.

        Return `lineno` if it is, 0 if not (e.g. a docstring, comment, blank
        line or EOF). Warning: testing is not comprehensive.
        'b'End of file'u'End of file'b'Blank or comment'u'Blank or comment'b'enable bpnumber [bpnumber ...]

        Enables the breakpoints given as a space separated list of
        breakpoint numbers.
        'u'enable bpnumber [bpnumber ...]

        Enables the breakpoints given as a space separated list of
        breakpoint numbers.
        'b'Enabled %s'u'Enabled %s'b'disable bpnumber [bpnumber ...]

        Disables the breakpoints given as a space separated list of
        breakpoint numbers.  Disabling a breakpoint means it cannot
        cause the program to stop execution, but unlike clearing a
        breakpoint, it remains in the list of breakpoints and can be
        (re-)enabled.
        'u'disable bpnumber [bpnumber ...]

        Disables the breakpoints given as a space separated list of
        breakpoint numbers.  Disabling a breakpoint means it cannot
        cause the program to stop execution, but unlike clearing a
        breakpoint, it remains in the list of breakpoints and can be
        (re-)enabled.
        'b'Disabled %s'u'Disabled %s'b'condition bpnumber [condition]

        Set a new condition for the breakpoint, an expression which
        must evaluate to true before the breakpoint is honored.  If
        condition is absent, any existing condition is removed; i.e.,
        the breakpoint is made unconditional.
        'u'condition bpnumber [condition]

        Set a new condition for the breakpoint, an expression which
        must evaluate to true before the breakpoint is honored.  If
        condition is absent, any existing condition is removed; i.e.,
        the breakpoint is made unconditional.
        'b'Breakpoint %d is now unconditional.'u'Breakpoint %d is now unconditional.'b'New condition set for breakpoint %d.'u'New condition set for breakpoint %d.'b'ignore bpnumber [count]

        Set the ignore count for the given breakpoint number.  If
        count is omitted, the ignore count is set to 0.  A breakpoint
        becomes active when the ignore count is zero.  When non-zero,
        the count is decremented each time the breakpoint is reached
        and the breakpoint is not disabled and any associated
        condition evaluates to true.
        'u'ignore bpnumber [count]

        Set the ignore count for the given breakpoint number.  If
        count is omitted, the ignore count is set to 0.  A breakpoint
        becomes active when the ignore count is zero.  When non-zero,
        the count is decremented each time the breakpoint is reached
        and the breakpoint is not disabled and any associated
        condition evaluates to true.
        'b'%d crossings'u'%d crossings'b'1 crossing'u'1 crossing'b'Will ignore next %s of breakpoint %d.'u'Will ignore next %s of breakpoint %d.'b'Will stop next time breakpoint %d is reached.'u'Will stop next time breakpoint %d is reached.'b'cl(ear) [filename:lineno | bpnumber ...]

        With a space separated list of breakpoint numbers, clear
        those breakpoints.  Without argument, clear all breaks (but
        first ask confirmation).  With a filename:lineno argument,
        clear all breaks at that line in that file.
        'u'cl(ear) [filename:lineno | bpnumber ...]

        With a space separated list of breakpoint numbers, clear
        those breakpoints.  Without argument, clear all breaks (but
        first ask confirmation).  With a filename:lineno argument,
        clear all breaks at that line in that file.
        'b'Clear all breaks? 'u'Clear all breaks? 'u'y'b'yes'u'yes'b'Deleted %s'u'Deleted %s'b'Invalid line number (%s)'u'Invalid line number (%s)'b'w(here)

        Print a stack trace, with the most recent frame at the bottom.
        An arrow indicates the "current frame", which determines the
        context of most commands.  'bt' is an alias for this command.
        'u'w(here)

        Print a stack trace, with the most recent frame at the bottom.
        An arrow indicates the "current frame", which determines the
        context of most commands.  'bt' is an alias for this command.
        'b'u(p) [count]

        Move the current frame count (default one) levels up in the
        stack trace (to an older frame).
        'u'u(p) [count]

        Move the current frame count (default one) levels up in the
        stack trace (to an older frame).
        'b'Oldest frame'u'Oldest frame'b'Invalid frame count (%s)'u'Invalid frame count (%s)'b'd(own) [count]

        Move the current frame count (default one) levels down in the
        stack trace (to a newer frame).
        'u'd(own) [count]

        Move the current frame count (default one) levels down in the
        stack trace (to a newer frame).
        'b'Newest frame'u'Newest frame'b'unt(il) [lineno]

        Without argument, continue execution until the line with a
        number greater than the current one is reached.  With a line
        number, continue execution until a line with a number greater
        or equal to that is reached.  In both cases, also stop when
        the current frame returns.
        'u'unt(il) [lineno]

        Without argument, continue execution until the line with a
        number greater than the current one is reached.  With a line
        number, continue execution until a line with a number greater
        or equal to that is reached.  In both cases, also stop when
        the current frame returns.
        'b'Error in argument: %r'u'Error in argument: %r'b'"until" line number is smaller than current line number'u'"until" line number is smaller than current line number'b's(tep)

        Execute the current line, stop at the first possible occasion
        (either in a function that is called or in the current
        function).
        'u's(tep)

        Execute the current line, stop at the first possible occasion
        (either in a function that is called or in the current
        function).
        'b'n(ext)

        Continue execution until the next line in the current function
        is reached or it returns.
        'u'n(ext)

        Continue execution until the next line in the current function
        is reached or it returns.
        'b'run [args...]

        Restart the debugged python program. If a string is supplied
        it is split with "shlex", and the result is used as the new
        sys.argv.  History, breakpoints, actions and debugger options
        are preserved.  "restart" is an alias for "run".
        'u'run [args...]

        Restart the debugged python program. If a string is supplied
        it is split with "shlex", and the result is used as the new
        sys.argv.  History, breakpoints, actions and debugger options
        are preserved.  "restart" is an alias for "run".
        'b'Cannot run %s: %s'u'Cannot run %s: %s'b'r(eturn)

        Continue execution until the current function returns.
        'u'r(eturn)

        Continue execution until the current function returns.
        'b'c(ont(inue))

        Continue execution, only stop when a breakpoint is encountered.
        'u'c(ont(inue))

        Continue execution, only stop when a breakpoint is encountered.
        'b'j(ump) lineno

        Set the next line that will be executed.  Only available in
        the bottom-most frame.  This lets you jump back and execute
        code again, or jump forward to skip code that you don't want
        to run.

        It should be noted that not all jumps are allowed -- for
        instance it is not possible to jump into the middle of a
        for loop or out of a finally clause.
        'u'j(ump) lineno

        Set the next line that will be executed.  Only available in
        the bottom-most frame.  This lets you jump back and execute
        code again, or jump forward to skip code that you don't want
        to run.

        It should be noted that not all jumps are allowed -- for
        instance it is not possible to jump into the middle of a
        for loop or out of a finally clause.
        'b'You can only jump within the bottom frame'u'You can only jump within the bottom frame'b'Jump failed: %s'u'Jump failed: %s'b'The 'jump' command requires a line number'u'The 'jump' command requires a line number'b'debug code

        Enter a recursive debugger that steps through the code
        argument (which is an arbitrary expression or statement to be
        executed in the current environment).
        'u'debug code

        Enter a recursive debugger that steps through the code
        argument (which is an arbitrary expression or statement to be
        executed in the current environment).
        'b'ENTERING RECURSIVE DEBUGGER'u'ENTERING RECURSIVE DEBUGGER'b'LEAVING RECURSIVE DEBUGGER'u'LEAVING RECURSIVE DEBUGGER'b'q(uit) | exit

        Quit from the debugger. The program being executed is aborted.
        'u'q(uit) | exit

        Quit from the debugger. The program being executed is aborted.
        'b'EOF

        Handles the receipt of EOF as a command.
        'u'EOF

        Handles the receipt of EOF as a command.
        'b'a(rgs)

        Print the argument list of the current function.
        'u'a(rgs)

        Print the argument list of the current function.
        'b'%s = %s'u'%s = %s'b'%s = *** undefined ***'u'%s = *** undefined ***'b'retval

        Print the return value for the last return of a function.
        'u'retval

        Print the return value for the last return of a function.
        'b'retval'u'retval'b'Not yet returned!'u'Not yet returned!'b'** raised %s **'u'** raised %s **'b'*** repr('u'*** repr('b') failed: 'u') failed: 'b' ***'u' ***'b'p expression

        Print the value of the expression.
        'u'p expression

        Print the value of the expression.
        'b'pp expression

        Pretty-print the value of the expression.
        'u'pp expression

        Pretty-print the value of the expression.
        'b'l(ist) [first[, last] | .]

        List source code for the current file.  Without arguments,
        list 11 lines around the current line or continue the previous
        listing.  With . as argument, list 11 lines around the current
        line.  With one argument, list 11 lines starting at that line.
        With two arguments, list the given range; if the second
        argument is less than the first, it is a count.

        The current line in the current frame is indicated by "->".
        If an exception is being debugged, the line where the
        exception was originally raised or propagated is indicated by
        ">>", if it differs from the current line.
        'u'l(ist) [first[, last] | .]

        List source code for the current file.  Without arguments,
        list 11 lines around the current line or continue the previous
        listing.  With . as argument, list 11 lines around the current
        line.  With one argument, list 11 lines starting at that line.
        With two arguments, list the given range; if the second
        argument is less than the first, it is a count.

        The current line in the current frame is indicated by "->".
        If an exception is being debugged, the line where the
        exception was originally raised or propagated is indicated by
        ">>", if it differs from the current line.
        'b'list'u'list'b'<frozen'u'<frozen'b'[EOF]'u'[EOF]'b'll | longlist

        List the whole source code for the current function or frame.
        'u'll | longlist

        List the whole source code for the current function or frame.
        'b'source expression

        Try to get source code for the given object and display it.
        'u'source expression

        Try to get source code for the given object and display it.
        'b'Print a range of lines.'u'Print a range of lines.'b'whatis expression

        Print the type of the argument.
        'u'whatis expression

        Print the type of the argument.
        'b'Method %s'u'Method %s'b'Function %s'u'Function %s'b'Class %s.%s'u'Class %s.%s'b'display [expression]

        Display the value of the expression if it changed, each time execution
        stops in the current frame.

        Without expression, list all display expressions for the current frame.
        'u'display [expression]

        Display the value of the expression if it changed, each time execution
        stops in the current frame.

        Without expression, list all display expressions for the current frame.
        'b'Currently displaying:'u'Currently displaying:'b'%s: %s'u'%s: %s'b'No expression is being displayed'u'No expression is being displayed'b'Unable to display %s: %r'u'Unable to display %s: %r'b'display %s: %s'u'display %s: %s'b'undisplay [expression]

        Do not display the expression any more in the current frame.

        Without expression, clear all display expressions for the current frame.
        'u'undisplay [expression]

        Do not display the expression any more in the current frame.

        Without expression, clear all display expressions for the current frame.
        'b'not displaying %s'u'not displaying %s'b'interact

        Start an interactive interpreter whose global namespace
        contains all the (global and local) names found in the current scope.
        'u'interact

        Start an interactive interpreter whose global namespace
        contains all the (global and local) names found in the current scope.
        'b'*interactive*'u'*interactive*'b'alias [name [command]]

        Create an alias called 'name' that executes 'command'.  The
        command must *not* be enclosed in quotes.  Replaceable
        parameters can be indicated by %1, %2, and so on, while %* is
        replaced by all the parameters.  If no command is given, the
        current alias for name is shown. If no name is given, all
        aliases are listed.

        Aliases may be nested and can contain anything that can be
        legally typed at the pdb prompt.  Note!  You *can* override
        internal pdb commands with aliases!  Those internal commands
        are then hidden until the alias is removed.  Aliasing is
        recursively applied to the first word of the command line; all
        other words in the line are left alone.

        As an example, here are two useful aliases (especially when
        placed in the .pdbrc file):

        # Print instance variables (usage "pi classInst")
        alias pi for k in %1.__dict__.keys(): print("%1.",k,"=",%1.__dict__[k])
        # Print instance variables in self
        alias ps pi self
        'u'alias [name [command]]

        Create an alias called 'name' that executes 'command'.  The
        command must *not* be enclosed in quotes.  Replaceable
        parameters can be indicated by %1, %2, and so on, while %* is
        replaced by all the parameters.  If no command is given, the
        current alias for name is shown. If no name is given, all
        aliases are listed.

        Aliases may be nested and can contain anything that can be
        legally typed at the pdb prompt.  Note!  You *can* override
        internal pdb commands with aliases!  Those internal commands
        are then hidden until the alias is removed.  Aliasing is
        recursively applied to the first word of the command line; all
        other words in the line are left alone.

        As an example, here are two useful aliases (especially when
        placed in the .pdbrc file):

        # Print instance variables (usage "pi classInst")
        alias pi for k in %1.__dict__.keys(): print("%1.",k,"=",%1.__dict__[k])
        # Print instance variables in self
        alias ps pi self
        'b'Unknown alias ''u'Unknown alias ''b'unalias name

        Delete the specified alias.
        'u'unalias name

        Delete the specified alias.
        'b'do_continue'u'do_continue'b'do_step'u'do_step'b'do_next'u'do_next'b'do_return'u'do_return'b'do_quit'u'do_quit'b'do_jump'u'do_jump'b'> 'u'> 'b'h(elp)

        Without argument, print the list of available commands.
        With a command name as argument, print help about that command.
        "help pdb" shows the full pdb documentation.
        "help exec" gives help on the ! command.
        'u'h(elp)

        Without argument, print the list of available commands.
        With a command name as argument, print help about that command.
        "help pdb" shows the full pdb documentation.
        "help exec" gives help on the ! command.
        'b'No help for %r; please do not run Python with -OO if you need command help'u'No help for %r; please do not run Python with -OO if you need command help'b'No help for %r; __doc__ string missing'u'No help for %r; __doc__ string missing'b'No help for %r'u'No help for %r'b'(!) statement

        Execute the (one-line) statement in the context of the current
        stack frame.  The exclamation point can be omitted unless the
        first word of the statement resembles a debugger command, e.g.:
        (Pdb) ! n=42
        (Pdb)

        To assign to a global variable you must always prefix the command with
        a 'global' command, e.g.:
        (Pdb) global list_options; list_options = ['-l']
        (Pdb)
        'u'(!) statement

        Execute the (one-line) statement in the context of the current
        stack frame.  The exclamation point can be omitted unless the
        first word of the statement resembles a debugger command, e.g.:
        (Pdb) ! n=42
        (Pdb)

        To assign to a global variable you must always prefix the command with
        a 'global' command, e.g.:
        (Pdb) global list_options; list_options = ['-l']
        (Pdb)
        'b'Helper function for break/clear parsing -- may be overridden.

        lookupmodule() translates (possibly incomplete) file or module name
        into an absolute file name.
        'u'Helper function for break/clear parsing -- may be overridden.

        lookupmodule() translates (possibly incomplete) file or module name
        into an absolute file name.
        'b'Return the error message as string if compiling `expr` fails.'u'Return the error message as string if compiling `expr` fails.'b'No help message found.'u'No help message found.'b'Usage: 'u'Usage: 'b'       'u'       'b'where'u'where'b'down'u'down'b'up'u'up'b'tbreak'u'tbreak'b'clear'u'clear'b'enable'u'enable'b'condition'u'condition'b'step'b'until'u'until'b'jump'u'jump'b'longlist'u'longlist'b'p'u'p'b'whatis'u'whatis'b'display'u'display'b'undisplay'u'undisplay'b'unalias'u'unalias'b'quit'u'quit'b'Execute the *statement* (given as a string or a code object)
    under debugger control.

    The debugger prompt appears before any code is executed; you can set
    breakpoints and type continue, or you can step through the statement
    using step or next.

    The optional *globals* and *locals* arguments specify the
    environment in which the code is executed; by default the
    dictionary of the module __main__ is used (see the explanation of
    the built-in exec() or eval() functions.).
    'u'Execute the *statement* (given as a string or a code object)
    under debugger control.

    The debugger prompt appears before any code is executed; you can set
    breakpoints and type continue, or you can step through the statement
    using step or next.

    The optional *globals* and *locals* arguments specify the
    environment in which the code is executed; by default the
    dictionary of the module __main__ is used (see the explanation of
    the built-in exec() or eval() functions.).
    'b'Evaluate the *expression* (given as a string or a code object)
    under debugger control.

    When runeval() returns, it returns the value of the expression.
    Otherwise this function is similar to run().
    'u'Evaluate the *expression* (given as a string or a code object)
    under debugger control.

    When runeval() returns, it returns the value of the expression.
    Otherwise this function is similar to run().
    'b'Call the function (a function or method object, not a string)
    with the given arguments.

    When runcall() returns, it returns whatever the function call
    returned. The debugger prompt appears as soon as the function is
    entered.
    'u'Call the function (a function or method object, not a string)
    with the given arguments.

    When runcall() returns, it returns whatever the function call
    returned. The debugger prompt appears as soon as the function is
    entered.
    'b'Enter the debugger at the calling stack frame.

    This is useful to hard-code a breakpoint at a given point in a
    program, even if the code is not otherwise being debugged (e.g. when
    an assertion fails). If given, *header* is printed to the console
    just before debugging begins.
    'u'Enter the debugger at the calling stack frame.

    This is useful to hard-code a breakpoint at a given point in a
    program, even if the code is not otherwise being debugged (e.g. when
    an assertion fails). If given, *header* is printed to the console
    just before debugging begins.
    'b'Enter post-mortem debugging of the given *traceback* object.

    If no traceback is given, it uses the one of the exception that is
    currently being handled (an exception must be being handled if the
    default is to be used).
    'u'Enter post-mortem debugging of the given *traceback* object.

    If no traceback is given, it uses the one of the exception that is
    currently being handled (an exception must be being handled if the
    default is to be used).
    'b'A valid traceback must be passed if no exception is being handled'u'A valid traceback must be passed if no exception is being handled'b'Enter post-mortem debugging of the traceback found in sys.last_traceback.'u'Enter post-mortem debugging of the traceback found in sys.last_traceback.'b'import x; x.main()'u'import x; x.main()'b'usage: pdb.py [-c command] ... [-m module | pyfile] [arg] ...

Debug the Python program given by pyfile. Alternatively,
an executable module or package to debug can be specified using
the -m switch.

Initial commands are read from .pdbrc files in your home directory
and in the current directory, if they exist.  Commands supplied with
-c are executed after commands from .pdbrc files.

To let the script run until an exception occurs, use "-c continue".
To let the script run up to a given line X in the debugged file, use
"-c 'until X'".'u'usage: pdb.py [-c command] ... [-m module | pyfile] [arg] ...

Debug the Python program given by pyfile. Alternatively,
an executable module or package to debug can be specified using
the -m switch.

Initial commands are read from .pdbrc files in your home directory
and in the current directory, if they exist.  Commands supplied with
-c are executed after commands from .pdbrc files.

To let the script run until an exception occurs, use "-c continue".
To let the script run up to a given line X in the debugged file, use
"-c 'until X'".'b'mhc:'u'mhc:'b'command='u'command='b'--command'u'--command'b'The program finished and will be restarted'u'The program finished and will be restarted'b'Restarting'u'Restarting'b'with arguments:'u'with arguments:'b'The program exited via sys.exit(). Exit status:'u'The program exited via sys.exit(). Exit status:'b'Uncaught exception. Entering post mortem debugging'u'Uncaught exception. Entering post mortem debugging'b'Running 'cont' or 'step' will restart the program'u'Running 'cont' or 'step' will restart the program'b'Post mortem debugger finished. The 'u'Post mortem debugger finished. The 'b' will be restarted'u' will be restarted'u'Lib.pdb'u'pdb'Create portable serialized representations of Python objects.

See module copyreg for a mechanism for registering custom picklers.
See module pickletools source for extensive comments.

Classes:

    Pickler
    Unpickler

Functions:

    dump(object, file)
    dumps(object) -> string
    load(file) -> object
    loads(bytes) -> object

Misc variables:

    __version__
    format_version
    compatible_formats

_compat_pickle_HAVE_PICKLE_BUFFER4.0format_version1.21.33.05.0compatible_formatsHIGHEST_PROTOCOLDEFAULT_PROTOCOLA common base class for the other pickling exceptions.This exception is raised when an unpicklable object is passed to the
    dump() method.

    This exception is raised when there is a problem unpickling an object,
    such as a security violation.

    Note that other exceptions may also be raised during unpickling, including
    (but not necessarily limited to) AttributeError, EOFError, ImportError,
    and IndexError.

    _StopSTOPPOPPOP_MARKDUPFLOATINTJBININTBININT1LONGBININT2NONEPERSIDBINPERSIDREDUCESTRINGBINSTRINGSHORT_BINSTRINGVBINUNICODEAPPENDBUILDGLOBALDICTEMPTY_DICTAPPENDSBINGETINSTLONG_BINGETLISTEMPTY_LISTOBJBINPUTLONG_BINPUTSETITEMEMPTY_TUPLESETITEMSBINFLOATI01
TRUEI00
FALSEPROTONEWOBJEXT1EXT2EXT4TUPLE1TUPLE2TUPLE3NEWTRUENEWFALSELONG1LONG4_tuplesize2codeBINBYTESSHORT_BINBYTESSHORT_BINUNICODEBINUNICODE8BINBYTES8EMPTY_SETADDITEMSFROZENSETNEWOBJ_EXSTACK_GLOBALMEMOIZEFRAMEBYTEARRAY8NEXT_BUFFERREADONLY_BUFFER[A-Z][A-Z0-9_]+$_Framer_FRAME_SIZE_MIN_FRAME_SIZE_TARGETfile_writestart_framingend_framingcommit_framewrite_large_bytes_Unframerfile_readfile_readlinefile_tellpickle exhausted before end of frameload_frameframe_sizebeginning of a new frame before end of current frame_getattributesubpathCan't get local attribute {!r} on {!r}Can't get attribute {!r} on {!r}whichmoduleFind the module an object belong to.encode_longEncode a long to a two's complement little-endian binary string.
    Note that 0 is a special case, returning an empty string, to save a
    byte in the LONG1 pickling context.

    >>> encode_long(0)
    b''
    >>> encode_long(255)
    b'\xff\x00'
    >>> encode_long(32767)
    b'\xff\x7f'
    >>> encode_long(-256)
    b'\x00\xff'
    >>> encode_long(-32768)
    b'\x00\x80'
    >>> encode_long(-128)
    b'\x80'
    >>> encode_long(127)
    b'\x7f'
    >>>
    signeddecode_longDecode a long from a two's complement little-endian binary string.

    >>> decode_long(b'')
    0
    >>> decode_long(b"\xff\x00")
    255
    >>> decode_long(b"\xff\x7f")
    32767
    >>> decode_long(b"\x00\xff")
    -256
    >>> decode_long(b"\x00\x80")
    -32768
    >>> decode_long(b"\x80")
    -128
    >>> decode_long(b"\x7f")
    127
    _Picklerfix_importsbuffer_callbackThis takes a binary file for writing a pickle data stream.

        The optional *protocol* argument tells the pickler to use the
        given protocol; supported protocols are 0, 1, 2, 3, 4 and 5.
        The default protocol is 4. It was introduced in Python 3.4, and
        is incompatible with previous versions.

        Specifying a negative protocol version selects the highest
        protocol version supported.  The higher the protocol used, the
        more recent the version of Python needed to read the pickle
        produced.

        The *file* argument must have a write() method that accepts a
        single bytes argument. It can thus be a file object opened for
        binary writing, an io.BytesIO instance, or any other custom
        object that meets this interface.

        If *fix_imports* is True and *protocol* is less than 3, pickle
        will try to map the new Python 3 names to the old module names
        used in Python 2, so that the pickle data stream is readable
        with Python 2.

        If *buffer_callback* is None (the default), buffer views are
        serialized into *file* as part of the pickle stream.

        If *buffer_callback* is not None, then it can be called any number
        of times with a buffer view.  If the callback returns a false value
        (such as None), the given buffer is out-of-band; otherwise the
        buffer is serialized in-band, i.e. inside the pickle stream.

        It is an error if *buffer_callback* is not None and *protocol*
        is None or smaller than 5.
        pickle protocol must be <= %dbuffer_callback needs protocol >= 5_buffer_callback_file_writefile must have a 'write' attributeframer_write_large_bytesClears the pickler's "memo".

        The memo is the data structure that remembers which objects the
        pickler has already seen, so that shared or recursive objects
        are pickled by reference and not by value.  This method is
        useful when re-using picklers.
        Write a pickled representation of obj to the open file.Pickler.__init__() was not called by %s.__init__()"Pickler.__init__() was not called by ""%s.__init__()"<BsavememoizeStore an object in the memo.putsave_persistent_idsave_persreducer_overridesave_globalCan't pickle %r object: %r%s must return string or tupleTuple returned by %s must have two to six elements"Tuple returned by %s must have ""two to six elements"save_reducepersistent IDs in protocol 0 must be ASCII stringslistitemsdictitemsstate_setterargs from save_reduce() must be a tuplefunc from save_reduce() must be callablefunc_nameargs[0] from {} args has no __new__args[0] from {} args has the wrong classargs[0] from __newobj__ args has no __new__args[0] from __newobj__ args has the wrong class_batch_appends_batch_setitemssave_nonesave_boolsave_long0x80000000<iL
save_float>dsave_bytessave_bytearraysave_picklebufferPickleBuffer can only pickled with protocol >= 5"PickleBuffer can only pickled with ""protocol >= 5"PickleBuffer can not be pickled when pointing to a non-contiguous buffer"PickleBuffer can not be pickled when ""pointing to a non-contiguous buffer"in_bandsave_strsurrogatepass\u005c\u0000\u000a\u000d\u001asave_tuplesave_list_BATCHSIZEsave_dictsave_setbatchsave_frozensetobj2Can't pickle %r: it's not the same object as %s.%sCan't pickle %r: it's not found as %s.%slastnamer_name_mappingr_import_mappingcan't pickle global identifier '%s.%s' using pickle protocol %i"can't pickle global identifier '%s.%s' using ""pickle protocol %i"save_type_UnpicklerbuffersThis takes a binary file for reading a pickle data stream.

        The protocol version of the pickle is detected automatically, so
        no proto argument is needed.

        The argument *file* must have two methods, a read() method that
        takes an integer argument, and a readline() method that requires
        no arguments.  Both methods should return bytes.  Thus *file*
        can be a binary file object opened for reading, an io.BytesIO
        object, or any other custom object that meets this interface.

        The file-like object must have two methods, a read() method
        that takes an integer argument, and a readline() method that
        requires no arguments.  Both methods should return bytes.
        Thus file-like object can be a binary file object opened for
        reading, a BytesIO object, or any other custom object that
        meets this interface.

        If *buffers* is not None, it should be an iterable of buffer-enabled
        objects that is consumed each time the pickle stream references
        an out-of-band buffer view.  Such buffers have been given in order
        to the *buffer_callback* of a Pickler object.

        If *buffers* is None (the default), then the buffers are taken
        from the pickle stream, assuming they are serialized there.
        It is an error for *buffers* to be None if the pickle stream
        was produced with a non-None *buffer_callback*.

        Other optional arguments are *fix_imports*, *encoding* and
        *errors*, which are used to control compatibility support for
        pickle stream generated by Python 2.  If *fix_imports* is True,
        pickle will try to map the old Python 2 names to the new names
        used in Python 3.  The *encoding* and *errors* tell pickle how
        to decode 8-bit string instances pickled by Python 2; these
        default to 'ASCII' and 'strict', respectively. *encoding* can be
        'bytes' to read these 8-bit string instances as bytes objects.
        _buffers_file_readline_file_readRead a pickled object representation from the open file.

        Return the reconstituted object hierarchy specified in the file.
        Unpickler.__init__() was not called by %s.__init__()"Unpickler.__init__() was not called by "_unframermetastackstopinstpop_markunsupported persistent id encounteredload_protounsupported pickle protocol: %dframe size > sys.maxsize: %dload_persidload_binpersidload_noneload_falseload_trueload_intload_binintload_binint1load_binint2load_longload_long1load_long4LONG pickle has negative byte countload_floatload_binfloat_decode_stringload_string"'the STRING opcode argument must be quotedload_binstringBINSTRING pickle has negative byte countload_binbytesBINBYTES exceeds system's maximum size of %d bytes"BINBYTES exceeds system's maximum size ""of %d bytes"load_unicodeload_binunicodeBINUNICODE exceeds system's maximum size of %d bytes"BINUNICODE exceeds system's maximum size "load_binunicode8BINUNICODE8 exceeds system's maximum size of %d bytes"BINUNICODE8 exceeds system's maximum size "load_binbytes8BINBYTES8 exceeds system's maximum size of %d bytes"BINBYTES8 exceeds system's maximum size "load_bytearray8BYTEARRAY8 exceeds system's maximum size of %d bytes"BYTEARRAY8 exceeds system's maximum size "load_next_bufferpickle stream refers to out-of-band data but no *buffers* argument was given"pickle stream refers to out-of-band data ""but no *buffers* argument was given"not enough out-of-band buffersload_readonly_bufferload_short_binstringload_short_binbytesload_short_binunicodeload_tupleload_empty_tupleload_tuple1load_tuple2load_tuple3load_empty_listload_empty_dictionaryload_empty_setload_frozensetload_listload_dict_instantiatein constructor for %s: %sload_instload_objload_newobjload_newobj_exload_globalload_stack_globalSTACK_GLOBAL requires strload_ext1get_extensionload_ext2load_ext4EXT specifies code <= 0unregistered extension code %dpickle.find_classload_reduceload_popload_pop_markload_dupload_getMemo value not found at index load_bingetload_long_bingetload_putnegative PUT argumentload_binputnegative BINPUT argumentload_long_binputnegative LONG_BINPUT argumentload_memoizeload_appendload_appendslist_objload_setitemload_setitemsload_additemsset_objload_buildinst_dictload_markload_stopCan't load pickle from unicode stringdisplay contents of the pickle filespickle_filethe pickle filerun self-test suiterun verbosely; only affects self-test run# Shortcut for use in isinstance testing# These are purely informational; no code uses these.# File format version we write# Original protocol 0# Protocol 0 with INST added# Original protocol 1# Protocol 1 with BINFLOAT added# Protocol 2# Protocol 3# Protocol 4# Protocol 5# Old format versions we can read# This is the highest protocol number we know how to read.# The protocol we write by default.  May be less than HIGHEST_PROTOCOL.# Only bump this if the oldest still supported version of Python already# includes it.# An instance of _Stop is raised by Unpickler.load_stop() in response to# the STOP opcode, passing the object that is the result of unpickling.# Pickle opcodes.  See pickletools.py for extensive docs.  The listing# here is in kind-of alphabetical order of 1-character pickle code.# pickletools groups them by purpose.# push special markobject on stack# every pickle ends with STOP# discard topmost stack item# discard stack top through topmost markobject# duplicate top stack item# push float object; decimal string argument# push integer or bool; decimal string argument# push four-byte signed int# push 1-byte unsigned int# push long; decimal string argument# push 2-byte unsigned int# push None# push persistent object; id is taken from string arg#  "       "         "  ;  "  "   "     "  stack# apply callable to argtuple, both on stack# push string; NL-terminated string argument# push string; counted binary string argument#  "     "   ;    "      "       "      " < 256 bytes# push Unicode string; raw-unicode-escaped'd argument#   "     "       "  ; counted UTF-8 string argument# append stack top to list below it# call __setstate__ or __dict__.update()# push self.find_class(modname, name); 2 string args# build a dict from stack items# push empty dict# extend list on stack by topmost stack slice# push item from memo on stack; index is string arg#   "    "    "    "   "   "  ;   "    " 1-byte arg# build & push class instance# push item from memo on stack; index is 4-byte arg# build list from topmost stack items# push empty list# store stack top in memo; index is string arg#   "     "    "   "   " ;   "    " 1-byte arg#   "     "    "   "   " ;   "    " 4-byte arg# add key+value pair to dict# build tuple from topmost stack items# push empty tuple# modify dict by adding topmost key+value pairs# push float; arg is 8-byte float encoding# not an opcode; see INT docs in pickletools.py# identify pickle protocol# build object by applying cls.__new__ to argtuple# push object from extension registry; 1-byte index# ditto, but 2-byte index# ditto, but 4-byte index# build 1-tuple from stack top# build 2-tuple from two topmost stack items# build 3-tuple from three topmost stack items# push True# push False# push long from < 256 bytes# push really big long# Protocol 3 (Python 3.x)# push bytes; counted binary string argument# push short string; UTF-8 length < 256 bytes# push very long string# push very long bytes string# push empty set on the stack# modify set by adding topmost stack items# build frozenset from topmost stack items# like NEWOBJ but work with keyword only arguments# same as GLOBAL but using names on the stacks# store top of the stack in memo# indicate the beginning of a new frame# push bytearray# push next out-of-band buffer# make top of stack readonly# Issue a single call to the write method of the underlying# file object for the frame opcode with the size of the# frame. The concatenation is expected to be less expensive# than issuing an additional call to write.# Issue a separate call to write to append the frame# contents without concatenation to the above to avoid a# memory copy.# Start the new frame with a new io.BytesIO instance so that# the file object can have delayed access to the previous frame# contents via an unreleased memoryview of the previous# io.BytesIO instance.# Terminate the current frame and flush it to the file.# Perform direct write of the header and payload of the large binary# object. Be careful not to concatenate the header and the payload# prior to calling 'write' as we do not want to allocate a large# temporary bytes object.# We intentionally do not insert a protocol 4 frame opcode to make# it possible to optimize file.read calls in the loader.# Tools used for pickling.# Protect the iteration by using a list copy of sys.modules against dynamic# modules that trigger imports of other modules upon calls to getattr.# bpo-42406# Pickling machinery# Check whether Pickler was initialized correctly. This is# only needed to mimic the behavior of _pickle.Pickler.dump().# The Pickler memo is a dictionary mapping object ids to 2-tuples# that contain the Unpickler memo key and the object being memoized.# The memo key is written to the pickle and will become# the key in the Unpickler's memo.  The object is stored in the# Pickler memo so that transient objects are kept alive during# pickling.# The use of the Unpickler memo length as the memo key is just a# convention.  The only requirement is that the memo values be unique.# But there appears no advantage to any other scheme, and this# scheme allows the Unpickler memo to be implemented as a plain (but# growable) array, indexed by memo key.# Return a PUT (BINPUT, LONG_BINPUT) opcode string, with argument i.# Return a GET (BINGET, LONG_BINGET) opcode string, with argument i.# Check for persistent id (defined by a subclass)# Check the memo# Check the type dispatch table# Call unbound method with explicit self# Check private dispatch table if any, or else# copyreg.dispatch_table# Check for a class with a custom metaclass; treat as regular# Check for a __reduce_ex__ method, fall back to __reduce__# Check for string returned by reduce(), meaning "save as global"# Assert that reduce() returned a tuple# Assert that it returned an appropriately sized tuple# Save the reduce() output and finally memoize the object# This exists so a subclass can override it# Save a persistent id reference# This API is called by some subclasses# A __reduce__ implementation can direct protocol 2 or newer to# use the more efficient NEWOBJ opcode, while still# allowing protocol 0 and 1 to work normally.  For this to# work, the function returned by __reduce__ should be# called __newobj__, and its first argument should be a# class.  The implementation for __newobj__# should be as follows, although pickle has no way to# verify this:# def __newobj__(cls, *args):#     return cls.__new__(cls, *args)# Protocols 0 and 1 will pickle a reference to __newobj__,# while protocol 2 (and above) will pickle a reference to# cls, the remaining args tuple, and the NEWOBJ code,# which calls cls.__new__(cls, *args) at unpickling time# (see load_newobj below).  If __reduce__ returns a# three-tuple, the state from the third tuple item will be# pickled regardless of the protocol, calling __setstate__# at unpickling time (see load_build below).# Note that no standard __newobj__ implementation exists;# you have to provide your own.  This is to enforce# compatibility with Python 2.2 (pickles written using# protocol 0 or 1 in Python 2.3 should be unpicklable by# Python 2.2).# If the object is already in the memo, this means it is# recursive. In this case, throw away everything we put on the# stack, and fetch the object back from the memo.# More new special cases (that work with older protocols as# well): when __reduce__ returns a tuple with 4 or 5 items,# the 4th and 5th item should be iterators that provide list# items and dict items (as (key, value) tuples), or None.# If a state_setter is specified, call it instead of load_build# to update obj's with its previous state.# First, push state_setter and its tuple of expected arguments# (obj, state) onto the stack.# simple BINGET opcode as obj is already memoized.# Trigger a state_setter(obj, state) function call.# The purpose of state_setter is to carry-out an# inplace modification of obj. We do not care about what the# method might return, so its output is eventually removed from# the stack.# Methods below this point are dispatched through the dispatch table# If the int is small enough to fit in a signed 4-byte 2's-comp# format, we can store it more efficiently than the general# case.# First one- and two-byte unsigned ints:# Next check for 4-byte signed ints:# bytes object is empty# bytearray is empty# Write data in-band# XXX The C implementation avoids a copy here# Write data out-of-band# Escape what raw-unicode-escape doesn't, but memoize the original.# EOF on DOS# tuple is empty# Subtle.  Same as in the big comment below.# proto 0 or proto 1 and tuple isn't empty, or proto > 1 and tuple# has more than 3 elements.# Subtle.  d was not in memo when we entered save_tuple(), so# the process of saving the tuple's elements must have saved# the tuple itself:  the tuple is recursive.  The proper action# now is to throw away everything we put on the stack, and# simply GET the tuple (it's already constructed).  This check# could have been done in the "for element" loop instead, but# recursive tuples are a rare thing.# proto 0 -- POP_MARK not available# No recursion.# proto 0 -- can't use EMPTY_LIST# Helper to batch up APPENDS sequences# else tmp is empty, and we're done# proto 0 -- can't use EMPTY_DICT# Helper to batch up SETITEMS sequences; proto >= 1 only# Non-ASCII identifiers are supported only with protocols >= 3.# Unpickling machinery# Check whether Unpickler was initialized correctly. This is# only needed to mimic the behavior of _pickle.Unpickler.dump().# Return a list of items pushed in the stack after last MARK instruction.# Corrupt or hostile pickle -- we never write one like this# Used to allow strings from Python 2 to be decoded either as# bytes or Unicode strings.  This should be used only with the# STRING, BINSTRING and SHORT_BINSTRING opcodes.# Strip outermost quotes# Deprecated BINSTRING uses signed 32-bit length# INST and OBJ differ only in how they get a class object.  It's not# only sensible to do the rest in a common routine, the two routines# previously diverged and grew different bugs.# klass is the class to instantiate, and k points to the topmost mark# object, following which are the arguments for klass.__init__.# Stack is ... markobject classobject arg1 arg2 ...# note that 0 is forbidden# Corrupt or hostile pickle.# Subclasses may override this.# Even if the PEP 307 requires extend() and append() methods,# fall back on append() if the object has no extend() method# for backward compatibility.# Shorthands# Use the faster _pickle if possible# Doctestb'Create portable serialized representations of Python objects.

See module copyreg for a mechanism for registering custom picklers.
See module pickletools source for extensive comments.

Classes:

    Pickler
    Unpickler

Functions:

    dump(object, file)
    dumps(object) -> string
    load(file) -> object
    loads(bytes) -> object

Misc variables:

    __version__
    format_version
    compatible_formats

'u'Create portable serialized representations of Python objects.

See module copyreg for a mechanism for registering custom picklers.
See module pickletools source for extensive comments.

Classes:

    Pickler
    Unpickler

Functions:

    dump(object, file)
    dumps(object) -> string
    load(file) -> object
    loads(bytes) -> object

Misc variables:

    __version__
    format_version
    compatible_formats

'b'PickleError'u'PickleError'b'PicklingError'u'PicklingError'b'UnpicklingError'u'UnpicklingError'b'Pickler'u'Pickler'b'Unpickler'u'Unpickler'b'dump'u'dump'b'dumps'u'dumps'b'load'u'load'b'loads'u'loads'b'PickleBuffer'u'PickleBuffer'b'4.0'u'4.0'b'1.2'u'1.2'b'1.3'u'1.3'b'2.0'u'2.0'b'3.0'u'3.0'b'5.0'u'5.0'b'A common base class for the other pickling exceptions.'u'A common base class for the other pickling exceptions.'b'This exception is raised when an unpicklable object is passed to the
    dump() method.

    'u'This exception is raised when an unpicklable object is passed to the
    dump() method.

    'b'This exception is raised when there is a problem unpickling an object,
    such as a security violation.

    Note that other exceptions may also be raised during unpickling, including
    (but not necessarily limited to) AttributeError, EOFError, ImportError,
    and IndexError.

    'u'This exception is raised when there is a problem unpickling an object,
    such as a security violation.

    Note that other exceptions may also be raised during unpickling, including
    (but not necessarily limited to) AttributeError, EOFError, ImportError,
    and IndexError.

    'b'J'b'K'b'R'b'V'b'd'b'j'b'l'b'o'b'I01
'b'I00
'b''b''b''b''b''b''b''b''b''b''b''b''b''b''b''b''b''b''b''b''b''b'[A-Z][A-Z0-9_]+$'u'[A-Z][A-Z0-9_]+$'b'pickle exhausted before end of frame'u'pickle exhausted before end of frame'b'beginning of a new frame before end of current frame'u'beginning of a new frame before end of current frame'b'Can't get local attribute {!r} on {!r}'u'Can't get local attribute {!r} on {!r}'b'Can't get attribute {!r} on {!r}'u'Can't get attribute {!r} on {!r}'b'Find the module an object belong to.'u'Find the module an object belong to.'b'Encode a long to a two's complement little-endian binary string.
    Note that 0 is a special case, returning an empty string, to save a
    byte in the LONG1 pickling context.

    >>> encode_long(0)
    b''
    >>> encode_long(255)
    b'\xff\x00'
    >>> encode_long(32767)
    b'\xff\x7f'
    >>> encode_long(-256)
    b'\x00\xff'
    >>> encode_long(-32768)
    b'\x00\x80'
    >>> encode_long(-128)
    b'\x80'
    >>> encode_long(127)
    b'\x7f'
    >>>
    'u'Encode a long to a two's complement little-endian binary string.
    Note that 0 is a special case, returning an empty string, to save a
    byte in the LONG1 pickling context.

    >>> encode_long(0)
    b''
    >>> encode_long(255)
    b'\xff\x00'
    >>> encode_long(32767)
    b'\xff\x7f'
    >>> encode_long(-256)
    b'\x00\xff'
    >>> encode_long(-32768)
    b'\x00\x80'
    >>> encode_long(-128)
    b'\x80'
    >>> encode_long(127)
    b'\x7f'
    >>>
    'b'Decode a long from a two's complement little-endian binary string.

    >>> decode_long(b'')
    0
    >>> decode_long(b"\xff\x00")
    255
    >>> decode_long(b"\xff\x7f")
    32767
    >>> decode_long(b"\x0. q  ,    